<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-11-06T05:21:42Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1525</id>
    <link href="https://theorydish.blog/2019/11/05/next-week-toca-sv-motwani-colloquium/" rel="alternate" type="text/html"/>
    <title>Next week: TOCA-SV + Motwani Colloquium</title>
    <summary>Our first TOCA-SV meeting of the academic year is coming up next Friday, in Tressider Oak Lounge, Stanford. Like last year, it will host the Motwani Colloquium. We have reserved some parking (see instructions below) on a first come first serve basis (so come early). Also see the schedule and abstract below. Parking There are 35 reserved spaces in Tresidder Lot (L-39) on November 15, 2019. Our  space numbers will be 14-48; see map for location. Posted signs to read Reserved for TOCA-SV CS Workshop. To avoid a citation, vehicle information is required to obtain permission to park in the designated reserved area. Use: https://stanford.nupark.com/v2/portal/eventregister/5201e8f7-9339-4acf-8416-62f137dbc523 See instructions. *Internet browser Chrome or Firefox are recommended and most compatible with the system.   Schedule: 10:30-11:10 Hanie Sedghi, Google AI, Size-free generalization bounds for convolutional neural networks 11:10-11:50 Dean Doron, Stanford University, Nearly Optimal Pseudorandomness from Hardness 11:50-12:30 Barna Saha, UC Berkeley, Algorithms for Fast Sequence Comparison 12:30-1:30 lunch 1:30-3:30 Student’s poster session 3:30-4:15 break 4:15-5:30 Motwani Colloquium, Ronitt Rubinfeld, MIT and Tel Aviv University,Local Computation Algorithms Abstracts Hanie Sedghi, Google AI Size-free generalization bounds for convolutional neural networks We prove bounds on the generalization error of convolutional networks. The bounds are characterized in terms of the training loss, the number of parameters, the Lipschitz constant of [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Our first TOCA-SV meeting of the academic year is coming up next Friday, in Tressider Oak Lounge, Stanford. Like last year, it will host the Motwani Colloquium. We have reserved some parking (see instructions below) on a first come first serve basis (so come early). Also see the schedule and abstract below.</p>
<div>
<p><strong>Parking</strong></p>
<p style="font-weight: 400;">There are <strong>35</strong> reserved spaces in <strong>Tresidder Lot (L-39)</strong> on <strong>November 15, 2019. Our </strong> space numbers will be <strong>14-48</strong>; see <a href="https://theorydish.files.wordpress.com/2019/11/tresidder-lot-l-39.pdf">map </a>for location. Posted signs to read <strong>Reserved for </strong><strong>TOCA-SV CS Workshop</strong><strong>.</strong></p>
<p style="font-weight: 400;"><strong>To avoid a citation, vehicle information is required to obtain permission to park in the designated reserved area. Use: </strong><a href="https://stanford.nupark.com/v2/portal/eventregister/5201e8f7-9339-4acf-8416-62f137dbc523">https://stanford.nupark.com/v2/portal/eventregister/5201e8f7-9339-4acf-8416-62f137dbc523</a> See <a href="https://theorydish.files.wordpress.com/2019/11/instructions-on-how-to-register-vehicles.pdf">instructions</a>.</p>
<p style="font-weight: 400;"><em>*Internet browser Chrome or Firefox are recommended and most compatible with the system.</em></p>
<p> </p>
</div>
<div><strong>Schedule</strong>:</div>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im"><span class="im"><span class="im">10:30-11:10 <a class="Oux49">Hanie Sedghi, Google AI, </a></span></span></span><em><span>Size-free generalization bounds for convolutional neural networks</span></em></div>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im">11:10-11:50 Dean Doron, Stanford University, <em>Nearly Optimal Pseudorandomness from Hardness</em></span></div>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im">11:50-12:30 Barna Saha, UC Berkeley, <em>Algorithms for Fast Sequence Comparison</em></span></div>
<div class="sharedaddy sd-sharing-enabled">
<div>
<div/>
<div>12:30-1:30 lunch</div>
<div/>
<div>1:30-3:30 Student’s poster session</div>
<div class="yj6qo ajU">
<div/>
<div class="ajR" id=":m2v"><span>3:30-4:15 break</span></div>
</div>
<div class="adL">
<div/>
<div>
<p>4:15-5:30 Motwani Colloquium, <span><span>Ronitt Rubinfeld, </span></span><span><span>MIT and Tel Aviv University,</span></span><em>Local Computation Algorithms</em></p>
</div>
</div>
</div>
<div/>
<div><strong>Abstracts</strong></div>
</div>
<div/>
<ul>
<li>Hanie Sedghi, Google AI<span class="im"><a class="Oux49"><br/>
</a></span></li>
</ul>
<div/>
<div><em><span>Size-free generalization bounds for convolutional neural networks</span></em></div>
<div/>
<div>We prove bounds on the generalization error of convolutional networks. The bounds are characterized in terms of the training loss, the number of parameters, the Lipschitz constant of the loss, and the distance of the initial and final weights. The bounds are independent of the number of pixels in the input, as well as the width and height of hidden feature maps. These are the first bounds for DNNs with such guarantees.  We present experiments with CIFAR-10, varying hyperparameters of a deep convolutional network, comparing our bounds with practical generalization gaps.</div>
<div/>
<ul>
<li><span class="im">Dean Doron, Stanford University, </span></li>
</ul>
<div/>
<div><span class="im"><em>Nearly Optimal Pseudorandomness from Hardness</em></span></div>
<div/>
<div>
<p>Existing techniques for derandomizing algorithms based on circuit lower bounds yield a large polynomial slowdown in running time. We show that assuming exponential lower bounds against nondeterministic circuits, we can convert any randomized algorithm running in time T to a deterministic one running in time nearly T^2. Under complexity-theoretic assumptions, such a slowdown is nearly optimal.</p>
<p>In this talk I will concentrate on the role of error-correcting codes in those techniques. We will see which properties of error-correcting codes are useful for constructing pseudorandomness primitives sufficient for derandomization, where they came short of achieving better slowdown, and how we can overcome that.</p>
<p>Based on joint work with Dana Moshkovitz, Justin Oh and David Zuckerman</p>
</div>
<div/>
<ul>
<li class="sharedaddy sd-sharing-enabled"><span class="im">Barna Saha, UC Berkeley, </span></li>
</ul>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im"><em>Algorithms for Fast Sequence Comparison</em></span></div>
<div/>
<div/>
<div class="sharedaddy sd-sharing-enabled">
<div>
<div>
<div> There are many basic problems over sequences. For example, computing the edit distance between two sequences, detecting how RNA sequences fold, finding the distance between a sequence and a language (collection of sequences), understanding how disbalanced a parenthesis sequence is. They have natural applications in various areas including computational biology, natural language processing, compiler optimization, and data cleaning. The last few years have seen a plethora of results where new faster algorithms have been developed for these problems with various trade-offs between approximation (quality of solution) and running time (scalability). In this talk, I will present some of the tools that have been developed from my work related to these problems. Depending on time and audience choices, we will cover one or more of the following.</div>
<div/>
<div>(i) A random walk based technique useful to measure how disbalanced a parenthesis sequence is, which has also been useful for streaming computation of edit distance.</div>
<div/>
<div>(ii) A dependent rounding technique that gives nearly optimal result in nearly optimal time for estimating distance between a sequence and a language, which can also be used to speed up other polynomial time problems, such as the all pairs shortest path computation on graphs.</div>
<div/>
<div>(iii) An amnesic dynamic programming technique that gives significantly faster approximation algorithm for RNA-folding, which can also be useful for many dynamic programming based problems that have Lipschitz property (most sequence problems have it).</div>
<div/>
<div>(iv) An elimination of shortest path technique that gives sublinear time algorithms for estimating edit distance for certain regimes of edit distance.</div>
<div/>
<div>The audience is encouraged to pick their favorite and convey that to the speaker at or before (by email) the talk.</div>
</div>
</div>
</div>
<div/>
<div class="sharedaddy sd-sharing-enabled">
<div>
<ul>
<li><span>Ronitt Rubinfeld, </span><span>MIT and Tel Aviv University,</span></li>
</ul>
<div>
<p><em>Local Computation Algorithms</em></p>
<p>Consider a setting in which inputs to and outputs from a computational problem are so large, that there is not time to read them in their entirety.   However, if one is only interested in small parts of the output at any given time, is it really necessary to solve the entire computational problem? Is it even necessary to view the whole input? We survey recent work in the model of  “local computation algorithms” which for a given input, supports queries by a user to values of specified bits of a legal output.  The goal is to design local computation algorithms in such a way that very little of the input needs to be seen in order to determine the value of any single bit of the output. Though this model describes sequential computations, techniques from local distributed algorithms have been extremely important in designing efficient local computation algorithms. In this talk, we describe results on a variety of problems for which sublinear time and space local computation algorithms have been developed — we will give special focus to finding maximal independent sets and sparse spanning graphs.</p>
</div>
</div>
</div>
<p> </p>
<p style="font-weight: 400;"/></div>
    </content>
    <updated>2019-11-06T02:20:06Z</updated>
    <published>2019-11-06T02:20:06Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-11-06T05:21:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01973</id>
    <link href="http://arxiv.org/abs/1911.01973" rel="alternate" type="text/html"/>
    <title>On the Quantum Complexity of Closest Pair and Related Problems</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aaronson:Scott.html">Scott Aaronson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chia:Nai=Hui.html">Nai-Hui Chia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Han=Hsuan.html">Han-Hsuan Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chunhao.html">Chunhao Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Ruizhe.html">Ruizhe Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01973">PDF</a><br/><b>Abstract: </b>The closest pair problem is a fundamental problem of computational geometry:
given a set of $n$ points in a $d$-dimensional space, find a pair with the
smallest distance. A classical algorithm taught in introductory courses solves
this problem in $O(n\log n)$ time in constant dimensions (i.e., when $d=O(1)$).
This paper asks and answers the question of the problem's quantum time
complexity. Specifically, we give an $\widetilde{O}(n^{2/3})$ algorithm in
constant dimensions, which is optimal up to a polylogarithmic factor by the
lower bound on the quantum query complexity of element distinctness. The key to
our algorithm is an efficient history-independent data structure that supports
quantum interference.
</p>
<p>In $\mathrm{polylog}(n)$ dimensions, no known quantum algorithms perform
better than brute force search, with a quadratic speedup provided by Grover's
algorithm. To give evidence that the quadratic speedup is nearly optimal, we
initiate the study of quantum fine-grained complexity and introduce the Quantum
Strong Exponential Time Hypothesis (QSETH), which is based on the assumption
that Grover's algorithm is optimal for CNF-SAT when the clause width is large.
We show that the na\"{i}ve Grover approach to closest pair in higher dimensions
is optimal up to an $n^{o(1)}$ factor unless QSETH is false. We also study the
bichromatic closest pair problem and the orthogonal vectors problem, with
broadly similar results.
</p></div>
    </summary>
    <updated>2019-11-06T02:20:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01960</id>
    <link href="http://arxiv.org/abs/1911.01960" rel="alternate" type="text/html"/>
    <title>Local Statistics, Semidefinite Programming, and Community Detection</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banks:Jess.html">Jess Banks</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Sidhanth.html">Sidhanth Mohanty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raghavendra:Prasad.html">Prasad Raghavendra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01960">PDF</a><br/><b>Abstract: </b>We propose a new hierarchy of semidefinite programming relaxations for
inference problems, inspired by recent ideas of `pseudocalibration' in the
Sum-of-Squares literature. As a test case, we consider the problem of community
detection in a distribution of random regular graphs we'll call the Degree
Regular Block Model, wherein the vertices are partitioned into $k$ communities,
and a graph is sampled conditional on a prescribed number of inter- and
intra-community edges. The problem of \emph{detection}, where we are to decide
with high probability whether a graph was drawn from this model or the uniform
distribution on regular graphs, is conjectured to undergo a computational phase
transition at a point called the Kesten-Stigum (KS) threshold, and we show (i)
that sufficiently high constant levels of our hierarchy can perform detection
arbitrarily close to this point, (ii) that our algorithm is robust to $o(n)$
adversarial edge perturbations, and (iii) that below Kesten-Stigum no level
constant level can do so.
</p>
<p>In the more-studied case of the (irregular) Stochastic Block Model, it is
known that efficient algorithms exist all the way down to this threshold,
although none are robust to adversarial perturbations of the graph when the
average degree is small. More importantly, there is little complexity-theoretic
evidence that detection is hard below Kesten-Stigum. In the DRBM with more than
two groups, it has not to our knowledge been proven that any algorithm succeeds
down to the KS threshold, let alone that one can do so robustly, and there is a
similar dearth of evidence for hardness below this point.
</p>
<p>Our SDP hierarchy is highly general and applicable to a wide range of
hypothesis testing problems.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01956</id>
    <link href="http://arxiv.org/abs/1911.01956" rel="alternate" type="text/html"/>
    <title>Parallel Approximate Undirected Shortest Paths Via Low Hop Emulators</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Andoni:Alexandr.html">Alexandr Andoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stein:Clifford.html">Clifford Stein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Peilin.html">Peilin Zhong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01956">PDF</a><br/><b>Abstract: </b>We present a $(1+\varepsilon)$-approximate parallel algorithm for computing
shortest paths in undirected graphs, achieving $\mathrm{poly}(\log n)$ depth
and $m\mathrm{poly}(\log n)$ work for $n$-nodes $m$-edges graphs. Although
sequential algorithms with (nearly) optimal running time have been known for
several decades, near-optimal parallel algorithms have turned out to be a much
tougher challenge. For $(1+\varepsilon)$-approximation, all prior algorithms
with $\mathrm{poly}(\log n)$ depth perform at least $\Omega(mn^{c})$ work for
some constant $c&gt;0$. Improving this long-standing upper bound obtained by Cohen
(STOC'94) has been open for $25$ years.
</p>
<p>We develop several new tools of independent interest. One of them is a new
notion beyond hopsets --- low hop emulator --- a $\mathrm{poly}(\log
n)$-approximate emulator graph in which every shortest path has at most
$O(\log\log n)$ hops (edges). Direct applications of the low hop emulators are
parallel algorithms for $\mathrm{poly}(\log n)$-approximate single source
shortest path (SSSP), Bourgain's embedding, metric tree embedding, and low
diameter decomposition, all with $\mathrm{poly}(\log n)$ depth and
$m\mathrm{poly}(\log n)$ work.
</p>
<p>To boost the approximation ratio to $(1+\varepsilon)$, we introduce
compressible preconditioners and apply it inside Sherman's framework (SODA'17)
to solve the more general problem of uncapacitated minimum cost flow (a.k.a.,
transshipment problem). Our algorithm computes a $(1+\varepsilon)$-approximate
uncapacitated minimum cost flow in $\mathrm{poly}(\log n)$ depth using
$m\mathrm{poly}(\log n)$ work. As a consequence, it also improves the
state-of-the-art sequential running time from $m\cdot 2^{O(\sqrt{\log n})}$ to
$m\mathrm{poly}(\log n)$.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01951</id>
    <link href="http://arxiv.org/abs/1911.01951" rel="alternate" type="text/html"/>
    <title>The Bron-Kerbosch Algorithm with Vertex Ordering is Output-Sensitive</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manoussakis:George.html">George Manoussakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01951">PDF</a><br/><b>Abstract: </b>The Bron-Kerbosch algorithm is a well known maximal clique enumeration
algorithm. So far it was unknown whether it was output sensitive or not. In
this paper we partially answer this question by proving that the Bron-Kerbosch
Algorithm with vertex ordering, first introduced and studied by Eppstein,
L\"offler and Strash in "Listing all maximal cliques in sparse graphs in
near-optimal time. International Symposium on Algorithms and Computation.
Springer, Berlin, Heidelberg, 2010" is output sensitive.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01931</id>
    <link href="http://arxiv.org/abs/1911.01931" rel="alternate" type="text/html"/>
    <title>Online matrix factorization for Markovian data and applications to Network Dictionary Learning</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lyu:Hanbaek.html">Hanbaek Lyu</a>, Deana Needell, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balzano:Laura.html">Laura Balzano</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01931">PDF</a><br/><b>Abstract: </b>Online Matrix Factorization (OMF) is a fundamental tool for dictionary
learning problems, giving an approximate representation of complex data sets in
terms of a reduced number of extracted features. Convergence guarantees for
most of the OMF algorithms in the literature assume independence between data
matrices, and the case of a dependent data stream remains largely unexplored.
In this paper, we show that the well-known OMF algorithm for i.i.d. stream of
data proposed in \cite{mairal2010online}, in fact converges almost surely to
the set of critical points of the expected loss function, even when the data
matrices form a Markov chain satisfying a mild mixing condition. Furthermore,
we extend the convergence result to the case when we can only approximately
solve each step of the optimization problems in the algorithm. For
applications, we demonstrate dictionary learning from a sequence of images
generated by a Markov Chain Monte Carlo (MCMC) sampler. Lastly, by combining
online non-negative matrix factorization and a recent MCMC algorithm for
sampling motifs from networks, we propose a novel framework of Network
Dictionary Learning, which extracts `network dictionary patches' from a given
network in an online manner that encodes main features of the network. We
demonstrate this technique on real-world text data.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01839</id>
    <link href="http://arxiv.org/abs/1911.01839" rel="alternate" type="text/html"/>
    <title>Fully Dynamic Matching: Beating 2-Approximation in $\Delta^\epsilon$ Update Time</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behnezhad:Soheil.html">Soheil Behnezhad</a>, Jakub Łącki, Vahab Mirrokni <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01839">PDF</a><br/><b>Abstract: </b>In fully dynamic graphs, we know how to maintain a 2-approximation of maximum
matching extremely fast, that is, in polylogarithmic update time or better. In
a sharp contrast and despite extensive studies, all known algorithms that
maintain a $2-\Omega(1)$ approximate matching are much slower. Understanding
this gap and, in particular, determining the best possible update time for
algorithms providing a better-than-2 approximate matching is a major open
question.
</p>
<p>In this paper, we show that for any constant $\epsilon &gt; 0$, there is a
randomized algorithm that with high probability maintains a $2-\Omega(1)$
approximate maximum matching of a fully-dynamic general graph in worst-case
update time $O(\Delta^{\epsilon}+\text{polylog } n)$, where $\Delta$ is the
maximum degree.
</p>
<p>Previously, the fastest fully dynamic matching algorithm providing a
better-than-2 approximation had $O(m^{1/4})$ update-time [Bernstein and Stein,
SODA 2016]. A faster algorithm with update-time $O(n^\epsilon)$ was known, but
worked only for maintaining the size (and not the edges) of the matching in
bipartite graphs [Bhattacharya, Henzinger, and Nanongkai, STOC 2016].
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01763</id>
    <link href="http://arxiv.org/abs/1911.01763" rel="alternate" type="text/html"/>
    <title>An Efficient Word Lookup System by using Improved Trie Algorithm</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Rahat Yeasin Emon, Sharmistha Chanda Tista <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01763">PDF</a><br/><b>Abstract: </b>Efficiently word storing and searching is an important task in computer
science. An application space complexity, time complexity, and overall
performance depend on this string data. Many word searching data structures and
algorithms exist in the current world but few of them have space compress
ability. Trie is a popular data structure for word searching for its linear
searching capability. It is the basic and important part of various computer
applications such as information retrieval, natural language processing,
database system, compiler, and computer network. But currently, the available
version of trie tree cannot be used widely because of its high memory
requirement. This paper proposes a new Radix trie based data structure for word
storing and searching which can share not only just prefix but also infix and
suffix and thus reduces memory requirement. We propose a new emptiness property
to Radix trie. Proposed trie has character cell reduction capability and it can
dramatically reduce any application runtime memory size. Using it as data tank
to an operating system the overall main memory requirement of a device can be
reduced to a large extent.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01761</id>
    <link href="http://arxiv.org/abs/1911.01761" rel="alternate" type="text/html"/>
    <title>Packing Trees into 1-planar Graphs</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luca:Felice_De.html">Felice De Luca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giacomo:Emilio_Di.html">Emilio Di Giacomo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hong:Seok=Hee.html">Seok-Hee Hong</a>, Stephen Kobourov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lenhart:William.html">William Lenhart</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liotta:Giuseppe.html">Giuseppe Liotta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meijer:Henk.html">Henk Meijer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tappini:Alessandra.html">Alessandra Tappini</a>, Stephen Wismath <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01761">PDF</a><br/><b>Abstract: </b>We introduce and study the 1-planar packing problem: Given $k$ graphs with
$n$ vertices $G_1, \dots, G_k$, find a 1-planar graph that contains the given
graphs as edge-disjoint spanning subgraphs. We mainly focus on the case when
each $G_i$ is a tree and $k=3$. We prove that a triple consisting of three
caterpillars or of two caterpillars and a path may not admit a 1-planar
packing, while two paths and a special type of caterpillar always have one. We
then study 1-planar packings with few crossings and prove that three paths
(resp. cycles) admit a 1-planar packing with at most seven (resp. fourteen)
crossings. We finally show that a quadruple consisting of three paths and a
perfect matching with $n \geq 12$ vertices admits a 1-planar packing, while
such a packing does not exist if $n \leq 10$.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01663</id>
    <link href="http://arxiv.org/abs/1911.01663" rel="alternate" type="text/html"/>
    <title>A Heuristic Algorithm Based on Tour Rebuilding Operator for the Traveling Salesman Problem</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yang.html">Yang Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Junbin.html">Junbin Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bai:Mingyuan.html">Mingyuan Bai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Chengjun.html">Chengjun Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Gang.html">Gang Liu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01663">PDF</a><br/><b>Abstract: </b>TSP (Traveling Salesman Problem), a classic NP-complete problem in
combinatorial optimization, is of great significance in multiple fields. Exact
algorithms for TSP are not practical due to their exponential time cost. Thus,
approximate algorithms become the research focus and can be further divided
into two types, tour construction algorithms and tour improvement algorithms.
Researches show that the latter type of algorithms can obtain better solutions
than the former one. However, traditional tour improvement algorithms have
shortcomings. They converge very slowly and tend to be trapped in local optima.
In practice, tour construction algorithms are often used in initialization of
tour improvement algorithms to speed up convergence. Nevertheless, such a
combination leads to no improvement on quality of solutions. In this paper, a
heuristic algorithm based on the new tour rebuilding operator is proposed. The
algorithm features rapid convergence and powerful global search. In the
experiments based on 40 instances in TSPLIB, the best known solutions of 22
instances are refreshed by the proposed method. Meanwhile, the best known
solutions of the other 18 instances are obtained.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01662</id>
    <link href="http://arxiv.org/abs/1911.01662" rel="alternate" type="text/html"/>
    <title>Discrete logarithm and Diffie-Hellman problems in identity black-box groups</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gabor Ivanyos, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Joux:Antoine.html">Antoine Joux</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santha:Miklos.html">Miklos Santha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01662">PDF</a><br/><b>Abstract: </b>We investigate the computational complexity of the discrete logarithm, the
computational Diffie-Hellman and the decisional Diffie-Hellman problems in some
identity black-box groups G_{p,t}, where p is a prime number and t is a
positive integer. These are defined as quotient groups of vector space
Z_p^{t+1} by a hyperplane H given through an identity oracle. While in general
black-box groups with unique encoding these computational problems are
classically all hard and quantumly all easy, we find that in the groups G_{p,t}
the situation is more contrasted. We prove that while there is a polynomial
time probabilistic algorithm to solve the decisional Diffie-Hellman problem in
$G_{p,1}$, the probabilistic query complexity of all the other problems is
Omega(p), and their quantum query complexity is Omega(sqrt(p)). Our results
therefore provide a new example of a group where the computational and the
decisional Diffie-Hellman problems have widely different complexity.
</p></div>
    </summary>
    <updated>2019-11-06T02:22:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01651</id>
    <link href="http://arxiv.org/abs/1911.01651" rel="alternate" type="text/html"/>
    <title>Weighted Min-Cut: Sequential, Cut-Query and Streaming Algorithms</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Sagnik.html">Sagnik Mukhopadhyay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nanongkai:Danupon.html">Danupon Nanongkai</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01651">PDF</a><br/><b>Abstract: </b>Consider the following {\em 2-respecting min-cut} problem. Given a weighted
graph $G$ and its spanning tree $T$, find the minimum cut among the cuts that
contain at most two edges in $T$. This problem is an important subroutine in
Karger's celebrated randomized near-linear-time min-cut algorithm [STOC'96]. We
present a new approach for this problem which can be easily implemented in many
settings, leading to the following randomized min-cut algorithms for weighted
graphs.
</p>
<p>* An $O(m \log^2 n+n\log^5 n)$-time sequential algorithm: This improves
Karger's long-standing $O(m \log^3 n)$ bound when the input graph is not
extremely sparse. Improvements over Karger's bounds were previously known only
under a rather strong assumption that the input graph is {\em simple}
(unweighted without parallel edges) [Henzinger, Rao, Wang, SODA'17; Ghaffari,
Nowicki, Thorup, SODA'20].
</p>
<p>* An algorithm that requires $\tilde O(n)$ {\em cut queries} to compute the
min-cut of a weighted graph: This answers an open problem by Rubinstein,
Schramm, and Weinberg [ITCS'18], who obtained a similar bound for simple
graphs. Our bound is tight up to polylogarithmic factors.
</p>
<p>* A {\em streaming} algorithm that requires $\tilde O(n)$ space and $O(\log
n)$ passes to compute the min-cut: The only previous non-trivial exact min-cut
algorithm in this setting is the 2-pass $\tilde O(n)$-space algorithm on simple
graphs [Rubinstein~et~al., ITCS'18] (observed by Assadi, Chen, and Khanna
[STOC'19]).
</p>
<p>In contrast to Karger's 2-respecting min-cut algorithm which deploys
sophisticated dynamic programming techniques, our approach exploits some cute
structural properties so that it only needs to compute the values of $\tilde
O(n)$ cuts corresponding to removing $\tilde O(n)$ pairs of tree edges, an
operation that can be done quickly in many settings.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01644</id>
    <link href="http://arxiv.org/abs/1911.01644" rel="alternate" type="text/html"/>
    <title>Fast Multiple Pattern Cartesian Tree Matching</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Geonmo.html">Geonmo Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Siwoo.html">Siwoo Song</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Faro:Simone.html">Simone Faro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lecroq:Thierry.html">Thierry Lecroq</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Park:Kunsoo.html">Kunsoo Park</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01644">PDF</a><br/><b>Abstract: </b>Cartesian tree matching is the problem of finding all substrings in a given
text which have the same Cartesian trees as that of a given pattern. In this
paper, we deal with Cartesian tree matching for the case of multiple patterns.
We present two fingerprinting methods, i.e., the parent-distance encoding and
the binary encoding. By combining an efficient fingerprinting method and a
conventional multiple string matching algorithm, we can efficiently solve
multiple pattern Cartesian tree matching. We propose three practical algorithms
for multiple pattern Cartesian tree matching based on the Wu-Manber algorithm,
the Rabin-Karp algorithm, and the Alpha Skip Search algorithm, respectively. In
the experiments we compare our solutions against the previous algorithm [18].
Our solutions run faster than the previous algorithm as the pattern lengths
increase. Especially, our algorithm based on Wu-Manber runs up to 33 times
faster.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01632</id>
    <link href="http://arxiv.org/abs/1911.01632" rel="alternate" type="text/html"/>
    <title>Learning Optimal Search Algorithms from Data</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chawla:Shuchi.html">Shuchi Chawla</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gergatsouli:Evangelia.html">Evangelia Gergatsouli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Teng:Yifeng.html">Yifeng Teng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tzamos:Christos.html">Christos Tzamos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Ruimin.html">Ruimin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01632">PDF</a><br/><b>Abstract: </b>Classical algorithm design is geared towards worst case instances and fails
to exploit structure that may be present in typical instances. Is it possible
to learn this structure from examples and exploit it algorithmically? We study
this question in the simplest algorithmic context -- search for a cheap
solution within an unstructured space. This setting captures, for example,
search for a short path to drive to work when only some routes may ever be
relevant to consider, or shopping online when there may only be a handful of
stores that offer the best prices.
</p>
<p>We propose a framework for learning optimal search algorithms from data that
captures the tradeoff between the cost of the solution and the time to find it.
We consider a setting with $n$ alternatives each having an unknown cost that
can be revealed one at a time. Given sample access to the distribution of the
costs, our goal is to learn an algorithm that minimizes the expected sum of the
cost of the chosen alternative and the total time to find it.
</p>
<p>Algorithms for this problem fall into three different classes, non-adaptive
which always query a fixed set of alternatives, partially-adaptive that query
alternatives in a fixed order until they decide to stop and fully-adaptive that
choose the next query based on the costs they've seen. While approximately
optimal fully-adaptive strategies cannot be learned efficiently, our main
result is that it is possible to learn a partially-adaptive strategy that
approximates the best non-adaptive and partially-adaptive strategies
efficiently both in terms of samples and computation.
</p>
<p>We extend our results to settings where multiple alternatives must be chosen
and study the case where any $k$ alternatives are feasible and the case where
the alternatives must form a matroid base e.g. picking a minimum cost spanning
tree.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01626</id>
    <link href="http://arxiv.org/abs/1911.01626" rel="alternate" type="text/html"/>
    <title>Faster Parallel Algorithm for Approximate Shortest Path</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jason.html">Jason Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01626">PDF</a><br/><b>Abstract: </b>We present the first $m\,\text{polylog}(n)$ work, $\text{polylog}(n)$ time
algorithm in the PRAM model that computes $(1+\epsilon)$-approximate
single-source shortest paths on weighted, undirected graphs. This improves upon
the breakthrough result of Cohen~[JACM'00] that achieves $O(m^{1+\epsilon_0})$
work and $\text{polylog}(n)$ time. While most previous approaches, including
Cohen's, leveraged the power of hopsets, our algorithm builds upon the recent
developments in \emph{continuous optimization}, studying the shortest path
problem from the lens of the closely-related \emph{minimum transshipment}
problem. To obtain our algorithm, we demonstrate a series of near-linear work,
polylogarithmic-time reductions between the problems of approximate shortest
path, approximate transshipment, and $\ell_1$-embeddings, and establish a
recursive algorithm that cycles through the three problems and reduces the
graph size on each cycle. As a consequence, we also obtain faster parallel
algorithms for approximate transshipment and $\ell_1$-embeddings with
polylogarithmic distortion. The minimum transshipment algorithm in particular
improves upon the previous best $m^{1+o(1)}$ work sequential algorithm of
Sherman~[SODA'17].
</p>
<p>To improve readability, the paper is almost entirely self-contained, save for
several staple theorems in algorithms and combinatorics.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01592</id>
    <link href="http://arxiv.org/abs/1911.01592" rel="alternate" type="text/html"/>
    <title>Unbounded lower bound for k-server against weak adversaries</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bienkowski:Marcin.html">Marcin Bienkowski</a>, Jarosław Byrka, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coester:Christian.html">Christian Coester</a>, Łukasz Jeż <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01592">PDF</a><br/><b>Abstract: </b>We study the resource augmented version of the $k$-server problem, also known
as the $k$-server problem against weak adversaries or the $(h,k)$-server
problem. In this setting, an online algorithm using $k$ servers is compared to
an offline algorithm using $h$ servers, where $h\le k$. For uniform metrics, it
has been known since the seminal work of Sleator and Tarjan (1985) that for any
$\epsilon&gt;0$, the competitive ratio drops to a constant if $k=(1+\epsilon)
\cdot h$. This result was later generalized to weighted stars (Young 1994) and
trees of bounded depth (Bansal et al. 2017). The main open problem for this
setting is whether a similar phenomenon occurs on general metrics.
</p>
<p>We resolve this question negatively. With a simple recursive construction, we
show that the competitive ratio is at least $\Omega(\log \log h)$, even as
$k\to\infty$. Our lower bound holds for both deterministic and randomized
algorithms. It also disproves the existence of a competitive algorithm for the
infinite server problem on general metrics.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01527</id>
    <link href="http://arxiv.org/abs/1911.01527" rel="alternate" type="text/html"/>
    <title>Same Stats, Different Graphs: Exploring the Space of Graphs in Terms of Graph Properties</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Hang.html">Hang Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huroyan:Vahan.html">Vahan Huroyan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soni:Utkarsh.html">Utkarsh Soni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Yafeng.html">Yafeng Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maciejewski:Ross.html">Ross Maciejewski</a>, Stephen Kobourov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01527">PDF</a><br/><b>Abstract: </b>Data analysts commonly utilize statistics to summarize large datasets. While
it is often sufficient to explore only the summary statistics of a dataset
(e.g., min/mean/max), Anscombe's Quartet demonstrates how such statistics can
be misleading. We consider a similar problem in the context of graph mining. To
study the relationships between different graph properties, we examine
low-order non-isomorphic graphs and provide a simple visual analytics system to
explore correlations across multiple graph properties. However, for larger
graphs, studying the entire space quickly becomes intractable. We use different
random graph generation methods to further look into the distribution of graph
properties for higher order graphs and investigate the impact of various
sampling methodologies. We also describe a method for generating many graphs
that are identical over a number of graph properties and statistics yet are
clearly different and identifiably distinct.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01522</id>
    <link href="http://arxiv.org/abs/1911.01522" rel="alternate" type="text/html"/>
    <title>Generalized Self-concordant Hessian-barrier algorithms</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pavel Dvurechensky, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Staudigl:Mathias.html">Mathias Staudigl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uribe:C=eacute=sar_A=.html">César A. Uribe</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01522">PDF</a><br/><b>Abstract: </b>Many problems in statistical learning, imaging, and computer vision involve
the optimization of a non-convex objective function with singularities at the
boundary of the feasible set. For such challenging instances, we develop a new
interior-point technique building on the Hessian-barrier algorithm recently
introduced in Bomze, Mertikopoulos, Schachinger and Staudigl, [SIAM J. Opt.
2019 29(3), pp. 2100-2127], where the Riemannian metric is induced by a
generalized self-concordant function. This class of functions is sufficiently
general to include most of the commonly used barrier functions in the
literature of interior point methods. We prove global convergence to an
approximate stationary point of the method, and in cases where the feasible set
admits an easily computable self-concordant barrier, we verify worst-case
optimal iteration complexity of the method. Applications in non-convex
statistical estimation and $L^{p}$-minimization are discussed to given the
efficiency of the method.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01515</id>
    <link href="http://arxiv.org/abs/1911.01515" rel="alternate" type="text/html"/>
    <title>Can the Elliptic Billiard Still Surprise Us?</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reznik:Dan.html">Dan Reznik</a>, Ronaldo Garcia, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koiller:Jair.html">Jair Koiller</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01515">PDF</a><br/><b>Abstract: </b>Can any secrets still be shed by that much studied, uniquely integrable,
Elliptic Billiard? Starting by examining the family of 3-periodic trajectories
and the loci of their Triangular Centers, one obtains a beautiful and
variegated gallery of curves: ellipses, quartics, sextics, circles, and even a
stationary point. Secondly, one notices this family conserves an intriguing
ratio: Inradius-to-Circumradius. In turn this implies three invariants as
corollaries: (i) the sum of bounce angle cosines, (ii) the product of excentral
cosines, and (iii) the ratio of excentral-to-orbit areas. Monge's Orthoptic
Circle's close relation to 4-periodic Billiard trajectories is well-known. Its
geometry provided clues with which to generalize 3-periodic invariants to
trajectories of an arbitrary number of edges. This was quite unexpected.
Indeed, the Elliptic Billiard did surprise us!
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01508</id>
    <link href="http://arxiv.org/abs/1911.01508" rel="alternate" type="text/html"/>
    <title>Verifying Visibility-Based Weak Consistency</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishna:Siddharth.html">Siddharth Krishna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emmi:Michael.html">Michael Emmi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Enea:Constantin.html">Constantin Enea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jovanovic:Dejan.html">Dejan Jovanovic</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01508">PDF</a><br/><b>Abstract: </b>Multithreaded programs generally leverage efficient and thread-safe
concurrent objects like sets, key-value maps, and queues. While some
concurrent-object operations are designed to behave atomically, each witnessing
the atomic effects of predecessors in a linearization order, others forego such
strong consistency to avoid complex control and synchronization bottlenecks.
For example, contains (value) methods of key-value maps may iterate through
key-value entries without blocking concurrent updates, to avoid unwanted
performance bottlenecks, and consequently overlook the effects of some
linearization-order predecessors. While such weakly-consistent operations may
not be atomic, they still offer guarantees, e.g., only observing values that
have been present.
</p>
<p>In this work we develop a methodology for proving that concurrent object
implementations adhere to weak-consistency specifications. In particular, we
consider (forward) simulation-based proofs of implementations against
relaxed-visibility specifications, which allow designated operations to
overlook some of their linearization-order predecessors, i.e., behaving as if
they never occurred. Besides annotating implementation code to identify
linearization points, i.e., points at which operations' logical effects occur,
we also annotate code to identify visible operations, i.e., operations whose
effects are observed; in practice this annotation can be done automatically by
tracking the writers to each accessed memory location. We formalize our
methodology over a general notion of transition systems, agnostic to any
particular programming language or memory model, and demonstrate its
application, using automated theorem provers, by verifying models of Java
concurrent object implementations.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01504</id>
    <link href="http://arxiv.org/abs/1911.01504" rel="alternate" type="text/html"/>
    <title>Statistical physics approaches to Unique Games</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coulson:Matthew.html">Matthew Coulson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davies:Ewan.html">Ewan Davies</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolla:Alexandra.html">Alexandra Kolla</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patel:Viresh.html">Viresh Patel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Regts:Guus.html">Guus Regts</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01504">PDF</a><br/><b>Abstract: </b>We show how two techniques from statistical physics can be adapted to solve a
variant of the notorious Unique Games problem, potentially opening new avenues
towards the Unique Games Conjecture. The variant, which we call Count Unique
Games, is a promise problem in which the "yes" case guarantees a certain number
of highly satisfiable assignments to the Unique Games instance. In the standard
Unique Games problem, the "yes" case only guarantees at least one such
assignment. We exhibit efficient algorithms for Count Unique Games based on
approximating a suitable partition function for the Unique Games instance via
(i) a zero-free region and polynomial interpolation, and (ii) the cluster
expansion. We also show that a modest improvement to the parameters for which
we give results would refute the Unique Games Conjecture.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01503</id>
    <link href="http://arxiv.org/abs/1911.01503" rel="alternate" type="text/html"/>
    <title>A Merge-Split Proposal for Reversible Monte Carlo Markov Chain Sampling of Redistricting Plans</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carter:Daniel.html">Daniel Carter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Herschlag:Gregory.html">Gregory Herschlag</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hunter:Zach.html">Zach Hunter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mattingly:Jonathan.html">Jonathan Mattingly</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01503">PDF</a><br/><b>Abstract: </b>We describe a Markov chain on redistricting plans that makes relatively
global moves. The chain is designed to be usable as the proposal in a Markov
Chain Monte Carlo (MCMC) algorithm. Sampling the space of plans amounts to
dividing a graph into a partition with a specified number elements which each
correspond to a different district. The partitions satisfy a collection of hard
constraints and the measure may be weighted with regard to a number of other
criteria. When these constraints and criteria are chosen to align well with
classical legal redistricting criteria, the algorithm can be used to generate a
collection of non-partisan, neutral plans. This collection of plans can serve
as a baseline against which a particular plan of interest is compared. If a
given plan has different racial or partisan qualities than what is typical of
the collection plans, the given plan may have been gerrymandered and is labeled
as an outlier.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01479</id>
    <link href="http://arxiv.org/abs/1911.01479" rel="alternate" type="text/html"/>
    <title>CC-circuits and the expressive power of nilpotent algebras</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kompatscher:Michael.html">Michael Kompatscher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01479">PDF</a><br/><b>Abstract: </b>We show that CC-circuits of bounded depth have the same expressive power as
polynomials over finite nilpotent algebras from congruence modular varieties.
We use this result to phrase and discuss an algebraic version of Barrington,
Straubing and Th\'erien's conjecture, which states that CC-circuits of bounded
depth need exponential size to compute AND.
</p>
<p>Furthermore we investigate the complexity of deciding identities and solving
equations in a fixed nilpotent algebra. Under the assumption that the
conjecture is true, we obtain quasipolynomial algorithms for both problems. On
the other hand, if AND is computable by uniform CC-circuits of bounded depth
and polynomial size, we can construct a nilpotent algebra with coNP-complete,
respectively NP-complete problem.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01469</id>
    <link href="http://arxiv.org/abs/1911.01469" rel="alternate" type="text/html"/>
    <title>Proximal Langevin Algorithm: Rapid Convergence Under Isoperimetry</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wibisono:Andre.html">Andre Wibisono</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01469">PDF</a><br/><b>Abstract: </b>We study the Proximal Langevin Algorithm (PLA) for sampling from a
probability distribution $\nu = e^{-f}$ on $\mathbb{R}^n$ under isoperimetry.
We prove a convergence guarantee for PLA in Kullback-Leibler (KL) divergence
when $\nu$ satisfies log-Sobolev inequality (LSI) and $f$ has bounded second
and third derivatives. This improves on the result for the Unadjusted Langevin
Algorithm (ULA), and matches the fastest known rate for sampling under LSI
(without Metropolis filter) with a better dependence on the LSI constant. We
also prove convergence guarantees for PLA in R\'enyi divergence of order $q &gt;
1$ when the biased limit satisfies either LSI or Poincar\'e inequality.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01465</id>
    <link href="http://arxiv.org/abs/1911.01465" rel="alternate" type="text/html"/>
    <title>On Clustering Incomplete Data</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganian:Robert.html">Robert Ganian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanj:Iyad.html">Iyad Kanj</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ordyniak:Sebastian.html">Sebastian Ordyniak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Szeider:Stefan.html">Stefan Szeider</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01465">PDF</a><br/><b>Abstract: </b>We study fundamental clustering problems for incomplete data. In this
setting, we are given a set of incomplete d-dimensional Boolean vectors
(representing the rows of a matrix), and the goal is to complete the missing
vector entries so that the set of complete vectors admits a partitioning into
at most k clusters with radius or diameter at most r. We develop a toolkit and
use it to give tight characterizations of the parameterized complexity of these
problems with respect to the parameters k, r, and the minimum number of rows
and columns needed to cover all the missing entries. We show that the
aforementioned problems are fixed-parameter tractable when parameterized by the
three parameters combined, and that dropping any of these three parameters
results in parameterized intractability. We extend this toolkit to settle the
parameterized complexity of other clustering problems, answering an open
question along the way. We also show how our results can be extended to data
over any constant-size domain. A byproduct of our results is that, for the
complete data setting, all problems under consideration are fixed-parameter
tractable parameterized by k+r.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01462</id>
    <link href="http://arxiv.org/abs/1911.01462" rel="alternate" type="text/html"/>
    <title>Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian Marginals</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goel:Surbhi.html">Surbhi Goel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karmalkar:Sushrut.html">Sushrut Karmalkar</a>, Adam Klivans <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01462">PDF</a><br/><b>Abstract: </b>We consider the problem of computing the best-fitting ReLU with respect to
square-loss on a training set when the examples have been drawn according to a
spherical Gaussian distribution (the labels can be arbitrary). Let
$\mathsf{opt} &lt; 1$ be the population loss of the best-fitting ReLU. We prove:
</p>
<p>1. Finding a ReLU with square-loss $\mathsf{opt} + \epsilon$ is as hard as
the problem of learning sparse parities with noise, widely thought to be
computationally intractable. This is the first hardness result for learning a
ReLU with respect to Gaussian marginals, and our results imply -{\emph
unconditionally}- that gradient descent cannot converge to the global minimum
in polynomial time.
</p>
<p>2. There exists an efficient approximation algorithm for finding the
best-fitting ReLU that achieves error $O(\mathsf{opt}^{2/3})$. The algorithm
uses a novel reduction to noisy halfspace learning with respect to $0/1$ loss.
</p>
<p>Prior work due to Soltanolkotabi [Sol17] showed that gradient descent can
find the best-fitting ReLU with respect to Gaussian marginals, if the training
set is exactly labeled by a ReLU.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01452</id>
    <link href="http://arxiv.org/abs/1911.01452" rel="alternate" type="text/html"/>
    <title>Pan-Private Uniformity Testing</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amin:Kareem.html">Kareem Amin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Joseph:Matthew.html">Matthew Joseph</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mao:Jieming.html">Jieming Mao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01452">PDF</a><br/><b>Abstract: </b>A centrally differentially private algorithm maps raw data to differentially
private outputs. In contrast, a locally differentially private algorithm may
only access data through public interaction with data holders, and this
interaction must be a differentially private function of the data. We study the
intermediate model of pan-privacy. Unlike a locally private algorithm, a
pan-private algorithm receives data in the clear. Unlike a centrally private
algorithm, the algorithm receives data one element at a time and must maintain
a differentially private internal state while processing this stream.
</p>
<p>First, we show that pan-privacy against multiple intrusions on the internal
state is equivalent to sequentially interactive local privacy. Next, we
contextualize pan-privacy against a single intrusion by analyzing the sample
complexity of uniformity testing over domain $[k]$. Focusing on the dependence
on $k$, centrally private uniformity testing has sample complexity
$\Theta(\sqrt{k})$, while noninteractive locally private uniformity testing has
sample complexity $\Theta(k)$. We show that the sample complexity of
pan-private uniformity testing is $\Theta(k^{2/3})$. By a new $\Omega(k)$ lower
bound for the sequentially interactive setting, we also separate pan-private
from sequentially interactive locally private and multi-intrusion pan-private
uniformity testing.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01420</id>
    <link href="http://arxiv.org/abs/1911.01420" rel="alternate" type="text/html"/>
    <title>GuessCompx: An empirical complexity estimation in R</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agenis=Nevers:Marc.html">Marc Agenis-Nevers</a>, Neeraj Dhanraj Bokde, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yaseen:Zaher_Mundher.html">Zaher Mundher Yaseen</a>, Mayur Shende <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01420">PDF</a><br/><b>Abstract: </b>This article introduces GuessCompx which is an R package that performs an
empirical estimation on the time and memory complexities of an algorithm or a
function. It tests multiple increasing-sizes samples of the user's data and
attempts to fit one of seven complexity functions: O(N), O(N^2), O(log(N)),
etc. Based on a best fit procedure using LOO-MSE (leave one out-mean squared
error), it also predicts the full computation time and memory usage on the
whole dataset. Conceptually, it relies on the base R functions system.time and
memory.size, the latter being only suitable for Windows users. Together with
this results, a plot and a significance test are returned. Complexity is
assessed with regard to the user's actual dataset through its size (and no
other parameter). This article provides several examples demonstrating several
cases (e.g., distance function, time series and custom function) and optimal
parameters tuning. The subject of the empirical computational complexity has
been relatively little studied in computer sciences, and such a package
provides a reliable, convenient and simple procedure for estimation process.
Further, the package does not require to have the code of the target function.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1212.2549</id>
    <link href="http://arxiv.org/abs/1212.2549" rel="alternate" type="text/html"/>
    <title>Subtraction makes computing integers faster</title>
    <feedworld_mtime>1572998400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jindal:Gorav.html">Gorav Jindal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1212.2549">PDF</a><br/><b>Abstract: </b>We show some facts regarding the question whether, for any number $n$, the
length of the shortest Addition Multiplications Chain (AMC) computing $n$ is
polynomial in the length of the shortest division-free Straight Line Program
(SLP) that computes $n$.
</p>
<p>If the answer to this question is "yes", then we can show a stronger upper
bound for $\mathrm{PosSLP}$, the important problem which essentially captures
the notion of efficient computation over the reals. If the answer is "no", then
this would demonstrate how subtraction helps generating integers
super-polynomially faster, given that addition and multiplication can be done
in unit time.
</p>
<p>In this paper, we show that, for almost all numbers, AMCs and SLPs need same
asymptotic length for computation. However, for one specific form of numbers,
SLPs are strictly more powerful than AMCs by at least one step of computation.
</p></div>
    </summary>
    <updated>2019-11-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/05/postdoc-in-complexity-theory-at-university-of-warwick-apply-by-december-2-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/05/postdoc-in-complexity-theory-at-university-of-warwick-apply-by-december-2-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc in Complexity Theory at University of Warwick (apply by December 2, 2019)</title>
    <summary>A Postdoctoral Research Fellow position at the University of Warwick in computational complexity and related areas is available for up to 16 months ending in March/2021. The start date can be negotiated for the successful candidate. Note that obtaining a phd before joining Warwick is not strictly necessary. The position is available in connection with […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A Postdoctoral Research Fellow position at the University of Warwick in computational complexity and related areas is available for up to 16 months ending in March/2021. The start date can be negotiated for the successful candidate. Note that obtaining a phd before joining Warwick is not strictly necessary.</p>
<p>The position is available in connection with a research grant of Igor Carboni Oliveira.</p>
<p>Website: <a href="https://www.dcs.warwick.ac.uk/~igorcarb/">https://www.dcs.warwick.ac.uk/~igorcarb/</a><br/>
Email: igorcarb@gmail.com</p></div>
    </content>
    <updated>2019-11-05T10:10:22Z</updated>
    <published>2019-11-05T10:10:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T05:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/151</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/151" rel="alternate" type="text/html"/>
    <title>TR19-151 |  Optimal Inapproximability with Universal Factor Graphs | 

	Johan Hastad, 

	Per Austrin, 

	Jonah Brown-Cohan</title>
    <summary>The factor graph of an instance of a constraint satisfaction problem (CSP) is the bipartite graph indicating which variables appear in each constraint.  An instance of the CSP is given by the factor graph together with a list of which predicate is applied for each constraint. We establish that many Max-CSPs remains as hard to approximate as in the general case even when the factor graph is fixed (depending only on the size of the instance) and known in advance.

Examples of results obtained for this restricted setting are:

Optimal inapproximability for Max-3-Lin.

Approximation resistance for predicates supporting pairwise independent subgroups.

Hardness of the ``$(2+\epsilon)$-Sat'' problem and other Promise CSPs.

The main technical tool used to establish these results is a new way of folding the long code which we call ``functional folding''.</summary>
    <updated>2019-11-05T09:01:26Z</updated>
    <published>2019-11-05T09:01:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-06T05:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/150</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/150" rel="alternate" type="text/html"/>
    <title>TR19-150 |  A Logical Characteristic of Read-Once Branching Programs | 

	Stanislav Žák</title>
    <summary>We present a mathematical model of the intuitive notions such as the
knowledge or the information arising at different stages of
computations on branching programs (b.p.). The model has two
appropriate
properties:\\
i) The "knowledge" arising at a stage of computation in question is
derivable from the "knowledge" arising at the previous stage
according to the rules of the model and according to the local
arrangement of the b.p.\\
ii) The model confirms the intuitively well-known fact that the
knowledge arising at a node of a computation depends not only on
it but in some cases also on a "mystery" information. (I. e.
different computations reaching the same node may have different
knowledge(s) arisen at it.)\\
We prove that with respect to our model no such information exists
in read-once b.p.`s but on the other hand in b. p.`s which are not
read-once such information must be present. The read-once property
forms a frontier.\\
More concretely, we may see the instances of our models as a systems
$S=(U,D)$ where $U$ is a universe of knowledge and $D$ are
derivation rules. We say that a b.p. $P$ is compatible with a system
$S$ iff along each computation in $P$ $S$ derives $F$ ($false$) or
$T$ ($true$) at the end correctly according to the label of the
reached sink. This key notion modifies the classic paradigm
according to which the computational complexity is defined with
respect to different classes of restricted b.p.`s (e.g. read-once
b.p.`s, k-b.p.`s, b.p.`s computing in limited time etc.). Now, the
restriction is defined by a subset of systems and only these
programs are taken into account which are compatible with
at least one of the chosen systems.\\
Further  we may understand the sets $U$ of knowledge(s) as a sets of
admissible logical formulae.  More rich  sets $U$`s imply the larger
(= more free) restrictions on b.p.`s and consequently the smaller
complexities of Boolean functions are detected. More rich logical
equipment implies stronger computational effectiveness.\\</summary>
    <updated>2019-11-05T08:46:13Z</updated>
    <published>2019-11-05T08:46:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-06T05:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/11/05/prague-summer-school-on-discrete-mathematics-2020/</id>
    <link href="https://cstheory-events.org/2019/11/05/prague-summer-school-on-discrete-mathematics-2020/" rel="alternate" type="text/html"/>
    <title>Prague Summer School on Discrete Mathematics 2020</title>
    <summary>August 24, 2012 – August 28, 2020 Prague, Czechia http://pssdm.math.cas.cz/ Registration deadline: March 15, 2020 A one-week summer school primarily for PhD students and postdocs. Lecture courses given by Subhash Khot (New York University) and Shayan Oveis Gharan (University of Washington).</summary>
    <updated>2019-11-05T07:50:37Z</updated>
    <published>2019-11-05T07:50:37Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-11-06T05:21:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1406</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/11/05/convex-body-chasing-steiner-point-sellke-point-and-soda-2020-best-papers/" rel="alternate" type="text/html"/>
    <title>Convex body chasing, Steiner point, Sellke point, and SODA 2020 best papers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Big congratulations to my former intern Mark Sellke, and to the CMU team (C. J. Argue, Anupam Gupta, Guru Guruganesh, and Ziye Tang) for jointly winning the best paper award at SODA 2020 (as well as the best student paper … <a href="https://blogs.princeton.edu/imabandit/2019/11/05/convex-body-chasing-steiner-point-sellke-point-and-soda-2020-best-papers/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Big congratulations to my former intern <a class="liexternal" href="http://web.stanford.edu/~msellke/main">Mark Sellke</a>, and to the CMU team (<a class="liexternal" href="http://www.math.cmu.edu/~cargue/">C. J. Argue</a>, <a class="liexternal" href="http://www.cs.cmu.edu/~anupamg/">Anupam Gupta</a>, Guru Guruganesh, and Ziye Tang) for jointly winning the <a class="liinternal" href="https://www.siam.org/conferences/cm/program/special-events/soda20-special-events">best paper award at SODA 2020</a> (as well as the best student paper for Mark)! They obtain a linear in the dimension competitive ratio for convex body chasing, a problem which was entirely open for any <img alt="d \geq 3" class="ql-img-inline-formula " height="16" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e001a3fd5bcc2fc507220b28ff996717_l3.png?resize=42%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="42"/> just two years ago. What’s more is that they found <a class="liinternal" href="https://arxiv.org/abs/1905.11968">the algorithm (and proof)</a> from The Book! Let me explain.</p>
<p> </p>
<p><strong>Convex body chasing</strong></p>
<p>In convex body chasing an online algorithm is presented at each time step with a convex body <img alt="K_t \subset \mathbb{R}^d" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3fdc69e932e1950b410306bf5e91f317_l3.png?resize=65%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="65"/>, and it must choose a point <img alt="x_t \in K_t" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-dcddd0271254f09cb70e59f7636af336_l3.png?resize=58%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="58"/>. The online algorithm is trying to minimize its total movement, namely <img alt="\sum_{t \geq 0} \|x_{t+1} - x_{t}\|" class="ql-img-inline-formula " height="21" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ac0ba40fd0d872561b9bbfe0c2430fa6_l3.png?resize=132%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="132"/> (all the norms here will be Euclidean, for simplicity). To evaluate the performance of the algorithm, one benchmarks it against the smallest movement one could achieve for this sequence of bodies, if one knew in advance the whole sequence. A good example to have in mind is if the sequence <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> corresponds to lines rotating around some fixed point, then the best thing to do is to move to this fixed point and never move again, while a greedy algorithm might have infinite movement (in the continuous time limit). The competitive ratio is the worst case (over all possible sequences of convex bodies) ratio of the algorithm’s performance to those of the oracle optimum. This problem was introduced in 1993 by Linial and Friedman, mainly motivated by considering a more geometric version of the <a class="liimagelink" href="https://blogs.princeton.edu/imabandit/2017/12/16/k-server-part-1-online-learning-and-online-algorithms/"><img alt="k" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9dc53f8ecc1bcf15020c6df4c12f1c27_l3.png?resize=9%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>-server problem</a>.</p>
<p>As it turns out, this problem in fact has a lot of “real” applications. It is not too surprising given how elementary the problem is. Just to give a flavor, <a class="liexternal" href="http://users.cms.caltech.edu/~adamw/">Adam Wierman</a> and friends show that <a class="lipdf" href="http://www.caia.swin.edu.au/cv/landrew/pubs/capacity_provision_ToN.pdf">dynamic powering of data centers</a> can be viewed as an instance of convex *function* chasing. In convex function chasing, instead of a convex body one gets a convex function <img alt="f_t" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9bdb4107531e167960c3d7ea0ac6c6e3_l3.png?resize=14%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="14"/>, and there is then a movement cost <img alt="\|x_t - x_{t-1}\|" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a5c985c7efa58f7b4fc27244d6ceecab_l3.png?resize=85%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="85"/> and a *service cost* <img alt="f_t(x_t)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9a9f0c7799e133ea6e52dce0ee96f00f_l3.png?resize=43%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="43"/>. While this is more general than convex body chasing, it turns out that convex body chasing in dimension <img alt="d+1" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c9bf571295c1727c51ef654b528967d2_l3.png?resize=39%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="39"/> is enough to solve convex function chasing in dimension <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> (this is left to the reader as an exercise). Roughly speaking in dynamic power management, one controls various power levels (number of servers online, etc), and a request correspond to a new set of jobs. Turning on/off servers has an associated cost (the movement cost), while servicing the jobs with a certain number of servers has an associated delay (the service cost). You get the idea.</p>
<p> </p>
<p><strong>The Steiner point</strong></p>
<p>In <a class="liinternal" href="https://arxiv.org/abs/1811.00999">a paper</a> to appear at SODA too, we propose (with <a class="liexternal" href="http://yintat.com/">Yin Tat Lee</a>, <a class="liinternal" href="https://web.stanford.edu/~yuanzhil/">Yuanzhi Li</a>, <a class="liinternal" href="https://www.weizmann.ac.il/math/klartag/home">Bo’az Klartag</a>, and <a class="liexternal" href="http://web.stanford.edu/~msellke/main">Mark Sellke</a>) to use the <strong>Steiner point</strong> for the nested convex body chasing problem. In nested convex body chasing the sequence of bodies is nested, and to account for irrelevant additive constant we assume that the oracle optimum starts from the worst point in the starting set <img alt="K_0" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-145ecd5f60fadeca35a63e23997d92f2_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>. In other words, opt is starting at the point the furthest away in <img alt="K_0" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-145ecd5f60fadeca35a63e23997d92f2_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> from the closest point in <img alt="K_T" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c59edf016e3136f9eb4e117bb8f69221_l3.png?resize=25%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/>, so its movement is exactly equal to the <a class="liinternal" href="https://en.wikipedia.org/wiki/Hausdorff_distance" rel="nofollow">Hausdorff distance</a> between <img alt="K_0" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-145ecd5f60fadeca35a63e23997d92f2_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> and <img alt="K_T" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c59edf016e3136f9eb4e117bb8f69221_l3.png?resize=25%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/>. So all we have to do is to give an online algorithm whose movement is proportional to this Hausdorff distance. Some kind of Lipschitzness in Hausdorff distance. Well, it turns out that mathematicians have been looking at this for centuries already, and Steiner back in the 1800’s introduced just what we need: a <strong>selector</strong> (a map from convex sets to points in them, i.e. <img alt="S(K) \in K" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9a5879256c4564abf0f19723bdcbd0f2_l3.png?resize=80%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="80"/> for any convex set <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/>) which is Lipschitz with respect to the Hausdorff distance, that is:</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \|S(K) - S(K')\| \leq L \cdot \mathrm{dist}_H(K,K') \,. \]" class="ql-img-displayed-equation " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-88bc573a98d3513706bc117297bfc04e_l3.png?resize=281%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="281"/></p>
<p>Note that obtaining such a selector is not trivial, for example the first natural guess would be the center of gravity, but it turns out that this is <strong>not</strong> Lipschitz (consider for example what happens with <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> being a very thin triangle and <img alt="K'" class="ql-img-inline-formula " height="14" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b063268581b06951ebc5637f21fad0fd_l3.png?resize=20%2C14&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/> being the base of this triangle). Crazy thing is, this Steiner point selector (to be defined shortly) is not only Lipschitz, it is in fact <strong>the most Lipschitz selector</strong> for convex sets. How would you prove such a thing? Well, you clearly need a miracle to happen, and the miracle here is that the Steiner point satisfies some symmetries, which define it uniquely. From there all you need to do is that starting with any selector, you can add some of these symmetries while also improving the Lipschitz constant (for more on this see the references in the linked paper above).</p>
<p>OK, so what is the Steiner point? It has many definitions, but a particular appealing one from an optimizer’s viewpoint is as follows. For a convex set <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> and a vector <img alt="\theta \in \mathbb{R}^d" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-24a3864c0a0fdb33b8b28c5c9e29f616_l3.png?resize=51%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="51"/> let <img alt="g_K(\theta)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d1ee2708d01f3d597e257c20c654f8bc_l3.png?resize=43%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="43"/> be the maximizer of the linear function <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> in the set <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/>. Then the Steiner point of <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/>, <img alt="\mathrm{St}(K)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-47dba33d5bf995134c83d02ac5b3b458_l3.png?resize=46%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="46"/> is defined by:</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{St}(K) = \mathbb{E}_{\theta : \|\theta\| \leq 1} [g_K(\theta)] \,. \]" class="ql-img-displayed-equation " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1ed1a61ff1d6b62cd71a620f8bdeebb5_l3.png?resize=193%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="193"/></p>
<p>In words: for any direction take the furthest point in <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> in that direction, and average over all directions. This feels like a really nice object, and clearly it satisfies <img alt="\mathrm{St}(K) \in K" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0600d9b6a7b40aa047e56d5b11f0f0d3_l3.png?resize=85%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="85"/> (i.e., it is a selector). The algorithm we proposed in our SODA paper is simply to move to <img alt="x_t = \mathrm{St}(K_t)" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-07cd7d19d64122c29f27b6976bbe68f2_l3.png?resize=90%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="90"/>. Let us now see how to analyze this algorithm.</p>
<p> </p>
<p><strong>The nested case proof</strong></p>
<p>First we give an alternative formula for the Steiner point. Denote <img alt="h_K(\theta) = \max_{x \in K} \theta \cdot x" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8eebb9649a1de2ee8930a5cc0519bb77_l3.png?resize=168%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="168"/>, and observe that <img alt="g_K(\theta) = \nabla h_K(\theta)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f721cf39b79100662e95d1ee8ef8d5ea_l3.png?resize=128%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="128"/> for almost all <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>. Thus using the <a class="liinternal" href="https://en.wikipedia.org/wiki/Divergence_theorem" rel="nofollow">divergence theorem</a> one obtains:</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{St}(K) = d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [\theta h_K(\theta)] \,. \]" class="ql-img-displayed-equation " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9e786f72667e6f0939c1fc5e0e436e41_l3.png?resize=225%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="225"/></p>
<p>(The factor <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> comes from the ratio of the volume of the ball to the sphere, and the <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> in the expectation is because the normal to <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> is <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> on the sphere.)</p>
<p>Now we have the following one-line inequality to control the movement of the Steiner point:</p>
<p class="ql-center-displayed-equation" style="line-height: 52px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\begin{align*} \|\mathrm{St}(K) - \mathrm{St}(K')\| &amp; = d \cdot \| \mathbb{E}_{\theta : \|\theta\| = 1} [\theta (h_K(\theta) - h_{K'}(\theta))] \| \\ &amp; \leq d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [ |h_K(\theta) - h_{K'}(\theta)| ] \end{align*}" class="ql-img-displayed-equation " height="52" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bf37a0d06362627ccbf1c16cdfccce58_l3.png?resize=410%2C52&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="410"/></p>
<p>It only remains to observe that <img alt="|h_K(\theta) - h_{K'}(\theta)| \leq \mathrm{dist}_H(K,K')" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-fa3f0632ef28037f09617b6c8b676ba7_l3.png?resize=249%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="249"/> to obtain a proof that Steiner is <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>-Lipschitz (in fact as an exercise you can try to improve the above argument to obtain <img alt="O(\sqrt{d})" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8286f5a825001e7cfbcea2430495a77b_l3.png?resize=51%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="51"/>-Lipschitz). Now for nested convex body chasing we will have <img alt="K' \subset K" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3c0e71eb2cbbf930d61ca3800bfa1559_l3.png?resize=61%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="61"/> so that</p>
<p><img alt="|h_K(\theta) - h_{K'}(\theta)| = h_K(\theta) - h_{K'}(\theta)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6e1794a42bb76829d10b26116a31d32e_l3.png?resize=267%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="267"/> (i.e., no absolute values), and thus the upper bound on the movement will telescope! More precisely:</p>
<p class="ql-center-displayed-equation" style="line-height: 96px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\begin{align*} \sum_{t \geq 0} \|\mathrm{St}(K_t) - \mathrm{St}(K_{t+1})\| &amp; \leq d \cdot \sum_{t \geq 0} \mathbb{E}_{\theta : \|\theta\| = 1} [ h_{K_t}(\theta) - h_{K_{t+1}}(\theta) ] \\ &amp; = d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [ h_{K_0}(\theta) - h_{K_{T}}(\theta) ] \\ &amp; \leq d \cdot \mathrm{dist}_H(K_0, K_T) \,. \end{align*}" class="ql-img-displayed-equation " height="96" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e648f7a36eb3795aae31e998ff0866c5_l3.png?resize=470%2C96&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="470"/></p>
<p>This proves that the Steiner point is <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>-competitive for nested convex body chasing. How to generalize this to the non-nested case seemed difficult, and the breakthrough of Mark and the CMU team is to bring back an old friend of the online algorithm community: the work function.</p>
<p> </p>
<p><strong>The work function</strong></p>
<p>The work function <img alt="W_t : \mathbb{R}^d \rightarrow \mathbb{R}" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c06617c85ba7669c6be3e632519a2dec_l3.png?resize=99%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="99"/> is defined as follows. For any point <img alt="x \in \mathbb{R}^d" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9c6f585f2818eec84b05213c11071a67_l3.png?resize=53%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="53"/> it is the smallest cost one can pay to satisfy all the requests <img alt="K_0, \hdots, K_t" class="ql-img-inline-formula " height="16" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6fade2700ee9892a15c16c975bae1750_l3.png?resize=82%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="82"/> and end up at <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>. First observe that this function is convex. Indeed take two point <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/>, and <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> the middle point between <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/> (any point on the segment between <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/> would be treated similarly). In the definition of the work function there is an associated trajectory for both <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/>. By convexity of the requests, the sequence of mid points between those two trajectories is a valid trajectory for <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>! And moreover the movement of this mid trajectory is (by triangle inequality) less than the average of the movement of the trajectory for <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/>. Hence <img alt="W_t((x+y)/2) \leq (W_t(x) + W_t(y))/2" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b2b62227d1720529c220c1704a46f21_l3.png?resize=277%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="277"/>.</p>
<p>A very simple property we will need from the work function is that the norm of its gradient carries some information on the current request. Namely, <img alt="x \not\in K_t \Rightarrow \|\nabla W_t(x)\| = 1" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3b1e7323a40ebc675833af415d7b3d42_l3.png?resize=191%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="191"/> (indeed, if <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> is not in the current request set, then the best way to end up there is to move to a point <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> in <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> and then move to <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>, and if <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> is a polytope then when you move a little bit <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> you don’t move <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>, so the cost is changing at rate <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>, hence the norm of the gradient being <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>). Or to put it differently: <img alt="\|\nabla W_t(x)\| &lt; 1 \Rightarrow x \in K_t" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5613103c6538abdfe07fb8a6f0bdf73_l3.png?resize=189%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="189"/>.</p>
<p> </p>
<p><strong>The Sellke point</strong></p>
<p>Mark’s beautiful idea (and the CMU team very much related –in fact equivalent– idea) to generalize the Steiner point to the non-nested case is to use the work function as a surrogate for the request. Steiner of <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> will clearly not work since all of <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> does not matter in the same way, as some points might be essentially irrelevant because they are very far from the previous requests, a fact which will be uncovered by the work function (while on the other hand the random direction from the Steiner point definition is oblivious to the geometry of the previous requests). So how to pick an appropriately random point in <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> while respecting the work function structure? Well we just saw that <img alt="\|\nabla W_t(x)\| &lt; 1 \Rightarrow x \in K_t" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5613103c6538abdfe07fb8a6f0bdf73_l3.png?resize=189%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="189"/>. So how about taking a random direction <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>, and applying the inverse of the gradient map, namely the gradient of the <strong>Fenchel dual</strong> <img alt="W_t^*" class="ql-img-inline-formula " height="17" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef52bfe9fd84a48a8585c0d4cc7445c5_l3.png?resize=25%2C17&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/>? Recall that the Fenchel dual is defined by:</p>
<p class="ql-center-displayed-equation" style="line-height: 29px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ W_t^*(\theta) = \max_{x \in \mathbb{R}^d} \theta \cdot x - W_t(x) \,. \]" class="ql-img-displayed-equation " height="29" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-38f4e45e13b56402f2542d6d10104c23_l3.png?resize=216%2C29&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="216"/></p>
<p>This is exactly the algorithm Mark proposes and it goes like this (Mark calls it the *functional Steiner point*):</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{Se}(K_t) = \mathbb{E}_{\theta : \|\theta\| &lt; 1} [\nabla W_t^*(\theta)] \,. \]" class="ql-img-displayed-equation " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1c48be67527ecd410d08235502958d42_l3.png?resize=219%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="219"/></p>
<p>Crucially this is a valid point, namely <img alt="\mathrm{Se}(K_t) \in K_t" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4a1a15b2c69480b3c0cad98acf3b2ad9_l3.png?resize=94%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="94"/>. Moreover just like for the Steiner point we can apply the divergence theorem and obtain:</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{Se}(K_t) = d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [\theta W_t^*(\theta)] \,. \]" class="ql-img-displayed-equation " height="22" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-329630ec5ed1634f7880d91ce9666807_l3.png?resize=235%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="235"/></p>
<p>The beautiful thing is that we can now <strong>exactly</strong> repeat the nested convex body argument, since <img alt="W_{t+1}^*(\theta) \leq W_t^*(\theta)" class="ql-img-inline-formula " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3dd6961afcbaae41b54d8e7651b9cd94_l3.png?resize=135%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="135"/> for all <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> (just like we had in the nested case <img alt="h_{K_{t+1}}(\theta) \leq h_{K_t}(\theta)" class="ql-img-inline-formula " height="21" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f34e37633e4a00d3fa90457f5a676ef7_l3.png?resize=139%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="139"/>) and so we get:</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{t \geq 0} \|\mathrm{Se}(K_t) - \mathrm{Se}(K_{t+1})\| \leq d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [ W_{0}^*(\theta) - W^*_{{T}}(\theta) ] \]" class="ql-img-displayed-equation " height="40" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-593f9a9e90a2740715be744ac89275ac_l3.png?resize=426%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="426"/></p>
<p>The first term with <img alt="W_0^*" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-03b6bb14cb85145aa8efb2ba6b6fba23_l3.png?resize=25%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/> is just some additive constant which we can ignore, while the second term is bounded as follows:</p>
<p class="ql-center-displayed-equation" style="line-height: 105px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\begin{align*} \mathbb{E}_{\theta : \|\theta\| = 1} [ - W^*_{{T}}(\theta) ] &amp; = \mathbb{E}_{\theta : \|\theta\| = 1} [ \min_{x \in \mathbb{R}^d} W_t(x) - \theta \cdot x ] \\ &amp; \leq \min_{x \in \mathbb{R}^d} \mathbb{E}_{\theta : \|\theta\| = 1}[ W_t(x) - \theta \cdot x ] \\ &amp; = \min_{x \in \mathbb{R}^d} W_t(x) \,. \end{align*}" class="ql-img-displayed-equation " height="105" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f7d98d503b4ecd2f79bb081ccddccceb_l3.png?resize=364%2C105&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="364"/></p>
<p>Thus we exactly proved that the movement of the Sellke point is upped bounded by a constant plus <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> times the minimum of the work function, and the latter is nothing but the value of the oracle optimum!</p>
<p>Note that once everything is done and said, the proof has only <strong>two</strong> inequalities (triangle inequality as in the nested case, and the minimum of the expectation is less than the expectation of the minimum). It doesn’t get any better than this!</p></div>
    </content>
    <updated>2019-11-05T05:40:20Z</updated>
    <published>2019-11-05T05:40:20Z</published>
    <category term="Theoretical Computer Science"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-11-05T23:53:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01414</id>
    <link href="http://arxiv.org/abs/1911.01414" rel="alternate" type="text/html"/>
    <title>Counting Small Permutation Patterns</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Even=Zohar:Chaim.html">Chaim Even-Zohar</a>, Calvin Leng <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01414">PDF</a><br/><b>Abstract: </b>A sample of n generic points in the xy-plane defines a permutation that
relates their ranks along the two axes. Every subset of k points similarly
defines a pattern, which occurs in that permutation. The number of occurrences
of small patterns in a large permutation arises in many areas, including
nonparametric statistics. It is therefore desirable to count them more
efficiently than the straightforward ~O(n^k) time algorithm.
</p>
<p>This work proposes new algorithms for counting patterns. We show that all
patterns of order 2 and 3, as well as eight patterns of order 4, can be counted
in nearly linear time. To that end, we develop an algebraic framework that we
call corner tree formulas. Our approach generalizes the existing methods and
allows a systematic study of their scope.
</p>
<p>Using the machinery of corner trees, we find twenty-three independent linear
combinations of order-4 patterns, that can be computed in time ~O(n). We also
describe an algorithm that counts another 4-pattern, and hence all 4-patterns,
in time ~O(n^(3/2)).
</p>
<p>As a practical application, we provide a nearly linear time computation of a
statistic by Yanagimoto (1970), Bergsma and Dassios (2010). This statistic
yields a natural and strongly consistent variant of Hoeffding's test for
independence of X and Y, given a random sample as above. This improves upon the
so far most efficient ~O(n^2) algorithm.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01411</id>
    <link href="http://arxiv.org/abs/1911.01411" rel="alternate" type="text/html"/>
    <title>Lifting Sum-of-Squares Lower Bounds: Degree-$2$ to Degree-$4$</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Sidhanth.html">Sidhanth Mohanty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raghavendra:Prasad.html">Prasad Raghavendra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jeff.html">Jeff Xu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01411">PDF</a><br/><b>Abstract: </b>The degree-$4$ Sum-of-Squares (SoS) SDP relaxation is a powerful algorithm
that captures the best known polynomial time algorithms for a broad range of
problems including MaxCut, Sparsest Cut, all MaxCSPs and tensor PCA. Despite
being an explicit algorithm with relatively low computational complexity, the
limits of degree-$4$ SoS SDP are not well understood. For example, existing
integrality gaps do not rule out a $(2-\varepsilon)$-algorithm for Vertex Cover
or a $(0.878+\varepsilon)$-algorithm for MaxCut via degree-$4$ SoS SDPs, each
of which would refute the notorious Unique Games Conjecture.
</p>
<p>We exhibit an explicit mapping from solutions for degree-$2$ Sum-of-Squares
SDP (Goemans-Williamson SDP) to solutions for the degree-$4$ Sum-of-Squares SDP
relaxation on boolean variables. By virtue of this mapping, one can lift lower
bounds for degree-$2$ SoS SDP relaxation to corresponding lower bounds for
degree-$4$ SoS SDPs. We use this approach to obtain degree-$4$ SoS SDP lower
bounds for MaxCut on random $d$-regular graphs, Sherington-Kirkpatrick model
from statistical physics and PSD Grothendieck problem.
</p>
<p>Our constructions use the idea of pseudocalibration towards candidate SDP
vectors, while it was previously only used to produce the candidate matrix
which one would show is PSD using much technical work. In addition, we develop
a different technique to bound the spectral norms of _graphical matrices_ that
arise in the context of SoS SDPs. The technique is much simpler and yields
better bounds in many cases than the _trace method_ -- which was the sole
technique for this purpose.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01402</id>
    <link href="http://arxiv.org/abs/1911.01402" rel="alternate" type="text/html"/>
    <title>Providing Input-Discriminative Protection for Local Differential Privacy</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Xiaolan.html">Xiaolan Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ming.html">Ming Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiong:Li.html">Li Xiong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cao:Yang.html">Yang Cao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01402">PDF</a><br/><b>Abstract: </b>Local Differential Privacy (LDP) provides provable privacy protection for
data collection without the assumption of the trusted data server. In the
real-world scenario, different data have different privacy requirements due to
the distinct sensitivity levels. However, LDP provides the same protection for
all data. In this paper, we tackle the challenge of providing
input-discriminative protection to reflect the distinct privacy requirements of
different inputs. We first present the Input-Discriminative LDP (ID-LDP)
privacy notion and focus on a specific version termed MinID-LDP, which is shown
to be a fine-grained version of LDP. Then, we develop the IDUE mechanism based
on Unary Encoding for single-item input and the extended mechanism IDUE-PS
(with Padding-and-Sampling protocol) for item-set input. The results on both
synthetic and real-world datasets validate the correctness of our theoretical
analysis and show that the proposed mechanisms satisfying MinID-LDP have better
utility than the state-of-the-art mechanisms satisfying LDP due to the
input-discriminative protection.
</p></div>
    </summary>
    <updated>2019-11-05T23:31:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01381</id>
    <link href="http://arxiv.org/abs/1911.01381" rel="alternate" type="text/html"/>
    <title>Bare quantum simultaneity versus classical interactivity in communication complexity</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gavinsky:Dmitry.html">Dmitry Gavinsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01381">PDF</a><br/><b>Abstract: </b>A relational bipartite communication problem is presented that has an
efficient quantum simultaneous-messages protocol, but no efficient classical
two-way protocol.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01374</id>
    <link href="http://arxiv.org/abs/1911.01374" rel="alternate" type="text/html"/>
    <title>Algorithms for Intersection Graphs of Multiple Intervals and Pseudo Disks</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inamdar:Tanmay.html">Tanmay Inamdar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01374">PDF</a><br/><b>Abstract: </b>Intersection graphs of planar geometric objects such as intervals, disks,
rectangles and pseudo-disks are well studied. Motivated by various
applications, Butman et al. in SODA 2007 considered algorithmic questions in
intersection graphs of $t$-intervals. A $t$-interval is a union of at most $t$
distinct intervals (here $t$ is a parameter) -- these graphs are referred to as
Multiple-Interval Graphs. Subsequent work by Kammer et al. in Approx 2010 also
considered $t$-disks and other geometric shapes. In this paper we revisit some
of these algorithmic questions via more recent developments in computational
geometry. For the minimum weight dominating set problem, we give a simple $O(t
\log t)$ approximation for Multiple-Interval Graphs, improving on the
previously known bound of $t^2$ . We also show that it is NP-hard to obtain an
$o(t)$-approximation in this case. In fact, our results hold for the
intersection graph of a set of t-pseudo-disks which is a much larger class. We
obtain an ${\Omega}(1/t)$-approximation for the maximum weight independent set
in the intersection graph of $t$-pseudo-disks. Our results are based on simple
reductions to existing algorithms by appropriately bounding the union
complexity of the objects under consideration.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01351</id>
    <link href="http://arxiv.org/abs/1911.01351" rel="alternate" type="text/html"/>
    <title>Faster Update Time for Turnstile Streaming Algorithms</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alman:Josh.html">Josh Alman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01351">PDF</a><br/><b>Abstract: </b>In this paper, we present a new algorithm for maintaining linear sketches in
turnstile streams with faster update time. As an application, we show that
$\log n$ \texttt{Count} sketches or \texttt{CountMin} sketches with a constant
number of columns (i.e., buckets) can be implicitly maintained in
\emph{worst-case} $O(\log^{0.582} n)$ update time using $O(\log n)$ words of
space, on a standard word RAM with word-size $w=\Theta(\log n)$. The exponent
$0.582\approx 2\omega/3-1$, where $\omega$ is the current matrix multiplication
exponent. Due to the numerous applications of linear sketches, our algorithm
improves the update time for many streaming problems in turnstile streams, in
the high success probability setting, without using more space, including
$\ell_2$ norm estimation, $\ell_2$ heavy hitters, point query with $\ell_1$ or
$\ell_2$ error, etc. Our algorithm generalizes, with the same update time and
space, to maintaining $\log n$ linear sketches, where each sketch partitions
the coordinates into $k&lt;\log^{o(1)} n$ buckets using a $c$-wise independent
hash function for constant $c$, and maintains the sum of coordinates for each
bucket. Moreover, if arbitrary word operations are allowed, the update time can
be further improved to $O(\log^{0.187} n)$, where $0.187\approx \omega/2-1$.
Our update algorithm is adaptive, and it circumvents the non-adaptive
cell-probe lower bounds for turnstile streaming algorithms by Larsen, Nelson
and Nguy{\^{e}}n (STOC'15).
</p>
<p>On the other hand, our result also shows that proving unconditional
cell-probe lower bound for the update time seems very difficult, even if the
space is restricted to be (nearly) the optimum. If $\omega=2$, the cell-probe
update time of our algorithm would be $\log^{o(1)} n$. Hence, proving any
higher lower bound would imply $\omega&gt;2$.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>
</feed>
