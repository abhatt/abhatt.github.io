<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-08-26T19:21:38Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/26/postdoc-at-uc-berkeley-apply-by-september-10-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/26/postdoc-at-uc-berkeley-apply-by-september-10-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at UC Berkeley (apply by September 10, 2020)</title>
    <summary>Please send a cover letter, CV, and research statement to the email below. In CV please list at least 3 references. In cover letter please identify faculty of interest. Also, have references submit letters to the e-mail below, with your name in the subject line. Multiple opportunities available; earliest deadline requires nomination by September 10th. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Please send a cover letter, CV, and research statement to the email below. In CV please list at least 3 references. In cover letter please identify faculty of interest. Also, have references submit letters to the e-mail below, with your name in the subject line. Multiple opportunities available; earliest deadline requires nomination by<br/>
September 10th.</p>
<p>Website: <a href="http://theory.cs.berkeley.edu/postdoc.html">http://theory.cs.berkeley.edu/postdoc.html</a><br/>
Email: tcs-postdoc-inquiries@lists.eecs.berkeley.edu</p></div>
    </content>
    <updated>2020-08-26T04:54:53Z</updated>
    <published>2020-08-26T04:54:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-26T19:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.11058</id>
    <link href="http://arxiv.org/abs/2008.11058" rel="alternate" type="text/html"/>
    <title>On the Maximum Number of Crossings in Star-Simple Drawings of $K_n$ with No Empty Lens</title>
    <feedworld_mtime>1598400000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Felsner:Stefan.html">Stefan Felsner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoffmann:Michael.html">Michael Hoffmann</a>, Kristin Knorr, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parada:Irene.html">Irene Parada</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.11058">PDF</a><br/><b>Abstract: </b>A star-simple drawing of a graph is a drawing in which adjacent edges do not
cross. In contrast, there is no restriction on the number of crossings between
two independent edges. When allowing empty lenses (a face in the arrangement
induced by two edges that is bounded by a 2-cycle), two independent edges may
cross arbitrarily many times in a star-simple drawing. We consider star-simple
drawings of $K_n$ with no empty lens. In this setting we prove an upper bound
of $3((n-4)!)$ on the maximum number of crossings between any pair of edges. It
follows that the total number of crossings is finite and upper bounded by $n!$.
</p></div>
    </summary>
    <updated>2020-08-26T01:24:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10932</id>
    <link href="http://arxiv.org/abs/2008.10932" rel="alternate" type="text/html"/>
    <title>Faster Reachability in Static Graphs</title>
    <feedworld_mtime>1598400000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanauer:Kathrin.html">Kathrin Hanauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a>, Jonathan Trummer <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10932">PDF</a><br/><b>Abstract: </b>One of the most fundamental problems in computer science is the reachability
problem: Given a directed graph and two vertices s and t, can s reach t via a
path? We revisit existing techniques and combine them with new approaches to
support a large portion of reachability queries in constant time using a
linear-sized reachability index. In an experimental study, we compare a variety
of algorithms with respect to their index-building and query times as well as
their memory footprint. All of them yield a time/space trade-off for queries.
Surprisingly, due to cache effects, a higher investment in space doesn't
necessarily pay off: Reachability queries can often be answered even
significantly faster than single memory accesses in a precomputed full
reachability matrix.
</p></div>
    </summary>
    <updated>2020-08-26T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10898</id>
    <link href="http://arxiv.org/abs/2008.10898" rel="alternate" type="text/html"/>
    <title>PAGE: A Simple and Optimal Probabilistic Gradient Estimator for Nonconvex Optimization</title>
    <feedworld_mtime>1598400000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Zhize.html">Zhize Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bao:Hongyan.html">Hongyan Bao</a>, Xiangliang Zhang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Richt=aacute=rik:Peter.html">Peter Richtárik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10898">PDF</a><br/><b>Abstract: </b>In this paper, we propose a novel stochastic gradient
estimator---ProbAbilistic Gradient Estimator (PAGE)---for nonconvex
optimization. PAGE is easy to implement as it is designed via a small
adjustment to vanilla SGD: in each iteration, PAGE uses the vanilla minibatch
SGD update with probability $p$ and reuses the previous gradient with a small
adjustment, at a much lower computational cost, with probability $1-p$. We give
a simple formula for the optimal choice of $p$. We prove tight lower bounds for
nonconvex problems, which are of independent interest. Moreover, we prove
matching upper bounds both in the finite-sum and online regimes, which
establish that Page is an optimal method. Besides, we show that for nonconvex
functions satisfying the Polyak-\L{}ojasiewicz (PL) condition, PAGE can
automatically switch to a faster linear convergence rate. Finally, we conduct
several deep learning experiments (e.g., LeNet, VGG, ResNet) on real datasets
in PyTorch, and the results demonstrate that PAGE converges much faster than
SGD in training and also achieves the higher test accuracy, validating our
theoretical results and confirming the practical superiority of PAGE.
</p></div>
    </summary>
    <updated>2020-08-26T01:21:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10895</id>
    <link href="http://arxiv.org/abs/2008.10895" rel="alternate" type="text/html"/>
    <title>Decentralized Custody Scheme with Game-Theoretic Security</title>
    <feedworld_mtime>1598400000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zhaohua.html">Zhaohua Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Guang.html">Guang Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10895">PDF</a><br/><b>Abstract: </b>Custodian is a core financial service in which the custodian holds in
safekeeping assets on behalf of the client. Although traditional custody
service is typically endorsed by centralized authorities, decentralized custody
scheme has become technically feasible since the emergence of digital assets,
and furthermore it is badly needed by new applications such as blockchain and
DeFi (Decentralized Finance). In this work, we propose a framework of
decentralized asset custody scheme that is able to support a large number of
custodians and safely hold customer assets of multiple times value of the total
security deposit. The proposed custody scheme distributes custodians and assets
into many custodian groups via combinatorial designs and random sampling, where
each group fully controls the assigned assets. Since every custodian group is
small, the overhead cost is significantly reduced. The liveness is also
improved because even a single alive group would be able to process
transactions. The security of this custody scheme is guaranteed in the
game-theoretic sense, such that any adversary corrupting a bounded fraction of
custodians cannot move assets more than his own security deposit. We further
analyze the security and performance of our constructions, and give explicit
examples with concrete numbers and figures for a better understanding of our
results.
</p></div>
    </summary>
    <updated>2020-08-26T01:22:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10828</id>
    <link href="http://arxiv.org/abs/2008.10828" rel="alternate" type="text/html"/>
    <title>Efficient Hierarchical Clustering for Classification and Anomaly Detection</title>
    <feedworld_mtime>1598400000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ishita Doshi, Sreekalyan Sajjalla, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choudhari:Jayesh.html">Jayesh Choudhari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhatt:Rushi.html">Rushi Bhatt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dasgupta:Anirban.html">Anirban Dasgupta</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10828">PDF</a><br/><b>Abstract: </b>We address the problem of large scale real-time classification of content
posted on social networks, along with the need to rapidly identify novel spam
types. Obtaining manual labels for user-generated content using editorial
labeling and taxonomy development lags compared to the rate at which new
content type needs to be classified. We propose a class of hierarchical
clustering algorithms that can be used both for efficient and scalable
real-time multiclass classification as well as in detecting new anomalies in
user-generated content. Our methods have low query time, linear space usage,
and come with theoretical guarantees with respect to a specific hierarchical
clustering cost function (Dasgupta, 2016). We compare our solutions against a
range of classification techniques and demonstrate excellent empirical
performance.
</p></div>
    </summary>
    <updated>2020-08-26T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10794</id>
    <link href="http://arxiv.org/abs/2008.10794" rel="alternate" type="text/html"/>
    <title>Simple Topological Drawings of $k$-Planar Graphs</title>
    <feedworld_mtime>1598400000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoffmann:Michael.html">Michael Hoffmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Chih=Hung.html">Chih-Hung Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reddy:Meghana_M=.html">Meghana M. Reddy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10794">PDF</a><br/><b>Abstract: </b>Every finite graph admits a \emph{simple (topological) drawing}, that is, a
drawing where every pair of edges intersects in at most one point. However, in
combination with other restrictions simple drawings do not universally exist.
For instance, \emph{$k$-planar graphs} are those graphs that can be drawn so
that every edge has at most $k$ crossings (i.e., they admit a \emph{$k$-plane
drawing}). It is known that for $k\le 3$, every $k$-planar graph admits a
$k$-plane simple drawing. But for $k\ge 4$, there exist $k$-planar graphs that
do not admit a $k$-plane simple drawing. Answering a question by Schaefer, we
show that there exists a function $f : \mathbb{N}\rightarrow\mathbb{N}$ such
that every $k$-planar graph admits an $f(k)$-plane simple drawing, for all
$k\in\mathbb{N}$. Note that the function $f$ depends on $k$ only and is
independent of the size of the graph. Furthermore, we develop an algorithm to
show that every $4$-planar graph admits an $8$-plane simple drawing.
</p></div>
    </summary>
    <updated>2020-08-26T01:25:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10709</id>
    <link href="http://arxiv.org/abs/2008.10709" rel="alternate" type="text/html"/>
    <title>Algorithms and Lower Bounds for the Worker-Task Assignment Problem</title>
    <feedworld_mtime>1598400000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berger:Aaron.html">Aaron Berger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, Adam Polak, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tidor:Jonathan.html">Jonathan Tidor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Nicole.html">Nicole Wein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10709">PDF</a><br/><b>Abstract: </b>We study the problem of assigning workers to tasks where each task has demand
for a particular number of workers, and the demands are dynamically changing
over time. Specifically, a worker-task assignment function $\phi$ takes a
multiset of $w$ tasks $T \subseteq [t]$ and produces an assignment $\phi(T)$
from the workers $1, 2, \ldots, w$ to the tasks $T$. The assignment function
$\phi$ is said to have switching cost at most $k$ if, for all task multisets
$T$, changing the contents of $T$ by one task changes $\phi(T)$ by at most $k$
worker assignments. The goal of the worker-task assignment problem is to
produce an assignment function $\phi$ with the minimum possible switching cost.
</p>
<p>Prior work on this problem (SSS'17, ICALP'20) observed a simple assignment
function $\phi$ with switching cost $\min(w, t - 1)$, but there has been no
success in constructing $\phi$ with sublinear switching cost. We construct the
first assignment function $\phi$ with sublinear, and in fact polylogarithmic,
switching cost. We give a probabilistic construction for $\phi$ that achieves
switching cost $O(\log w \log (wt))$ and an explicit construction that achieves
switching cost $\operatorname{polylog} (wt)$.
</p>
<p>From the lower bounds side, prior work has used involved arguments to prove
constant lower bounds on switching cost, but no super-constant lower bounds are
known. We prove the first super-constant lower bound on switching cost. In
particular, we show that for any value of $w$ there exists a value of $t$ for
which the optimal switching cost is $w$. That is, when $w \ll t$, the trivial
bound on switching cost is optimal.
</p>
<p>We also consider an application of the worker-task assignment problem to a
metric embeddings problem. In particular, we use our results to give the first
low-distortion embedding from sparse binary vectors into low-dimensional
Hamming space.
</p></div>
    </summary>
    <updated>2020-08-26T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=790</id>
    <link href="https://emanueleviola.wordpress.com/2020/08/25/my-monitor-setup/" rel="alternate" type="text/html"/>
    <title>My monitor setup</title>
    <summary>In the not-distant future there will be a single monitor that gets you the best of both worlds. For the contemporaneous, I maintain that the above is the best monitor setup available to us in 2020. I use the tiny E-ink monitor as much as possible, including now, for my blitz matches on chess.com, and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><img alt="" class="wp-image-792" src="https://emanueleviola.files.wordpress.com/2020/08/webcam-toy-photo7.jpg?w=800"/></figure>

<p>In the not-distant future there will be a single monitor that gets you the best of both worlds. For the contemporaneous, I maintain that the above is the best monitor setup available to us in 2020. I use the tiny E-ink monitor as much as possible, including now, for my blitz matches on chess.com, and of course for writing and sometimes reviewing papers. But as I mentioned earlier unfortunately for certain bureaucratic tasks that not all of us can skip altogether you just need a bigger monitor with color. So I push a button on the hdmi switch, and the image blasts open on the 30-inch screen, <em>m’illumino d’immenso</em>, and suddenly the mouse feels like the interface from <em>Minority Reports</em>.</p></div>
    </content>
    <updated>2020-08-25T19:35:48Z</updated>
    <published>2020-08-25T19:35:48Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="tech"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-08-26T19:20:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/colt2020/</id>
    <link href="https://differentialprivacy.org/colt2020/" rel="alternate" type="text/html"/>
    <title>Conference Digest - COLT 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.learningtheory.org/colt2020/">COLT 2020</a> was held online in July, and featured nine papers on differential privacy, as well as a keynote talk by Salil Vadhan.
While differential privacy has always had a home in the COLT community, it seems like this year was truly exceptional in terms of the number of results.
We link all the content below, including pointers to the papers, videos on Youtube, and the page on the conference website. 
Please let us know if we missed any papers on differential privacy, either in the comments below or by email.</p>

<h2 id="keynote">Keynote</h2>
<ul>
  <li><a href="http://www.learningtheory.org/colt2020/virtual/speaker_1.html">The Theory and Practice of Differential Privacy</a> (<a href="https://www.youtube.com/watch?v=4bpFDpT1t7I">video</a>)<br/>
<a href="https://salil.seas.harvard.edu/">Salil Vadhan</a></li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/1907.08743">Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit</a> (<a href="https://www.youtube.com/watch?v=dgGdARyU6oY">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_96.html">page</a>)<br/>
<a href="https://people.ece.cornell.edu/acharya/">Jayadev Acharya</a>, <a href="http://www.cs.columbia.edu/~ccanonne/">Clément L. Canonne</a>, <a href="https://web.stanford.edu/~yjhan/">Yanjun Han</a>, <a href="http://www.zitengsun.com/">Ziteng Sun</a>, <a href="https://ece.iisc.ac.in/~htyagi/">Himanshu Tyagi</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2003.04509">Closure Properties for Private Classification and Online Prediction</a> (<a href="https://www.youtube.com/watch?v=U9hqJH6sEyY">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_320.html">page</a>)<br/>
<a href="https://web.math.princeton.edu/~nalon/">Noga Alon</a>, <a href="https://www.cs.bgu.ac.il/~beimel/">Amos Beimel</a>, <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.01452">Pan-Private Uniformity Testing</a> (<a href="https://www.youtube.com/watch?v=yMXAjEGDXdI">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_141.html">page</a>)<br/>
<a href="http://amin.kareemx.com/">Kareem Amin</a>, <a href="https://www.majos.net/">Matthew Joseph</a>, <a href="https://sites.google.com/view/jieming-mao">Jieming Mao</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.01100">Efficient, Noise-Tolerant, and Private Learning via Boosting</a> (<a href="https://www.youtube.com/watch?v=xCh7oZKcINs">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_304.html">page</a>)<br/>
<a href="https://cs-people.bu.edu/mbun/">Mark Bun</a>, <a href="https://marco.ntime.org/">Marco L. Carmosino</a>, <a href="http://cseweb.ucsd.edu/~jlsorrel/">Jessica Sorrell</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.10541">PAC Learning with Stable and Private Predictions</a> (<a href="https://www.youtube.com/watch?v=jZlgmBUQ4nU">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_37.html">page</a>)<br/>
<a href="https://yuvaldagan.wordpress.com/">Yuval Dagan</a>, <a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.09465">Locally Private Hypothesis Selection</a> (<a href="https://www.youtube.com/watch?v=MGeBYQ7lJYw">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_5.html">page</a>)<br/>
<a href="https://www.microsoft.com/en-us/research/people/sigopi/">Sivakanth Gopi</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan D. Kulkarni</a>, <a href="http://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a>, <a href="https://zstevenwu.com/">Zhiwei Steven Wu</a>, <a href="https://huanyuzhang.github.io/">Huanyu Zhang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.09464">Private Mean Estimation of Heavy-Tailed Distributions</a> (<a href="https://www.youtube.com/watch?v=6NVuAZqxrSE">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_6.html">page</a>)<br/>
<a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="http://www.ccs.neu.edu/home/vikrantsinghal/">Vikrant Singhal</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.10137">Privately Learning Thresholds: Closing the Exponential Gap</a> (<a href="https://www.youtube.com/watch?v=uGTfJsJAkh0">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_219.html">page</a>)<br/>
<a href="http://www.cs.tau.ac.il/~haimk/">Haim Kaplan</a>, <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a>, <a href="https://www.tau.ac.il/~mansour/">Yishay Mansour</a>, <a href="http://www.wisdom.weizmann.ac.il/~naor/">Moni Naor</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2001.09122">Reasoning About Generalization via Conditional Mutual Information</a> (<a href="https://www.youtube.com/watch?v=c5fzeqiTwWk">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_98.html">page</a>)<br/>
<a href="http://www.thomas-steinke.net/">Thomas Steinke</a>, <a href="http://www.ccs.neu.edu/home/lydiazak/">Lydia Zakynthinou</a></p>
  </li>
</ul></div>
    </summary>
    <updated>2020-08-25T14:00:00Z</updated>
    <published>2020-08-25T14:00:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-08-26T19:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/25/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/25/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-30-2020/" rel="alternate" type="text/html"/>
    <title>Assistant Professor (tenure-track) and Professor positions in Computer Science at Institute of Science and Technology Austria (apply by October 30, 2020)</title>
    <summary>The Institute of Science and Technology Austria (IST Austria) invites applications for several open positions in all areas of computer science. IST Austria values diversity and is committed to equal opportunity. We strive for increasing the number of women, particularly in fields where they are underrepresented, and therefore we strongly encourage female researchers to apply. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Institute of Science and Technology Austria (IST Austria) invites applications for several open positions in all areas of computer science.</p>
<p>IST Austria values diversity and is committed to equal opportunity. We strive for increasing the number of women, particularly in fields where they are underrepresented, and therefore we strongly encourage female researchers to apply.</p>
<p>Website: <a href="https://ist.ac.at/en/jobs/faculty/">https://ist.ac.at/en/jobs/faculty/</a><br/>
Email: faculty.recruiting@ist.ac.at</p></div>
    </content>
    <updated>2020-08-25T13:23:45Z</updated>
    <published>2020-08-25T13:23:45Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-26T19:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10583</id>
    <link href="http://arxiv.org/abs/2008.10583" rel="alternate" type="text/html"/>
    <title>Layered Drawing of Undirected Graphs with Generalized Port Constraints</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Walter:Julian.html">Julian Walter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zink:Johannes.html">Johannes Zink</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baumeister:Joachim.html">Joachim Baumeister</a>, Alexander Wolff <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10583">PDF</a><br/><b>Abstract: </b>The aim of this research is a practical method to draw cable plans of complex
machines. Such plans consist of electronic components and cables connecting
specific ports of the components. Since the machines are configured for each
client individually, cable plans need to be drawn automatically. The drawings
must be well readable so that technicians can use them to debug the machines.
In order to model plug sockets, we introduce port groups; within a group, ports
can change their position (which we use to improve the aesthetics of the
layout), but together the ports of a group must form a contiguous block.
</p>
<p>We approach the problem of drawing such cable plans by extending the
well-known Sugiyama framework such that it incorporates ports and port groups.
Since the framework assumes directed graphs, we propose several ways to orient
the edges of the given undirected graph. We compare these methods
experimentally, both on real-world data and synthetic data that carefully
simulates real-world data. We measure the aesthetics of the resulting drawings
by counting bends and crossings. Using these metrics, we compare our approach
to Kieler [JVLC 2014], a library for drawing graphs in the presence of port
constraints.
</p></div>
    </summary>
    <updated>2020-08-25T23:28:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10582</id>
    <link href="http://arxiv.org/abs/2008.10582" rel="alternate" type="text/html"/>
    <title>A Unified and Fine-Grained Approach for Light Spanners</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Le:Hung.html">Hung Le</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solomon:Shay.html">Shay Solomon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10582">PDF</a><br/><b>Abstract: </b>Seminal works on light spanners from recent years provide near-optimal
tradeoffs between the stretch and lightness of spanners in general graphs,
minor-free graphs, and doubling metrics. In FOCS'19 the authors provided a
``truly optimal'' tradeoff for Euclidean low-dimensional spaces. Some of these
papers employ inherently different techniques than others. Moreover, the
runtime of these constructions is rather high.
</p>
<p>In this work, we present a unified and fine-grained approach for light
spanners. Besides the obvious theoretical importance of unification, we
demonstrate the power of our approach in obtaining (1) stronger lightness
bounds, and (2) faster construction times. Our results include:
</p>
<p>_ $K_r$-minor-free graphs: A truly optimal spanner construction and a fast
construction.
</p>
<p>_ General graphs: A truly optimal spanner -- almost and a linear-time
construction with near-optimal lightness.
</p>
<p>_ Low dimensional Euclidean spaces: We demonstrate that Steiner points help
in reducing the lightness of Euclidean $1+\epsilon$-spanners almost
quadratically for $d\geq 3$.
</p></div>
    </summary>
    <updated>2020-08-25T23:28:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10577</id>
    <link href="http://arxiv.org/abs/2008.10577" rel="alternate" type="text/html"/>
    <title>Fast and Simple Modular Subset Sum</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Axiotis:Kyriakos.html">Kyriakos Axiotis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Backurs:Arturs.html">Arturs Backurs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Ce.html">Ce Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakos:Vasileios.html">Vasileios Nakos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tzamos:Christos.html">Christos Tzamos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Hongxun.html">Hongxun Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10577">PDF</a><br/><b>Abstract: </b>We revisit the Subset Sum problem over the finite cyclic group $\mathbb{Z}_m$
for some given integer $m$. A series of recent works has provided
asymptotically optimal algorithms for this problem under the Strong Exponential
Time Hypothesis. Koiliaris and Xu (SODA'17, TALG'19) gave a deterministic
algorithm running in time $\tilde{O}(m^{5/4})$, which was later improved to
$O(m \log^7 m)$ randomized time by Axiotis et al. (SODA'19). In this work, we
present two simple algorithms for the Modular Subset Sum problem running in
near-linear time in $m$, both efficiently implementing Bellman's iteration over
$\mathbb{Z}_m$. The first one is a randomized algorithm running in time
$O(m\log^2 m)$, that is based solely on rolling hash and an elementary
data-structure for prefix sums; to illustrate its simplicity we provide a short
and efficient implementation of the algorithm in Python. Our second solution is
a deterministic algorithm running in time $O(m\ \mathrm{polylog}\ m)$, that
uses dynamic data structures for string manipulation. We further show that the
techniques developed in this work can also lead to simple algorithms for the
All Pairs Non-Decreasing Paths Problem (APNP) on undirected graphs, matching
the asymptotically optimal running time of $\tilde{O}(n^2)$ provided in the
recent work of Duan et al. (ICALP'19).
</p></div>
    </summary>
    <updated>2020-08-25T23:23:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10526</id>
    <link href="http://arxiv.org/abs/2008.10526" rel="alternate" type="text/html"/>
    <title>Stochastic Multi-level Composition Optimization Algorithms with Level-Independent Convergence Rates</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balasubramanian:Krishnakumar.html">Krishnakumar Balasubramanian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghadimi:Saeed.html">Saeed Ghadimi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Anthony.html">Anthony Nguyen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10526">PDF</a><br/><b>Abstract: </b>In this paper, we study smooth stochastic multi-level composition
optimization problems, where the objective function is a nested composition of
$T$ functions. We assume access to noisy evaluations of the functions and their
gradients, through a stochastic first-order oracle. For solving this class of
problems, we propose two algorithms using moving-average stochastic estimates,
and analyze their convergence to an $\epsilon$-stationary point of the problem.
We show that the first algorithm, which is a generalization of [22] to the $T$
level case, can achieve a sample complexity of $\mathcal{O}(1/\epsilon^6)$ by
using mini-batches of samples in each iteration. By modifying this algorithm
using linearized stochastic estimates of the function values, we improve the
sample complexity to $\mathcal{O}(1/\epsilon^4)$. This modification also
removes the requirement of having a mini-batch of samples in each iteration. To
the best of our knowledge, this is the first time that such an online algorithm
designed for the (un)constrained multi-level setting, obtains the same sample
complexity of the smooth single-level setting, under mild assumptions on the
stochastic first-order oracle.
</p></div>
    </summary>
    <updated>2020-08-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10459</id>
    <link href="http://arxiv.org/abs/2008.10459" rel="alternate" type="text/html"/>
    <title>Limiting crossing numbers for geodesic drawings on the sphere</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonamy:Marthe.html">Marthe Bonamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohar:Bojan.html">Bojan Mohar</a>, Alexandra Wesolek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10459">PDF</a><br/><b>Abstract: </b>We introduce a model for random geodesic drawings of the complete bipartite
graph $K_{n,n}$ on the unit sphere $\mathbb{S}^2$ in $\mathbb{R}^3$, where we
select the vertices in each bipartite class of $K_{n,n}$ with respect to two
non-degenerate probability measures on $\mathbb{S}^2$. It has been proved
recently that many such measures give drawings whose crossing number
approximates the Zarankiewicz number (the conjectured crossing number of
$K_{n,n}$). In this paper we consider the intersection graphs associated with
such random drawings. We prove that for any probability measures, the resulting
random intersection graphs form a convergent graph sequence in the sense of
graph limits. The edge density of the limiting graphon turns out to be
independent of the two measures as long as they are antipodally symmetric.
However, it is shown that the triangle densities behave differently. We examine
a specific random model, blow-ups of antipodal drawings $D$ of $K_{4,4}$, and
show that the triangle density in the corresponding crossing graphon depends on
the angles between the great circles containing the edges in $D$ and can attain
any value in the interval $\bigl(\frac{83}{12288}, \frac{128}{12288}\bigr)$.
</p></div>
    </summary>
    <updated>2020-08-25T23:40:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10406</id>
    <link href="http://arxiv.org/abs/2008.10406" rel="alternate" type="text/html"/>
    <title>An Efficient Algorithm for Finding Sets of Optimal Routes</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ido Zoref, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Orda:Ariel.html">Ariel Orda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10406">PDF</a><br/><b>Abstract: </b>In several important routing contexts it is required to identify a set of
routes, each of which optimizes a different criterion. For instance, in the
context of vehicle routing, one route would minimize the total distance
traveled, while other routes would also consider the total travel time or the
total incurred cost, or combinations thereof. In general, providing such a set
of diverse routes is obtained by finding optimal routes with respect to
different sets of weights on the network edges. This can be simply achieved by
consecutively executing a standard shortest path algorithm. However, in the
case of a large number of weight sets, this may require an excessively large
number of executions of such an algorithm, thus incurring a prohibitively large
running time.
</p>
<p>We indicate that, quite often, the different edge weights reflect different
combinations of some "raw" performance metrics (e.g., delay, cost). In such
cases, there is an inherent dependency among the different weights of the same
edge. This may well result in some similarity among the shortest routes, each
of which being optimal with respect to a specific set of weights. In this
study, we aim to exploit such similarity in order to improve the performance of
the solution scheme.
</p>
<p>Specifically, we contemplate edge weights that are obtained through different
linear combinations of some (``raw'') edge performance metrics. We establish
and validate a novel algorithm that efficiently computes a shortest path for
each set of edge weights. We demonstrate that, under reasonable assumptions,
the algorithm significantly outperforms the standard approach. Similarly to the
standard approach, the algorithm iteratively searches for routes, one per set
of edge weights; however, instead of executing each iteration independently, it
reduces the average running time by skillfully sharing information among the
iterations.
</p></div>
    </summary>
    <updated>2020-08-25T23:24:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10376</id>
    <link href="http://arxiv.org/abs/2008.10376" rel="alternate" type="text/html"/>
    <title>Stochastic Gradient Descent Works Really Well for Stress Minimization</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Katharina Börsig, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandes:Ulrik.html">Ulrik Brandes</a>, Barna Pasztor <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10376">PDF</a><br/><b>Abstract: </b>Stress minimization is among the best studied force-directed graph layout
methods because it reliably yields high-quality layouts. It thus comes as a
surprise that a novel approach based on stochastic gradient descent (Zheng,
Pawar and Goodman, TVCG 2019) is claimed to improve on state-of-the-art
approaches based on majorization. We present experimental evidence that the new
approach does not actually yield better layouts, but that it is still to be
preferred because it is simpler and robust against poor initialization.
</p></div>
    </summary>
    <updated>2020-08-25T23:31:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10331</id>
    <link href="http://arxiv.org/abs/2008.10331" rel="alternate" type="text/html"/>
    <title>Computing the Real Isolated Points of an Algebraic Hypersurface</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Le:Huu_Phuoc.html">Huu Phuoc Le</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Din:Mohab_Safey_El.html">Mohab Safey El Din</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Timo_de.html">Timo de Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10331">PDF</a><br/><b>Abstract: </b>Let $\mathbb{R}$ be the field of real numbers. We consider the problem of
computing the real isolated points of a real algebraic set in $\mathbb{R}^n$
given as the vanishing set of a polynomial system. This problem plays an
important role for studying rigidity properties of mechanism in material
designs. In this paper, we design an algorithm which solves this problem. It is
based on the computations of critical points as well as roadmaps for answering
connectivity queries in real algebraic sets. This leads to a probabilistic
algorithm of complexity $(nd)^{O(n\log(n))}$ for computing the real isolated
points of real algebraic hypersurfaces of degree $d$. It allows us to solve in
practice instances which are out of reach of the state-of-the-art.
</p></div>
    </summary>
    <updated>2020-08-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10316</id>
    <link href="http://arxiv.org/abs/2008.10316" rel="alternate" type="text/html"/>
    <title>A Strategic Routing Framework and Algorithms for Computing Alternative Paths</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bl=auml=sius:Thomas.html">Thomas Bläsius</a>, Maximilian Böther, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischbeck:Philipp.html">Philipp Fischbeck</a>, Tobias Friedrich, Alina Gries, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/H=uuml=ffner:Falk.html">Falk Hüffner</a>, Otto Kißig, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lenzner:Pascal.html">Pascal Lenzner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molitor:Louise.html">Louise Molitor</a>, Leon Schiller, Armin Wells, Simon Wietheger <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10316">PDF</a><br/><b>Abstract: </b>Traditional navigation services find the fastest route for a single driver.
Though always using the fastest route seems desirable for every individual,
selfish behavior can have undesirable effects such as higher energy consumption
and avoidable congestion, even leading to higher overall and individual travel
times. In contrast, strategic routing aims at optimizing the traffic for all
agents regarding a global optimization goal. We introduce a framework to
formalize real-world strategic routing scenarios as algorithmic problems and
study one of them, which we call Single Alternative Path (SAP), in detail.
There, we are given an original route between a single origin--destination
pair. The goal is to suggest an alternative route to all agents that optimizes
the overall travel time under the assumption that the agents distribute among
both routes according to a psychological model, for which we introduce the
concept of Pareto-conformity. We show that the SAP problem is NP-complete, even
for such models. Nonetheless, assuming Pareto-conformity, we give multiple
algorithms for different variants of SAP, using multi-criteria shortest path
algorithms as subroutines. Moreover, we prove that several natural models are
in fact Pareto-conform. The implementation of our algorithms serves as a proof
of concept, showing that SAP can be solved in reasonable time even though the
algorithms have exponential running time in the worst case.
</p></div>
    </summary>
    <updated>2020-08-25T23:27:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10280</id>
    <link href="http://arxiv.org/abs/2008.10280" rel="alternate" type="text/html"/>
    <title>Extending Partial Orthogonal Drawings</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angelini:Patrizio.html">Patrizio Angelini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rutter:Ignaz.html">Ignaz Rutter</a>, Sandhya T P <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10280">PDF</a><br/><b>Abstract: </b>We study the planar orthogonal drawing style within the framework of partial
representation extension. Let $(G,H,{\Gamma}_H )$ be a partial orthogonal
drawing, i.e., G is a graph, $H\subseteq G$ is a subgraph and ${\Gamma}_H$ is a
planar orthogonal drawing of H. We show that the existence of an orthogonal
drawing ${\Gamma}_G$ of $G$ that extends ${\Gamma}_H$ can be tested in linear
time. If such a drawing exists, then there also is one that uses $O(|V(H)|)$
bends per edge. On the other hand, we show that it is NP-complete to find an
extension that minimizes the number of bends or has a fixed number of bends per
edge.
</p></div>
    </summary>
    <updated>2020-08-25T23:32:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10223</id>
    <link href="http://arxiv.org/abs/2008.10223" rel="alternate" type="text/html"/>
    <title>An Optimal Separation of Randomized and Quantum Query Complexity</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a>, Andrey A. Storozhenko, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Pei.html">Pei Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10223">PDF</a><br/><b>Abstract: </b>We prove that for every decision tree, the absolute values of the Fourier
coefficients of given order $\ell\geq1$ sum to at most
$c^{\ell}\sqrt{\binom{d}{\ell}(1+\log n)^{\ell-1}},$ where $n$ is the number of
variables, $d$ is the tree depth, and $c&gt;0$ is an absolute constant. This bound
is essentially tight and settles a conjecture due to Tal (arxiv 2019; FOCS
2020). The bounds prior to our work degraded rapidly with $\ell,$ becoming
trivial already at $\ell=\sqrt{d}.$
</p>
<p>As an application, we obtain, for any positive integer $k,$ a partial
function on $n$ bits that has bounded-error quantum query complexity at most
$\lceil k/2\rceil$ and randomized query complexity $\tilde{\Omega}(n^{1-1/k}).$
This separation of bounded-error quantum versus randomized query complexity is
best possible, by the results of Aaronson and Ambainis (STOC 2015). Prior to
our work, the best known separation was polynomially weaker: $O(1)$ versus
$n^{2/3-\epsilon}$ for any $\epsilon&gt;0$ (Tal, FOCS 2020).
</p></div>
    </summary>
    <updated>2020-08-25T23:20:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10192</id>
    <link href="http://arxiv.org/abs/2008.10192" rel="alternate" type="text/html"/>
    <title>Polygons with Prescribed Angles in 2D and 3D</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Efrat:Alon.html">Alon Efrat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fulek:Radoslav.html">Radoslav Fulek</a>, Stephen Kobourov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10192">PDF</a><br/><b>Abstract: </b>We consider the construction of a polygon $P$ with $n$ vertices whose turning
angles at the vertices are given by a sequence $A=(\alpha_0,\ldots,
\alpha_{n-1})$, $\alpha_i\in (-\pi,\pi)$, for $i\in\{0,\ldots, n-1\}$. The
problem of realizing $A$ by a polygon can be seen as that of constructing a
straight-line drawing of a graph with prescribed angles at vertices, and hence,
it is a special case of the well studied problem of constructing an \emph{angle
graph}.
</p>
<p>In 2D, we characterize sequences $A$ for which every generic polygon
$P\subset \mathbb{R}^2$ realizing $A$ has at least $c$ crossings, for every
$c\in \mathbb{N}$, and describe an efficient algorithm that constructs, for a
given sequence $A$, a generic polygon $P\subset \mathbb{R}^2$ that realizes $A$
with the minimum number of crossings.
</p>
<p>In 3D, we describe an efficient algorithm that tests whether a given sequence
$A$ can be realized by a (not necessarily generic) polygon $P\subset
\mathbb{R}^3$, and for every realizable sequence the algorithm finds a
realization.
</p></div>
    </summary>
    <updated>2020-08-25T23:34:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10062</id>
    <link href="http://arxiv.org/abs/2008.10062" rel="alternate" type="text/html"/>
    <title>Streaming Submodular Matching Meets the Primal-Dual Method</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Roie.html">Roie Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10062">PDF</a><br/><b>Abstract: </b>We study streaming submodular maximization subject to matching/$b$-matching
constraints (MSM/MSbM), and present improved upper and lower bounds for these
problems. On the upper bounds front, we give primal-dual algorithms achieving
the following approximation ratios.
</p>
<p>$\bullet$ $3+2\sqrt{2}\approx 5.828$ for monotone MSM, improving the previous
best ratio of $7.75$.
</p>
<p>$\bullet$ $4+3\sqrt{2}\approx 7.464$ for non-monotone MSM, improving the
previous best ratio of $9.899$.
</p>
<p>$\bullet$ $3+\epsilon$ for maximum weight b-matching, improving the previous
best ratio of $4+\epsilon$.
</p>
<p>On the lower bounds front, we improve on the previous best lower bound of
$\frac{e}{e-1}\approx 1.582$ for MSM, and show ETH-based lower bounds of
$\approx 1.914$ for polytime monotone MSM streaming algorithms.
</p>
<p>Our most substantial contributions are our algorithmic techniques. We show
that the (randomized) primal-dual method, which originated in the study of
maximum weight matching (MWM), is also useful in the context of MSM. To our
knowledge, this is the first use of primal-dual based analysis for streaming
submodular optimization. We also show how to reinterpret previous algorithms
for MSM in our framework; hence, we hope our work is a step towards unifying
old and new techniques for streaming submodular maximization, and that it paves
the way for further new results.
</p></div>
    </summary>
    <updated>2020-08-25T23:22:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.10052</id>
    <link href="http://arxiv.org/abs/2008.10052" rel="alternate" type="text/html"/>
    <title>Node-Connectivity Terminal Backup, Separately-Capacitated Multiflow, and Discrete Convexity</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hirai:Hiroshi.html">Hiroshi Hirai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ikeda:Motoki.html">Motoki Ikeda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.10052">PDF</a><br/><b>Abstract: </b>The terminal backup problems (Anshelevich and Karagiozova (2011)) form a
class of network design problems: Given an undirected graph with a requirement
on terminals, the goal is to find a minimum cost subgraph satisfying the
connectivity requirement. The node-connectivity terminal backup problem
requires a terminal to connect other terminals with a number of node-disjoint
paths. This problem is not known whether is NP-hard or tractable. Fukunaga
(2016) gave a $4/3$-approximation algorithm based on LP-rounding scheme using a
general LP-solver. In this paper, we develop a combinatorial algorithm for the
relaxed LP to find a half-integral optimal solution in $O(m\log (nUA)\cdot
\operatorname{MF}(kn,m+k^2n))$ time, where $n$ is the number of nodes, $m$ is
the number of edges, $k$ is the number of terminals, $A$ is the maximum
edge-cost, $U$ is the maximum edge-capacity, and $\operatorname{MF}(n',m')$ is
the time complexity of a max-flow algorithm in a network with $n'$ nodes and
$m'$ edges. The algorithm implies that the $4/3$-approximation algorithm for
the node-connectivity terminal backup problem is also efficiently implemented.
For the design of algorithm, we explore a connection between the
node-connectivity terminal backup problem and a new type of a multiflow, called
a separately-capacitated multiflow. We show a min-max theorem which extends
Lov\'{a}sz-Cherkassky theorem to the node-capacity setting. Our results build
on discrete convexity in the node-connectivity terminal backup problem.
</p></div>
    </summary>
    <updated>2020-08-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.09921</id>
    <link href="http://arxiv.org/abs/2008.09921" rel="alternate" type="text/html"/>
    <title>Digraphs Homomorphism Problems with Maltsev Condition</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kinne:Jeff.html">Jeff Kinne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Murali:Ashwin.html">Ashwin Murali</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Arash.html">Arash Rafiey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09921">PDF</a><br/><b>Abstract: </b>We consider a generalization of finding a homomorphism from an input digraph
$G$ to a fixed digraph $H$, HOM($H$). In this setting, we are given an input
digraph $G$ together with a list function from $G$ to $2^H$. The goal is to
find a homomorphism from $G$ to $H$ with respect to the lists if one exists.
</p>
<p>We show that if the list function is a Maltsev polymorphism then deciding
whether $G$ admits a homomorphism to $H$ is polynomial time solvable. In our
approach, we only use the existence of the Maltsev polymorphism. Furthermore,
we show that deciding whether a relational structure $\mathcal{R}$ admits a
Maltsev polymorphism is a special case of finding a homormphism from a graph
$G$ to a graph $H$ and a list function with a Maltsev polymorphism. Since the
existence of Maltsev is not required in our algorithm, we can decide in
polynomial time whether the relational structure $\mathcal{R}$ admits Maltsev
or not.
</p>
<p>We also discuss forbidden obstructions for the instances admitting Maltsev
list polymorphism. We have implemented our algorithm and tested on instances
arising from linear equations, and other types of instances.
</p></div>
    </summary>
    <updated>2020-08-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.09877</id>
    <link href="http://arxiv.org/abs/2008.09877" rel="alternate" type="text/html"/>
    <title>Improved Weighted Additive Spanners</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Michael.html">Michael Elkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gitlitz:Yuval.html">Yuval Gitlitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neiman:Ofer.html">Ofer Neiman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09877">PDF</a><br/><b>Abstract: </b>Graph spanners and emulators are sparse structures that approximately
preserve distances of the original graph. While there has been an extensive
amount of work on additive spanners, so far little attention was given to
weighted graphs. Only very recently
\cite{DBLP:journals/corr/abs-1907-11422,DBLP:journals/corr/abs-2002-07152}
extended the classical +2 (respectively, +4) spanners for unweighted graphs of
size $O(n^{3/2})$ (resp., $O(n^{7/5})$) to the weighted setting, where the
additive error is $+2W$ (resp., $+4W$). This means that for every pair $u,v$,
the additive stretch is at most $+2W_{u,v}$, where $W_{u,v}$ is the maximal
edge weight on the shortest $u-v$ path (weights are normalized so that the
minimum edge weight is 1). In addition,
\cite{DBLP:journals/corr/abs-2002-07152} showed a randomized algorithm yielding
a $+8W_{max}$ spanner of size $O(n^{4/3})$, here $W_{max}$ is the maximum edge
weight in the entire graph.
</p>
<p>In this work we improve the latter result by devising a simple deterministic
algorithm for a $+(6+\varepsilon)W$ spanner for weighted graphs with size
$O(n^{4/3})$ (for any constant $\varepsilon&gt;0$), thus nearly matching the
classical +6 spanner of size $O(n^{4/3})$ for unweighted graphs. We also show a
simple randomized algorithm for a $+4W$ emulator of size $\tilde{O}(n^{4/3})$.
</p></div>
    </summary>
    <updated>2020-08-25T23:26:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.09822</id>
    <link href="http://arxiv.org/abs/2008.09822" rel="alternate" type="text/html"/>
    <title>On the Size of Minimal Separators for Treedepth Decomposition</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Zijian.html">Zijian Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suppakitpaisarn:Vorapong.html">Vorapong Suppakitpaisarn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09822">PDF</a><br/><b>Abstract: </b>We give a conjecture that we still have an optimal treedepth decomposition
even we use only minimal separators no larger than the treewidth of input
graphs. Then, we give some theoretical results for the conjecture. Treedepth
decomposition has several practical applications and can be used to speed up
many parameterized algorithms. There are several works aiming to give a
scalable and exact method for the decomposition. Those include works based on a
set of all minimal separators. In our experiments with several graphs, when we
consider only minimal separators which are no larger than treewidth, we can
significantly speed up the decomposition while still have an optimal treedepth
decomposition. By the conjecture, we solve more instances than any algorithm
submitted to PACE 2020. Theoretically, we prove that the conjecture for many
classes of graphs. We also prove a relaxed version of the conjecture that the
size of the separators should not be larger than $2 \cdot tw + 1$ when $tw$ is
the treewidth.
</p></div>
    </summary>
    <updated>2020-08-25T23:21:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.09806</id>
    <link href="http://arxiv.org/abs/2008.09806" rel="alternate" type="text/html"/>
    <title>Structural Parameterizations of Tracking Paths Problem</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choudhary:Pratibha.html">Pratibha Choudhary</a>, Venkatesh Raman <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09806">PDF</a><br/><b>Abstract: </b>Given a graph $G$ with source and destination vertices $s,t\in V(G)$
respectively, \textsc{Tracking Paths} asks for a minimum set of vertices
$T\subseteq V(G)$, such that the sequence of vertices encountered in each
simple path from $s$ to $t$ is unique. The problem was proven \textsc{NP}-hard
\cite{tr-j} and was found to admit a quadratic kernel when parameterized by the
size of the desired solution \cite{quadratic}. Following recent trends, for the
first time, we study \textsc{Tracking Paths} with respect to structural
parameters of the input graph, parameters that measure how far the input graph
is, from an easy instance. We prove that \textsc{Tracking Paths} admits
fixed-parameter tractable (\textsc{FPT}) algorithms when parameterized by the
size of vertex cover, and the size of cluster vertex deletion set for the input
graph.
</p></div>
    </summary>
    <updated>2020-08-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.09660</id>
    <link href="http://arxiv.org/abs/2008.09660" rel="alternate" type="text/html"/>
    <title>Deletion to Induced Matching</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Akash.html">Akash Kumar</a>, Mithilesh Kumar <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09660">PDF</a><br/><b>Abstract: </b>In the DELETION TO INDUCED MATCHING problem, we are given a graph $G$ on $n$
vertices, $m$ edges and a non-negative integer $k$ and asks whether there
exists a set of vertices $S \subseteq V(G) $ such that $|S|\le k$ and the size
of any connected component in $G-S$ is exactly 2. In this paper, we provide a
fixed-parameter tractable (FPT) algorithm of running time $O^*(1.748^{k})$ for
the DELETION TO INDUCED MATCHING problem using branch-and-reduce strategy and
path decomposition. We also extend our work to the exact-exponential version of
the problem.
</p></div>
    </summary>
    <updated>2020-08-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.09654</id>
    <link href="http://arxiv.org/abs/2008.09654" rel="alternate" type="text/html"/>
    <title>Metrics and Ambits and Sprawls, Oh My</title>
    <feedworld_mtime>1598313600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hetland:Magnus_Lie.html">Magnus Lie Hetland</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09654">PDF</a><br/><b>Abstract: </b>A follow-up to my previous tutorial on metric indexing, this paper walks
through the classic structures, placing them all in the context of the recently
proposed "sprawl of ambits" framework. The indexes are presented as
configurations of a single, more general structure, all queried using the same
search procedure.
</p></div>
    </summary>
    <updated>2020-08-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7790</id>
    <link href="https://windowsontheory.org/2020/08/24/highlights-of-algorithms-halg-free-aug-31-sep-2/" rel="alternate" type="text/html"/>
    <title>Highlights of Algorithms (HALG) -free – Aug 31- Sep 2</title>
    <summary>[Guest post by Yossi Azar] The 5th Highlights of Algorithms conference (HALG 2020) will take place Aug 31- Sep 2, 2020. http://highlightsofalgorithms.org/ The Highlights of Algorithms conference is a forum for presenting the highlights of recent developments in algorithms and for discussing potential further advances in this area. The conference will provide a broad picture […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post by Yossi Azar]</em></p>



<p>The 5th <strong>Highlights of Algorithms conference (HALG 2020)</strong> will take place Aug 31- Sep 2, 2020. <a href="http://highlightsofalgorithms.org/" rel="noreferrer noopener" target="_blank">http://highlightsofalgorithms.org/</a></p>



<p>The Highlights of Algorithms conference is a forum for presenting the highlights of recent developments in algorithms and for discussing potential further advances in this area. The conference will provide a broad picture of the latest research in algorithms through a series of invited talks, as well as short talks. <br/>Invited talks includes top algorithmic surveys and papers from FOCS/STOC/SODA/COLT/PODC/SPAA/ITCS/PODS (2019-20)</p>



<p><br/>PROGRAM<br/>The conference will take place online on Mon, Aug 31-Wed, Sep 2 from 12:00 noon until 19:30 CEST (Europe time) <a href="http://highlightsofalgorithms.org/programme" rel="noreferrer noopener" target="_blank">http://highlightsofalgorithms.org/programme</a></p>



<p>The short contributed talk are on Sep 1-2, 9:45-11:30 CEST <a href="http://highlightsofalgorithms.org/shorttalks" rel="noreferrer noopener" target="_blank">http://highlightsofalgorithms.org/shorttalks</a></p>



<p>REGISTRATION<br/>Registration is free but mandatory<br/>Please register on our webpage: <a href="https://highlightsofalgorithms2020.ethz.ch/registration" rel="noreferrer noopener" target="_blank">https://highlightsofalgorithms2020.ethz.ch/registration</a></p></div>
    </content>
    <updated>2020-08-24T19:17:23Z</updated>
    <published>2020-08-24T19:17:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-08-26T19:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/</id>
    <link href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/" rel="alternate" type="text/html"/>
    <title>IDEAL Special Quarter (Theory of Deep Learning)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 21 – December 12, 2020 Online (https://www.ideal.northwestern.edu/special-quarters/fall-2020/) https://www.ideal.northwestern.edu/special-quarters/fall-2020/registration There will be a Special Quarter on Theory of Deep Learning this Fall as a part of IDEAL – The Institute for Data, Econometrics, Algorithms, and Learning, runs jointly with TTIC and the University of Chicago. The Special Quarter will be entirely online, and take place … <a class="more-link" href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/">Continue reading <span class="screen-reader-text">IDEAL Special Quarter (Theory of Deep Learning)</span></a></div>
    </summary>
    <updated>2020-08-24T16:02:27Z</updated>
    <published>2020-08-24T16:02:27Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-26T19:21:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1663724076500583508</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1663724076500583508/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/08/sharp-p-and-issue-of-natural-problems.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1663724076500583508" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1663724076500583508" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/08/sharp-p-and-issue-of-natural-problems.html" rel="alternate" type="text/html"/>
    <title>Sharp P and the issue of `natural problems'</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> #P was defined by Valiant as a way to pin down that the PERMANENT of a matrix is hard to compute.</p><p>The definition I give is equivalent to the one Valiant gave.</p><p>g is in #P if there exists p a poly and B in P such that</p><p>g(x) = | { y : |y| = p(|x|) and (x,y) \in B } |</p><p>A function f is #P-complete if g is in #P and for all g in #P,  f is poly-Turing reducible to g.</p><p>#SAT is the function that, given a formula, returns the number of satisfying assignments. It is #P-complete by looking at the proof the Cook-Levin Theorem. The reduction of f to #SAT only makes one query to #SAT. A common way to show that #A is #P-complete is to show that SAT \le A with a reduction that preserves the number of solutions. </p><p>Valiant proved that PERM was #P-complete (his reduction only used 1 call to PERM).</p><p>There are problems in P whose #-version is #-P complete: Matching and DNF-SAT are two of them.</p><p>Notice that I defined #SAT directly, not in terms of a poly p and a set B as above. Here is why: if you use poly p and set B one can do obnoxious things like: </p><p>SAT = { phi : exists yz 2n-bits long such that phi(y)=T and z is prime }</p><p>The # version of this definition is not really what I want (though I am sure its #P-complete).</p><p>Valiant (see <a href="https://www.math.cmu.edu/~af1p/Teaching/MCC17/Papers/enumerate.pdf">here</a> and <a href="http://www.math.cmu.edu/~af1p/Teaching/MCC17/Papers/permanent.pdf">here</a>) and Simon (see <a href="https://link.springer.com/content/pdf/10.1007%2F3-540-08342-1_37.pdf">here</a>) showed that  for many known NPC-problems A, #A is #P-complete. They meant NATURAL problems. Is it true for all natural NP-complete problems?</p><p>Unfortunately the statement `All NATURAL NPC problems give rise to #P-complete functions' is hard (impossible?) to state rigorously and hence hard (impossible?) to prove. </p><p>1) Is there a natural A in NP such that #A is NOT #P-complete (under assumptions)?</p><p>2) Are there any theorems that show a large set of NPC problems have #P counterparts? Or are we doomed to, when we want to show some #A is #P-complete, come up with a new proof?</p><p>3) Can one PROVE there are NPC problems A such that #A is NOT #P-complete? (under assumptions).</p></div>
    </content>
    <updated>2020-08-24T01:40:00Z</updated>
    <published>2020-08-24T01:40:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-26T19:20:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron</id>
    <link href="https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron.html" rel="alternate" type="text/html"/>
    <title>Bricard’s jumping octahedron</title>
    <summary>The Schönhardt polyhedron is a non-convex octahedron that can be formed from a convex regular octahedron by twisting two opposite faces, stretching and deforming the other faces as you twist. It’s well known for not having any interior diagonals, and for being impossible to subdivide into tetrahedra without introducing new vertices. But long before Erich Schönhardt described it in 1928 in connection with these properties, Raoul Bricard was investigating flexible octahedra, in connection with Cauchy’s theorem on the rigidity of polyhedra. The Schönhardt polyhedron forms an interesting example of flexibility, as I learned from a 1975 collection of lecture notes by Branko Grünbaum on “Lost Mathematics”). I’m not entirely sure that it was known to Bricard (it’s not clear from Bricard’s paper and Grünbaum doesn’t really say so) but it wouldn’t surprise me if it was.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="https://en.wikipedia.org/wiki/Sch%C3%B6nhardt_polyhedron">Schönhardt polyhedron</a> is a non-convex octahedron that can be formed from a convex regular octahedron by twisting two opposite faces, stretching and deforming the other faces as you twist. It’s well known for not having any interior diagonals, and for being impossible to subdivide into tetrahedra without introducing new vertices. But long before Erich Schönhardt described it in 1928 in connection with these properties, Raoul Bricard was investigating <a href="https://en.wikipedia.org/wiki/Bricard_octahedron">flexible octahedra</a>, in connection with <a href="https://en.wikipedia.org/wiki/Cauchy%27s_theorem_(geometry)">Cauchy’s theorem on the rigidity of polyhedra</a>. The Schönhardt polyhedron forms an interesting example of flexibility, as I learned from a 1975 collection of lecture notes by Branko Grünbaum on “<a href="https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/15700/Lost%20Mathematics.pdf?fterence=1">Lost Mathematics</a>”). I’m not entirely sure that it was known to Bricard (it’s not clear from Bricard’s paper and Grünbaum doesn’t really say so) but it wouldn’t surprise me if it was.</p>

<p>Cauchy’s theorem states that the shape of every convex polyhedron is uniquely determined by the shapes and connectivity of its faces. There can be no other convex polyhedron that has faces of the same shape, connected in the same way. But in some cases (like the regular icosahedron) you can dent some of the faces in to make a different, non-convex polyhedron with the same face shapes and connectivity. So Cauchy’s theorem doesn’t immediately extend to non-convex polyhedra. In fact, certain non-convex “<a href="https://en.wikipedia.org/wiki/Flexible_polyhedron">flexible polyhedra</a>” can deform continuously into an infinite range of shapes, without changing the shape or connectivity of their faces. Bricard’s octahedra are self-crossing examples and later investigators found examples without self-crossings.</p>

<p>But Grünbaum describes a different, non-self-crossing non-convex octahedron, the “jumping octahedron”. Rather than having a continuous range of rigid shapes, it has exactly two shapes, both of which have faces of the same shapes and connectivity. Unlike the example of the regular icosahedron and dented icosahedron, the two shapes have dihedral angles that are convex and concave in the same places. If you make this polyhedron out of perfectly rigid faces, with hinged connections at their edges, it could only be in one or the other of its two shapes: you wouldn’t be able to get it to the other shape without taking it apart and rebuilding it. But if you make it out of a material that’s stiff enough to hold its shape but flexible enough to deform a little, you can make a model that jumps or snaps from one shape to the other when you twist it. If you deform it a little out of shape, it will snap back to the nearest of its two valid shapes. Here’s one I made very roughly from some light cardstock and transparent tape, in its two shapes, one with only slightly-concave long diagonals down its sides and the other much more twisted and folded up:</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img alt="Jumping octahedron" src="http://www.ics.uci.edu/~eppstein/pix/jumping-octahedron/1-m.jpg" style="border-style: solid; border-color: black;" width="315"/></td>
<td style="padding: 10px;"><img alt="Jumping octahedron" src="http://www.ics.uci.edu/~eppstein/pix/jumping-octahedron/2-m.jpg" style="border-style: solid; border-color: black;" width="315"/></td>
</tr></tbody></table></div>

<p>My model makes an interesting squelchy sound when I twist it from the more upright shape to the more twisted one, because these two shapes have different volumes and the air has to get out through the cracks between the faces. If I had perfectly sealed all these cracks, the pressure change would prevent it from changing shape. This change in volume is a big contrast from the Bricard octahedra and other continuously-flexible polyhedra, which must maintain constant volume as they flex.</p>

<p>The net I folded it from looks like this:</p>

<p style="text-align: center;"><img alt="Net for jumping octahedron" src="https://11011110.github.io/blog/assets/2020/jumping-octahedron-net.svg"/></p>

<p>It’s in two parts in order to make the seams of my model be symmetric, but also that way it fits better onto a single sheet of paper or card. It consists of two equilateral-triangle faces (the faces at the top and bottom of the model shown above) and six identical obtuse triangles on the sides. In my net and model, these triangles are isosceles, but that’s not important. The important part is that, if one of these triangles is projected onto the line between it and the equilateral triangle, its projected length is slightly more than the length of the connecting edge (because it’s an obtuse triangle) but not too long: longer by a factor strictly between one and</p>

\[\frac{1}{2}+\frac{1}{\sqrt{3}}\approx 1.07735.\]

<p>If you make the projection too short (with a right or acute side triangle shape) then it will not have two different shapes that maintain the same faces and convex-concave relation at each dihedral. If you make the projection too long, then you won’t be able to put it together at all while keeping all the faces flat. An explanation for some of this behavior can be seen from the diagram below, which shows the bottom equilateral triangle and one of the obtuse side triangles of the polyhedron, flattened out into a single plane, from a top view.</p>

<p style="text-align: center;"><img alt="Overhead view of two faces of the jumping octahedron" src="https://11011110.github.io/blog/assets/2020/jumping-octahedron-overhead.svg"/></p>

<p>If you fold these two triangles on their connecting edge, keeping the bottom equilateral triangle fixed but lifting the obtuse triangle into space, then the outer vertex of the obtuse triangle will rotate through a semicircle, but the plane of this semicircle is perpendicular to the plane of view of the diagram, so in top view it just looks like a line, the red line in the diagram. The edge along which the two triangles are attached is the axis of rotation, so it’s perpendicular to the semicircle of rotation and to the projected red line. If you fold all three edges of the bottom equilateral triangle at equal angles, then by symmetry the tips of the three folded obtuse triangles will form another equilateral triangle, and the size of this equilateral triangle will depend on the fold angle. If the vertices of this second equilateral triangle project to points on the yellow circle (the circumcircle of the bottom equilateral triangle) then this triangle will have exactly the correct size to attach the top face. This is only possible when the vertex of the obtuse triangle in the drawing is folded to a point that projects to of the two crossings of the red line and the yellow circle. The two fold angles for which this happens give the two shapes of the jumping octahedron.</p>

<p>The constraint that the side triangles be obtuse is what is needed to make the two crossing points of the red line and the circle be in the same arc of the circle relative to the vertices of the bottom equilateral triangle. The constraint that their projected length should be only a little bit longer than the side length of the equilateral triangle is what is needed to make the red line cross the circle at all. So these two constraints are necessary to make the jumping octahedron work. There’s one more necessary constraint: the height of the obtuse triangle above the edge connecting it to the equilateral triangle has to be large enough to reach both of the crossing points of the red line. When I started to make the model I was worried about a different geometric constraint: maybe the twisted state of the model is so twisted that its inner folded parts cross each other near the center of the model? But that can’t happen. If it did happen, the projected view of the model would have the side triangles folded into a position where they cover the center of the yellow circle. But that would mean that the top triangle’s vertices are too far around the yellow circle, past the point where the farthest point of the red line can cross.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104737012685827990">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-08-22T17:46:00Z</updated>
    <published>2020-08-22T17:46:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-23T07:53:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20013</id>
    <link href="https://gilkalai.wordpress.com/2020/08/22/quantum-matters/" rel="alternate" type="text/html"/>
    <title>Quantum Matters</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A comparison between the Google estimator U for the fidelity and two improved estimators that we studied  MLE (maximum likelihood estimator) and V (a variant of U). (More figures at the end of the post.) Here are some links on … <a href="https://gilkalai.wordpress.com/2020/08/22/quantum-matters/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2020/08/fig_2.jpeg"><img alt="" class="alignnone size-full wp-image-20101" height="472" src="https://gilkalai.files.wordpress.com/2020/08/fig_2.jpeg?w=640&amp;h=472" width="640"/></a></p>
<p><span style="color: #ff0000;">A comparison between the Google estimator U for the fidelity and two improved estimators that we studied  MLE (maximum likelihood estimator) and V (a variant of U). (More figures at the end of the post.)</span></p>
<p>Here are some links on quantum matters. I hope to return to them in more detail in some future posts.</p>
<h2>1. A <a href="https://gilkalai.files.wordpress.com/2019/11/stat-quantum2.pdf">paper</a> with Yosi Rinott and Tomer Shoham on the Statistics of Google’s experiment</h2>
<p>Yosef Rinott, Tomer Shoham and Gil Kalai:  <a href="https://gilkalai.files.wordpress.com/2019/11/stat-quantum2.pdf">Statistical aspects of the quantum supremacy demonstration</a>, (<a href="https://arxiv.org/abs/2008.05177">arXive</a>)</p>
<p><strong>Abstract:</strong></p>
<blockquote><p><span style="color: #0000ff;"><em>The notable claim of quantum supremacy presented by Google’s team in 2019 consists of demonstrating the ability of a quantum circuit to generate, albeit with considerable noise, bitstrings from a distribution that is considered hard to simulate on classical computers. Verifying that the generated data is indeed from the claimed distribution and assessing the circuit’s noise level and its fidelity is a purely statistical undertaking.</em></span></p>
<p><span style="color: #0000ff;"><em>The objective of this paper is to explain the relations between quantum computing and some of the statistical aspects involved in demonstrating quantum supremacy in terms that are accessible to statisticians, computer scientists, and mathematicians.</em></span></p>
<p><span style="color: #0000ff;"><em>Starting with the statistical analysis in Google’s demonstration, which we explain, we study various estimators of the fidelity, and different approaches to testing the distributions generated by the quantum computer. We propose different noise models, and discuss their implications. A preliminary study of the Google data, focusing mostly on circuits of 12 and 14 qubits is discussed throughout the paper.</em></span></p></blockquote>
<p>I am greatly enjoying working with Yosi and Tomer, and I hope to devote a special post to the very interesting statistics of the Google supremacy experiment.</p>
<h2/>
<h2>2. My paper <a href="https://gilkalai.files.wordpress.com/2020/08/laws-blog2.pdf">The Argument against Quantum Computers, the Quantum Laws of Nature, and Google’s Supremacy Claims</a></h2>
<p>Here is how the paper concludes</p>
<blockquote><p><span style="color: #0000ff;"><em>Over the past four decades, the very idea of quantum computation has led to many advances in several areas of physics, engineering, computer science, and mathematics. I expect that the most important application will eventually be the understanding of the impossibility of quantum error-correction and quantum computation. Overall, the debate over quantum computing is a fascinating one, and I can see a clear silver lining: major advances in human ability to simulate quantum physics and quantum chemistry are expected to emerge if quantum computational supremacy can be demonstrated and quantum computers can be built, but also if quantum computational supremacy cannot be demonstrated and quantum computers cannot be built.</em></span></p>
<p><span style="color: #0000ff;"><em>Some of the insights and methods characteristic of the area of quantum computation might be useful for classical computation of realistic quantum systems – which is, apparently, what nature does.</em></span></p></blockquote>
<p> </p>
<p>The link above is the most recent version that will be updated; Here is the <a href="https://arxiv.org/abs/2008.05188">arXive version</a>. A discussion on <a href="https://news.ycombinator.com/item?id=23291071">Hacker News</a>.</p>
<h2/>
<h2>3. My Dec 2019 surprise lecture and the panel discussion</h2>
<p>My Dec  19 2019 (B.C.) surprise lecture at the mathematics of quantum computing school and the afternoon panel on the same day. It turned out that the lecture was videotaped. The slides can be seen in <a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/">this post</a>. Remarkably, social distancing was pioneered by the session chair toward the end of the lecture (while not justified in that case).</p>
<p/>
<p>Here once again again is <a href="https://youtu.be/_Yb7uIGBynU">the link for the panel discussion on quantum supremacy</a> of the same day (<a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/">reviewed here</a>) . Here is a quote of mine from the panel.</p>
<blockquote><p><em><span style="color: #0000ff;">Of course, it is important to think what are the implications of quantum supremacy, is it useful? what does it say on the extended Church-Turing thesis? on prospects for quantum error-correction and universal quantum computers? etc. but I think that in the next few years one thing that we need to also concentrate on is the following question: Is the Google experiment correct? Is this a correct scientific verification of quantum supremacy?</span></em></p></blockquote>
<h2/>
<h2>4. My July 15 USTLC lecture</h2>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/4slides.png"><img alt="" class="alignnone size-full wp-image-20091" height="364" src="https://gilkalai.files.wordpress.com/2020/08/4slides.png?w=640&amp;h=364" width="640"/></a></p>
<p><span style="color: #ff0000;">Four slides from my USTLC zoom lecture</span><span style="color: #ff0000;">. (Click to enlarge.)<br/>
</span></p>
<p>Here is the <a href="https://idc-il.zoom.us/rec/share/4v58MpbZ-CBJG7OO1E3SYYN-P426aaa82ndLr_cMyEgOuIwdOStnnIw18Xsg0dUr?fbclid=IwAR31ShatGHJ1bWpVCdBPUoWhG3VjqmhfD1kQBFVLGzmvtNlWNMW-T58_0dw">videotaped Zoom presentation</a> and <a href="https://gilkalai.files.wordpress.com/2019/11/july1.pptx">here are the slides</a>.</p>
<h2/>
<h2>5. A small taste of quantum poetry for the skeptics. (A full post is coming.)</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/dslide16.png"><img alt="" class="alignnone size-large wp-image-19013" height="362" src="https://gilkalai.files.wordpress.com/2019/12/dslide16.png?w=640&amp;h=362" width="640"/></a></p>
<p><span style="color: #ff0000;">Poems by Peter Shor and Renan Gross (click to enlarge)</span></p>
<p>Peter Shor <a href="https://twitter.com/PeterShor1/status/1199299777743204354">pioneered</a> quantum poetry for the skeptics over Twitter. There were many very nice contributions all over social media by <a href="https://gilkalai.files.wordpress.com/2019/12/dslide16.png">Renan Gross</a>, John Dowling, Nidit Nanda, ⟨dl|yonge|mallo⟩, Alfred Marcel Bruckstein, Kenneth Regan, and others. <strong>Keep the quantum poems coming!</strong> Of course, the poems should be taken with humor. Here is a small taste.</p>
<h3><span style="color: #993366;">My short response to Peter’s poem</span></h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>Understanding nature and ourselves is a worthy dream</em></span><br/>
<span style="color: #0000ff;"><em>Requiring no interaction with the supreme</em></span></h3>
</blockquote>
<h3><span style="color: #993366;">Limericks</span></h3>
<h3>Jon Dowling</h3>
<p><span id="more-20013"/></p>
<blockquote><p><em>A quantum computer from Google,</em><br/>
<em>Turned the Church-Turing thesis to strudel.</em><br/>
<em>And yet there remain,</em><br/>
<em>Many doubting this claim,</em><br/>
<em>And we lash all of them with wet noodles.</em></p></blockquote>
<h3>Avi Wigderson</h3>
<blockquote><p><em>“There once was a quantum computer</em><br/>
<em>Whose pet was a five-legged hamster …”</em><br/>
<em>So Peter and Gil</em><br/>
<em>Their grandchildren will</em><br/>
<em>Tell “…happy they lived ever after”</em></p></blockquote>
<p>Avi suggests a kids’ chorus saying “yeah, right” or “sure, sure”, after each line</p>
<h3><span style="color: #993366;">Six-word stories</span></h3>
<h3>Ehud Friedgut</h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>For sale: <span class="il">quantum</span> computer. Never used.</em></span></h3>
</blockquote>
<h3>Another 6-word story (mine) with a rhyme (of some sort)</h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>Michelson and Morley weren’t </em></span><em><strong><span style="color: #0000ff;">G</span><span style="color: #ff0000;">o</span><span style="color: #ffcc00;">o</span><span style="color: #0000ff;">g</span><span style="color: #339966;">l</span><span style="color: #ff0000;">e</span></strong></em><span style="color: #0000ff;"><em> employees.</em></span></h3>
</blockquote>
<h2/>
<h2>6. More figures from my paper with Yosi and Tomer.</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/plot_3.jpeg"><img alt="" class="alignnone size-full wp-image-20102" height="350" src="https://gilkalai.files.wordpress.com/2020/08/plot_3.jpeg?w=640&amp;h=350" width="640"/></a></p>
<p><span style="color: #ff0000;">Various estimators for the fidelity for the Google data compared to simulations. </span></p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/fig_8.jpeg"><img alt="" class="alignnone size-full wp-image-20103" height="519" src="https://gilkalai.files.wordpress.com/2020/08/fig_8.jpeg?w=640&amp;h=519" width="640"/></a></p>
<p><span style="color: #ff0000;">The model expected values compared to the empirical distribution. On the left for the real data and on the right for simulated data.  As it turned out the Google noise model does not fit for the sample data. (Our readout model provides only a small improvement.)  </span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/hists.jpeg"><img alt="" class="alignnone size-full wp-image-20104" height="249" src="https://gilkalai.files.wordpress.com/2020/08/hists.jpeg?w=640&amp;h=249" width="640"/></a></p>
<p><span style="color: #ff0000;">The size biased distribution fits the model very well.</span></p></div>
    </content>
    <updated>2020-08-22T17:02:49Z</updated>
    <published>2020-08-22T17:02:49Z</published>
    <category term="Quantum"/>
    <category term="Statistics"/>
    <category term="Tomer Shoham"/>
    <category term="Yosi Rinott"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-08-26T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/127</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/127" rel="alternate" type="text/html"/>
    <title>TR20-127 |  $k$-Forrelation Optimally Separates Quantum and Classical Query Complexity | 

	Nikhil Bansal, 

	Makrand Sinha</title>
    <summary>Aaronson and Ambainis (SICOMP '18) showed that any partial function on $N$ bits that can be computed with an advantage $\delta$ over a random guess by making $q$ quantum queries, can also be computed classically with an advantage $\delta/2$ by a randomized decision tree making ${O}_q(N^{1-\frac{1}{2q}}\delta^{-2})$ queries. Moreover, they conjectured the $k$-Forrelation problem --- a partial function that can be computed with $q = \lceil k/2 \rceil$ quantum queries --- to be a suitable candidate for exhibiting such an extremal separation. 
    
     We prove their conjecture by showing a tight lower bound of $\widetilde{\Omega}_k(N^{1-1/k})$ for the randomized query complexity of $k$-Forrelation, where the advantage $\delta = 1/\mathrm{polylog}^k(N)$ and $\widetilde{\Omega}_k$ hides $\mathrm{polylog}^k(N)$ factors. Our proof relies on classical Gaussian tools, in particular, Gaussian interpolation and Gaussian integration by parts, and in fact, shows a more general statement, that to prove lower bounds for $k$-Forrelation against a family of functions, it suffices to bound the $\ell_1$-weight of the Fourier coefficients at levels $k, 2k, 3k, \ldots, (k-1)k$ for functions in the family.</summary>
    <updated>2020-08-21T19:02:19Z</updated>
    <published>2020-08-21T19:02:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-26T19:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/21/phd-or-postdoc-at-goethe-university-frankfurt-apply-by-august-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/21/phd-or-postdoc-at-goethe-university-frankfurt-apply-by-august-31-2020/" rel="alternate" type="text/html"/>
    <title>PhD or Postdoc at Goethe University Frankfurt (apply by August 31, 2020)</title>
    <summary>The research group by Holger Dell at Goethe University Frankfurt is inviting applications for a three-year PhD or Postdoc position, starting at the earliest possible date. Potential topics include the algorithmic theory of network science, algebraic graph algorithms, fine-grained and parameterized complexity, “classical” complexity theory, as well as adjacent areas. Website: https://www.t.cs.uni-frankfurt.de/positions/ Email: recruiting2020@holgerdell.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The research group by Holger Dell at Goethe University Frankfurt is inviting applications for a three-year PhD or Postdoc position, starting at the earliest possible date. Potential topics include the algorithmic theory of network science, algebraic graph algorithms, fine-grained and parameterized complexity, “classical” complexity theory, as well as adjacent areas.</p>
<p>Website: <a href="https://www.t.cs.uni-frankfurt.de/positions/">https://www.t.cs.uni-frankfurt.de/positions/</a><br/>
Email: recruiting2020@holgerdell.com</p></div>
    </content>
    <updated>2020-08-21T14:41:55Z</updated>
    <published>2020-08-21T14:41:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-26T19:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17421</id>
    <link href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/" rel="alternate" type="text/html"/>
    <title>Logical Complexity of Proofs</title>
    <summary>If you cannot find proofs, talk about them. Robert Reckhow with his advsior Stephen Cook famously started the formal study of the complexity of proofs with their 1979 paper. They were interested in the length of the shortest proofs of propositional statements. Georg Kreisel and others may have looked at proof length earlier, but one […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>If you cannot find proofs, talk about them.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/rr/" rel="attachment wp-att-17427"><img alt="" class="alignright size-medium wp-image-17427" height="119" src="https://rjlipton.files.wordpress.com/2020/08/rr.png?w=300&amp;h=119" width="300"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Robert Reckhow with his advsior Stephen Cook famously started the formal study of the complexity of proofs with their 1979 <a href="https://www.cs.toronto.edu/~sacook/homepage/cook_reckhow.pdf">paper</a>. They were interested in the length of the shortest <a href="https://en.wikipedia.org/wiki/Proof_complexity">proofs</a> of propositional statements. Georg Kreisel and others may have looked at proof length earlier, but one of the key insights of Reckhow and Cook is that low level propositional logic is important.</p>
<p>
Today I thought we might look at the complexity of proofs.</p>
<p>
Cook and Reckhow were motivated by issues like: How hard is it to prove that a graph has no clique of a certain size? Or how hard to prove that some program halts on all inputs of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>? All of these questions ask about the length of proofs in a precise sense. Proofs have been around forever, back to Euclid at least, but Cook and Reckhow were the first to formally study the lengths of proofs. </p>
<p>
They were not directly interested in actual proofs. The kind you can find in the <a href="https://arxiv.org/archive/math">arXiv</a> or in a math journal, or at a conference—online or not. The kind that are in their paper.<br/>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/paper-5/" rel="attachment wp-att-17432"><img alt="" class="aligncenter size-medium wp-image-17432" height="60" src="https://rjlipton.files.wordpress.com/2020/08/paper.png?w=300&amp;h=60" width="300"/></a></p>
<p>We are talking today about these types of proofs. Not proofs that graphs have cliques. But proofs that a no planar graph can have a <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/> clique. </p>
<p><a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/unknown-144/" rel="attachment wp-att-17430"><img alt="" class="aligncenter size-full wp-image-17430" src="https://rjlipton.files.wordpress.com/2020/08/unknown.png?w=600"/></a></p>
<p>
</p><p/><h2> Proofs </h2><p/>
<p/><p>
Proofs are what we strive to find ever day. They the coin that measures progress in a mathematical field like complexity theory. We do sometimes work out examples, sometimes do computations to confirm conjectures on small examples, sometimes consider analogies to other proofs. But mostly we want to understand proofs. We want to create new ones and understand others proofs. </p>
<p>
Years ago when studying the graph isomorphism problem, I did some extensive computations for the random case. That is for the case of isomorphism for a random dense graphs against a worst case other graph. The computations helped me improve my result. It did not yield a proof, of course, but helped me realize that a certain lemma could be improved from a bound <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> to <img alt="{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(1)}"/>. My results were dominated by <a href="https://www.researchgate.net/profile/Stanley_Selkow/publication/220618511_Random_Graph_Isomorphism/links/00463537d337e6a35d000000/Random-Graph-Isomorphism.pdf">paper</a> of Laszlo Babai, Paul Erdös, and Stanley Selkow. Oh well. </p>
<p>
</p><p/><h2> Proofs Complexity </h2><p/>
<p/><p>
There are several measures of complexity for proofs. One is the length. Long proofs are difficult to find, difficult to write up, difficult to read, and difficult to check. Another less obvious measure is the logical structure of a proof. What does this mean?</p>
<p>
Our idea is that a proof can be modeled by a formula from propositional logic. The <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> is what we are trying to prove and the letters <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and so on are for statements we already know.  </p>
<li>
<img alt="{(A \rightarrow P)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A \rightarrow P)}"/>  This is a direct proof. <p/>
</li><li>
<img alt="{(\neg P \rightarrow \neg A)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cneg+P+%5Crightarrow+%5Cneg+A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\neg P \rightarrow \neg A)}"/>  This is a proof by contradiction. <p/>
</li><li>
<img alt="{( A \vee \neg A \rightarrow P)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28+A+%5Cvee+%5Cneg+A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{( A \vee \neg A \rightarrow P)}"/>  This is proof that uses a statement <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> that may be true or false. <p/>
<p>
The last is a slight cheat, we use <img alt="{A \vee \neg A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cvee+%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \vee \neg A}"/> to stand for a kind of axiom. A perfect example is from number theory. Let <img alt="{\pi(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi(X)}"/> be the number of primes less than <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and the function <img alt="{li(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{li(x)}"/> the <a href="https://en.wikipedia.org/w/index.php?title=Logarithmic_integral_function&amp;action=edit&amp;section=1">logarithmic function</a>. 	</p>
<p align="center"><img alt="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%3D+%5Cint_0%5Ex+%5Cfrac%7Bdt%7D%7B%5Cln+t%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. "/></p>
<p>The prime number <a href="https://en.wikipedia.org/wiki/Prime_number_theorem">theorem</a> says that 	</p>
<p align="center"><img alt="\displaystyle  \pi(x) = li(x) + E(x), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+%3D+li%28x%29+%2B+E%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) = li(x) + E(x), "/></p>
<p>an error term. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/graph/" rel="attachment wp-att-17425"><img alt="" class="aligncenter size-medium wp-image-17425" height="171" src="https://rjlipton.files.wordpress.com/2020/08/graph.png?w=300&amp;h=171" width="300"/></a>
</td>
</tr>
<tr>
</tr>
</tbody></table>
<p>
It was noted that <img alt="{li(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{li(x)}"/> is larger than <img alt="{\pi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi(x)}"/> for known values. The obvious question was that could 	</p>
<p align="center"><img alt="\displaystyle  li(x) \ge \pi(x), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%5Cge+%5Cpi%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  li(x) \ge \pi(x), "/></p>
<p>be always true? If so this would be an interesting inequality. In 1914 John Littlewood famously <a href="https://www.google.com/books/edition/_/2SUrpE8NK6sC?hl=en&amp;gbpv=1&amp;pg=PA33&amp;dq=John+Littlewood+pi+nd+li">proved</a> that this was not true: </p>
<blockquote><p><b>Theorem 1</b> <em> If the Riemann Hypothesis is true: 	</em></p><em>
<p align="center"><img alt="\displaystyle  \pi(x) - li(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) - li(x) "/></p>
<p>is infinitely often positive and negative. If the Riemann Hypothesis is false: 	</p>
<p align="center"><img alt="\displaystyle  \pi(x) - li(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) - li(x) "/></p>
</em><p><em>is infinitely often positive and negative. </em>
</p></blockquote>
<p/><p>
Thus he proved that 	</p>
<p align="center"><img alt="\displaystyle  \pi(x) - li(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) - li(x) "/></p>
<p>is infinitely often positive and negative whether the the Riemann is true or not. </p>
<p>
</p><p/><h2> Proofs in Trouble </h2><p/>
<p/><p>
A sign of a proof in danger is, in my opinion, is not just the length. A better measure I think is the logical flow of proof. I know of no actual proof that uses this structure: 	</p>
<p align="center"><img alt="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28A+%5Crightarrow+B%29+%5Crightarrow+%28%28A+%5Cvee+C%29+%5Crightarrow+%28B+%5Cvee+C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) "/></p>
<p>Do you? Even if your proof is only a few lines or even pages, if the high level flow was the above tautology I would be worried. </p>
<p>
Another example is <img alt="{P \rightarrow P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%5Crightarrow+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P \rightarrow P}"/>. This of course is a circular proof. It seems hard to believe we would actually do this, but it has happen. The key is that no one says: I will assume the theorem to prove it. The flaw is disguised better than that.</p>
<p>
I cannot formally define this measure. Perhaps it is known, but I do think that it would be an additional measure. For actual proofs, ones we use every day, perhaps it would be valuable. I know I have looked at an attempted proof of X and noticed the logical flow in this sense was too complex. So complex that it was wrong. The author of the potential proof was me. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is this measure, the logical flow of a proof, of any interest? </p>
<p/></li></font></font></div>
    </content>
    <updated>2020-08-19T13:00:52Z</updated>
    <published>2020-08-19T13:00:52Z</published>
    <category term="Oldies"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="complexity proof"/>
    <category term="Logic"/>
    <category term="logical flow"/>
    <category term="proof length"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-26T19:20:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-41257542542066199</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/41257542542066199/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=41257542542066199" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/41257542542066199" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/41257542542066199" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2020/08/moment-multicalibration-for-uncertainty.html" rel="alternate" type="text/html"/>
    <title>Moment Multicalibration for Uncertainty Estimation</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This blog post is about<a href="https://arxiv.org/abs/2008.08037" target="_blank"> a new paper</a> that I'm excited about, which is joint work with <a href="https://www.cis.upenn.edu/~chrjung/" target="_blank">Chris Jung</a>,<a href="https://economics.sas.upenn.edu/people/changhwa-lee" target="_blank"> Changhwa Lee</a>, <a href="https://sites.google.com/view/malleshpai/">Mallesh Pai</a>, and <a href="https://sites.google.com/site/quaerereverum9/">Ricky Vohra</a>. <div><br/></div><div>Suppose you are diagnosed with hypertension, and your doctor recommends that you take a certain drug to lower your blood pressure. The latest research, she tells you, finds that the drug lowers diastolic blood pressure by an average of 10 mm Hg. You remember your statistics class from college, and so you ask about confidence intervals. She looks up the paper, and tells you that it reports a 95% confidence interval of [5, 15]. How should you interpret this? </div><div><br/></div><div>What you might naively hope is that [5, 15] represents a <i>conditional prediction interval</i>. If you have some set of observable features $x$, and a label $y$ (in this case corresponding to your decrease in diastolic blood pressure after taking the drug), a 95% conditional prediction interval would promise that:</div><div>$$\Pr_y [y \in [5, 15] | x] \geq 0.95$$</div><div><br/></div><div>In other words, a conditional prediction interval would promise that given all of your observed features, <i>over the unrealized/unmeasured randomness of the world</i>, there is a 95% chance that your diastolic blood pressure will decrease by between 5 and 15 points. </div><div><br/></div><div>But if you think about it, coming up with a conditional prediction interval is essentially impossible in a rich feature space. If $x$ contains lots of information about you, then probably there was nobody in the original study population that exactly matched your set of features $x$, and so we have no information at all about the conditional distribution on $y$ given $x$ --- i.e. no samples at all from the distribution over which our coverage probability supposedly holds! So how can you expect any sort of promise at all? There are two typical ways around this difficulty. </div><div><br/></div><div>The first is to make heroic assumptions about the data generation process. For example, if we assume that the world looks like an ordinary least squares model, and that there is a linear relationship between $y$ and $x$, then we can form a confidence region around the parameters of the model, and from that derive prediction intervals. But these prediction intervals are not valid if the model fails to hold, which it inevitably will. </div><div><br/></div><div>The second is to give up on conditional prediction intervals, and instead give <i>marginal prediction intervals</i>. This is what the <a href="https://arxiv.org/abs/0706.3188" target="_blank">conformal prediction</a> literature aims to do. A marginal prediction interval looks quite similar to a conditional prediction interval (at least syntactically), and promises:</div><div>$$\Pr_{(x,y)} [y \in [5, 15] ] \geq 0.95$$</div><div><br/></div><div>Rather than conditioning on your features $x$, a marginal prediction interval averages over all people, and promises that 95% of people who take the drug have their diastolic blood pressure lowered by between 5 and 15 points. But the semantics of this promise are quite different than that of a conditional prediction interval. Because the average is now taken over a large, heterogeneous population, very little is promised to <i>you</i>. For example, it might be that for patients in your demographic group (e.g. middle aged women with Sephardic Jewish ancestry and a family history of diabetes) that the drug is actually expected to raise blood pressure rather than lower it. Because this subgroup represents less than 5% of the population, it is entirely consistent with the marginal prediction interval being correct. Of course, if you are lucky, then perhaps someone has conducted a study of people from this demographic group and has computed marginal prediction intervals over it! But what if there are multiple different groups that you are a member of, over which the results seem to conflict? For example, you might also have a low BMI value and have unusually good cholesterol readings --- features of a group for which the drug works unusually well. Which uncertainty estimate should you trust, if you are a member of both groups? </div><div><br/></div><div>These concerns actually arise already when we think about the semantics of mean estimations ("the expected drop in blood pressure amongst patients who take this drug is 10 mm Hg"). Ideally, if you were a patient with features $x$, then 10 would be an estimate of $\mathbb{E}[y | x]$. But just as with uncertainty estimation, in a large feature space, we typically have no information about the distribution on $y$ conditional on $x$ (because we have never met anyone exactly like <i>you</i> before), and so instead what we have is just an estimate of $\mathbb{E}[y]$ --- i.e. averaging over people. If you have a method of making predictions $f(x)$ as a function of features $x$, then a standard performance metric is <i>calibration</i> --- which informally asks that for every prediction $p$, amongst all people for whom we predicted $f(x) = p$, the average of the realized labels $y$ should be $p$. Again, estimates of this form promise little to individuals, because they are averages over a large and heterogeneous population.   </div><div><br/></div><div>Several years ago, <a href="https://arxiv.org/abs/1711.08513" target="_blank">Hebert-Johnson et al.</a> proposed a nice way to interpolate between the (impossible) ideal of offering conditional mean predictions  $f(x) = \mathbb{E}[y | x]$, and the weak guarantee of merely offering calibrated predictions $f$. Roughly speaking, they proposed to specify a very large collection of potentially intersecting groups $G$ (representing e.g. demographic groups like Sephardic Jewish women with a family history of diabetes, and hypertensive patients with low cholesterol and BMI values, etc) and to ask that a trained predictor be <i>simultaniously</i> calibrated on each sufficiently large group in $G$. They showed how to accomplish this using a polynomially sized sample from the underlying distribution, with polynomial running time overhead, on top of the cost of solving learning problems over $G$. </div><div><br/></div><div>In our paper, we --- roughly speaking --- show how to accomplish the same thing, but for variances and other higher moments, in addition to just means. And our "multicalibrated moment estimates" can be used to construct prediction intervals in exactly the same way that real moments of the conditional label distribution could be used. If you used the real (unknown) label distribution moments, you would have gotten conditional prediction intervals. If you use our multi-calibrated moments, you get marginal prediction intervals that are simultaneously valid as averaged over each of the groups in $G$. So, for example, our hypertensive patient above could interpret her prediction interval --- if it was constructed from multicalibrated moment estimates computed from her features --- as an average over each of the demographic groups that she is a member of (so long as they are contained within $G$), and all of those interpretations would be simultaneously valid. </div><div><br/></div><div>I'll leave the details to the paper --- including what exactly we mean by "moment multicalibration". I'll just note that a major difficulty is that variances and higher moments --- unlike expectations --- do not combine linearly, so it is no longer sensible to ask that "amongst all people for whom we predicted variance v, the true variance should be v" --- because even the true conditional label variances do not satisfy this property. But it <i>is </i>sensible to ask that a pair of mean and moment predictions be calibrated in this way: "amongst all people for whom we predicted mean $\mu$ and variance v, the true mean should be $\mu$ and the true variance should be $v$." This is what we call "mean-conditioned moment calibration", and it is satisfied by the true distributional moments. </div><div><br/></div><div>The paper is here: <a href="https://arxiv.org/abs/2008.08037">Moment Multicalibration for Uncertainty Estimation</a>.</div><div><br/></div></div>
    </content>
    <updated>2020-08-19T11:47:00Z</updated>
    <published>2020-08-19T11:47:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2020-08-19T11:47:59Z</updated>
    </source>
  </entry>
</feed>
