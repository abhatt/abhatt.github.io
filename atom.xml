<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-14T18:21:31Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5151224614999297675</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5151224614999297675/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/the-iphonification-of-everything.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5151224614999297675" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5151224614999297675" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/the-iphonification-of-everything.html" rel="alternate" type="text/html"/>
    <title>The iPhonification of Everything</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">So you've got an iPhone XS in Space Grey. Congrats, so do 20 million other people. Maybe you have different cases but otherwise the hardware in all these phones are virtually identical. Yet you can tell with a glance that this is your phone. You can personalize apps and other elements of the home screen. It's your calendar and email and music.<br/>
<br/>
What? You've dropped your phone over Niagara falls. Luckily you've backed up your data. So you go back to Apple and buy another Space Grey iPhone XS and restore your data. Physically it's a completely different phone but for all practical purposes it's though you still had the original phone. Your phone is not defined by the device but the data that resides on it.<br/>
<br/>
It's not just phones. I can log into Google on anyone's Chrome browser and it will feel like my machine.<br/>
<br/>
Now we've all heard about a future world where nobody owns cars and we get driven around in self-driving Ubers, Lyfts and Waymos. One argument against this world is that people feel connected to their cars and unwilling to commute in some generic vehicle. But one can also imagine the car knows who you are, knows how you like your music, your lighting, how you adjust your seats even how your car drives. It becomes your car. Maybe even has electronic bumper stickers that change to support your political party.<br/>
<br/>
You can imagine the same for hotel rooms, your office, maybe even your apartment. It won't replicate your dog (or will it?) but as we get define more by our data than our things, do our things matter at all?</div>
    </content>
    <updated>2019-02-14T12:52:00Z</updated>
    <published>2019-02-14T12:52:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-14T12:58:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05027</id>
    <link href="http://arxiv.org/abs/1902.05027" rel="alternate" type="text/html"/>
    <title>Proximity Queries for Absolutely Continuous Parametric Curves</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lakshmanan:Arun.html">Arun Lakshmanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patterson:Andrew.html">Andrew Patterson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cichella:Venanzio.html">Venanzio Cichella</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hovakimyan:Naira.html">Naira Hovakimyan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05027">PDF</a><br/><b>Abstract: </b>In motion planning problems for autonomous robots, such as self-driving cars,
the robot must ensure that its planned path is not in close proximity to
obstacles in the environment. However, the problem of evaluating the proximity
is generally non-convex and serves as a significant computational bottleneck
for motion planning algorithms. In this paper, we present methods for a general
class of absolutely continuous parametric curves to compute: (i) the minimum
separating distance, (ii) tolerance verification, and (iii) collision
detection. Our methods efficiently compute bounds on obstacle proximity by
bounding the curve in a convex region. This bound is based on an upper bound on
the curve arc length that can be expressed in closed form for a useful class of
parametric curves including curves with trigonometric or polynomial bases. We
demonstrate the computational efficiency and accuracy of our approach through
numerical simulations of several proximity problems.
</p></div>
    </summary>
    <updated>2019-02-14T02:46:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04960</id>
    <link href="http://arxiv.org/abs/1902.04960" rel="alternate" type="text/html"/>
    <title>Counting Answers to Existential Questions</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dell:Holger.html">Holger Dell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roth:Marc.html">Marc Roth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wellnitz:Philip.html">Philip Wellnitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04960">PDF</a><br/><b>Abstract: </b>Conjunctive queries select and are expected to return certain tuples from a
relational database. We study the potentially easier problem of counting all
selected tuples, rather than enumerating them. In particular, we are interested
in the problem's parameterized and data complexity, where the query is
considered to be small or fixed, and the database is considered to be large. We
identify two structural parameters for conjunctive queries that capture their
inherent complexity: The dominating star size and the linked matching number.
If the dominating star size of a conjunctive query is large, then we show that
counting solution tuples to the query is at least as hard as counting
dominating sets, which yields a fine-grained complexity lower bound under the
Strong Exponential Time Hypothesis as well as a #W[2]-hardness result.
Moreover, if the linked matching number of a conjunctive query is large, then
we show that the structure of the query is so rich that arbitrary queries up to
a certain size can be encoded into it; this essentially establishes
#A[2]-completeness. Using ideas stemming from Lov\'asz, we lift complexity
results from the class of conjunctive queries to arbitrary existential or
universal formulas that might contain inequalities and negations on constraints
over the free variables. As a consequence, we obtain a complexity
classification that generalizes previous results of Chen, Durand, and Mengel
(ToCS 2015; ICDT 2015; PODS 2016) for conjunctive queries and of Curticapean
and Marx (FOCS 2014) for the subgraph counting problem. Our proof also relies
on graph minors, and we show a strengthening of the Excluded-Grid-Theorem which
might be of independent interest: If the linked matching number is large, then
not only can we find a large grid somewhere in the graph, but we can find a
large grid whose diagonal has disjoint paths leading into an assumed
node-well-linked set.
</p></div>
    </summary>
    <updated>2019-02-14T02:22:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04919</id>
    <link href="http://arxiv.org/abs/1902.04919" rel="alternate" type="text/html"/>
    <title>New Results on Directed Edge Dominating Set</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Belmonte:R=eacute=my.html">Rémy Belmonte</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanaka:Tesshu.html">Tesshu Hanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katsikarelis:Ioannis.html">Ioannis Katsikarelis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Eun_Jung.html">Eun Jung Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lampis:Michael.html">Michael Lampis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04919">PDF</a><br/><b>Abstract: </b>We study a family of generalizations of Edge Dominating Set on directed
graphs called Directed $(p,q)$-Edge Dominating Set. In this problem an arc
$(u,v)$ is said to dominate itself, as well as all arcs which are at distance
at most $q$ from $v$, or at distance at most $p$ to $u$.
</p>
<p>First, we give significantly improved FPT algorithms for the two most
important cases of the problem, $(0,1)$-dEDS and $(1,1)$-dEDS (that correspond
to versions of Dominating Set on line graphs), as well as polynomial kernels.
We also improve the best-known approximation for these cases from logarithmic
to constant. In addition, we show that $(p,q)$-dEDS is FPT parameterized by
$p+q+tw$, but W-hard parameterized by $tw$ (even if the size of the optimal is
added as a second parameter), where $tw$ is the treewidth of the underlying
graph of the input.
</p>
<p>We then go on to focus on the complexity of the problem on tournaments. Here,
we provide a complete classification for every possible fixed value of $p,q$,
which shows that the problem exhibits a surprising behavior, including cases
which are in P; cases which are solvable in quasi-polynomial time but not in P;
and a single case $(p=q=1)$ which is NP-hard (under randomized reductions) and
cannot be solved in sub-exponential time, under standard assumptions.
</p></div>
    </summary>
    <updated>2019-02-14T02:20:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04828</id>
    <link href="http://arxiv.org/abs/1902.04828" rel="alternate" type="text/html"/>
    <title>On the achromatic number of signed graphs</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lajou:Dimitri.html">Dimitri Lajou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04828">PDF</a><br/><b>Abstract: </b>In this paper, we generalize the concept of complete coloring and achromatic
number to 2-edge-colored graphs and signed graphs. We give some useful
relationships between different possible definitions of such achromatic numbers
and prove that computing any of them is NP-complete.
</p></div>
    </summary>
    <updated>2019-02-14T02:21:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04805</id>
    <link href="http://arxiv.org/abs/1902.04805" rel="alternate" type="text/html"/>
    <title>Task-based Augmented Contour Trees with Fibonacci Heaps</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gueunet:Charles.html">Charles Gueunet</a>, P. Fortin, J Jomier, J Tierny <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04805">PDF</a><br/><b>Abstract: </b>This paper presents a new algorithm for the fast, shared memory, multi-core
computation of augmented contour trees on triangulations. In contrast to most
existing parallel algorithms our technique computes augmented trees, enabling
the full extent of contour tree based applications including data segmentation.
Our approach completely revisits the traditional, sequential contour tree
algorithm to re-formulate all the steps of the computation as a set of
independent local tasks. This includes a new computation procedure based on
Fibonacci heaps for the join and split trees, two intermediate data structures
used to compute the contour tree, whose constructions are efficiently carried
out concurrently thanks to the dynamic scheduling of task parallelism. We also
introduce a new parallel algorithm for the combination of these two trees into
the output global contour tree. Overall, this results in superior time
performance in practice, both in sequential and in parallel thanks to the
OpenMP task runtime. We report performance numbers that compare our approach to
reference sequential and multi-threaded implementations for the computation of
augmented merge and contour trees. These experiments demonstrate the run-time
efficiency of our approach and its scalability on common workstations. We
demonstrate the utility of our approach in data segmentation applications.
</p></div>
    </summary>
    <updated>2019-02-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04785</id>
    <link href="http://arxiv.org/abs/1902.04785" rel="alternate" type="text/html"/>
    <title>Constructing Antidictionaries in Output-Sensitive Space</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ayad:Lorraine_A=_K=.html">Lorraine A. K. Ayad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Badkobeh:Golnaz.html">Golnaz Badkobeh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fici:Gabriele.html">Gabriele Fici</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/H=eacute=liou:Alice.html">Alice Héliou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pissis:Solon_P=.html">Solon P. Pissis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04785">PDF</a><br/><b>Abstract: </b>A word $x$ that is absent from a word $y$ is called minimal if all its proper
factors occur in $y$. Given a collection of $k$ words $y_1,y_2,\ldots,y_k$ over
an alphabet $\Sigma$, we are asked to compute the set
$\mathrm{M}^{\ell}_{y_{1}\#\ldots\#y_{k}}$ of minimal absent words of length at
most $\ell$ of word $y=y_1\#y_2\#\ldots\#y_k$, $\#\notin\Sigma$. In data
compression, this corresponds to computing the antidictionary of $k$ documents.
In bioinformatics, it corresponds to computing words that are absent from a
genome of $k$ chromosomes. This computation generally requires $\Omega(n)$
space for $n=|y|$ using any of the plenty available $\mathcal{O}(n)$-time
algorithms. This is because an $\Omega(n)$-sized text index is constructed over
$y$ which can be impractical for large $n$. We do the identical computation
incrementally using output-sensitive space. This goal is reasonable when
$||\mathrm{M}^{\ell}_{y_{1}\#\ldots\#y_{N}}||=o(n)$, for all $N\in[1,k]$. For
instance, in the human genome, $n \approx 3\times 10^9$ but
$||\mathrm{M}^{12}_{y_{1}\#\ldots\#y_{k}}|| \approx 10^6$. We consider a
constant-sized alphabet for stating our results. We show that all
$\mathrm{M}^{\ell}_{y_{1}},\ldots,\mathrm{M}^{\ell}_{y_{1}\#\ldots\#y_{k}}$ can
be computed in
$\mathcal{O}(kn+\sum^{k}_{N=1}||\mathrm{M}^{\ell}_{y_{1}\#\ldots\#y_{N}}||)$
total time using $\mathcal{O}(\mathrm{MaxIn}+\mathrm{MaxOut})$ space, where
$\mathrm{MaxIn}$ is the length of the longest word in $\{y_1,\ldots,y_{k}\}$
and
$\mathrm{MaxOut}=\max\{||\mathrm{M}^{\ell}_{y_{1}\#\ldots\#y_{N}}||:N\in[1,k]\}$.
Proof-of-concept experimental results are also provided confirming our
theoretical findings and justifying our contribution.
</p></div>
    </summary>
    <updated>2019-02-14T02:43:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04764</id>
    <link href="http://arxiv.org/abs/1902.04764" rel="alternate" type="text/html"/>
    <title>Explicit lower bounds on strong simulation of quantum circuits in terms of $T$-gate count</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Cupjin.html">Cupjin Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Newman:Michael.html">Michael Newman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Szegedy:Mario.html">Mario Szegedy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04764">PDF</a><br/><b>Abstract: </b>We investigate Clifford+$T$ quantum circuits with a small number of
$T$-gates. Using the sparsification lemma, we identify time complexity lower
bounds in terms of $T$-gate count below which a strong simulator would improve
on the state-of-the-art $3$-SAT solving.
</p></div>
    </summary>
    <updated>2019-02-14T02:21:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04741</id>
    <link href="http://arxiv.org/abs/1902.04741" rel="alternate" type="text/html"/>
    <title>Learning and Generalization for Matching Problems</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Alon.html">Alon Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hassidim:Avinatan.html">Avinatan Hassidim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mansour:Yishay.html">Yishay Mansour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moran:Shay.html">Shay Moran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04741">PDF</a><br/><b>Abstract: </b>We study a classic algorithmic problem through the lens of statistical
learning. That is, we consider a matching problem where the input graph is
sampled from some distribution. This distribution is unknown to the algorithm;
however, an additional graph which is sampled from the same distribution is
given during a training phase (preprocessing). More specifically, the
algorithmic problem is to match $k$ out of $n$ items that arrive online to $d$
categories ($d\ll k \ll n$). Our goal is to design a two-stage online algorithm
that retains a small subset of items in the first stage which contains an
offline matching of maximum weight. We then compute this optimal matching in a
second stage. The added statistical component is that before the online
matching process begins, our algorithms learn from a training set consisting of
another matching instance drawn from the same unknown distribution. Using this
training set, we learn a policy that we apply during the online matching
process. We consider a class of online policies that we term \emph{thresholds
policies}. For this class, we derive uniform convergence results both for the
number of retained items and the value of the optimal matching. We show that
the number of retained items and the value of the offline optimal matching
deviate from their expectation by $O(\sqrt{k})$. This requires usage of
less-standard concentration inequalities (standard ones give deviations of
$O(\sqrt{n})$). Furthermore, we design an algorithm that outputs the optimal
offline solution with high probability while retaining only $O(k\log \log n)$
items in expectation.
</p></div>
    </summary>
    <updated>2019-02-14T02:30:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04740</id>
    <link href="http://arxiv.org/abs/1902.04740" rel="alternate" type="text/html"/>
    <title>CSPs with Global Modular Constraints: Algorithms and Hardness via Polynomial Representations</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brakensiek:Joshua.html">Joshua Brakensiek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gopi:Sivakanth.html">Sivakanth Gopi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruswami:Venkatesan.html">Venkatesan Guruswami</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04740">PDF</a><br/><b>Abstract: </b>We study the complexity of Boolean constraint satisfaction problems (CSPs)
when the assignment must have Hamming weight in some congruence class modulo M,
for various choices of the modulus M. Due to the known classification of
tractable Boolean CSPs, this mainly reduces to the study of three cases: 2-SAT,
HORN-SAT, and LIN-2 (linear equations mod 2). We classify the moduli M for
which these respective problems are polynomial time solvable, and when they are
not (assuming the ETH). Our study reveals that this modular constraint lends a
surprising richness to these classic, well-studied problems, with interesting
broader connections to complexity theory and coding theory. The HORN-SAT case
is connected to the covering complexity of polynomials representing the NAND
function mod M. The LIN-2 case is tied to the sparsity of polynomials
representing the OR function mod M, which in turn has connections to modular
weight distribution properties of linear codes and locally decodable codes. In
both cases, the analysis of our algorithm as well as the hardness reduction
rely on these polynomial representations, highlighting an interesting algebraic
common ground between hard cases for our algorithms and the gadgets which show
hardness. These new complexity measures of polynomial representations merit
further study.
</p>
<p>The inspiration for our study comes from a recent work by N\"agele, Sudakov,
and Zenklusen on submodular minimization with a global congruence constraint.
Our algorithm for HORN-SAT has strong similarities to their algorithm, and in
particular identical kind of set systems arise in both cases. Our connection to
polynomial representations leads to a simpler analysis of such set systems, and
also sheds light on (but does not resolve) the complexity of submodular
minimization with a congruency requirement modulo a composite M.
</p></div>
    </summary>
    <updated>2019-02-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04738</id>
    <link href="http://arxiv.org/abs/1902.04738" rel="alternate" type="text/html"/>
    <title>Mesh: Compacting Memory Management for C/C++ Applications</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Powers:Bobby.html">Bobby Powers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tench:David.html">David Tench</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berger:Emery_D=.html">Emery D. Berger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McGregor:Andrew.html">Andrew McGregor</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04738">PDF</a><br/><b>Abstract: </b>Programs written in C/C++ can suffer from serious memory fragmentation,
leading to low utilization of memory, degraded performance, and application
failure due to memory exhaustion. This paper introduces Mesh, a plug-in
replacement for malloc that, for the first time, eliminates fragmentation in
unmodified C/C++ applications. Mesh combines novel randomized algorithms with
widely-supported virtual memory operations to provably reduce fragmentation,
breaking the classical Robson bounds with high probability. Mesh generally
matches the runtime performance of state-of-the-art memory allocators while
reducing memory consumption; in particular, it reduces the memory of
consumption of Firefox by 16% and Redis by 39%.
</p></div>
    </summary>
    <updated>2019-02-14T02:29:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04735</id>
    <link href="http://arxiv.org/abs/1902.04735" rel="alternate" type="text/html"/>
    <title>Computing the Yolk in Spatial Voting Games without Computing Median Lines</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gudmundsson:Joachim.html">Joachim Gudmundsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wong:Sampson.html">Sampson Wong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04735">PDF</a><br/><b>Abstract: </b>The yolk is an important concept in spatial voting games as it generalises
the equilibrium and provides bounds on the uncovered set. We present
near-linear time algorithms for computing the yolk in the spatial voting model
in the plane. To the best of our knowledge our algorithm is the first algorithm
that does not require precomputing the median lines and hence able to break the
existing $O(n^{4/3})$ bound which equals the known upper bound on the number of
median lines. We avoid this requirement by using Megiddo's parametric search,
which is a powerful framework that could lead to faster algorithms for many
other spatial voting problems.
</p></div>
    </summary>
    <updated>2019-02-14T02:44:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04728</id>
    <link href="http://arxiv.org/abs/1902.04728" rel="alternate" type="text/html"/>
    <title>Learning Ising Models with Independent Failures</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goel:Surbhi.html">Surbhi Goel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klivans:Adam_R=.html">Adam R. Klivans</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04728">PDF</a><br/><b>Abstract: </b>We give the first efficient algorithm for learning the structure of an Ising
model that tolerates independent failures; that is, each entry of the observed
sample is missing with some unknown probability p. Our algorithm matches the
essentially optimal runtime and sample complexity bounds of recent work for
learning Ising models due to Klivans and Meka (2017).
</p>
<p>We devise a novel unbiased estimator for the gradient of the Interaction
Screening Objective (ISO) due to Vuffray et al. (2016) and apply a stochastic
multiplicative gradient descent algorithm to minimize this objective. Solutions
to this minimization recover the neighborhood information of the underlying
Ising model on a node by node basis.
</p></div>
    </summary>
    <updated>2019-02-14T02:28:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04703</id>
    <link href="http://arxiv.org/abs/1902.04703" rel="alternate" type="text/html"/>
    <title>Assessing Solution Quality of 3SAT on a Quantum Annealing Platform</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gabor:Thomas.html">Thomas Gabor</a>, Sebastian Zielinski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feld:Sebastian.html">Sebastian Feld</a>, Christoph Roch, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seidel:Christian.html">Christian Seidel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neukart:Florian.html">Florian Neukart</a>, Isabella Galter, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mauerer:Wolfgang.html">Wolfgang Mauerer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Linnhoff=Popien:Claudia.html">Claudia Linnhoff-Popien</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04703">PDF</a><br/><b>Abstract: </b>When solving propositional logic satisfiability (specifically 3SAT) using
quantum annealing, we analyze the effect the difficulty of different instances
of the problem has on the quality of the answer returned by the quantum
annealer. A high-quality response from the annealer in this case is defined by
a high percentage of correct solutions among the returned answers. We show that
the phase transition regarding the computational complexity of the problem,
which is well-known to occur for 3SAT on classical machines (where it causes a
detrimental increase in runtime), persists in some form (but possibly to a
lesser extent) for quantum annealing.
</p></div>
    </summary>
    <updated>2019-02-14T02:21:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04629</id>
    <link href="http://arxiv.org/abs/1902.04629" rel="alternate" type="text/html"/>
    <title>Crowdsourced PAC Learning under Classification Noise</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heinecke:Shelby.html">Shelby Heinecke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reyzin:Lev.html">Lev Reyzin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04629">PDF</a><br/><b>Abstract: </b>In this paper, we analyze PAC learnability from labels produced by
crowdsourcing. In our setting, unlabeled examples are drawn from a distribution
and labels are crowdsourced from workers who operate under classification
noise, each with their own noise parameter. We develop an end-to-end
crowdsourced PAC learning algorithm that takes unlabeled data points as input
and outputs a trained classifier. Our three-step algorithm incorporates
majority voting, pure-exploration bandits, and noisy-PAC learning. We prove
several guarantees on the number of tasks labeled by workers for PAC learning
in this setting and show that our algorithm improves upon the baseline by
reducing the total number of tasks given to workers. We demonstrate the
robustness of our algorithm by exploring its application to additional
realistic crowdsourcing settings.
</p></div>
    </summary>
    <updated>2019-02-14T02:38:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04569</id>
    <link href="http://arxiv.org/abs/1902.04569" rel="alternate" type="text/html"/>
    <title>Computational Complexity and the Nature of Quantum Mechanics</title>
    <feedworld_mtime>1550102400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Benavoli:Alessio.html">Alessio Benavoli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Facchini:Alessandro.html">Alessandro Facchini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zaffalon:Marco.html">Marco Zaffalon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04569">PDF</a><br/><b>Abstract: </b>Quantum theory (QT) has been confirmed by numerous experiments, yet we still
cannot fully grasp the meaning of the theory. As a consequence, the quantum
world appears to us paradoxical. Here we shed new light on QT by having it
follow from two main postulates (i) the theory should be logically consistent;
(ii) inferences in the theory should be computable in polynomial time. The
first postulate is what we require to each well-founded mathematical theory.
The computation postulate defines the physical component of the theory. We show
that the computation postulate is the only true divide between QT, seen as a
generalised theory of probability, and classical probability. All quantum
paradoxes, and entanglement in particular, arise from the clash of trying to
reconcile a computationally intractable, somewhat idealised, theory (classical
physics) with a computationally tractable theory (QT) or, in other words, from
regarding physics as fundamental rather than computation.
</p></div>
    </summary>
    <updated>2019-02-14T02:27:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4121</id>
    <link href="https://www.scottaaronson.com/blog/?p=4121" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4121#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4121" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Four updates</title>
    <summary xml:lang="en-US">A few weeks ago, I was at QIP’2019 in Boulder, CO. This week I was at SQuInT’2019 in Albuquerque, NM. There were lots of amazing talks—feel free to ask in the comments section. There’s an interview with me at the website “GigaOm,” conducted by Byron Reese and entitled Quantum Computing: Capabilities and Limits. I didn’t […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few weeks ago, I was at <a href="http://jila.colorado.edu/qip2019/">QIP’2019</a> in Boulder, CO.  This week I was at <a href="http://physics.unm.edu/SQuInT/2019/index.php">SQuInT’2019</a> in Albuquerque, NM.  There were lots of amazing talks—feel free to ask in the comments section.</p>



<p>There’s an interview with me at the website “GigaOm,” conducted by Byron Reese and entitled <a href="https://gigaom.com/2019/01/17/quantum-computing-capabilities-and-limits-an-interview-with-scott-aaronson/">Quantum Computing: Capabilities and Limits</a>.  I didn’t proofread the transcript and it has some errors in it, but hopefully the meaning comes through.  In other interview news, if you were interested in my podcast with Adam Ford in Melbourne but don’t like YouTube, Adam has helpfully prepared transcripts of the two longest segments: <a href="http://www.scifuture.org/the-ghost-in-the-quantum-turing-machine-scott-aaronson/">The Ghost in the Quantum Turing Machine</a> and <a href="http://www.scifuture.org/the-winding-road-to-quantum-supremacy-scott-aaronson/">The Winding Road to Quantum Supremacy</a>.</p>



<p>The <em>New York Times</em> ran an article entitled <a href="https://www.nytimes.com/2019/01/24/technology/computer-science-courses-college.html">The Hard Part of Computer Science? Getting Into Class</a>, about the surge in computer science majors all over the US, and the shortage of professors to teach them.  The article’s go-to example of a university where this is happening is UT Austin, and there’s extensive commentary from my department chair, Don Fussell.</p>



<p>The <a href="http://acm-stoc.org/stoc2019/STOC%202019%20accepted%20papers.html">STOC’2019 accepted papers list</a> is finally out.  Lots of cool stuff!</p></div>
    </content>
    <updated>2019-02-13T04:43:23Z</updated>
    <published>2019-02-13T04:43:23Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-13T04:44:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04495</id>
    <link href="http://arxiv.org/abs/1902.04495" rel="alternate" type="text/html"/>
    <title>The Cost of Privacy: Optimal Rates of Convergence for Parameter Estimation with Differential Privacy</title>
    <feedworld_mtime>1550016000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:T=_Tony.html">T. Tony Cai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yichen.html">Yichen Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Linjun.html">Linjun Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04495">PDF</a><br/><b>Abstract: </b>Privacy-preserving data analysis is a rising challenge in contemporary
statistics, as the privacy guarantees of statistical methods are often achieved
at the expense of accuracy. In this paper, we investigate the tradeoff between
statistical accuracy and privacy in mean estimation and linear regression,
under both the classical low-dimensional and modern high-dimensional settings.
A primary focus is to establish minimax optimality for statistical estimation
with the $(\varepsilon,\delta)$-differential privacy constraint. To this end,
we find that classical lower bound arguments fail to yield sharp results, and
new technical tools are called for. We first develop a general lower bound
argument for estimation problems with differential privacy constraints, and
then apply the lower bound argument to mean estimation and linear regression.
For these statistical problems, we also design computationally efficient
algorithms that match the minimax lower bound up to a logarithmic factor. In
particular, for the high-dimensional linear regression, a novel private
iterative hard thresholding pursuit algorithm is proposed, based on a privately
truncated version of stochastic gradient descent. The numerical performance of
these algorithms is demonstrated by simulation studies and applications to real
data containing sensitive information, for which privacy-preserving statistical
methods are necessary.
</p></div>
    </summary>
    <updated>2019-02-13T23:21:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04427</id>
    <link href="http://arxiv.org/abs/1902.04427" rel="alternate" type="text/html"/>
    <title>Compressed Range Minimum Queries</title>
    <feedworld_mtime>1550016000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Paweł Gawrychowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jo:Seungbum.html">Seungbum Jo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mozes:Shay.html">Shay Mozes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weimann:Oren.html">Oren Weimann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04427">PDF</a><br/><b>Abstract: </b>Given a string $S$ of $n$ integers in $[0,\sigma)$, a range minimum query
$\textsf{RMQ}(i, j)$ asks for the index of the smallest integer in $S[i \dots
j]$. It is well known that the problem can be solved with a succinct data
structure of size $2n + o(n)$ and constant query-time. In this paper we show
how to preprocess $S$ into a {\em compressed representation} that allows fast
range minimum queries. This allows for {\em sublinear} size data structures
with logarithmic query time. The most natural approach is to use string
compression and construct a data structure for answering range minimum queries
directly on the compressed string. We investigate this approach using grammar
compression. We then consider an alternative approach. Even if $S$ is not
compressible, its Cartesian tree necessarily is. Therefore, instead of
compressing $S$ using string compression, we compress the Cartesian tree of $S$
using tree compression. We show that this approach can be exponentially better
than the former, is never worse by more than an $O(\sigma)$ factor (i.e. for
constant alphabets it is never asymptotically worse), and can in fact be worse
by an $\Omega(\sigma)$ factor.
</p></div>
    </summary>
    <updated>2019-02-13T23:21:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04256</id>
    <link href="http://arxiv.org/abs/1902.04256" rel="alternate" type="text/html"/>
    <title>A Theory of Selective Prediction</title>
    <feedworld_mtime>1550016000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qiao:Mingda.html">Mingda Qiao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Gregory.html">Gregory Valiant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04256">PDF</a><br/><b>Abstract: </b>We consider a model of selective prediction, where the prediction algorithm
is given a data sequence in an online fashion and asked to predict a
pre-specified statistic of the upcoming data points. The algorithm is allowed
to choose when to make the prediction as well as the length of the prediction
window, possibly depending on the observations so far. We prove that, even
without any distributional assumption on the input data stream, a large family
of statistics can be estimated to non-trivial accuracy. To give one concrete
example, suppose that we are given access to an arbitrary binary sequence $x_1,
\ldots, x_n$ of length $n$. Our goal is to accurately predict the average
observation, and we are allowed to choose the window over which the prediction
is made: for some $t &lt; n$ and $m \le n - t$, after seeing $t$ observations we
predict the average of $x_{t+1}, \ldots, x_{t+m}$. We show that the expected
squared error of our prediction can be bounded by $O\left(\frac{1}{\log
n}\right)$, and prove a matching lower bound. This result holds for any
sequence (that is not adaptive to when the prediction is made, or the predicted
value), and the expectation of the error is with respect to the randomness of
the prediction algorithm. Our results apply to more general statistics of a
sequence of observations, and we highlight several open directions for future
work.
</p></div>
    </summary>
    <updated>2019-02-13T23:20:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04121</id>
    <link href="http://arxiv.org/abs/1902.04121" rel="alternate" type="text/html"/>
    <title>On the Convergence of Network Systems</title>
    <feedworld_mtime>1550016000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kipouridis:Evangelos.html">Evangelos Kipouridis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsichlas:Kostas.html">Kostas Tsichlas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04121">PDF</a><br/><b>Abstract: </b>The apparent disconnection between the microscopic and the macroscopic is a
major issue in the understanding of complex systems. To this extend, we study
the convergence of repeatedly applying local rules on a network, and touch on
the expressive power of this model. We look at network systems and study their
behavior when different types of local rules are applied on them. For a very
general class of local rules, we prove convergence and provide a certain member
of this class that, when applied on a graph, efficiently computes its k-core
and its (k-1)-crust giving hints on the expressive power of such a model.
Furthermore, we provide guarantees on the speed of convergence for an important
subclass of the aforementioned class. We also study more general rules, and
show that they do not converge. Our counterexamples resolve an open question of
(Zhang, Wang, Wang, Zhou, KDD- 2009) as well, concerning whether a certain
process converges. Finally, we show the universality of our network system, by
providing a local rule under which it is Turing-Complete.
</p></div>
    </summary>
    <updated>2019-02-13T23:22:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.07844</id>
    <link href="http://arxiv.org/abs/1812.07844" rel="alternate" type="text/html"/>
    <title>Beyond z=0. The Deutsch-Jozsa decided monochromatic languages</title>
    <feedworld_mtime>1550016000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marinho:Eraldo_Pereira.html">Eraldo Pereira Marinho</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.07844">PDF</a><br/><b>Abstract: </b>The present work points out that the Deutsch-Jozsa algorithm was the first
formal description of a quantum decider. In particular, it is studied here the
class of languages whose indicator functions allow the Deutsch-Jozsa algorithm
to output a monochromatic result, beyond the trivial case z = 0 for constant
indicator functions. To illustrate examples of randomly balanced languages and
some monochromatic cases, it was performed classical computational simulations
of the Deutsch-Jozsa quantum algorithm for the specific cases of 4 and 6
qubits, respectively. The general case of the Deutsch-Jozsa decided languages
are named balanced languages, and their outcomes from the simulation suggest
that such languages are equivalent to the quantum superposition of the
monochromatic cases.
</p></div>
    </summary>
    <updated>2019-02-13T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5768393804446188224</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5768393804446188224/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html" rel="alternate" type="text/html"/>
    <title>I think ze was confused  -- in favor of genderless pronouns</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">You've probably heard the following:<br/>
<br/>
<br/>
               At first I didn't want to get an X but now that I have it, I can't imagine life without one.<br/>
<br/>
X could be telegraph, radio, TV, color TV, VCR, CD player, streaming, Netflix, Amazon prime, an uber account, Washer and Dryer, Car Phones (remember those), Cell Phones. If you go back in history  wrist watches or sun dials (or wrist-sun-dials!).<br/>
<br/>
This has happened to me recently though not with an object. I read an article someplace saying that ze can be used instead of he or she. It was referring to nonbinaries (using `they' never quite sounded right) but actually it would be great if this was a general genderless pronoun. I am not making a political statement here (although I doubt I have any readers who are against genderless pronouns).<br/>
<br/>
Once I came across the term ze I found places to use it and now I can't imagine not using it.<br/>
<br/>
In a recent article I wrote I needed to say that someone was probably confused, but I did not know their gender. I used<br/>
<br/>
                                                         Ze was probably confused<br/>
<br/>
which is much better than<br/>
<br/>
                                                         S/he was probably confused<br/>
<br/>
                                                         He or she was probably confused<br/>
<br/>
                                                         The student was probably confused<br/>
<br/>
                                                         They were probably confused.<br/>
<br/>
Note that the first two leave out nonbinaries.<br/>
<br/>
0) In the article I put in a footnote saying what ze meant. In the future I may not have to.<br/>
<br/>
1) Will ze catch on? This blog post is an attempt to hasten the practice.<br/>
<br/>
2) Is there a term for his/her that is non-gendered? If not then maybe zer.<br/>
<br/>
3) Will there be political pushback on this usage? If its phrased as a way to include nonbinaries than unfortunately yes. If its phrased as above as when you don't know the gender, what do you do, then no.<br/>
<br/>
4) Is <i> nonbinary </i>the correct term? If not then please politely correct me in the comments.<br/>
<br/>
5) Has Ms replaced Miss and Mrs?<br/>
<br/>
I have used the term ze several times since then- often when I get email from a student such that I can't tell from the first name what their gender is, and I need to forward the email, such as<br/>
<br/>
                   Ze wants to take honors discrete math but does not have the prerequisite, but<br/>
                   since ze placed in the top five in the math olympiad, we'll let zer take it.<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-02-11T19:43:00Z</updated>
    <published>2019-02-11T19:43:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-14T12:58:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/</id>
    <link href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/" rel="alternate" type="text/html"/>
    <title>Parameterized Approximation Algorithms Workshop (PAAW) 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 8, 2019 Patras, Greece https://sites.google.com/site/aefeldmann/parameterized-approximation-algorithms-workshop-paaw-2019 Submission deadline: April 26, 2019 Registration deadline: April 30, 2019 The 2019 edition of the Parameterized Approximation Algorithms Workshop (PAAW) will take place as a satellite workshop of ICALP 2019 in Patras, Greece, on Monday July 8th 2019. — Topics of interest — – Parameterized approximation algorithms – Lossy … <a class="more-link" href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/">Continue reading <span class="screen-reader-text">Parameterized Approximation Algorithms Workshop (PAAW) 2019</span></a></div>
    </summary>
    <updated>2019-02-11T15:31:13Z</updated>
    <published>2019-02-11T15:31:13Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-02-14T18:21:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://bit-player.org/?p=2137</id>
    <link href="http://bit-player.org/2019/divisive-factorials" rel="alternate" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials#comments" rel="replies" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials/feed/atom" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Divisive factorials!</title>
    <summary type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml">The other day I was derailed by this tweet from Fermat’s Library: The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready … <a href="http://bit-player.org/2019/divisive-factorials">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The other day I was derailed by this tweet from Fermat’s Library:</p>
<p><img alt="Inverse factorial tweet" border="0" class="aligncenter" height="385" src="http://bit-player.org/wp-content/uploads/2019/02/inverse-factorial-tweet.png" width="592"/></p>
<p class="undent">The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready sort of way. Since the multiplicative version of \(n!\) goes to infinity as \(n\) increases, the “divisive” version should go to zero. And \(\frac{n^2}{n!}\) does exactly that; the polynomial function \(n^2\) grows slower than the exponential function \(n!\) for large enough \(n\):</p>
<p>\[\frac{1}{1}, \frac{4}{2}, \frac{9}{6}, \frac{16}{24}, \frac{25}{120}, \frac{36}{720}, \frac{49}{5040}, \frac{64}{40320}, \frac{81}{362880}, \frac{100}{3628800}.\]</p>
<p class="undent">But why does the quotient take the particular form \(\frac{n^2}{n!}\)? Where does the \(n^2\) come from?</p>
<p>To answer that question, I had to revisit the long-ago trauma of learning to divide fractions, but I pushed through the pain. Proceeding from left to right through the formula in the tweet, we first get \(\frac{n}{n-1}\). Then, dividing that quantity by \(n-2\) yields</p>
<p>\[\cfrac{\frac{n}{n-1}}{n-2} = \frac{n}{(n-1)(n-2)}.\]</p>
<p class="undent">Continuing in the same way, we ultimately arrive at:</p>
<p>\[n \mathbin{/} (n-1) \mathbin{/} (n-2) \mathbin{/} (n-3) \mathbin{/} \cdots \mathbin{/} 1 = \frac{n}{(n-1) (n-2) (n-3) \cdots 1} = \frac{n}{(n-1)!}\]</p>
<p class="undent">To recover the tweet’s stated result of \(\frac{n^2}{n!}\), just multiply numerator and denominator by \(n\). (To my taste, however, \(\frac{n}{(n-1)!}\) is the more perspicuous expression.)</p>
<hr/>
<p>I am a card-carrying factorial fanboy. You can keep your fancy Fibonaccis; <em>this</em> is my favorite function. Every time I try out a new programming language, my first exercise is to write a few routines for calculating factorials. Over the years I have pondered several variations on the theme, such as replacing \(\times\) with \(+\) in the definition (which produces triangular numbers). But I don’t think I’ve ever before considered substituting \(\mathbin{/}\) for \(\times\). It’s messy. Because multiplication is commutative and associative, you can define \(n!\) simply as the product of all the integers from \(1\) through \(n\), without worrying about the order of the operations. With division, order can’t be ignored. In general, \(x \mathbin{/} y \ne y \mathbin{/}x\), and \((x \mathbin{/} y) \mathbin{/} z \ne x \mathbin{/} (y \mathbin{/} z)\).</p>
<p>The Fermat’s Library tweet puts the factors in descending order: \(n, n-1, n-2, \ldots, 1\). The most obvious alternative is the ascending sequence \(1, 2, 3, \ldots, n\). What happens if we define the divisive factorial as \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\)? Another visit to the schoolroom algorithm for dividing fractions yields this simple answer:</p>
<p>\[1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n = \frac{1}{2 \times 3 \times 4 \times \cdots \times n} = \frac{1}{n!}.\]</p>
<p class="undent">In other words, when we repeatedly divide while counting up from \(1\) to \(n\), the final quotient is the reciprocal of \(n!\).  (I wish I could put an exclamation point at the end of that sentence!) If you’re looking for a canonical answer to the question, “What do you get if you divide instead of multiplying in \(n!\)?” I would argue that \(\frac{1}{n!}\) is a better candidate than \(\frac{n}{(n - 1)!}\). Why not embrace the symmetry between \(n!\) and its inverse?</p>
<p>Of course there are many other ways to arrange the <em>n</em> integers in the set \(\{1 \ldots n\}\). How many ways? As it happens, \(n!\) of them! Thus it would seem there are \(n!\) distinct ways to define the divisive \(n!\) function. However, looking at the answers for the two permutations discussed above suggests there’s a simpler pattern at work. Whatever element of the sequence happens to come first winds up in the numerator of a big fraction, and the denominator is the product of all the other elements. As a result, there are really only \(n\) different outcomes—assuming we stick to performing the division operations from left to right. For any integer \(k\) between \(1\) and \(n\), putting \(k\) at the head of the queue creates a divisive \(n!\) equal to \(k\) divided by all the other factors. We can write this out as:</p>
<p>\[\cfrac{k}{\frac{n!}{k}}, \text{ which can be rearranged as } \frac{k^2}{n!}.\]</p>
<p class="undent">And thus we also solve the minor mystery of how \(\frac{n}{(n-1)!}\) became \(\frac{n^2}{n!}\) in the tweet.</p>
<p>It’s worth noting that all of these functions converge to zero as \(n\) goes to infinity. Asymptotically speaking, \(\frac{1^2}{n!}, \frac{2^2}{n!}, \ldots, \frac{n^2}{n!}\) are all alike.</p>
<hr/>
<p>Ta dah! Mission accomplished. Problem solved. Done and dusted. Now we know everything there is to know about divisive factorials, right?</p>
<p>Well, maybe there’s one more question. What does the computer say? If you take your favorite factorial algorithm, and do as the tweet suggests, replacing any appearance of the \(\times\) (or <code>*</code>) operator with <code>/</code>, what happens? Which of the \(n\) variants of divisive \(n!\) does the program produce?</p>
<p>Here’s <em>my</em> favorite algorithm for computing factorials, in the form of a <a href="https://julialang.org/">Julia</a> program:</p>
<pre class="language-julia"><code>function mul!(n)
    if n == 1
        return 1
    else
        return n * mul!(n - 1)
    end
end
</code></pre>
<p>This is the algorithm that has introduced generations of nerds to the concept of recursion. In narrative form it says: If \(n\) is \(1\), then \(mul!(n)\) is \(1\). Otherwise, evaluate the function \(mul!(n-1)\), then multiply the result by \(n\). You might ask what happens if \(n\) is zero or negative. You might ask, but please don’t. For present purposes, \(n \in \mathbb{N}\).Starting with any positive \(n\), the sequence of recursive calls must eventually bottom out with \(n = 1\).</p>
<p>The function can be written more tersely using Julia’s one-liner style of definition:.</p>
<pre class="language-julia"><code>mul!(n)  =  n == 1 ? 1 : n * mul!(n - 1)</code></pre>
<p>The right side of the assignment statement is a conditional expression, or ternary operator, which has the form <code>a ? b : c</code>. Here <code>a</code> is a boolean test clause, which must return a value of either <code>true</code> or <code>false</code>. If <code>a</code> is <code>true</code>, clause <code>b</code> is evaluated, and the result becomes the value of the entire expression. Otherwise clause <code>c</code> is evaluated.</p>
<p>Just to be sure I’ve got this right, here are the first 10 factorials, as calculated by this program:</p>
<pre class="language-julia"><code>[mul!(n) for n in 1:10]
10-element Array{Int64,1}:
       1
       2
       6
      24
     120
     720
    5040
   40320
  362880
 3628800</code></pre>
<p class="indent">Now let’s edit that definition and convert the single occurence of <code>*</code> to a <code>/</code>, leaving everything else (except the name of the function) unchanged.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n / div!(n - 1)</code></pre>
<p>And here’s what comes back when we run the program for values of \(n\) from \(1\) through \(20\):</p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]
20-element Array{Real,1}:
 1                 
 2.0               
 1.5               
 2.6666666666666665
 1.875             
 3.2               
 2.1875            
 3.657142857142857 
 2.4609375         
 4.063492063492063 
 2.70703125        
 4.432900432900433 
 2.9326171875      
 4.773892773892774 
 3.14208984375     
 5.092152292152292 
 3.338470458984375 
 5.391690662278897 
 3.523941040039063 
 5.675463855030418 </code></pre>
<p>Huh? That sure doesn’t look like it’s converging to zero—not as \(\frac{1}{n!}\) or as \(\frac{n}{n - 1}\). As a matter of fact, it doesn’t look like it’s going to converge at all. The graph below suggests the sequence is made up of two alternating components, both of which appear to be slowly growing toward infinity as well as diverging from one another.</p>
<p><img alt="Div" border="0" class="aligncenter" height="" src="http://bit-player.org/wp-content/uploads/2019/02/div.svg" width=""/></p>
<p class="indent">In trying to make sense of what we’re seeing here, it helps to change the output type of the <code>div!</code> function. Instead of applying the division operator <code>/</code>, which returns the quotient as a floating-point number, we can substitute the  <code>//</code> operator, which returns an exact rational quotient, reduced to lowest terms.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n // div!(n - 1)</code></pre>
<p class="undent">Here’s the sequence of values for <code>n in 1:20</code>:</p>
<pre class="language-julia"><code>20-element Array{Real,1}:
       1      
      2//1    
      3//2    
      8//3    
     15//8    
     16//5    
     35//16   
    128//35   
    315//128  
    256//63   
    693//256  
   1024//231  
   3003//1024 
   2048//429  
   6435//2048 
  32768//6435 
 109395//32768
  65536//12155
 230945//65536
 262144//46189 </code></pre>
<p>The list is full of curious patterns. It’s a double helix, with even numbers and odd numbers zigzagging in complementary strands. The even numbers are not just even; they are all powers of \(2\). Also, they appear in pairs—first in the numerator, then in the denominator—and their sequence is nondecreasing. But there are gaps; not all powers of \(2\) are present. The odd strand looks even more complicated, with various small prime factors flitting in and out of the numbers. (The primes <em>have</em> to be small—smaller than \(n\), anyway.)</p>
<p>This outcome took me by surprise. I had really expected to see a much tamer sequence, like those I worked out with pencil and paper. All those jagged, jitterbuggy ups and downs made no sense. Nor did the overall trend of unbounded growth in the ratio. How could you keep dividing and dividing, and wind up with bigger and bigger numbers?</p>
<p>At this point you may want to pause before reading on, and try to work out your own theory of where these zigzag numbers are coming from. If you need a hint, you can get a strong one—almost a spoiler—by looking up the sequence of numerators or the sequence of denominators in the <a href="http://oeis.org">Online Encyclopedia of Integer Sequences</a>.</p>
<hr/>
<p>Here’s another hint. A small edit to the <code>div!</code> program completely transforms the output. Just flip the final clause, changing <code>n // div!(n - 1)</code> into <code>div!(n - 1) // n</code>. </p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : div!(n - 1) // n</code></pre>
<p class="undent">Now the results look like this:</p>
<pre class="language-julia"><code>10-element Array{Real,1}:
  1                    
 1//2                  
 1//6                  
 1//24                 
 1//120                
 1//720                
 1//5040               
 1//40320              
 1//362880             
 1//3628800</code></pre>
<p>This is the inverse factorial function we’ve already seen, the series of quotients generated when you march left to right through an ascending sequence of divisors \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\). </p>
<p>It’s no surprise that flipping the final clause in the procedure alters the outcome. After all, we know that division is not commutative or associative. What’s not so easy to see is why the sequence of quotients generated by the original program takes that weird zigzag form. What mechanism is giving rise to those paired powers of 2 and the alternation of odd and even?</p>
<p>I have found that it’s easier to explain what’s going on in the zigzag sequence when I describe an iterative version of the procedure, rather than the recursive one. (This is an embarrassing admission for someone who has argued that recursive definitions are easier to reason about, but there you have it.) Here’s the program:</p>
<pre class="language-julia"><code>function div!_iter(n)
    q = 1
    for i in 1:n
        q = i // q
    end
    return q
end</code></pre>
<p>I submit that this looping procedure is operationally identical to the recursive function, in the sense that if <code>div!(n)</code> and <code>div!_iter(n)</code> both return a result for some positive integer <code>n</code>, it will always be the same result. Here’s my evidence: </p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]    [div!_iter(n) for n in 1:20]
            1                         1//1    
           2//1                       2//1    
           3//2                       3//2    
           8//3                       8//3    
          15//8                      15//8    
          16//5                      16//5    
          35//16                     35//16   
         128//35                    128//35   
         315//128                   315//128  
         256//63                    256//63   
         693//256                   693//256  
        1024//231                  1024//231  
        3003//1024                 3003//1024 
        2048//429                  2048//429  
        6435//2048                 6435//2048 
       32768//6435                32768//6435 
      109395//32768              109395//32768
       65536//12155               65536//12155
      230945//65536              230945//65536
      262144//46189              262144//46189</code></pre>
<p>To understand the process that gives rise to these numbers, consider the successive values of the variables \(i\) and \(q\) each time the loop is executed. Initially, \(i\) and \(q\) are both set to \(1\); hence, after the first passage through the loop, the statement <code>q = i // q</code> gives \(q\) the value \(\frac{1}{1}\). Next time around, \(i = 2\) and \(q = \frac{1}{1}\), so \(q\)’s new value is \(\frac{2}{1}\). On the third iteration, \(i = 3\) and \(q = \frac{2}{1}\), yielding \(\frac{i}{q} \rightarrow \frac{3}{2}\). If this is still confusing, try thinking of \(\frac{i}{q}\) as \(i \times \frac{1}{q}\). The crucial observation is that on every passage through the loop, \(q\) is inverted, becoming \(\frac{1}{q}\).</p>
<p>If you unwind these operations, and look at the multiplications and divisions that go into each element of the series, a pattern emerges:</p>
<p>\[\frac{1}{1}, \quad \frac{2}{1}, \quad \frac{1 \cdot 3}{2}, \quad \frac{2 \cdot 4}{1 \cdot 3}, \quad \frac{1 \cdot 3 \cdot 5}{2 \cdot 4} \quad \frac{2 \cdot 4 \cdot 6}{1 \cdot 3 \cdot 5}\]</p>
<p class="undent">The general form is:</p>
<p>\[\frac{1 \cdot 3 \cdot 5 \cdot \cdots \cdot n}{2 \cdot 4 \cdot \cdots \cdot (n-1)} \quad (\text{odd } n) \qquad  \frac{2 \cdot 4 \cdot 6 \cdot \cdots \cdot n}{1 \cdot 3 \cdot 5 \cdot \cdots \cdot (n-1)} \quad (\text{even } n).<br/>
\]</p>
<hr/>
<p>The functions \(1 \cdot 3 \cdot 5 \cdot \cdots \cdot n\) for odd \(n\) and \(2 \cdot 4 \cdot 6 \cdot \cdots \cdot n\) for even \(n\) have a name! They are known as double factorials, with the notation \(n!!\). Terrible terminology, no? Better to have named them “semi-factorials.” And if I didn’t know better, I would read \(n!!\) as “the factorial of the factorial.” The double factorial of <em>n</em> is defined as the product of <em>n</em> and all smaller positive integers of the same parity. Thus our peculiar sequence of zigzag quotients is simply \(\frac{n!!}{(n-1)!!}\).</p>
<p>A <a href="https://www.tandfonline.com/doi/abs/10.4169/math.mag.85.3.177">2012 article</a> by Henry W. Gould and Jocelyn Quaintance (behind a paywall, regrettably) surveys the applications of double factorials. They turn up more often than you might guess. In the middle of the 17th century John Wallis came up with this identity:</p>
<p>\[\frac{\pi}{2} = \frac{2 \cdot 2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdots}{1 \cdot 3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdots} = \lim_{n \rightarrow \infty} \frac{((2n)!!)^2}{(2n + 1)!!(2n - 1)!!}\]</p>
<p class="undent">An even weirder series, involving the cube of a quotient of double factorials, sums to \(\frac{2}{\pi}\). That one was discovered by (who else?) Srinivasa Ramanujan.</p>
<p>Gould and Quaintance also discuss the double factorial counterpart of binomial coefficients. The standard binomial coefficient is defined as:</p>
<p>\[\binom{n}{k} = \frac{n!}{k! (n-k)!}.\]</p>
<p class="undent">The double version is:</p>
<p>\[\left(\!\binom{n}{k}\!\right) = \frac{n!!}{k!! (n-k)!!}.\]</p>
<p class="undent">Note that our zigzag numbers fit this description and therefore qualify as double factorial binomial coefficients. Specifically, they are the numbers:</p>
<p>\[\left(\!\binom{n}{1}\!\right) = \left(\!\binom{n}{n - 1}\!\right) = \frac{n!!}{1!! (n-1)!!}.\]</p>
<p class="undent">The regular binomial \(\binom{n}{1}\) is not very interesting; it is simply equal to \(n\). But the doubled version \(\left(\!\binom{n}{1}\!\right)\), as we’ve seen, dances a livelier jig. And, unlike the single binomial, it is not always an integer. (The only integer values are \(1\) and \(2\).)</p>
<p>Seeing the zigzag numbers as ratios of double factorials explains quite a few of their properties, starting with the alternation of evens and odds. We can also see why all the even numbers in the sequence are powers of 2. Consider the case of \(n = 6\). The numerator of this fraction is \(2 \cdot 4 \cdot 6 = 48\), which acquires a factor of \(3\) from the \(6\). But the denominator is \(1 \cdot 3 \cdot 5 = 15\). The \(3\)s above and below cancel, leaving \(\frac{16}{5}\). Such cancelations will happen in every case. Whenever an odd factor \(m\) enters the even sequence, it must do so in the form \(2 \cdot m\), but at that point \(m\) itself must already be present in the odd sequence.</p>
<hr/>
<p>Is the sequence of zigzag numbers a reasonable answer to the question, “What happens when you divide instead of multiply in \(n!\)?” Or is the computer program that generates them just a buggy algorithm? My personal judgment is that \(\frac{1}{n!}\) is a more intuitive answer, but \(\frac{n!!}{(n - 1)!!}\) is more interesting.</p>
<p>Furthermore, the mere existence of the zigzag sequence broadens our horizons. As noted above, if you insist that the division algorithm must always chug along the list of \(n\) factors in order, at each stop dividing the number on the left by the number on the right, then there are only \(n\) possible outcomes, and they all look much alike. But the zigzag solution suggests wilder possibilities. We can formulate the task as follows. Take the set of factors \(\{1 \dots n\}\), select a subset, and invert all the elements of that subset; now multiply all the factors, both the inverted and the upright ones. If the inverted subset is empty, the result is the ordinary factorial \(n!\). If <em>all</em> of the factors are inverted, we get the inverse \(\frac{1}{n!}\). And if every second factor is inverted, starting with \(n - 1\), the result is an element of the zigzag sequence.</p>
<p>These are only a few among the many possible choices; in total there are \(2^n\) subsets of \(n\) items. For example, you might invert every number that is prime or a power of a prime \((2, 3, 4, 5, 7, 8, 9, 11, \dots)\). For small \(n\), the result jumps around but remains consistently less than \(1\):</p>
<p><img alt="Prime powers" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/prime-powers.svg" width=""/></p>
<p class="undent">If I were to continue this plot to larger \(n\), however, it would take off for the stratosphere. Prime powers get sparse farther out on the number line.</p>
<hr/>
<p>Here’s a question. We’ve seen factorial variants that go to zero as \(n\) goes to infinity, such as \(1/n!\). We’ve seen other variants grow without bound as \(n\) increases, including \(n!\) itself, and the zigzag numbers. Are there any versions of the factorial process that converge to a finite bound other than zero?</p>
<p>My first thought was this algorithm:</p>
<pre class="language-julia"><code>function greedy_balance(n)
    q = 1
    while n &gt; 0
        q = q &gt; 1 ? q /= n : q *= n
        n -= 1
    end
    return q
end</code></pre>
<p class="undent">We loop through the integers from \(n\) down to \(1\), calculating the running product/quotient \(q\) as we go. At each step, if the current value of \(q\) is greater than \(1\), we divide by the next factor; otherwise, we multiply. This scheme implements a kind of feedback control or target-seeking behavior. If \(q\) gets too large, we reduce it; too small and we increase it. I conjectured that as \(n\) goes to infinity, \(q\) would settle into an ever-narrower range of values near \(1\).</p>
<p>Running the experiment gave me another surprise:</p>
<p><img alt="Greedy balance linear" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance_linear.svg" width=""/></p>
<p class="undent">That sawtooth wave is not quite what I expected. One minor peculiarity is that the curve is not symmetric around \(1\); the excursions above have higher amplitude than those below. But this distortion is more visual than mathematical. Because \(q\) is a ratio, the distance from \(1\) to \(10\) is the same as the distance from \(1\) to \(\frac{1}{10}\), but it doesn’t look that way on a linear scale. The remedy is to plot the log of the ratio:</p>
<p><img alt="Greedy balance" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance.svg" width=""/></p>
<p>Now the graph is symmetric, or at least approximately so, centered on \(0\), which is the logarithm of \(1\). But a larger mystery remains. The sawtooth waveform is very regular, with a period of \(4\), and it shows no obvious signs of shrinking toward the expected limiting value of \(\log q = 0\). Numerical evidence suggests that as \(n\) goes to infinity the peaks of this curve converge on a value just above \(q = \frac{5}{3}\), and the troughs approach a value just below \(q = \frac{3}{5}\). (The corresponding base-\(10\) logarithms are roughly \(\pm0.222\). I have not worked out why this should be so. Perhaps someone will explain it to me.</p>
<p>The failure of this greedy algorithm doesn’t mean we can’t find a divisive factorial that converges to \(q = 1\). If we work with the logarithms of the factors, this procedure becomes an instance of a well-known compu­tational problem called the number partitioning problem. You are given a set of real numbers and asked to divide it into two sets whose sums are equal, or as close to equal as possible. It’s a certifiably hard problem, but it has also been called (<a href="http://bit-player.org/bph-publications/AmSci-2002-03-Hayes-NPP.pdf">PDF</a>) “the easiest hard problem.”For any given \(n\), we might find that inverting some other subset of the factors gives a better approximation to \(n! = 1\). For small \(n\), we can solve the problem by brute force: Just look at all \(2^n\) subsets and pick the best one.</p>
<p>I have computed the optimal partitionings up to \(n = 30\), where there are a billion possibilities to choose from.</p>
<p><img alt="Optimum balance graph" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/optimum_balance_graph.svg" width=""/></p>
<p class="undent">The graph is clearly flatlining. You could use the same method to force convergence to any other value between \(0\) and \(n!\).</p>
<p>And thus we have yet another answer to the question in the tweet that launched this adventure. What happens when you divide instead of multiply in n!? Anything you want.</p></div>
    </content>
    <updated>2019-02-10T08:48:33Z</updated>
    <published>2019-02-10T08:48:33Z</published>
    <category scheme="http://bit-player.org" term="computing"/>
    <category scheme="http://bit-player.org" term="mathematics"/>
    <author>
      <name>Brian Hayes</name>
      <uri>http://bit-player.org</uri>
    </author>
    <source>
      <id>http://bit-player.org/feed/atom</id>
      <link href="http://bit-player.org" rel="alternate" type="text/html"/>
      <link href="http://bit-player.org/feed/atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">An amateur's outlook on computation and mathematics</subtitle>
      <title xml:lang="en-US">bit-player</title>
      <updated>2019-02-10T20:48:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra</id>
    <link href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html" rel="alternate" type="text/html"/>
    <title>Big convex polyhedra in grids</title>
    <summary>I recently wrote here about big convex polygons in grids, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about <a href="https://11011110.github.io/blog/2018/09/05/big-convex-polygons.html">big convex polygons in grids</a>, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an  grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</p>

<p>The problem is included in a 2008 survey by Imre Bárány,<sup id="fnref:bar"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bar">1</a></sup> according to whom the maximum number of vertices is</p>



<p>For instance, in three dimensional  grids the maximum number of vertices is .</p>

<p>One way to find polyhedra with this many vertices is to take the convex hull of the points in a ball,<sup id="fnref:bl"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bl">2</a></sup> <sup id="fnref:bd"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bd">3</a></sup> or in scaled copies of any fixed smooth convex body. Another way, which should generate polyhedra with a somewhat less irregular appearance and (up to constant factors) the same number of vertices, is to take the <a href="https://en.wikipedia.org/wiki/Minkowski_addition">Minkowski sum</a> of all line segments (up to scaling and translation) that will fit into a smaller grid, of side length . For instance, the <a href="https://en.wikipedia.org/wiki/Truncated_rhombicuboctahedron">truncated rhombicuboctahedron</a> below<sup id="fnref:ruen"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:ruen">4</a></sup> is the Minkowski sum of all the line segments that fit into a unit cube. Its 96 vertices lie in a  grid. In general, this method produces a <a href="https://en.wikipedia.org/wiki/Zonohedron">zonohedron</a> whose complexity can be analyzed in terms of a -dimensional arrangement of  hyperplanes. As long as this arrangement is not too degenerate (which it appears not to be, but I haven’t worked out the details carefully) this should give
a number of vertices within a constant factor of the number coming from the convex hull construction.</p>

<p style="text-align: center;"><img alt="Truncated rhombicuboctahedron" src="https://11011110.github.io/blog/assets/2019/truncated-rhombicuboctahedron2.png"/></p>

<p>A matching upper bound comes from a 1963 paper by G. K. Andrews,<sup id="fnref:and"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:and">5</a></sup> and Bárány writes that although several more proofs have been published none of them is easy. I’m not sure whether the difficulty is in getting the exact bound or in the fact that Andrews and the later proofs allow more general shapes with volume  that don’t fit into a grid, but it’s not hard to get close to the right bound simply by counting the number of possible facets of a given volume . By using <a href="https://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm">lattice basis reduction</a> the integer vectors in the hyperplane through any facet have a nearly-orthogonal basis whose product of lengths is proportional to . By considering how this product of lengths can be broken down into factors of different scales, and counting how many integer vectors of those lengths exist, it follows that the number of possible facets of volume  is . Combining this with the  surface area of a grid polytope gives the correct upper bound on the number of vertices up to a polylog factor.</p>

<p>What about when the dimension is not constant? An easy construction for high dimensions is to take all points with a fixed distance  from the grid center. There are  possible values for the distance, so this construction produces a convex polytope with  vertices. It comes from a 1946 paper by Behrend, who uses this idea to find <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">dense sets of integers with no arithmetic progressions</a>.<sup id="fnref:beh"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:beh">6</a></sup>
It is never worse to use the convex hull of the ball than the points on a sphere,
and a celebrated paper by Elkin from 2011 (in the appendix of the published version) gives another proof of the  bound for convex hulls of balls (for ) in which the constant factor of the  is universal, not depending on . So when  is singly exponential in ,  becomes constant and the convex hull technique produces  vertices, improving Behrend’s construction for progression-free sets by the same  factor.<sup id="fnref:elk"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:elk">7</a></sup></p>

<div class="footnotes">
  <ol>
    <li id="fn:bar">
      <p>Bárány, Imre (2008), “Extremal problems for convex lattice polytopes: a survey”, <em>Surveys on Discrete and Computational Geometry</em>, Contemporary Mathematics 453, Amer. Math. Soc., pp. 87–103, <a href="https://doi.org/10.1090/conm/453/08796">doi:10.1090/conm/453/08796</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=2405678">MR2405678</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bar">↩</a></p>
    </li>
    <li id="fn:bl">
      <p>Bárány, Imre and Larman, David (1998), “The convex hull of the integer points in a large ball”, <em>Math. Ann.</em> 312 (1), pp. 167–181, <a href="https://doi.org/10.1007/s002080050217">doi:10.1007/s002080050217</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1645957">MR1645957</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bl">↩</a></p>
    </li>
    <li id="fn:bd">
      <p>Balog, Antal and Deshouillers, Jean-Marc (1999), “On some convex lattice polytopes”. <em>Number Theory in Progress</em>, Vol. 2 (Zakopane-Kościelisko, 1997), de Gruyter, pp. 591–606, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1689533">MR1689533</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bd">↩</a></p>
    </li>
    <li id="fn:ruen">
      <p>Ruen, Tom (2014), “Truncated rhombicuboctahedron”, CC-BY-SA 4.0, <a href="https://commons.wikimedia.org/wiki/File:Truncated_rhombicuboctahedron2.png">File:Truncated rhombicuboctahedron2.png</a> on Wikimedia commons. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:ruen">↩</a></p>
    </li>
    <li id="fn:and">
      <p>Andrews, George E. (1963), “A lower bound for the volume of strictly convex bodies with many boundary lattice points”, <em>Trans. Amer. Math. Soc.</em> 106, pp. 270–279, <a href="https://doi.org/10.2307/1993769">doi:10.2307/1993769</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0143105">MR0143105</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:and">↩</a></p>
    </li>
    <li id="fn:beh">
      <p>Behrend, F. A. (1946), “On sets of integers which contain no three terms in arithmetical progression”, <em>Proc. Nat. Acad. Sci.</em> 32 (12), pp. 331–332, <a href="https://doi.org/10.1073/pnas.32.12.331">doi:10.1073/pnas.32.12.331</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0018694">MR0018694</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:beh">↩</a></p>
    </li>
    <li id="fn:elk">
      <p>Elkin, Michael (2011), “An improved construction of progression-free sets”, <em>Israel J. Math.</em> 184, pp. 93–128, <a href="https://arxiv.org/abs/0801.4310">arXiv:0801.4310</a>, <a href="https://doi.org/10.1007%2Fs11856-011-0061-1">doi:10.1007/s11856-011-0061-1</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=2823971">MR2823971</a>. The paragraph describing Elkin’s results was updated from an earlier more tentative version in the original post. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:elk">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101564963348879092">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-02-09T15:07:00Z</updated>
    <published>2019-02-09T15:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-11T18:35:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1087</id>
    <link href="https://ptreview.sublinear.info/?p=1087" rel="alternate" type="text/html"/>
    <title>News for January 2019</title>
    <summary>Minimax Testing of Identity to a Reference Ergodic Markov Chain, by Geoffrey Wolfer and Aryeh Kontorovich (arXiv). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by Daskalakis, Dikkala, and Gravin: we wish to test whether a Markov chain is equal to some reference chain, or far from […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Minimax Testing of Identity to a Reference Ergodic Markov Chain</strong>, by Geoffrey Wolfer and Aryeh Kontorovich (<a href="https://arxiv.org/abs/1902.00080">arXiv</a>). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by <a href="https://arxiv.org/abs/1704.06850">Daskalakis, Dikkala, and Gravin</a>: we wish to test whether a Markov chain is equal to some reference chain, or far from it. This improves on previous work by considering a stronger distance measure than before, and showing that the sample complexity only depends on properties of the reference chain (which we are trying to test identity to). It additionally proves instance-by-instance bounds (where the sample complexity depends on properties of the specific chain we wish to test identity to).</p>



<p><strong>Almost Optimal Distribution-free Junta Testing</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/1901.00717">arXiv</a>). This paper provides a \(\tilde O(k/\varepsilon)\)-query algorithm with two-sided error for testing if a Boolean function is a \(k\)-junta (that is, its value depends only on \(k\) of its variables) in the distribution-free model (where distance is measured with respect to an unknown distribution from which we can sample). This complexity is a quadratic improvement over the \(\tilde O(k^2)/\varepsilon\)-query algorithm of <a href="https://arxiv.org/abs/1802.04859">Chen, Liu, Servedio, Sheng, and Xie</a>. This complexity is also near-optimal, as shown in a lower bound by Saglam (which we covered back in <a href="https://ptreview.sublinear.info/?p=1030">August</a>).</p>



<p><strong>Exponentially Faster Massively Parallel Maximal Matching</strong>, by Soheil Behnezhad, MohammadTaghi Hajiaghayi, and David G. Harris (<a href="https://arxiv.org/abs/1901.03744">arXiv</a>). The authors consider maximal matching in the Massively Parallel Computation (MPC) model. They show that one can compute a maximal matching in \(O(\log \log \Delta)\)-rounds, with \(O(n)\) space per machine. This is an exponential improvement over the previous works, which required either \(\Omega(\log n)\) rounds or \(n^{1 + \Omega(1)}\) space per machine. Corollaries of their result include approximation algorithms for vertex cover, maximum matching, and weighted maximum matching. </p></div>
    </content>
    <updated>2019-02-08T18:30:54Z</updated>
    <published>2019-02-08T18:30:54Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-02-13T23:24:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3379</id>
    <link href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/" rel="alternate" type="text/html"/>
    <title>ACM SIGecom Elections</title>
    <summary>The following message just went out to ACM SIGecom members: ———- Forwarded message ——— From: Monique Chang &lt;chang@hq.acm.org&gt; Date: Mon, Feb 4, 2019 at 2:20 PM Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement To: &lt;SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org&gt; Dear ACM SIGecom Member, The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election. Chair […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="font-weight: 400;">The following message just went out to ACM SIGecom members:</span></p>
<blockquote><p>———- Forwarded message ———<br/>
From: <strong>Monique Chang</strong> &lt;<a href="mailto:chang@hq.acm.org">chang@hq.acm.org</a>&gt;<br/>
Date: Mon, Feb 4, 2019 at 2:20 PM<br/>
Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement<br/>
To: &lt;<a href="mailto:SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org">SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org</a>&gt;</p>
<p>Dear ACM SIGecom Member,</p>
<p>The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election.</p>
<p><strong><u>Chair</u></strong><br/>
(Running Unopposed)</p>
<p>Nicole Immorlica</p>
<p><strong><u>Vice-Chair</u></strong></p>
<p>Scott Kominers</p>
<p>Ariel Procaccia</p>
<p><strong><u>Secretary-Treasurer</u></strong></p>
<p>Hu Fu</p>
<p>Katrina Ligett</p>
<p>In accordance with the ACM SIG Bylaws, additional candidates may be placed on the ballot by petition. All candidates must be ACM Professional Members, as well as members of the SIG. Anyone interested in petitioning must inform ACM Headquarters, Pat Ryan (<a href="mailto:ryanp@hq.acm.org">ryanp@hq.acm.org</a>), and SIGecom’s Secretary-Treasurer, Jenn Wortman Vaughan (<a href="mailto:jenn@microsoft.com">jenn@microsoft.com</a>), of their intent to petition by <strong>15 March 2019</strong>. Petitions must be submitted to ACM Headquarters for verification by <strong>2 April 2019</strong>.</p>
<p>Monique Chang</p>
<p>ACM SIG Elections Coordinator</p>
<p>Office of Policy and Administration</p></blockquote>
<p><span style="font-weight: 400;">Three things for members of our community to note:</span></p>
<ol>
<li style="font-weight: 400;">It’s important vote (once the link goes out; note that the current email is just an announcement and an invitation for additional candidates to petition to be included on the ballot). The SIG leadership is very important for the ongoing direction of our organization. Your vote makes a difference, because our elections are often decided by small margins.</li>
</ol>
<ol start="2">
<li style="font-weight: 400;">If you didn’t get this email, you’re likely not registered as a member of our SIG. Membership costs only $5 for students and $10 for others; AFAIK, you don’t have to be an ACM member to be a SIG member. Our number of members is an important signal to the ACM about the strength of our community (which is why we have set our fees so low). Votes like this one are also restricted to members! If your membership has lapsed, or if you’ve never taken the plunge, this might be a good occasion to do so, by clicking on the link below:</li>
</ol>
<p style="font-weight: 400;"><a href="https://www.acm.org/special-interest-groups/sigs/sigecom">https://www.acm.org/special-interest-groups/sigs/sigecom</a></p>
<ol start="3">
<li style="font-weight: 400;">Thanks to our nominations chair, David Parkes, who put together the slate of candidates just listed, and also to all of the candidates who agreed to serve. Our community is really lucky to have such a strong and deep pool of volunteers, and this is one more example. Indeed, in advance, I’d particularly like to thank those candidates who *don’t* win, whoever they turn out to be: it’s thankless to stick one’s neck out for an election only to see someone else get chosen (often by a small margin; see #1), but your willingness to serve is much appreciated.</li>
</ol></div>
    </content>
    <updated>2019-02-08T02:44:19Z</updated>
    <published>2019-02-08T02:44:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-02-14T18:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/017" rel="alternate" type="text/html"/>
    <title>TR19-017 |  Fourier bounds and pseudorandom generators for product tests | 

	Chin Ho Lee</title>
    <summary>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to \{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on disjoint $m$-bit inputs.  We prove that for every positive integer $d$,
\[
  \sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d .
\]
Our upper bound is tight up to a constant factor in the $O(\cdot)$.  Our proof builds on a new "level-$d$ inequality" that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any $[0,1]$-valued function $f$ in terms of its expectation, which may be of independent interest.

As a result, we construct pseudorandom generators for such functions with seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$.  Our generator in particular works for the well-studied class of combinatorial rectangles, where in addition we allow the bits to be read in any order.  Even for this special case, previous generators have an extra $\tilde O(\log(1/\varepsilon))$ factor in their seed lengths. 

Using Schur-convexity, we also extend our results to functions $f_i$ whose range is $[-1,1]$.</summary>
    <updated>2019-02-07T14:59:22Z</updated>
    <published>2019-02-07T14:59:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-14T18:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/016" rel="alternate" type="text/html"/>
    <title>TR19-016 |  The hardest halfspace | 

	Alexander A. Sherstov</title>
    <summary>We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the infinity norm by polynomials and rational functions of any given degree.  Our main result is an explicit construction of the "hardest" halfspace, for which we prove polynomial and rational approximation lower bounds that match the trivial upper bounds achievable for all halfspaces.  This completes a lengthy line of work started by Myhill and Kautz (1961).

As an application, we construct a communication problem with essentially the largest possible gap, of $n$ versus $2^{-\Omega(n)},$ between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap of $\log n$ versus $\Omega(n)$ between the communication complexity with unbounded versus weakly unbounded error, improving quadratically on previous constructions and completing a line of work started by Babai, Frankl, and Simon (FOCS 1986). Our results further generalize to the $k$-party number-on-the-forehead model, where we obtain an explicit separation of $\log n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly unbounded error. This gap is a quadratic improvement on previous work and matches the state of the art for number-on-the-forehead lower bounds.</summary>
    <updated>2019-02-07T14:57:13Z</updated>
    <published>2019-02-07T14:57:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-14T18:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-971154734717743655</id>
    <link href="https://blog.computationalcomplexity.org/feeds/971154734717743655/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html" rel="alternate" type="text/html"/>
    <title>An Immerman-Szelepcsényi Story</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As a grad student in the late 80's I had the opportunity to witness many great and often surprising theorems in computational complexity. Let me tell you about one of them, the Immerman-Szelepcsényi result that <a href="https://blog.computationalcomplexity.org/2003/06/foundations-of-complexity-lesson-19.html">nondeterministic space is closed under complement</a>. I wish I had the original emails for this story but instead I'm working from memory and apologies if I get some of the details wrong. I'm expanding from a <a href="https://blog.computationalcomplexity.org/2002/08/last-spring-i-saw-copenhagen-great.html">short version</a> from the early days of this blog.<br/>
<br/>
I started my graduate work at UC Berkeley in 1985 and then moved to MIT in the summer of '86, following my advisor Michael Sipser. In the summer of 1987, Neil Immerman, then at Yale, proved his famous result building on his work in <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> In those days you didn't email papers, he made copies and sent them by US postal mail to several major researchers in complexity including Sipser. But Sipser was away for the summer, I believe in Russia, and the paper sat in his office.<br/>
<br/>
Immerman also sent the paper to a Berkeley professor, probably Manuel Blum, who gave it to one of his students who decided to speak about the result in a student-led seminar. I forgot who was the student, maybe Moni Naor. I was still on the Berkeley email list so I got the talk announcement and went into complexity ecstasy over the news. I asked Moni (or whomever was giving the talk) if he could tell me details and he sent me a nice write-up of the proof. Given the importance of the result, I sent the proof write-up out to the MIT theory email list.<br/>
<br/>
Guess who was on the MIT theory list? Neil Immerman. Neil wrote back with his own explanation of the proof. Neil explained how it came out of descriptive complexity but as a pure write-up of a proof of the theorem, Moni did an excellent job.<br/>
<br/>
We found out about Robert Szelepcsényi when his paper showed up a few months later in the Bulletin of the European Association for Theoretical Computer Science. Szelepcsényi came to the problem from formal languages, whether context-sensitive languages (nondeterministic linear space) was closed under complement. Szelepcsényi, an undergrad in Slovakia at the time, heard about the problem in a class he took. Szelepcsényi's proof was very similar to Immerman. Szelepcsényi's paper took longer to get to US researchers but likely was proven and written about the same time as Immerman.<br/>
<br/>
Even though both papers were <a href="https://doi.org/10.1137/0217058">published</a> <a href="https://doi.org/10.1007/BF00299636">separately</a> we refer to the result as Immerman-Szelepcsényi and is now just some old important theorem you see in introductory theory classes.</div>
    </content>
    <updated>2019-02-07T12:47:00Z</updated>
    <published>2019-02-07T12:47:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-14T12:58:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/015" rel="alternate" type="text/html"/>
    <title>TR19-015 |  QMA Lower Bounds for Approximate Counting | 

	William Kretschmer</title>
    <summary>We prove a query complexity lower bound for $QMA$ protocols that solve approximate counting: estimating the size of a set given a membership oracle. This gives rise to an oracle $A$ such that $SBP^A \not\subset QMA^A$, resolving an open problem of Aaronson [2]. Our proof uses the polynomial method to derive a lower bound for the $SBQP$ query complexity of the $AND$ of two approximate counting instances. We use Laurent polynomials as a tool in our proof, showing that the "Laurent polynomial method" can be useful even for problems involving ordinary polynomials.</summary>
    <updated>2019-02-07T08:16:08Z</updated>
    <published>2019-02-07T08:16:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-14T18:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15634</id>
    <link href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/" rel="alternate" type="text/html"/>
    <title>An Old But Cool Result</title>
    <summary>Solving a type of Fermat Equation Leo Moser was a mathematician who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge numbers. Today I want to talk about one of his results with a very short proof. No, it is not about […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/><p>
<font color="#0044cc"><br/>
<em>Solving a type of Fermat Equation</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/unknown-117/" rel="attachment wp-att-15639"><img alt="" class="alignright size-full wp-image-15639" src="https://rjlipton.files.wordpress.com/2019/02/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"/></td>
</tr>
</tbody>
</table>
<p>
Leo Moser was a <a href="https://en.wikipedia.org/wiki/Leo_Moser">mathematician</a> who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge <a href="https://en.wikipedia.org/wiki/Steinhaus-Moser_notation">numbers</a>.</p>
<p>
Today I want to talk about one of his results with a very short proof.</p>
<p>
No, it is not about worms. That is a <a href="https://en.wikipedia.org/wiki/Moser%27s_worm_problem">question</a> in discrete geometry that is still open I believe: “What is the region of smallest area which can accommodate every planar arc of length one?” The region must be able to hold the arc inside but the curve can be moved and rotated to allow it to fit. A disk of diameter <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> works and has area about <img alt="{ 0.78}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.78%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.78}"/>. It is possible to do much better and get around <img alt="{ 0.27}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.27}"/>. </p>
<p><a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/worm3/" rel="attachment wp-att-15636"><img alt="" class="aligncenter size-medium wp-image-15636" height="143" src="https://rjlipton.files.wordpress.com/2019/02/worm3.png?w=300&amp;h=143" width="300"/></a></p>
<p>See this <a href="https://www.nada.kth.se/~johanh/snakes.pdf">paper</a> for some additional details.</p>
<p>
No, it is not about a conjecture of Paul Erdős See <a href="https://arxiv.org/pdf/1011.2956.pdf">this</a> for a great paper on this result: </p>
<blockquote><p><b>Theorem 1</b> <em> Suppose that 	</em></p><em>
<p align="center"><img alt="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%5E%7Bk%7D+%2B+2%5E%7Bk%7D+%2B+%5Ccdots+%2B+%28m-1%29%5E%7Bk%7D+%3D+m%5E%7Bk%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. "/></p>
<p>Then any <img alt="{(m,k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Ck%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{(m,k)}"/> solution in integers with <img alt="{k \ge 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cge+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k \ge 2}"/> must have 	</p>
<p align="center"><img alt="\displaystyle  m &gt; 10^{10^{6}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m+%3E+10%5E%7B10%5E%7B6%7D%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  m &gt; 10^{10^{6}}. "/></p>
</em><p><em/>
</p></blockquote>
<p>Erdős conjectured there are no solutions at all. It is easy to check that for <img alt="{k=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=1}"/> the unique solution is a bit smaller: 	</p>
<p align="center"><img alt="\displaystyle  1 + 2 = 3." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%2B+2+%3D+3.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 + 2 = 3."/></p>
<p>
</p><p/><h2> The Result </h2><p/>
<p/><p>
Yes, it is about the solution to a natural family of Diophantine equations. This result of Moser comes from an old paper of his. The result can be found on the wonderful blog called <a href="https://www.cut-the-knot.org/arithmetic/algebra/TwoParameterFermat.shtml">cut-the-knot</a> written by Alexander Bogomolny.</p>
<p>
The question considered by Moser is simple to state: </p>
<blockquote><p><b> </b> <em> Consider the equation over the integers <img alt="{x^{a} + y^{b} = z^{c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} = z^{c}}"/> where <img alt="{a, b, c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2C+b%2C+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{a, b, c}"/> are fixed values that are relatively prime. Show that there are infinitely many integer solutions. </em>
</p></blockquote>
<p/><p>
The surprise, to me, is that this equation always has integer solutions. I thought about it for a bit and had no idea how to even start.</p>
<p>
The solution is as follows. The initial insight is that the restriction on the exponents implies that there are integers <img alt="{m, n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m, n}"/> so that <img alt="{abm + 1 = cn}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Babm+%2B+1+%3D+cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{abm + 1 = cn}"/>. </p>
<p>
Wait a minute. We must be careful by what we mean by “the values of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> are relatively prime.” We need more than the greatest common divisor (GCD) of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. We need that <img alt="{ab}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bab%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ab}"/> and <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> are relatively prime. Note that <img alt="{6,10,15}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2C10%2C15%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6,10,15}"/> have GCD equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> but no matter which of the triple is “<img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/>” we cannot find the needed <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/>: 	</p>
<p align="center"><img alt="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%286%5Ccdot+10%2C15%29+%3E+1%2C+%2810%5Ccdot+15%2C+6%29%3E1%2C+%2815%2C6+%5Ccdot+10%29+%3E+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. "/></p>
<p>I thank Subrahmanyam Kalyanasundaram for catching this.</p>
<p>
The next idea is not to look for a single set of solutions but rather to find a parametrized solution. That is try to find expressions for <img alt="{x,y,z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y,z}"/> that depend on some variables <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> so that for all <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> the equation is satisfied. </p>
<p>
Then set 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. "/></p>
<p>Note as <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> vary over integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> vary over integers too. The claim is that this is a parameterization of the equation. Let’s see why. We need to figure out what <img alt="{x^{a} + y^{b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b}}"/> is equal to. It looks a bit nasty but it is not. Let <img alt="{W = u^{abm} + v^{abm}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BW+%3D+u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{W = u^{abm} + v^{abm}}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}W^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7DW%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}W^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}W^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7DW%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}W^{am}. "/></p>
<p>So <img alt="{x^{a} + y^{b} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} }"/> is 	</p>
<p align="center"><img alt="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u%5E%7Babm%7D+W%5E%7Babm%7D+%2B+v%5E%7Babm%7DW%5E%7Babm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. "/></p>
<p>Which magically is 	</p>
<p align="center"><img alt="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++W%5E%7Babm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29+%3D+W%5E%7Babm%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. "/></p>
<p>Thus setting 	</p>
<p align="center"><img alt="\displaystyle  z = W^{n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++z+%3D+W%5E%7Bn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  z = W^{n} "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+W%5E%7Babm%2B1%7D+%3D+W%5E%7Bcn%7D+%3D+%28W%5E%7Bn%7D%29%5E%7Bc%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. "/></p>
<p>Very neat. By the way we do need to note that as <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> run through integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> and <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> vary enough to get an infinite number of solutions. A simple growth argument shows that this is true.</p>
<p>
The key trick was to <b>not</b> use a standard idea and apply the binomial theorem and expand 	</p>
<p align="center"><img alt="\displaystyle  (u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (u^{abm} + v^{abm})^{bm}. "/></p>
<p>My algebra DNA suggests that expanding such an expression is often a good idea. Here it would lead to a mess. This is a case where using the binomial expansion does not work.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I really like Moser’s clever solution to the diophantine equation 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = z^{c}. "/></p>
<p>Note that it must fail when <img alt="{a=b=c=p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a=b=c=p}"/> for <img alt="{p&gt;2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p&gt;2}"/> by the famous solution to the original Fermat equation. </p></font></font></div>
    </content>
    <updated>2019-02-06T12:57:11Z</updated>
    <published>2019-02-06T12:57:11Z</published>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Diophantine"/>
    <category term="Fermat"/>
    <category term="worm problem"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-14T18:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1062</id>
    <link href="http://corner.mimuw.edu.pl/?p=1062" rel="alternate" type="text/html"/>
    <title>HALG 2019 - Call For Submissions of Short Contributed Presentations</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a … <a href="http://corner.mimuw.edu.pl/?p=1062">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a different venue or journal (or to be submitted there) is welcome.</p>
<p>If you would like to present your results at HALG 2019, please submit their details the abstract of the talk or the contribution of the poster via EasyChair: <a href="https://easychair.org/conferences/?conf=halg2019" rel="noopener noreferrer" target="_blank">https://easychair.org/conferences/?conf=halg2019</a></p>
<p>The abstract should include (when relevant) information where the results have been published/accepted (e.g., conference), and where they are publicly available (e.g., arXiv). All submissions will be reviewed by the program committee, giving priority to new work not formally published yet, and to papers published in 2018 or later.</p>
<p>Submissions deadline: March 15th, 2019.<br/>
Late submissions will be accepted subject to space constraints.</p></div>
    </content>
    <updated>2019-02-06T11:41:10Z</updated>
    <published>2019-02-06T11:41:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-02-13T23:23:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=92</id>
    <link href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/" rel="alternate" type="text/html"/>
    <title>Extremal Combinatorics V: POSETS</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the remaining post V on partially ordered sets of my series on extremal combinatorics (I,II,III,IV,VI).  We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting … <a href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is the remaining post V on partially ordered sets of my series on extremal combinatorics (<a href="https://gilkalai.wordpress.com/2008/05/01/extremal-combinatorics-i/">I</a>,<a href="https://gilkalai.wordpress.com/2008/07/17/extermal-combinatorics-ii-some-geometry-and-number-theory/">II</a>,<a href="https://gilkalai.wordpress.com/2008/09/28/extremal-combinatorics-iii-some-basic-theorems/">III</a>,<a href="https://gilkalai.wordpress.com/2008/10/06/extremal-combinatorics-iv-shifting/">IV</a>,<a href="https://gilkalai.wordpress.com/2009/05/21/extremal-combinatorics-vi-the-frankl-wilson-theorem/">VI</a>). </em></p>
<p>We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting with the order relation on the integers and reals in algebra and in Euclidean geometry. The set of all subsets of a set can be partially ordered by inclusion and this is a very basic example of posets. While the study of order and posets is a separate area on its own, parts of it are very important in extremal combinatorics and we will give a little taste here.</p>
<p style="text-align: center;"><span style="color: #0000ff;"><strong>Dear readers, please contribute your favorite result or problem on partially ordered sets (or Sorting) in the comment session.</strong></span></p>
<p>A chain <img alt="C \subset P" class="latex" src="https://s0.wp.com/latex.php?latex=C+%5Csubset+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C \subset P"/> in a POSET is a set of elements so that every two of them are comparable. An antichain $A \subset P$ is a set of elements so that every two distinct elemenאs in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are incomparable.  (Antichains are also called independent sets.) An immediate but important Lemma is:</p>
<p><strong>The immediate lemma:</strong> The intersection of a chain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and an antichain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> contains at most one element. <strong><span style="color: #993366;">Walla!</span></strong></p>
<h3>Dilworth’s theorem</h3>
<p>Dilworth’s theorem (DT): Every finite partially ordered <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> set can be covered by <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains.</p>
<p>(By the immediate lemma, at least <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains are needed.)</p>
<p>Dual Dilworth theorem: Every partially ordered sets can be covered by <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains.</p>
<p>(By the immediate lemma, at least <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains are needed.)</p>
<p>The proof of the dual Dilworth theorem is easy. Note that the set <img alt="A_1=MIN(P)" class="latex" src="https://s0.wp.com/latex.php?latex=A_1%3DMIN%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_1=MIN(P)"/> of minimal elements of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is an antichain. Let <img alt="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%3D+MIN+%28P%5Cbackslash+%28A_1+%5Ccup+A_2+%5Ccup+%5Cdots+A_%7Bk-1%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))"/>. We need two easy observations. First, <img alt="A_k is an antichain" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+is+an+antichain&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k is an antichain"/> and second: If <img alt="A_k \ne \emptyset" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k \ne \emptyset"/> then there is a chain with one element from <img alt="A_i: 1 \le i\le k" class="latex" src="https://s0.wp.com/latex.php?latex=A_i%3A+1+%5Cle+i%5Cle+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i: 1 \le i\le k"/>. <strong><span style="color: #0000ff;">Walla!</span></strong></p>
<p>The proof of Dilworth’s theorem is by induction on $|P|$. For the induction step you first consider the case where every antichain of maximal size is either <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> or <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/>. In this case you consider a chain with one element in <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> and one element in <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/> and delete these elements from <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For the resulting post <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/>, <img alt="a(Q)=a(P)-1" class="latex" src="https://s0.wp.com/latex.php?latex=a%28Q%29%3Da%28P%29-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(Q)=a(P)-1"/> and we can use the induction hypothesis.</p>
<p>Otherwise there is an antichain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of maximum size <img alt="t=a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a(P)"/> which is not <em>MAX(P)</em> or <em>MIN(P)</em>.  Put <img alt="A=\{a_1,a_2,\dots,a_t\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7Ba_1%2Ca_2%2C%5Cdots%2Ca_t%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{a_1,a_2,\dots,a_t\}"/>. Let <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are larger or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>, and let <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are smaller or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<p>Now,</p>
<ol>
<li><img alt="P^+ \cup P^-=P" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccup+P%5E-%3DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cup P^-=P"/>. Otherwise we could add an element to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to form a larger antichain.</li>
<li><img alt="P^+ \cap P^- = A" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccap+P%5E-+%3D+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cap P^- = A"/>. Otherwise, there will be two elements of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> which are comparable.</li>
</ol>
<p>So by the induction hypothesis <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> can be covered by <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1^+, C_2^+, \dots, C_t^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E%2B%2C+C_2%5E%2B%2C+%5Cdots%2C+C_t%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^+, C_2^+, \dots, C_t^+"/> and <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> can be covered by <img alt="a(P" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P"/>$ chains <img alt="C_1^-, C_2^-, \dots, C_t^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E-%2C+C_2%5E-%2C+%5Cdots%2C+C_t%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^-, C_2^-, \dots, C_t^-"/>. Bu re-indexing we can assume that both <img alt="C_i^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^+"/> and <img alt="C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^-"/> contains <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>. It follows that <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/> is the minimal element in $C_i^+$ and the maximal element in $C_i^-$ and hence <img alt="C_i=:C_i^+ \cup C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%3D%3AC_i%5E%2B+%5Ccup+C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i=:C_i^+ \cup C_i^-"/> is a chain. The <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1, C_2, \dots, C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2C+C_2%2C+%5Cdots%2C+C_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1, C_2, \dots, C_t"/> cover <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. <span style="color: #993366;"><strong>Sababa!</strong></span></p>
<p>An <strong>important Corollary</strong> both from Dilworth’s theorem and its dual is that</p>
<p style="text-align: center;"><img alt="a(P) c(P) \ge |P|." class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29+c%28P%29+%5Cge+%7CP%7C.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P) c(P) \ge |P|."/></p>
<h3>Erdos-Szekeres theorem</h3>
<p>The fundamental Erdos Szekeres theorem asserts that if <img alt="n=ab+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3Dab%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=ab+1"/> then every sequence <img alt="a_1,a_2,\dots ,a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_n"/> of different real numbers contains a monotone increasing sequence of length <img alt="a+1" class="latex" src="https://s0.wp.com/latex.php?latex=a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a+1"/> or a monotone decreasing sequence of length <img alt="b+1" class="latex" src="https://s0.wp.com/latex.php?latex=b%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b+1"/>.</p>
<p>There are simple proofs. For example, associate to every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> a pair <img alt="(I_k,D_k)" class="latex" src="https://s0.wp.com/latex.php?latex=%28I_k%2CD_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(I_k,D_k)"/> of integers where  <img alt="I_k" class="latex" src="https://s0.wp.com/latex.php?latex=I_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I_k"/> is the maximum length of the increasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/> and <img alt="D_k" class="latex" src="https://s0.wp.com/latex.php?latex=D_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_k"/> is the maximum length of the deccreasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/>. The result follows from the easy observation that all these pairs are different.</p>
<p>Both Dilworth’ theorem and its easy dual imply easily (in fact we need only the important corollary) the Erdos Szekeres theorem when we define the following partial order: <img alt="i &lt; k" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; k"/> if both <img alt="i&lt;k" class="latex" src="https://s0.wp.com/latex.php?latex=i%3Ck&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i&lt;k"/> and <img alt="a_i &lt; a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_i+%3C+a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i &lt; a_k"/>.</p>
<h3>Looking at Sperner’s theorem again</h3>
<p>Sperner’s theorem asserts that the maximal size of an antichain of subsets of an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> elements set is <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/>. By Dilworth’s theorem it follows that we can cover all sets by <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/> chains (and, of course when we exhibit such a covering it reproves Sperner’s theorem). A symmetric saturated chain decomposition is a partition of <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/> (=all subsets of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/>) to saturated chains where each chain has, for some <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>, sets of sizes $k,k+1,\dots,d-k$. You can build such a decomposition inductively.</p>
<p>Start with a decomposition for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> for each chain <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/> create a new chain <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> by adding the element <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/> to every set. And then move the top set in <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> to <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/>.  <strong>Walla!</strong></p>
<p>This is the beginning of a very beautiful story related also to the Dedekind Problem about  number of antichains in <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png"><img alt="" class="alignnone size-full wp-image-16834" height="489" src="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png?w=640&amp;h=489" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Curtis Greene and Danny Kleitman</span></strong></p>
<h3>The Greene-Kleitman theorem</h3>
<p>Let <img alt="a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k(P)"/> be the maximum size of the union <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> antichains in a poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For every chain For every chain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> we have <img alt="|C \cap X| \le \min\{|C|,k\}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CC+%5Ccap+X%7C+%5Cle+%5Cmin%5C%7B%7CC%7C%2Ck%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|C \cap X| \le \min\{|C|,k\}"/>. Therefore for a partition of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> to chains <img alt="C_1,C_2,\dots,C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2CC_2%2C%5Cdots%2CC_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1,C_2,\dots,C_t"/> we   have <img alt="\sum\min\{|C_i|,k\ge |X|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5Cge+%7CX%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\ge |X|"/>. The <a href="https://www.encyclopediaofmath.org/index.php/Greene-Kleitman_theorem">Greene-Kleitman theorem</a> asserts that there is always  a decomposition into chains with <img alt="\sum\min\{|C_i|,k\}=a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5C%7D%3Da_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\}=a_k(P)"/>.</p>
<h3>The perfect graph theorem.</h3>
<p>What is the relation between the very easy dual Dilworth theorem and the harder Dilworth theorem? As it turns out there is a very general theorem, Lovasz’ perfect graph theorem, that shows that these two theorems are equivalent.</p>
<p>A graph G is perfect if for every induced subgraph H, the chromatic number equals the clique number. Lovasz’ theorem  (conjectured by Claude Berge) asserts that complements of perfect graphs are perfect. The perfectness of the comparability graph of a poset amounts to the dual Dilworth theorem, and for its complement it is the Dilworth theorem. Lovasz in fact proved that perfectness is equivalent to the relation $\latex \omega(H)\cdot \alpha (H) \ge |H|$ for every induced subgraph H. (For posets this is our important corollary above.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png"><img alt="" class="alignnone size-full wp-image-16832" height="239" src="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png?w=640&amp;h=239" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Jeff Kahn and Jake Baron </span></strong><span style="color: #ff0000;">(</span><span style="color: #ff0000;"><a href="http://archive.dimacs.rutgers.edu/DIMACS_highlights/tuza/tuza.html">see here on their 2016 asymptotic solution to Tusza’s conjecture</a></span><span style="color: #ff0000;">),</span><strong><span style="color: #ff0000;"> Mike Saks, and Nati Linial</span></strong></p>
<h3>Startling theorems on POSETS: Kahn-Saks,  Linial-Saks, Linial-Kahn, and Kahn-Saks</h3>
<p>Here  are some beautiful and important theorems on posets. An order ideas <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> of a post is a set of elements so that if <img alt="x in I" class="latex" src="https://s0.wp.com/latex.php?latex=x+in+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x in I"/> and <img alt="y &lt; x" class="latex" src="https://s0.wp.com/latex.php?latex=y+%3C+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y &lt; x"/> then <img alt="y \in I" class="latex" src="https://s0.wp.com/latex.php?latex=y+%5Cin+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y \in I"/>.</p>
<p><strong>Theorem (Linial-Saks, 1985):</strong> In every poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> there is an element which is contained in more than δ and less than 1-δ order ideas of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.  (<a href="http://www.cs.huji.ac.il/~nati/PAPERS/central_element.pdf">Paper</a>)</p>
<p><strong>Theorem (Kahn-Saks, 1984):</strong> For every Poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which is not a chain there are two incomparable elements <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> such that the number of linear extensions of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> for which <img alt="x&lt;y" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x&lt;y"/> is between 3/11 and 8/11. (<a href="https://link.springer.com/article/10.1007/BF00565647">Paper</a>)</p>
<p>A <a href="http://www.cs.huji.ac.il/~nati/PAPERS/brunn_minkowski.pdf">simpler proof</a> was found in the late 80s by Kahn and Linial and by Karzanov and Khachiyan. It  is  based on the Brunn Minkowski theorem and gives a weaker constant <img alt="1/2e" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2e"/> .</p>
<p><strong>Theorem (Kahn-Saks, 1987)</strong>: For every finite distributive lattice <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> the maximum antichain is of size <img alt="o(|L|)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%7CL%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(|L|)"/>. (<a href="https://core.ac.uk/download/pdf/82629369.pdf">Paper</a>)</p>
<p>Lattices are special types of posets with the property that for every set of elements (pairs <img alt="\{x,y\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bx%2Cy%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{x,y\}"/> suffice in the finite case), there is a unique minimal elements above them all (denoted for pairs by <i>x</i> ∧ <i>y</i>) and a unique maximal element (denoted for pairs by <i>x</i> ∨ <i>y</i>) below them all.</p>
<p>A <a href="https://en.wikipedia.org/wiki/Distributive_lattice">distributive lattice</a> is a lattice that satisfies for every <em>x, y</em> and <em>z</em>, the relation</p>
<p style="text-align: center;"><i>x</i> ∧ (<i>y</i> ∨ <i>z</i>) = (<i>x</i> ∧ <i>y</i>) ∨ (<i>x</i> ∧ <i>z</i>)</p>
<p>Birkhoff’s representation theorem asserts that finite distributive lattices can be represented as order ideals of posets (ordered by inclusion).</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-02-05T11:18:54Z</updated>
    <published>2019-02-05T11:18:54Z</published>
    <category term="Combinatorics"/>
    <category term="Claude Berge"/>
    <category term="Curtis Greene"/>
    <category term="Daniel Kleitman"/>
    <category term="Dilworth's theorem"/>
    <category term="Extremal combinatorics"/>
    <category term="Jeff Kahn"/>
    <category term="Laci Lovasz"/>
    <category term="Mike Saks"/>
    <category term="Nati Linial"/>
    <category term="Posets"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-14T18:20:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-8542550481798271953</id>
    <link href="http://processalgebra.blogspot.com/feeds/8542550481798271953/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=8542550481798271953" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8542550481798271953" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8542550481798271953" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/02/two-awards-at-hicss19-for-csgssi.html" rel="alternate" type="text/html"/>
    <title>Two awards at HICSS’19 for CS@GSSI student Roberto Verdecchia</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><div><a href="https://robertoverdecchia.github.io/" target="_blank">Roberto Verdecchia</a>, a third-year Ph.D. student of the Gran Sasso Science Institute (GSSI) and the Vrije Universiteit Amsterdam (VU) has received two distinct prizes at the 52nd Hawaii International Conference on System Sciences (HICSS’19;<span> </span><a href="http://hicss.hawaii.edu/" style="color: #1155cc;" target="_blank">http://hicss.hawaii.edu/</a>) for his research paper “<a href="https://robertoverdecchia.github.io/papers/HICSS_2019.pdf" style="color: #1155cc;" target="_blank">DecidArch: Playing Cards as Software Architects</a>”, which is <span style="font-family: Helvetica; font-size: 12px;">co-authored with</span><i style="font-family: Helvetica; font-size: 12px;"> </i>Patricia Lago, Jia F. Cai (both at VU Amsterdam), Remco C. de Boer (ArchiXL) and Philippe Kruchten (University of British Columbia). Out of over 780 papers presented at HICCS within 11 different research tracks, the study was presented with the “Best Paper award” of the Software Education and Training track. Additionally, the article was also selected as one of the five “ISSIP-IBM-CBA Student Paper Award for Best Industry Studies Paper” of HICCS’19.</div><div><br/>The study presents a novel educational game conceived to train students and practitioners in concepts related to software architecture and decision making. The game is currently used as an interactive session of the course “Software Architecture”, taught at the Vrije Universiteit Amsterdam.<br/><br/>The two prizes were adjudicated independently by two distinct committees.</div><div> </div><div>Congratulations to Roberto!</div><div><br/></div><div>Let me close by adding that I expect that Roberto will deliver his PhD thesis in the autumn 2019 and will soon be on the job market. If you have a postdoc or tenure-track  position in SE, keep him mind. </div></div></div>
    </content>
    <updated>2019-02-05T08:58:00Z</updated>
    <published>2019-02-05T08:58:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-02-12T10:35:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4206</id>
    <link href="https://lucatrevisan.wordpress.com/2019/02/04/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-11/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>新年快乐！ Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><img alt="8cxnLMGdi" class="alignnone size-full wp-image-4207" src="https://lucatrevisan.files.wordpress.com/2019/02/8cxnlmgdi.png?w=584"/></p>
<p>新年快乐！</p></div>
    </content>
    <updated>2019-02-05T06:45:35Z</updated>
    <published>2019-02-05T06:45:35Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-02-14T18:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4122</id>
    <link href="https://www.scottaaronson.com/blog/?p=4122" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4122#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4122" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sabineblogging</title>
    <summary xml:lang="en-US">I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including Sabine Hossenfelder’s New York Times column arguing that we shouldn’t.  (See also the responses by Jeremy Bernstein and Lisa Randall, and the discussion on Peter Woit’s blog, and Daniel Harlow’s Facebook thread, and this Vox […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including <a href="https://www.nytimes.com/2019/01/23/opinion/particle-physics-large-hadron-collider.html">Sabine Hossenfelder’s <em>New York Times</em> column</a> arguing that we shouldn’t.  (See also the <a href="https://www.nytimes.com/2019/02/01/opinion/letters/physics-research-collider-cern.html">responses</a> by Jeremy Bernstein and Lisa Randall, and the <a href="http://www.math.columbia.edu/~woit/wordpress/?p=10768">discussion on Peter Woit’s blog</a>, and <a href="https://www.facebook.com/daniel.harlow.31/posts/10104284984149212">Daniel Harlow’s Facebook thread</a>, and <a href="https://www.vox.com/future-perfect/2019/1/22/18192281/cern-large-hadron-collider-future-circular-collider-physics">this <em>Vox</em> piece</a> by Kelsey Piper.)  Let me blog about this as a way of cracking my knuckles or tuning my violin, just getting back into blog-shape after a long hiatus for travel and family and the beginning of the semester.</p>
<p>Regardless of whether this opinion is widely shared among my colleagues, I like Sabine.  I’ve often found her <a href="http://backreaction.blogspot.com/">blogging</a> funny and insightful, and I wish more non-Lubos physicists would articulate their thoughts for the public the way she does, rather than just standing on the sidelines and criticizing the ones who do. I find it unfortunate that some of the replies to Sabine’s arguments dwelled on her competence and “standing” in physics (even if we set aside—as we should—Lubos’s misogynistic rants, whose predictability could be used to calibrate atomic clocks). It’s like this: if high-energy physics <em>had</em> reached a pathological state of building bigger and bigger colliders for no good reason, then we’d <em>expect</em> that it would take a semi-outsider to say so in public, so then it wouldn’t be a further surprise to find precisely such a person doing it.</p>
<p>Not for the first time, though, I find myself coming down on the opposite side as Sabine. Basically, <em>if</em> civilization could get its act together and find the money, I think it would be pretty awesome to build a new collider to push forward the energy frontier in our understanding of the universe.<br/><!--StartFragment--></p>


<p>Note that I’m not making the much stronger claim that this is the <em>best possible</em> use of $20 billion for science.  Plausibly a thousand $20-million projects could be found that would advance our understanding of reality by more than a new collider would.  But it’s also important to realize that that’s not the question at stake here.  When, for example, the US Congress cancelled the <a href="https://en.wikipedia.org/wiki/Superconducting_Super_Collider">Superconducting Supercollider</a> midway through construction—partly, it’s believed, on the basis of opposition from eminent physicists in other subfields, who argued that they could do equally important science for much cheaper—none of the SSC budget, as in 0% of it, ever <em>did</em> end up redirected to those other subfields.  In practice, then, the question of “whether a new collider is worth it” is probably best considered in absolute terms, rather than relative to other science projects.</p>



<p>What I found most puzzling, in Sabine’s writings on this subject, was the leap in logic from</p>



<ol><li>many theorists expected that superpartners, or other new particles besides the Higgs boson, had a good chance of being discovered at the LHC, based on statistical arguments about “natural” parameter values, and</li><li>the basic soundness of naturalness arguments was always open to doubt, and indeed the LHC results to date offer zero support for them, and</li><li>many of the same theorists now want an even bigger collider, and continue to expect new particles to be found, and haven’t sufficiently reckoned with their previous failed predictions, to …</li><li><strong>therefore</strong> we shouldn’t build the bigger collider.</li></ol>



<p>How do we get from 1-3 to 4: is the idea that we should <em>punish</em> the errant theorists, by withholding an experiment that they want, in order to deter future wrong predictions?  After step 3, it seems to me that Sabine could equally well have gone to: and therefore it’s all the more important that we <em>do</em> build a new collider, in order to establish all the more conclusively that there’s just an energy desert up there—and that I, Sabine, was right to emphasize that possibility, and those other theorists were wrong to downplay it!</p>



<p>Like, I gather that there are independently motivated scenarios where there <em>would</em> be only the Higgs at the LHC scale, and then new stuff at the next energy scale beyond it.  And as an unqualified outsider who enjoys talking to friends in particle physics and binge-reading about it, I’d find it hard to assign the totality of those scenarios less than ~20% credence or more than ~80%—certainly if the actual experts don’t either.</p>



<p>And crucially, it’s not as if <em>raising the collision energy</em> is just one arbitrary direction in which to look for new fundamental physics, among a hundred a-priori equally promising directions.  Basically, there’s raising the collision energy and then there’s everything else.  By raising the energy, you’re not testing one specific idea for physics beyond Standard Model, but a hundred or a thousand ideas in one swoop.</p>



<p>The situation reminds me a little of the quantum computing skeptics who say: scalable QC can never work, in practice and probably even in principle; the mainstream physics community only <em>thinks</em> it can work because of groupthink and hype; therefore, we shouldn’t waste more funds trying to make it work.  With the sole, very interesting exception of Gil Kalai, none of the skeptics ever seem to draw what strikes me as an equally logical conclusion: whoa, let’s go <em>full speed ahead</em> with trying to build a scalable QC, because there’s an epochal revolution in physics to be had here—once the experimenters finally see that I was right and the mainstream was wrong, and they start to unravel the reasons why!</p>



<p>Of course, $20 billion is a significant chunk of change, by the standards of science even if not by the standards of random government wastages (like our recent $11 billion shutdown).  And ultimately, decisions do need to be made about which experiments are most interesting to pursue with limited resources.  And if a future circular collider <em>were</em> built, and if it indeed just found a desert, I think the balance would tilt pretty strongly toward Sabine’s position—that is, toward declining to build an even bigger and more expensive collider after that.  If the Patriots drearily won every Superbowl 13-3, year after year after year, eventually no one would watch anymore and the Superbowl would get cancelled (well, maybe that will happen for other reasons…).</p>



<p>But it’s worth remembering that—correct me if I’m wrong—so far there have been <em>no</em> cases in the history of particle physics of massively expanding the energy frontier and finding absolutely nothing new there (i.e., nothing that at least conveyed multiple bits of information, as the Higgs mass did).  And while my opinion should count for less than a neutrino mass, just thinking it over a-priori, I keep coming back to the question: before we close the energy frontier for good, shouldn’t there have been at least <em>one</em> unmitigated null result, rather than zero?</p></div>
    </content>
    <updated>2019-02-04T12:30:47Z</updated>
    <published>2019-02-04T12:30:47Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-13T04:44:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9219479121065296157</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9219479121065296157/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html" rel="alternate" type="text/html"/>
    <title>Don't know Football but still want bet on the Superb Owl?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>
(Superb Owl is not a typo. I've heard (and it could be wrong) that the  NFL guards their copyright so you can't even say `Buy Beer here for the YOU KNOW WHATl' but instead `Buy Beer here for the big game''. Stephen Colbert a long time ago go around this by calling the game Superb Owl.)</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
If I knew more about football  I might place a bet related to the Superb Owl. What kind of bets can I place?</div>
<div>
<br/></div>
<div>
1) Bet the point spread: Last time I looked the Patriots were a 2.5 point favorite. So either bet that Patriots will win by more than  2.5 or the Rams will lose by less than 2.5 or just win.</div>
<div>
<br/></div>
<div>
2) Over-Under: bet that either the total score will be over 56.5 or under it.</div>
<div>
<br/></div>
<div>
 There are prop-bets-- bets that are ABOUT the game but not related to the final score.</div>
<div>
<br/></div>
<div>
I've seen the following</div>
<div>
<br/></div>
<div>
1) Tom Brady will retire after the game. I wonder if Tom Brady (or a friend of his) could bet on this one knowing some inside information. Not i any state in America, but off-shore...</div>
<div>
<br/></div>
<div>
2) Jamie White will score the first touchdown.</div>
<div>
<br/></div>
<div>
3) Will Gladys Knight's   National Anthem go longer than 1 minute, 50 seconds (it was 1:47 seconds a few days ago but it shifted to 1:50).</div>
<div>
<br/></div>
<div>
Amazingly, this last one is what Josh Hermsmeyer (on Nate Silver's Webpage)  chose to focus on: <a href="https://fivethirtyeight.com/features/the-super-bowls-best-matchup-is-gladys-knight-vs-the-clock/">here</a>. Note that:</div>
<div>
<br/></div>
<div>
1) The people who picked 1 minute 50 seconds as the over-under probably didn't do much research. They might have set it to get the same number of people on both sides, which may explain the shift; however, I can't imagine this bet got that much action. Then again, I'm not that imaginative.</div>
<div>
<br/></div>
<div>
2) Josh DID. He did an  analysis of what is likely (he thinks it will go longer)</div>
<div>
<br/></div>
<div>
3) So- can Josh bet on this an clean up? Can you bet on this and clean up?</div>
<div>
<br/></div>
<div>
4) There is an issue: Some kinds of bets are legal in some places (betting who will WIN or beat a point-spread is legal in Las Vegas-- the Supreme court struck down a federal anti-betting rule). Some prop bets are legal. The Gladys Knight one is not.  Why not? Someone could have inside information! Gladys Knight would!</div>
<div>
<br/></div>
<div>
So you CAN bet  Rams+2.5 beats the Patriots LEGALLY</div>
<div>
<br/></div>
<div>
but to bet Gladys Knight's National Anthem will take more than 1 minute 50 seconds you might need to use  BITCOIN, and go to some offshore account. Too much sugar for a <a href="https://en.bitcoin.it/wiki/Satoshi_(unit)">satoshi</a>.</div>
<div>
<br/></div>
<div>
5) There is another issue- there is no such thing as a sure thing (I blogged on that <a href="https://blog.computationalcomplexity.org/2008/02/there-is-no-such-thing-as-sure-thing.html">here</a>). People who bet on sports for a living (I know one such person and will blog about that later) play THE LONG GAME. So to say</div>
<div>
<br/></div>
<div>
          <i> I will withdraw X dollars (for large X)  from my investments and bet it on </i></div>
<div>
<i>          Gladys Knight's</i><i>  Star Spangled Banner to go more than 1 minute 50 seconds</i></div>
<div>
<i>          because its a sure thing</i></div>
<div>
<br/></div>
<div>
Would be... a very bad idea.<br/>
<br/>
The above was all written the day before Superb Owl. Now its the next day and Gladys Knight has sung the National Anthem. So who won the Gladys Knight Bowl? The answer is not as straightforward as it could be, see <a href="https://www.usatoday.com/story/sports/nfl/super-bowl/2019/02/03/super-bowl-2019-gladys-knight-causes-prop-bet-controversy-anthem/2764778002/">here</a>.</div>
<div>
<br/></div></div>
    </content>
    <updated>2019-02-04T02:36:00Z</updated>
    <published>2019-02-04T02:36:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-14T12:58:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/014" rel="alternate" type="text/html"/>
    <title>TR19-014 |  A New Proof of Nonsignalling Multiprover Parallel Repetition Theorem | 

	Himanshu Tyagi, 

	Shun Watanabe</title>
    <summary>We present an information theoretic proof of the nonsignalling multiprover parallel repetition theorem, a recent extension of its two-prover variant that underlies many hardness of approximation results. The original proofs used de Finetti type decomposition for strategies. We present a new proof that is based on a technique we introduced recently for proving strong converse results in multiuser information theory and entails a change of measure after replacing hard information constraints with soft ones.</summary>
    <updated>2019-02-03T12:39:00Z</updated>
    <published>2019-02-03T12:39:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-14T18:20:36Z</updated>
    </source>
  </entry>
</feed>
