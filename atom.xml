<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-01-07T10:22:05Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1259</id>
    <link href="https://thmatters.wordpress.com/2019/01/07/catcs-mailing-list-and-sign-up-link/" rel="alternate" type="text/html"/>
    <title>CATCS mailing list and sign-up link</title>
    <summary>CATCS is starting up a new mailing list to send out annual newsletters. Messages will be sent out 1-2 times every year describing recent projects undertaken by the committee, funding opportunities, links to useful resources, etc. Anyone interested in hearing about our activities is welcome to sign up at this link. You do not have […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>CATCS is starting up a new mailing list to send out annual newsletters. Messages will be sent out 1-2 times every year describing recent projects undertaken by the committee, funding opportunities, links to useful resources, etc. Anyone interested in hearing about our activities is welcome to sign up at <a href="https://groups.google.com/forum/#!forum/catcs-news">this link</a>. You do not have to be a member of SIGACT to sign up.<span style="color: #000000; font-family: Arial, sans-serif;"><br/>
</span></p>
<div/></div>
    </content>
    <updated>2019-01-07T08:42:09Z</updated>
    <published>2019-01-07T08:42:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2019-01-07T10:21:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42167</id>
    <link href="https://cstheory.stackexchange.com/questions/42167/decomposition-for-a-certain-class-of-graphs" rel="alternate" type="text/html"/>
    <title>Decomposition for a certain class of graphs</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose a graph, <span class="math-container">$G = (V,E)$</span> is characterized as a lattice/network of cliques as in the picture below. Does there exist some decomposition principle (i.e. on the right) for <span class="math-container">$G$</span>, that yields some special structure that may be used to explain efficiencies experienced with what are supposed to be combinatorial hard problems?</p>

<p><a href="https://i.stack.imgur.com/FTbx8.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/FTbx8.png"/></a></p></div>
    </summary>
    <updated>2019-01-07T06:19:24Z</updated>
    <published>2019-01-07T06:19:24Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="co.combinatorics"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="treewidth"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="integer-lattice"/>
    <author>
      <name>Student</name>
      <uri>https://cstheory.stackexchange.com/users/51578</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.01178</id>
    <link href="http://arxiv.org/abs/1901.01178" rel="alternate" type="text/html"/>
    <title>A New Approach to Multi-Party Peer-to-Peer Communication Complexity</title>
    <feedworld_mtime>1546819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ros=eacute=n:Adi.html">Adi Rosén</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Urrutia:Florent.html">Florent Urrutia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.01178">PDF</a><br/><b>Abstract: </b>We introduce new models and new information theoretic measures for the study
of communication complexity in the natural peer-to-peer, multi-party,
number-in-hand setting. We prove a number of properties of our new models and
measures, and then, in order to exemplify their effectiveness, we use them to
prove two lower bounds. The more elaborate one is a tight lower bound of
$\Omega(kn)$ on the multi-party peer-to-peer randomized communication
complexity of the $k$-player, $n$-bit Disjointness function. The other one is a
tight lower bound of $\Omega(kn)$ on the multi-party peer-to-peer randomized
communication complexity of the $k$-player, $n$-bit bitwise parity function.
Both lower bounds hold when $n=\Omega(k)$. The lower bound for Disjointness
improves over the lower bound that can be inferred from the result of Braverman
et al. (FOCS 2013), which was proved in the coordinator model and can yield a
lower bound of $\Omega(kn/\log k)$ in the peer-to-peer model.
</p>
<p>To the best of our knowledge, our lower bounds are the first tight
(non-trivial) lower bounds on communication complexity in the natural
peer-to-peer multi-party setting.
</p>
<p>In addition to the above results for communication complexity, we also prove,
using the same tools, an $\Omega(n)$ lower bound on the number of random bits
necessary for the (information theoretic) private computation of the
$k$-player, $n$-bit Disjointness function.
</p></div>
    </summary>
    <updated>2019-01-07T02:20:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-01-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.01172</id>
    <link href="http://arxiv.org/abs/1901.01172" rel="alternate" type="text/html"/>
    <title>Faster and Smaller Two-Level Index for Network-based Trajectories</title>
    <feedworld_mtime>1546819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rivera:Rodrigo.html">Rodrigo Rivera</a>, Andrea Rodríguez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seco:Diego.html">Diego Seco</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.01172">PDF</a><br/><b>Abstract: </b>Two-level indexes have been widely used to handle trajectories of moving
objects that are constrained to a network. The top-level of these indexes
handles the spatial dimension, whereas the bottom level handles the temporal
dimension. The latter turns out to be an instance of the interval-intersection
problem, but it has been tackled by non-specialized spatial indexes. In this
work, we propose the use of a compact data structure on the bottom level of
these indexes. Our experimental evaluation shows that our approach is both
faster and smaller than existing solutions.
</p></div>
    </summary>
    <updated>2019-01-07T02:21:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.01135</id>
    <link href="http://arxiv.org/abs/1901.01135" rel="alternate" type="text/html"/>
    <title>About the Complexity of Two-Stage Stochastic IPs</title>
    <feedworld_mtime>1546819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klein:Kim=Manuel.html">Kim-Manuel Klein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.01135">PDF</a><br/><b>Abstract: </b>We consider so called $2$-stage stochastic integer programs (IPs) and their
generalized form of multi-stage stochastic IPs. A $2$-stage stochastic IP is an
integer program of the form $\max \{ c^T x \mid Ax = b, l \leq x \leq u, x \in
\mathbb{Z}^n \}$ where the constraint matrix $A \in \mathbb{Z}^{s \times r}$
consists roughly of $n$ repetition of a block matrix $A$ on the vertical line
and $n$ repetitions of a matrix $B \in \mathbb{Z}^{t \times r}$ on the
diagonal. In this paper we improve upon an algorithmic result by Hemmecke and
Schultz form 2003 to solve $2$-stage stochastic IPs. The algorithm is based on
the Graver augmentation framework where our main contribution is to give an
explicit double exponential bound on the size of the augmenting steps. The
previous bound for the size of the augmenting steps relied on non-constructive
finiteness arguments from computational algebra and therefore only am implicit
bound was known that depends on parameters $r,s,t$ and $\Delta$, where $\Delta$
is the largest entry od the constraint matrix. Our new improved bound however
is obtained by a novel theorem which argues about the intersection of paths in
a vector space. As a result of our new bound we obtain an algorithm to solve
$2$-stage stochastic IPs in time $poly(n,t) \cdot f(r,s,\Delta)$, where $f$ is
a double exponential function. To complement our result, we also prove a double
exponential lower bound for the size of the augmenting steps.
</p></div>
    </summary>
    <updated>2019-01-07T02:21:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00992</id>
    <link href="http://arxiv.org/abs/1901.00992" rel="alternate" type="text/html"/>
    <title>High-order curvilinear hybrid mesh generation for CFD simulations</title>
    <feedworld_mtime>1546819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Julian Marcon, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Turner:Michael.html">Michael Turner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peir=oacute=:Joaquim.html">Joaquim Peiró</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moxey:David.html">David Moxey</a>, Claire R. Pollard, Henry Bucklow, Mark Gammon <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00992">PDF</a><br/><b>Abstract: </b>We describe a semi-structured method for the generation of high-order hybrid
meshes suited for the simulation of high Reynolds number flows. This is
achieved through the use of highly stretched elements in the viscous boundary
layers near the wall surfaces. CADfix is used to first repair any possible
defects in the CAD geometry and then generate a medial object based
decomposition of the domain that wraps the wall boundaries with partitions
suitable for the generation of either prismatic or hexahedral elements. The
latter is a novel distinctive feature of the method that permits to obtain
well-shaped hexahedral meshes at corners or junctions in the boundary layer.
The medial object approach allows greater control on the "thickness" of the
boundary-layer mesh than is generally achievable with advancing layer
techniques. CADfix subsequently generates a hybrid straight sided mesh of
prismatic and hexahedral elements in the near-field region modelling the
boundary layer, and tetrahedral elements in the far-field region covering the
rest of the domain. The mesh in the near-field region provides a framework that
facilitates the generation, via an isoparametric technique, of layers of highly
stretched elements with a distribution of points in the direction normal to the
wall tailored to efficiently and accurately capture the flow in the boundary
layer. The final step is the generation of a high-order mesh using NekMesh, a
high-order mesh generator within the Nektar++ framework. NekMesh uses the
CADfix API as a geometry engine that handles all the geometrical queries to the
CAD geometry required during the high-order mesh generation process. We will
describe in some detail the methodology using a simple geometry, a NACA wing
tip, for illustrative purposes. Finally, we will present two examples of
application to reasonably complex geometries proposed by NASA as CFD validation
cases.
</p></div>
    </summary>
    <updated>2019-01-07T02:22:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00990</id>
    <link href="http://arxiv.org/abs/1901.00990" rel="alternate" type="text/html"/>
    <title>A variational approach to high-order r-adaptation</title>
    <feedworld_mtime>1546819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Julian Marcon, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Turner:Michael.html">Michael Turner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moxey:David.html">David Moxey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherwin:Spencer_J=.html">Spencer J. Sherwin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peir=oacute=:Joaquim.html">Joaquim Peiró</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00990">PDF</a><br/><b>Abstract: </b>A variational framework, initially developed for high-order mesh
optimisation, is being extended for r-adaptation. The method is based on the
minimisation of a functional of the mesh deformation. To achieve adaptation,
elements of the initial mesh are manipulated using metric tensors to obtain
target elements. The nonlinear optimisation in turns adapts the final
high-order mesh to best fit the description of the target elements by
minimising the element distortion. Encouraging preliminary results prove that
the method behaves well and can be used in the future for more extensive work
which shall include the use of error indicators from CFD simulations.
</p></div>
    </summary>
    <updated>2019-01-07T02:22:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00988</id>
    <link href="http://arxiv.org/abs/1901.00988" rel="alternate" type="text/html"/>
    <title>Near-Optimal Lower Bounds on the Threshold Degree and Sign-Rank of AC^0</title>
    <feedworld_mtime>1546819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Pei.html">Pei Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00988">PDF</a><br/><b>Abstract: </b>The threshold degree of a Boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is
the minimum degree of a real polynomial $p$ that represents $f$ in sign:
$\mathrm{sgn}\; p(x)=(-1)^{f(x)}.$ A related notion is sign-rank, defined for a
Boolean matrix $F=[F_{ij}]$ as the minimum rank of a real matrix $M$ with
$\mathrm{sgn}\; M_{ij}=(-1)^{F_{ij}}$. Determining the maximum threshold degree
and sign-rank achievable by constant-depth circuits ($\text{AC}^{0}$) is a
well-known and extensively studied open problem, with complexity-theoretic and
algorithmic applications.
</p>
<p>We give an essentially optimal solution to this problem. For any
$\epsilon&gt;0,$ we construct an $\text{AC}^{0}$ circuit in $n$ variables that has
threshold degree $\Omega(n^{1-\epsilon})$ and sign-rank
$\exp(\Omega(n^{1-\epsilon})),$ improving on the previous best lower bounds of
$\Omega(\sqrt{n})$ and $\exp(\tilde{\Omega}(\sqrt{n}))$, respectively. Our
results subsume all previous lower bounds on the threshold degree and sign-rank
of $\text{AC}^{0}$ circuits of any given depth, with a strict improvement
starting at depth $4$. As a corollary, we also obtain near-optimal bounds on
the discrepancy, threshold weight, and threshold density of $\text{AC}^{0}$,
strictly subsuming previous work on these quantities. Our work gives some of
the strongest lower bounds to date on the communication complexity of
$\text{AC}^{0}$.
</p></div>
    </summary>
    <updated>2019-01-07T02:21:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-01-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00984</id>
    <link href="http://arxiv.org/abs/1901.00984" rel="alternate" type="text/html"/>
    <title>Quantum Insertion-Deletion Channels</title>
    <feedworld_mtime>1546819200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Janet Leahy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Touchette:Dave.html">Dave Touchette</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yao:Penghui.html">Penghui Yao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00984">PDF</a><br/><b>Abstract: </b>We introduce a model of quantum insertion-deletion (insdel) channels. Insdel
channels are meant to represent, for example, synchronization errors arising in
data transmission. In the classical setting, they represent a strict
generalization of the better-understood corruption error channels, and until
recently, had mostly resisted effort toward a similar understanding as their
corruption counterparts. They have received considerable attention in recent
years. Very recently, Haeupler and Shahrasbi developed a framework, using what
they call synchronisation strings, that allows one to turn insdel-type errors
into corruption-type errors. These can then be handled by the use of standard
error-correcting codes. We show that their framework can be extended to the
quantum setting, providing a way to turn quantum insdel errors into quantum
corruption errors, which can be handled with standard quantum error-correcting
codes.
</p></div>
    </summary>
    <updated>2019-01-07T02:21:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42166</id>
    <link href="https://cstheory.stackexchange.com/questions/42166/algorithm-for-k-best-non-perfect-bipartite-matchings" rel="alternate" type="text/html"/>
    <title>Algorithm for K-best NON perfect bipartite matchings</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I was reading this great article: <a href="https://core.ac.uk/download/pdf/82129717.pdf" rel="nofollow noreferrer">https://core.ac.uk/download/pdf/82129717.pdf</a></p>

<p>It solves a generalization of the maximum sum assignment problem by finding the k best assignments and not only the best.
However, it only looks at perfect matchings. I'm am especially interested in bipartite matchings.</p>

<p>In particular, for the bipartite graphs, the Theorem 1 p. 161 uses the fact that the matchings are considered perfect.</p>

<p>How can I solve the k-best assignment problem for general bipartite graphs?</p></div>
    </summary>
    <updated>2019-01-06T23:47:08Z</updated>
    <published>2019-01-06T23:47:08Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="matching"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="bipartite-graphs"/>
    <author>
      <name>Labo</name>
      <uri>https://cstheory.stackexchange.com/users/43172</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4355005625360509962</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4355005625360509962/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/when-is-kilogram-not-kilogram.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4355005625360509962" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4355005625360509962" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/when-is-kilogram-not-kilogram.html" rel="alternate" type="text/html"/>
    <title>When is a kilogram not a kilogram?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A long long time ago the standards for meter's, kilograms, etc was an actual physical object.<br/>
<br/>
Those days are long gone of course. For example, the meter is defined is the length of the path traveled by light in 1/299,792,458 th of a second. Why such an odd number (can fractions be odd?)? Because they retrofitted it to what that the meter is.  Rather than go to France and compare my stick to the one under a glass case I can just measure the speed of light. Oh. That sounds hard!<br/>
<br/>
It matters a bit since the weight of what was the standard kilogram did increase over time, though of course not by much. When did the measurements for stuff STOP being based on physical objects and was all done based on constants of the universe?<br/>
<br/>
The answer surprised me:<br/>
<br/>
On Nov 16, 2018 (yes, you read that light) they decided that by May 20, 2019, the Kilogram will be defined in terms of Plank's constant. I have not been able to find out how they will use Plank, maybe they don't know yet (they do and its known -- see the first comment) .With that, there are no more standards based on physical objects. Read about it <a href="https://www.wired.com/story/new-kilogram-definition-based-on-planck-constant/">here</a>.<br/>
<br/>
Why did it take so long? I honestly don't know and I am tossing that question out to my readers. You can leave serious or funny answers, and best if I can't tell which is which!<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-01-06T21:35:00Z</updated>
    <published>2019-01-06T21:35:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-01-07T09:37:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15562</id>
    <link href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/" rel="alternate" type="text/html"/>
    <title>Predictions For 2019</title>
    <summary>The problem of predicting ‘when’ not just ‘what’ Cropped from Toronto Star source Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s 1984. He wrote an exclusive feature for the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The problem of predicting ‘when’ not just ‘what’</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg"><img alt="" class="alignright wp-image-15564" height="167" src="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg?w=180&amp;h=167" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Toronto Star <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s <em>1984</em>. He wrote an exclusive <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">feature</a> for the Toronto Star newspaper predicting what the world would be like 35 years hence, that is, in 2019.</p>
<p>
Today we give our take on his predictions and make our own for the rest of 2019.</p>
<p>
Asimov’s essay began by presupposing the absence of nuclear holocaust without predicting it. It then focused on two subjects: computerization and use of outer space. On the spectrum of evaluations subtended by this laudatory BBC <a href="https://www.bbc.com/news/technology-46736024">piece</a> and this critical <a href="https://www.thestar.com/news/world/2018/12/27/isaac-asimov-you-were-no-nostradamus.html">column</a> in the Toronto Star itself, we’re closer to the latter. On space he predicted we’d be mining the Moon by now; instead nothing more landed on the Moon until the Chinese <a href="https://en.wikipedia.org/wiki/Chang'e_3">Chang’e 3</a> mission in 2013 and <a href="https://en.wikipedia.org/wiki/Chang'e_4">Chang’e 4</a> happening now. His 35-year span should be lengthened to over a century.</p>
<p>
On computerization and robotics he was mostly right except again for the timespan: he said the transition would be “about over” by 2019 whereas it may be entering its period of greatest flux only now. However, for the end of 1983 we think the “whats” of his predictions were easy. Personal computers had already been around for almost a decade. Computer systems for business were plentiful. The Internet was already a proclaimed goal and the text-based <a href="https://en.wikipedia.org/wiki/Usenet">Usenet</a> was already operating. Asimov’s essay seems to miss how the combination of these three would soon move points of control outward to end-users. </p>
<p>
We still think what he wrote about space and robots will happen. This shows the problem of predictions is not just ‘what’ but ‘when.’ For another instance of being wrong on ‘when’ too soon, Ken told a Harvard Law graduate who visited him in Oxford in 1984 that what we now call <a href="https://en.wikipedia.org/wiki/Deepfake">deepfake</a> videos were imminent. We’ll make the rest of this post more about ‘when’ than ‘what.’</p>
<p>
</p><p/><h2> Predictions in Past Years </h2><p/>
<p/><p>
Here are some predictions that we have made before. Seems we did not make any new predictions last year—oh well—but see <a href="https://rjlipton.wordpress.com/2018/01/02/predictions-we-didnt-make/">this</a>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>No circuit lower bound of <img alt="{1000n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1000n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1000n}"/> or better will be proved for SAT.</em> Well that’s a freebie.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>A computer scientist will win a Nobel Prize.</em> No—indeed, less close than other years.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>At least five claims that <img alt="{\mathsf{P}=\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}=\mathsf{NP}}"/> and five that <img alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P} \neq \mathsf{NP}}"/> will be made.</em> </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> A “provably” secure crypto-system will be broken. For this one we don’t have to check any claims. We just pocket the ‘yes’ answer. Really, could you ever prove the opposite? How about the <a href="https://cacm.acm.org/magazines/2019/1/233523-imperfect-forward-secrecy/abstract">attack</a> on Diffie-Hellman in the current CACM?</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>An Earth-sized planet will be detected orbiting within the habitable zone of its single star.</em> The “when” for this one came in 2017 already. We are retiring it.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>A Clay problem will be solved, or at least notable progress made.</em> Again we sense that the answer on progress is “no.” This includes saying that nothing substantial seems to have emerged from Sir Michael Atiyah’s <a href="https://aperiodical.com/2018/09/atiyah-riemann-hypothesis-proof-final-thoughts/">claim</a> of proving the Riemann Hypothesis. However, we note <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">via</a> Gil Kalai’s blog that a longstanding problem called the <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/>-conjecture for spheres has been <a href="https://arxiv.org/abs/1812.10454">solved</a> by Karim Adiprasito.</p>
<p>
</p><p/><h2> Predictions This Year </h2><p/>
<p/><p>
We will add some new predictions—it seems unfair to keep repeating sure winners. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Deep learning methods will be found able to solve integer factoring.</em> This will place current cryptography is trouble.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Deep learning methods will be found to help prove that factoring is hard.</em></p>
<p>
These may not be as contradictory as they seem. There is a long-known <a href="http://www.cs.sfu.ca/~kabanets/papers/natural-learning-short.pdf">connection</a> between certain learning algorithms and the <a href="https://en.wikipedia.org/wiki/Natural_proof">natural</a> <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">proofs</a> of Alexander Razborov and Stephen Rudich. The hardness predicate at the core of a natural proof is a classifier to distinguish (succinct) hard Boolean functions from easy ones. There is a duality between upper and lower bounds that in particular leads to the unconditional result that the discrete log problem, which is related to factoring and equally amenable to Peter Shor’s famous polynomial-time quantum algorithm, does not have natural proofs of hardness—because their existence would make discrete log relatively easy. </p>
<p>
Talking about quantum, we predict:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>Quantum supremacy will be proved—finally.</em> But be careful: there is a problem with this whole direction. See the next section.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>An algorithm originating in a theoretical model will be enshrined in law.</em> </p>
<p>
There are several near-term opportunities for this. The Supreme Court yesterday agreed to <a href="https://www.cnn.com/2019/01/04/politics/supreme-court-gerrymandering-cases/index.html">hear</a> two cases on partisan gerrymandering, at least one of which promises to codify an algorithmic criterion for excessive vote dilution. Maine adopted a automatic-runoff voting system whose dependence on computer implementation gave grounds for an unsuccessful <a href="https://www.americanthinker.com/blog/2018/11/maine_gop_rep_sues_to_stop_counting_ranked_choice_ballots.html">lawsuit</a>. Algorithmic fairness is a burgeoning area which we <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">discussed</a> a year-plus ago. <a href="https://www.sciencemag.org/news/2019/01/can-set-equations-keep-us-census-data-private">Use</a> of differential privacy by the U.S. Census could involve legislation. We distinguish legal provisions from the myriad problematic uses of algorithmic models in public and private <em>policy</em> ranging from credit evaluations to parole decisions to college admissions and much else.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <em>The lines between heuristically solvable and really hard problems will become clearer.</em> We have <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">previously</a> <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">opined</a> that the great success of SAT solvers in particular renders the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> question moot for many purposes. Well, now we say the opposite: SAT solvers will hit a wall.</p>
<p>
</p><p/><h2> Quantum Supremacy and Advantage </h2><p/>
<p/><p>
Ken recently attended a workshop in central New York that aimed to bring together researchers in many fields working on quantum devices. Materials for the workshop led off with the question of building quantum computers and highlighted Gil Kalai’s skeptical position in particular. An <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">eight</a>–<a href="https://rjlipton.wordpress.com/2012/02/15/nature-does-not-conspire/">part</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">debate</a> between him and Aram Harrow which we hosted in 2012 <a href="https://rjlipton.wordpress.com/2012/03/05/the-quantum-super-pac/">involved</a> also John Preskill and <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">ended</a> with a discussion of quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>, a term advanced that year by Preskill. The workshop preferred the term quantum <em>advantage</em>. We interpret these terms as having the following distinction:</p>
<ul>
<li>
(a) Quantum <em>supremacy</em> means that a quantum device can perform general-purpose computations that no classical program or device can emulate in comparably feasible time. <p/>
</li><li>
(b) Quantum <em>advantage</em> means that some particular practical task can be achieved by available quantum devices at lower costs than near-term available classical devices.
</li></ul>
<p>
As theoreticians we tend to think about (a) but many businesses and public-sector organizations would be ecstatic to have (b) in important applications. </p>
<p>
A new angle on (a) was shown by the new construction by Ran Raz and Avishay Tal of an oracle <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> such that <img alt="{\mathsf{BQP}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{BQP}^A}"/> is not in <img alt="{\mathsf{PH}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPH%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{PH}^A}"/>. This was <a href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html">hailed</a> as the “result of the year” by Lance Fortnow (his second and our first is this <a href="https://eccc.weizmann.ac.il/report/2018/006/">progress</a> on the Unique Games Conjecture), and Scott Aaronson furnished a great <a href="https://www.scottaaronson.com/blog/?p=3827">discussion</a> of its genesis and further ramifications in complexity theory. <a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">Several</a> <a href="https://cacm.acm.org/magazines/2019/1/233514-quantum-leap/fulltext">popular</a> <a href="https://www.thehindu.com/sci-tech/science/quantum-computers-have-an-edge-over-classical-ones-says-the-oracle/article24420375.ece">articles</a> tried to pump this as non-oracle evidence for (a). But there is the over-arching problem:</p>
<blockquote><p><b> </b> <em> We know <img alt="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Csubseteq+BPP+%5Csubseteq+BQP+%5Csubseteq+PP+%5Csubseteq+P%5E%7B%5C%23P%7D+%5Csubseteq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}"/> but we don’t know <img alt="{\mathsf{P \neq PSPACE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq PSPACE}}"/>. </em>
</p></blockquote>
<p/><p>
So how are we ever going to be able to <em>prove</em> any form of supremacy? Even if we replace ‘polynomial time’ as our definition of ‘feasible’ by something more concrete, how can we prove that successful classical heuristics <em>do not exist</em>? On a certain practical problem of general import, Ewin Tang, a teenager in Texas advised by Scott, <a href="https://arxiv.org/abs/1807.04271">designed</a> an improved classical algorithm for low-rank matrix completion that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">eliminated</a> a previous quantum exponential advantage in the time dependence on the rank parameter. It is not just a case of <em>whether</em> we can prove supremacy, but judging <em>when</em> general quantum computers will be built to realize it.</p>
<p>
Whereas, the <em>when</em> involved in (b) is <em>now</em>. If a quantum device can do something useful now that classical methods are not delivering now, then it does not matter if the latter could be improved at greater hardware and development cost to work a year from now. This has been the gung-ho tenor of many responses to the recently-<a href="https://www.fedscoop.com/trump-signs-national-quantum-initiative-law/">signed</a> National Quantum Initiative Act. We do, however, still need to find and build said devices…</p>
<p>
As for the status of (a), we don’t know any better thought for January than the Janus-like title of this <a href="https://arxiv.org/abs/1807.10749">paper</a> by Igor Markov, Aneeqa Fatima, Sergei Isakov, and Sergio Boixo: </p>
<blockquote><p><b> </b> <em> “Quantum Supremacy Is Both Closer and Farther than It Appears.” </em>
</p></blockquote>
<p>
</p><p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What are your predictions for 2019? What are the most important matters we’ve left unsaid?</p>
<p>
[added some words to end of intro]</p></font></font></div>
    </content>
    <updated>2019-01-06T19:03:39Z</updated>
    <published>2019-01-06T19:03:39Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="2018"/>
    <category term="2019"/>
    <category term="Isaac Asimov"/>
    <category term="New Year's"/>
    <category term="predictions"/>
    <category term="quantum advantage"/>
    <category term="quantum supremacy"/>
    <category term="year-in-review"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-01-07T10:20:55Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42163</id>
    <link href="https://cstheory.stackexchange.com/questions/42163/immutable-space-model" rel="alternate" type="text/html"/>
    <title>Immutable Space Model</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have heard it said that time is more precious than space because we can reuse space but not time.  What if we treat space with this much reverence?</p>

<h3>What is generally known about models of computation in which space is immutable?</h3>

<p>I would expect such models to initialize each memory cell to some "blank" state and then only allow the writing of some "non-blank" value to each cell at most once.</p>

<p>The study of <a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="noreferrer">persistent data structures</a> seems to me like a possible way to answer this question.</p>

<p>I thought of this question while studying functional programming, which highly values immutability.</p></div>
    </summary>
    <updated>2019-01-06T15:37:04Z</updated>
    <published>2019-01-06T15:37:04Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="reference-request"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.data-structures"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="functional-programming"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="space-complexity"/>
    <author>
      <name>Tyson Williams</name>
      <uri>https://cstheory.stackexchange.com/users/3964</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42161</id>
    <link href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete" rel="alternate" type="text/html"/>
    <title>Is this partition problem strongly NP-complete?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Some computational problems have variants that appear to be harder. For instance, Graph Automorphism (GA) problem has quasi-polynomial time algorithm ( by Babai's Graph Isomorphism result) while the fixed-point free GA problem is NP-complete. </p>

<p><a href="https://en.wikipedia.org/wiki/Partition_problem" rel="nofollow noreferrer">Partition problem</a> is weakly NP-complete problem since it has pseudo-polynomial time algorithm. I am interested in variants that are strongly NP-complete.</p>

<p>Here is a variant of partition problem:</p>

<p>Restricted partition problem</p>

<p><strong>Input</strong>: Set <span class="math-container">$S$</span> of <span class="math-container">$2N$</span> integers, and a collection <span class="math-container">$P$</span> of pairs from <span class="math-container">$S$</span>, <span class="math-container">$0 \lt |P| \lt N$</span> </p>

<p><strong>Query</strong>: Is there a partition of <span class="math-container">$S$</span> into two equal cardinality parts <span class="math-container">$A$</span> and <span class="math-container">$S-A$</span> such that both parts have the same sum and no pair in <span class="math-container">$P$</span> has both elements in one side of the partition?</p>

<blockquote>
  <p>Is this variant of partition problem NP-complete in the strong sense? </p>
</blockquote>

<p>This was posted first on <a href="https://mathoverflow.net/questions/306039/is-this-partition-problem-strongly-np-complete">Math overflow</a> (I believe the posted answer is incorrect since the proposed dynamic programming algorithm does not take into consideration the cardinality of <span class="math-container">$P$</span>).</p></div>
    </summary>
    <updated>2019-01-06T12:45:42Z</updated>
    <published>2019-01-06T12:45:42Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="partition-problem"/>
    <author>
      <name>Mohammad Al-Turkistany</name>
      <uri>https://cstheory.stackexchange.com/users/495</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42160</id>
    <link href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph" rel="alternate" type="text/html"/>
    <title>maximize edges minus vertices in a weighted graph</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>for a given weighted vertices and edges graph, we want to find the maximum subgraph. the maximum subgraph is made of some vertices and some edges of the given graph which sum of the edges minus sum of the vertices is maximum. what is the algorithm for this problem? or any help with the code please.</p></div>
    </summary>
    <updated>2019-01-06T11:00:18Z</updated>
    <published>2019-01-06T11:00:18Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <author>
      <name>andrew</name>
      <uri>https://cstheory.stackexchange.com/users/51663</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/003</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/003" rel="alternate" type="text/html"/>
    <title>TR19-003 |  Near-Optimal Lower Bounds on the Threshold Degree and Sign-Rank of AC^0 | 

	Alexander A. Sherstov, 

	Pei Wu</title>
    <summary>The threshold degree of a Boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is the minimum degree of a real polynomial $p$ that represents $f$ in sign: $\mathrm{sgn}\; p(x)=(-1)^{f(x)}.$ A related notion is sign-rank, defined for a Boolean matrix $F=[F_{ij}]$ as the minimum rank of a real matrix $M$ with $\mathrm{sgn}\; M_{ij}=(-1)^{F_{ij}}$.  Determining the maximum threshold degree and sign-rank achievable by constant-depth circuits ($\text{AC}^{0}$) is a well-known and extensively studied open problem, with complexity-theoretic and algorithmic applications.

We give an essentially optimal solution to this problem. For any $\epsilon&gt;0,$ we construct an $\text{AC}^{0}$ circuit in $n$ variables that has threshold degree $\Omega(n^{1-\epsilon})$ and sign-rank $\exp(\Omega(n^{1-\epsilon})),$ improving on the previous best lower bounds of $\Omega(\sqrt{n})$ and $\exp(\tilde{\Omega}(\sqrt{n}))$, respectively. Our results subsume all previous lower bounds on the threshold degree and sign-rank of $\text{AC}^{0}$ circuits of any given depth, with a strict improvement starting at depth $4$. As a corollary, we also obtain near-optimal bounds on the discrepancy, threshold weight, and threshold density of $\text{AC}^{0}$, strictly subsuming previous work on these quantities.  Our work gives some of the strongest lower bounds to date on the communication complexity of $\text{AC}^{0}$.</summary>
    <updated>2019-01-06T08:28:49Z</updated>
    <published>2019-01-06T08:28:49Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-01-07T10:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/002</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/002" rel="alternate" type="text/html"/>
    <title>TR19-002 |  Complexity of Linear Operators | 

	Alexander Kulikov, 

	Ivan Mikhailin, 

	Vladimir Podolskii, 

	Andrey Mokhov</title>
    <summary>Let $A \in \{0,1\}^{n \times n}$ be a matrix with $z$ zeroes and $u$ ones and $x$ be an $n$-dimensional vector of formal variables over a semigroup $(S, \circ)$. How many semigroup operations are required to compute the linear operator $Ax$?

As we observe in this paper, this problem contains as a special case the well-known range queries problem and has a rich variety of applications in such areas as graph algorithms, functional programming, circuit complexity, and others. It is easy to compute $Ax$ using $O(u)$ semigroup operations. The main question studied in this paper is: can $Ax$ be computed using $O(z)$ semigroup operations? We prove that in general this is not possible: there exists a matrix $A \in \{0,1\}^{n \times n}$ with exactly two zeroes in every row (hence $z=2n$) whose complexity is $\Theta(n\alpha(n))$ where $\alpha(n)$ is the inverse Ackermann function. However, for the case when the semigroup is commutative, we give a constructive proof of an $O(z)$ upper bound. This implies that in commutative settings, complements of sparse matrices can be processed as efficiently as sparse matrices (though the corresponding algorithms are more involved). Note that this covers the cases of Boolean and tropical semirings that have numerous applications, e.g., in graph theory. 

As a simple application of the presented linear-size construction, we show how to multiply two $n\times n$ matrices over an arbitrary semiring in $O(n^2)$ time if one of these matrices is a 0/1-matrix with $O(n)$ zeroes (i.e., a complement of a sparse matrix).</summary>
    <updated>2019-01-06T05:55:08Z</updated>
    <published>2019-01-06T05:55:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-01-07T10:20:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42159</id>
    <link href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often" rel="alternate" type="text/html"/>
    <title>NuSMV - How to indicate the execution should visit some states infinitely often?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have the following kripke structure:</p>

<p><a href="https://i.stack.imgur.com/3xDPG.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/3xDPG.png"/></a></p>

<p>I need my model to follow the LTL constraint that state d will be visited infinitely often:</p>

<pre><code>LTLSPEC  G F (modelState=d)
</code></pre>

<p>This constraint fails due to existence of the loop .... b-&gt;c-&gt;b-&gt;c ......  </p>

<p>Question: What would be a solution to this problem? This may be related to fair traces, but I am not very familiar with that, or how to indicate d as a fair state in NuSMV. </p>

<p>I am learning model checking on my own and I appreciate your help very much.</p></div>
    </summary>
    <updated>2019-01-06T05:47:32Z</updated>
    <published>2019-01-06T05:47:32Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="model-checking"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="formal-methods"/>
    <author>
      <name>Fabiana</name>
      <uri>https://cstheory.stackexchange.com/users/51646</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00754</id>
    <link href="http://arxiv.org/abs/1901.00754" rel="alternate" type="text/html"/>
    <title>Sparsification of Binary CSPs</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Silvia Butti, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zivny:Stanislav.html">Stanislav Zivny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00754">PDF</a><br/><b>Abstract: </b>A cut $\varepsilon$-sparsifier of a weighted graph $G$ is a re-weighted
subgraph of $G$ of (quasi)linear size that preserves the size of all cuts up to
a multiplicative factor of $\varepsilon$. Since their introduction by Bencz\'ur
and Karger [STOC'96], cut sparsifiers have proved extremely influential and
found various applications. Going beyond cut sparsifiers, Filtser and
Krauthgamer [SIDMA'17] gave a precise classification of which binary Boolean
CSPs are sparsifiable. In this paper, we extend their result to binary CSPs on
arbitrary finite domains.
</p></div>
    </summary>
    <updated>2019-01-06T23:21:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00718</id>
    <link href="http://arxiv.org/abs/1901.00718" rel="alternate" type="text/html"/>
    <title>Mergeable Dictionaries With Shifts</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, Mikko Berggren Etienne, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00718">PDF</a><br/><b>Abstract: </b>We revisit the mergeable dictionaries with shift problem, where the goal is
to maintain a family of sets subject to search, split, merge, make-set, and
shift operations. The search, split, and make-set operations are the usual
well-known textbook operations. The merge operation merges two sets and the
shift operation adds or subtracts an integer from all elements in a set. Note
that unlike the join operation on standard balanced search tree structures,
such as AVL trees or 2-4 trees, the merge operation has no restriction on the
key space of the input sets and supports merging arbitrarily interleaved sets.
This problem is a key component in searching Lempel-Ziv compressed texts, in
the mergeable trees problem, and in the union-split-find problem.
</p>
<p>We present the first solution achieving O(log U) amortized time for all
operations, where {1, 2, ..., U} is the universe of the sets. This bound is
optimal when the size of the universe is polynomially bounded by the sum of the
sizes of the sets. Our solution is simple and based on a novel extension of
biased search trees.
</p></div>
    </summary>
    <updated>2019-01-06T23:25:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00717</id>
    <link href="http://arxiv.org/abs/1901.00717" rel="alternate" type="text/html"/>
    <title>Almost Optimal Distribution-free Junta Testing</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bshouty:Nader_H=.html">Nader H. Bshouty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00717">PDF</a><br/><b>Abstract: </b>We consider the problem of testing whether an unknown $n$-variable Boolean
function is a $k$-junta in the distribution-free property testing model, where
the distance between function is measured with respect to an arbitrary and
unknown probability distribution over $\{0,1\}^n$. Chen, Liu, Servedio, Sheng
and Xie showed that the distribution-free $k$-junta testing can be performed,
with one-sided error, by an adaptive algorithm that makes $\tilde
O(k^2)/\epsilon$ queries. In this paper, we give a simple two-sided error
adaptive algorithm that makes $\tilde O(k/\epsilon)$ queries.
</p></div>
    </summary>
    <updated>2019-01-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00695</id>
    <link href="http://arxiv.org/abs/1901.00695" rel="alternate" type="text/html"/>
    <title>The Product Knapsack Problem: Approximation and Complexity</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pferschy:Ulrich.html">Ulrich Pferschy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schauer:Joachim.html">Joachim Schauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thielen:Clemens.html">Clemens Thielen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00695">PDF</a><br/><b>Abstract: </b>We consider the product knapsack problem, which is the variant of the
classical 0-1 knapsack problem where the objective consists of maximizing the
product of the profits of the selected items. These profits are allowed to be
positive or negative. We show that this recently introduced variant of the
knapsack problem is weakly NP-hard and present a fully polynomial-time
approximation scheme (FPTAS) for the problem. Moreover, we analyze the
approximation quality achieved by a natural extension of the classical greedy
procedure to the product knapsack problem.
</p></div>
    </summary>
    <updated>2019-01-06T23:24:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00650</id>
    <link href="http://arxiv.org/abs/1901.00650" rel="alternate" type="text/html"/>
    <title>A Fast Sketch Method for Mining User Similarities over Fully Dynamic Graph Streams</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jia:Peng.html">Peng Jia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Pinghui.html">Pinghui Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Jing.html">Jing Tao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guan:Xiaohong.html">Xiaohong Guan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00650">PDF</a><br/><b>Abstract: </b>Many real-world networks such as Twitter and YouTube are given as fully
dynamic graph streams represented as sequences of edge insertions and
deletions. (e.g., users can subscribe and unsubscribe to channels on YouTube).
Existing similarity estimation methods such as MinHash and OPH are customized
to static graphs. We observe that they are indeed sampling methods and exhibit
a sampling bias when applied to fully dynamic graph streams, which results in
large estimation errors. To solve this challenge, we develop a fast and
accurate sketch method VOS. VOS processes each edge in the graph stream of
interest with small time complexity O(1) and uses small memory space to build a
compact sketch of the dynamic graph stream over time. Based on the sketch built
on-the-fly, we develop a method to estimate user similarities over time. We
conduct extensive experiments and the experimental results demonstrate the
efficiency and efficacy of our method.
</p></div>
    </summary>
    <updated>2019-01-06T23:22:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00626</id>
    <link href="http://arxiv.org/abs/1901.00626" rel="alternate" type="text/html"/>
    <title>A modified greedy algorithm to improve bounds for the vertex cover number</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>R. Dharmarajan, D. Ramachandran <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00626">PDF</a><br/><b>Abstract: </b>In any attempt at designing an efficient algorithm for the minimum vertex
cover problem, obtaining good upper and lower bounds for the vertex cover
number could be crucial. In this article we present a modified greedy algorithm
of worst-case time complexity O(n3) to obtain bounds for the vertex cover
number of an input graph of order n. Using simple facts, the proposed algorithm
computes a lower bound for the vertex cover number. Then using this lower bound
it outputs a minimal vertex cover and hence gives an upper bound. The algorithm
ensures the output vertex cover is always minimal, which feature is an
improvement upon the existing greedy algorithms.
</p></div>
    </summary>
    <updated>2019-01-06T23:26:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00622</id>
    <link href="http://arxiv.org/abs/1901.00622" rel="alternate" type="text/html"/>
    <title>Efficient Race Detection with Futures</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Utterback:Robert.html">Robert Utterback</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agrawal:Kunal.html">Kunal Agrawal</a>, Jeremy Fineman, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:I=Ting_Angelina.html">I-Ting Angelina Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00622">PDF</a><br/><b>Abstract: </b>This paper addresses the problem of provably efficient and practically good
on-the-fly determinacy race detection in task parallel programs that use
futures. Prior works determinacy race detection have mostly focused on either
task parallel programs that follow a series-parallel dependence structure or
ones with unrestricted use of futures that generate arbitrary dependences. In
this work, we consider a restricted use of futures and show that it can be race
detected more efficiently than general use of futures.
</p>
<p>Specifically, we present two algorithms: MultiBags and MultiBags+. MultiBags
targets programs that use futures in a restricted fashion and runs in time
$O(T_1 \alpha(m,n))$, where $T_1$ is the sequential running time of the
program, $\alpha$ is the inverse Ackermann's function, $m$ is the total number
of memory accesses, $n$ is the dynamic count of places at which parallelism is
created. Since $\alpha$ is a very slowly growing function (upper bounded by $4$
for all practical purposes), it can be treated as a close-to-constant overhead.
MultiBags+ an extension of MultiBags that target programs with general use of
futures. It runs in time $O((T_1+k^2)\alpha(m,n))$ where $T_1$, $\alpha$, $m$
and $n$ are defined as before, and $k$ is the number of future operations in
the computation. We implemented both algorithms and empirically demonstrate
their efficiency.
</p></div>
    </summary>
    <updated>2019-01-06T23:26:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00532</id>
    <link href="http://arxiv.org/abs/1901.00532" rel="alternate" type="text/html"/>
    <title>Adversarial Robustness May Be at Odds With Simplicity</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakkiran:Preetum.html">Preetum Nakkiran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00532">PDF</a><br/><b>Abstract: </b>Current techniques in machine learning are so far are unable to learn
classifiers that are robust to adversarial perturbations. However, they are
able to learn non-robust classifiers with very high accuracy, even in the
presence of random perturbations. Towards explaining this gap, we highlight the
hypothesis that $\textit{robust classification may require more complex
classifiers (i.e. more capacity) than standard classification.}$
</p>
<p>In this note, we show that this hypothesis is indeed possible, by giving
several theoretical examples of classification tasks and sets of "simple"
classifiers for which: (1) There exists a simple classifier with high standard
accuracy, and also high accuracy under random $\ell_\infty$ noise. (2) Any
simple classifier is not robust: it must have high adversarial loss with
$\ell_\infty$ perturbations. (3) Robust classification is possible, but only
with more complex classifiers (exponentially more complex, in some examples).
</p>
<p>Moreover, $\textit{there is a quantitative trade-off between robustness and
standard accuracy among simple classifiers.}$ This suggests an alternate
explanation of this phenomenon, which appears in practice: the tradeoff may
occur not because the classification task inherently requires such a tradeoff
(as in [Tsipras-Santurkar-Engstrom-Turner-Madry `18]), but because the
structure of our current classifiers imposes such a tradeoff.
</p></div>
    </summary>
    <updated>2019-01-06T23:20:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.00512</id>
    <link href="http://arxiv.org/abs/1901.00512" rel="alternate" type="text/html"/>
    <title>Real-Time EEG Classification via Coresets for BCI Applications</title>
    <feedworld_mtime>1546732800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Eitan Netzer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frid:Alex.html">Alex Frid</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Dan.html">Dan Feldman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00512">PDF</a><br/><b>Abstract: </b>A brain-computer interface (BCI) based on the motor imagery (MI) paradigm
translates one's motor intention into a control signal by classifying the
Electroencephalogram (EEG) signal of different tasks. However, most existing
systems either (i) use a high-quality algorithm to train the data off-line and
run only classification in real-time, since the off-line algorithm is too slow,
or (ii) use low-quality heuristics that are sufficiently fast for real-time
training but introduces relatively large classification error. In this work, we
propose a novel processing pipeline that allows real-time and parallel learning
of EEG signals using high-quality but possibly inefficient algorithms. This is
done by forging a link between BCI and core-sets, a technique that originated
in computational geometry for handling streaming data via data summarization.
</p>
<p>We suggest an algorithm that maintains the representation such coreset
tailored to handle the EEG signal which enables: (i) real time and continuous
computation of the Common Spatial Pattern (CSP) feature extraction method on a
coreset representation of the signal (instead on the signal itself) , (ii)
improvement of the CSP algorithm efficiency with provable guarantees by
applying CSP algorithm on the coreset, and (iii) real time addition of the data
trials (EEG data windows) to the coreset.
</p>
<p>For simplicity, we focus on the CSP algorithm, which is a classic algorithm.
Nevertheless, we expect that our coreset will be extended to other algorithms
in future papers. In the experimental results we show that our system can
indeed learn EEG signals in real-time for example a 64 channels setup with
hundreds of time samples per second. Full open source is provided to reproduce
the experiment and in the hope that it will be used and extended to more
coresets and BCI applications in the future.
</p></div>
    </summary>
    <updated>2019-01-06T23:24:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42158</id>
    <link href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems" rel="alternate" type="text/html"/>
    <title>Best polynomial-time approximation factor for NP-optimization problems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let us say that a function <span class="math-container">$f(n)$</span> is the <strong>best approximation factor</strong> for an NP-optimization problem, if both of the following hold:</p>

<ol>
<li><p>There exist a polynomial-time algorithm <span class="math-container">$A,$</span> and an integer <span class="math-container">$n_0$</span>, such that <span class="math-container">$A$</span> provides an <span class="math-container">$f(n)$</span>-approximation for the NP-optimization problem for every instance with size <span class="math-container">$n\geq n_0$</span>. (Note: the role of <span class="math-container">$n_0$</span> is merely to treat potentially deviant small instances, which might make the function "ugly.")</p></li>
<li><p>There is no polynomial-time <span class="math-container">$(1-o(1))f(n)$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p></li>
</ol>

<p>A classic example where such a best approximation is known is the SET COVER problem (for a summary and references see its Wikipedia page): the Greedy Algorithm provides an <span class="math-container">$\ln n$</span> approximation, but there is no  <span class="math-container">$(1-o(1))\ln n$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p>

<p><strong>Questions:</strong></p>

<ol>
<li><p>Which are some other interesting NP-optimization problems for which a best approximation factor, along with its realizing algorithm, are known?  </p></li>
<li><p>Are there any counterexamples, i.e., NP-optimization problems, for which such a best approximation cannot exist, unless <span class="math-container">$P=NP$</span>?</p></li>
</ol></div>
    </summary>
    <updated>2019-01-05T16:54:03Z</updated>
    <published>2019-01-05T16:54:03Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-hardness"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-hardness"/>
    <author>
      <name>Andras Farago</name>
      <uri>https://cstheory.stackexchange.com/users/12710</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1075</id>
    <link href="https://ptreview.sublinear.info/?p=1075" rel="alternate" type="text/html"/>
    <title>News for December 2018</title>
    <summary>Happy near year, and best wishes to those close and \(\varepsilon\)-far! December concluded the year with 4 new preprints, spanning quite a lot of the property testing landscape: Testing Stability Properties in Graphical Hedonic Games, by Hendrik Fichtenberger and Anja Rey (arXiv). The authors of this paper consider the problem of deciding whether a given […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Happy near year, and best wishes to those close and \(\varepsilon\)-far! December concluded the year with 4 new preprints, spanning quite a lot of the property testing landscape:</p>



<p><strong>Testing Stability Properties in Graphical Hedonic Games</strong>, by Hendrik Fichtenberger and Anja Rey (<a href="https://arxiv.org/abs/1812.09249">arXiv</a>). The authors of this paper consider the problem of deciding whether a given <em>hedonic game</em>  possesses some “coalition stability” in a property testing framework. Namely, recall that a hedonic game is a game where players (nodes) form coalitions (subsets of nodes) based on their individual preferences and local information about the considered coalition, thus resulting in a partition of the original graph. <br/> Several notions exist to evaluate how good such a partition is, based on how “stable” the given coalitions are. This work focuses on hedonic games corresponding to bounded-degree graphs, introducing and studying the property testing question of deciding <em>(for several such notions of stability)</em> whether a given game admits a stable coalition structure, or is far from admitting such a partition.</p>



<p><strong>Spectral methods for testing cluster structure of graphs</strong>, by Sandeep Silwal and Jonathan Tidor (<a href="https://arxiv.org/abs/1812.11564">arXiv</a>). Staying among bounded-degree graphs, we turn to testing clusterability of graphs, the focus of this paper. Given an \(n\)-node graph \(G\) of degree at most \(d\) and parameters \(k, \phi\), say that \(G\) is \((k, \phi)\)-clusterable if it can be partitioned in \(k\) parts of inner conductance at least \(\phi\).<br/>Analyzing properties of a random walk on \(G\), this work gives a bicriterion guarantee (\((k, \phi)\)-clusterable vs. \(\varepsilon\)-far from \((k, \phi^\ast)\)-clusterable, where \(\phi^\ast \approx \varepsilon^2\phi^2\)) for the case \(k=2\), improving on previous work by Czumaj, Peng, and Sohler’15.</p>



<p>We then switch from graphs to probability distributions with our third paper:</p>



<p><strong>Inference under Information Constraints I: Lower Bounds from Chi-Square Contraction</strong>, by Jayadev Acharya, Clément Canonne, and Himanshu Tyagi (<a href="https://arxiv.org/abs/1812.11476">arXiv</a>). <em>(Disclaimer: I’m one of the authors.)</em> In this paper, the first of an announced series of three, the authors generalize the settings of two previous works we covered <a href="https://ptreview.sublinear.info/?m=201805">here</a> and <a href="https://ptreview.sublinear.info/?m=201809">there</a> to consider the general question of distribution testing and learning when the \(n\) i.i.d. samples are distributed among \(n\) players, which each can only communicate their sample to the central algorithm by respecting some pre-specified local information constraint <em>(e.g., privacy, or noise, or communication budget)</em>. This paper develops a general lower bound framework to study such questions, with a systematic focus on the power of public vs. private randomness between the \(n\) parties, and instantiate it to obtain tight bounds in the aforementioned locally private and communication-limited settings. (Spoiler: public randomness strictly helps, but not always.)</p>



<p>Finally, after games, graphs, and distributions, our fourth paper of the month concerns testing of functions:</p>



<p><strong>Partial Function Extension with Applications to Learning and Property Testing</strong>, by Umang Bhaskar and Gunjan Kumar (<a href="https://arxiv.org/abs/1812.05821">arXiv</a>). This work focuses on a problem quite related to property testing, that of partial function extension: given as input \(n\) pairs point/value from a purported function on a domain \(X\) of size \(|X| &gt; n\), one is tasked with deciding whether there does exist (resp., with finding) a function  \(f\) on \(X\) consistent with these \(n\) values which further satisfies a specific property, such as linearity or convexity. This is indeed very reminiscent of property testing, where one gets to query these \(n\) points and must decide (approximate) consistency with such a well-behaved function. Here, the authors study the computational hardness of this partial function extension problem, specifically for properties such as subadditivity and XOS (a sub-property of subadditivity); and as corollaries obtain new property testers for the classes of subadditive and XOS functions.</p>



<p>As usual, if you know of some work we missed from last December, let us know in the comments!</p></div>
    </content>
    <updated>2019-01-05T14:50:24Z</updated>
    <published>2019-01-05T14:50:24Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-01-07T07:21:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42155</id>
    <link href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1" rel="alternate" type="text/html"/>
    <title>Why can't a left-recursive, non-deterministic, or ambiguous grammar be LL(1)?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I've learned from several sources that an LL(1) grammar is:</p>

<ol>
<li>unambiguous,</li>
<li>not left-recursive,</li>
<li>and, deterministic (left-factorized).</li>
</ol>

<p>What I can't fully understand is why the above is true for any LL(1) grammar. I know the LL(1) parsing table will have multiple entries at some cells, but what I really want to get is a formal and general (not with an example) proof to the following proposition(s):</p>

<p>A left-recursive (1), non-deterministic (2), or ambiguous (3) grammar is not LL(1).</p></div>
    </summary>
    <updated>2019-01-05T13:29:02Z</updated>
    <published>2019-01-05T13:29:02Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="fl.formal-languages"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="grammars"/>
    <author>
      <name>Mr Geek</name>
      <uri>https://cstheory.stackexchange.com/users/39204</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/001</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/001" rel="alternate" type="text/html"/>
    <title>TR19-001 |  On OBDD-based algorithms and proof systems that dynamically change order of   variables | 

	Alexander Knop, 

	Dmitry Itsykson, 

	Dmitry Sokolov, 

	Andrei Romashchenko</title>
    <summary>In 2004 Atserias, Kolaitis and Vardi proposed OBDD-based propositional proof systems that prove unsatisfiability of a CNF formula by deduction of identically false OBDD from OBDDs representing clauses of the initial formula. All OBDDs in such proofs have the same order of variables. We initiate the study of OBDD based proof systems that additionally contain a rule that allows changing the order in OBDDs. At first, we consider a proof system OBDD($\land$, reordering) that uses the conjunction (join) rule and the rule that allows changing the order. We exponentially separate this proof system from OBDD($\land$) proof system that uses only the conjunction rule. We prove two exponential lower bounds on the size of OBDD($\land$, reordering) refutations of Tseitin formulas and the pigeonhole principle. The first lower bound was previously unknown even for OBDD($\land$) proofs and the second one extends the result of Tveretina et al. from OBDD($\land$) to OBDD($\land$, reordering).

In 2004 Pan and Vardi proposed an approach to the propositional satisfiability problem based on OBDDs and symbolic quantifier elimination (we denote algorithms based on this approach as OBDD($\land$, $\exists$) algorithms). An instance of the propositional satisfiability problem is considered as an existential quantified propositional formula. The algorithm chooses an order on variables and creates an ordered binary decision diagram (OBDD) $D$ that initially represents the constant $1$ function. Then the algorithm downloads to $D$ clauses of the CNF one by one, and applies to $D$ the elimination of the existential quantifier for variable $x$ if all clauses that contain $x$ are already downloaded. We augment these algorithms with the operation of reordering of variables and call the new scheme OBDD($\land$, $\exists$, reordering) algorithms. We notice that there exists an OBDD($\land$, $\exists$) algorithm that solves satisfiable and unsatisfiable Tseitin formulas in polynomial time. In contrast, we show that there exist formulas representing systems of linear equations over $\mathbb{F}_2$ that are hard for OBDD($\land$, $\exists$, reordering)  algorithms. Our hard instances are satisfiable formulas representing systems of linear equations over $\mathbb{F}_2$ that
correspond to some checksum matrices of error correcting codes.</summary>
    <updated>2019-01-05T07:55:37Z</updated>
    <published>2019-01-05T07:55:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-01-07T10:20:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42150</id>
    <link href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com" rel="alternate" type="text/html"/>
    <title>Prove that if A is NP-complete and B is coNP-complete, than AxB is NP-, coNP-complete</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>AxB means cartesian product of A and B.</p>

<p>May someone help me with this? I even have no idea how to prove that AxB belongs to NP or coNP</p></div>
    </summary>
    <updated>2019-01-04T22:45:04Z</updated>
    <published>2019-01-04T22:45:04Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-hardness"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="complexity-classes"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-complete"/>
    <author>
      <name>guest</name>
      <uri>https://cstheory.stackexchange.com/users/51651</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42148</id>
    <link href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission" rel="alternate" type="text/html"/>
    <title>Feel dissatisfied after each submission</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am a third year graduate student at a "top-20" university who works on fine-grained complexity (lots of playing with 3-SUM, OV and the usual popular hardness conjectures). I have been fairly productive over the last year or so and have 3 accepted papers and two submitted papers. All of this to say that I am a fairly experienced graduate student and what I am about to describe is not anecdotal.</p>

<p>Every submission brings me more dissatisfaction than satisfaction. Just before I start working on a problem, me and my advisor identify a list of concrete questions that need to be answered. After lots of thinking, we have some very nice non-trivial results which gives me a lot of happiness and satisfaction. As we start to write down all of the results, inevitably, there are some more interesting variants that pop up but are much harder to make progress on. After the initial euphoria point, I feel everything seems to go downhill. There are so many variants that also need to be answered, are clearly in the purview of the problem at hand but I am not able to. By the time we submit the paper, I am so dismayed that results in the paper seem almost trivial. Perhaps this is simply tunnel vision, but I can't overcome the sadness about not being able to answer peripheral questions (although these make for a terrific conclusion section).</p>

<p>This has happened every single time and I am wondering if this is a common feeling. Do other people in theory community feel the same way? I am not sure if this is an academia wide feeling. My fellow graduate students from other areas are over the moon after every submission (but this is just anecdotal).</p>

<p>Edit - I see that there is another soft-question on the front page. I apologize for adding another one. Its holiday season and (only?) after a few drinks, one starts to ponder over these things!</p></div>
    </summary>
    <updated>2019-01-04T17:14:28Z</updated>
    <published>2019-01-04T17:14:28Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="soft-question"/>
    <author>
      <name>karmanaut</name>
      <uri>https://cstheory.stackexchange.com/users/35523</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1474</id>
    <link href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/" rel="alternate" type="text/html"/>
    <title>On PAC Analysis and Deep Neural Networks</title>
    <summary>Guest post by Amit Daniely and Roy Frostig. For years now—especially since the landmark work of Krishevsky et. al.—learning deep neural networks has been a method of choice in prediction and regression tasks, especially in perceptual domains found in computer vision and natural language processing. How effective might it be for solving theoretical tasks? Specifically, focusing on supervised learning: Can a deep neural network, paired with a stochastic gradient method, be shown to PAC learn any interesting concept class in polynomial time? Depending on assumptions, and on one’s definition of “interesting,” present-day learning theory gives answers ranging from “no, that would solve hard problems,” to, more recently: Theorem: Networks with depth between 2 and ,1 having standard activation functions,2 with weights initialized at random and trained with stochastic gradient descent, learn, in polynomial time, constant degree large margin polynomial thresholds. Learning constant-degree polynomials can also be done simply with a linear predictor over a polynomial embedding, or, in other words, by learning a halfspace. That said, what a linear predictor can do is also essentially the state of the art in PAC learning, so this result pushes neural net learning at least as far as one might hope at first. [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Guest post by <a href="http://amitdaniely.com/">Amit Daniely</a> and <a href="https://cs.stanford.edu/~rfrostig/">Roy Frostig</a>.</em></p>
<p>For years now—especially since the landmark work of <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">Krishevsky et. al.</a>—learning deep neural networks has been a method of choice in prediction and regression tasks, especially in perceptual domains found in computer vision and natural language processing. How effective might it be for solving <em>theoretical</em> tasks?</p>
<p>Specifically, focusing on supervised learning:</p>
<blockquote><p>Can a deep neural network, paired with a stochastic gradient method, be shown to <a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning">PAC learn</a> any interesting concept class in polynomial time?</p></blockquote>
<p>Depending on assumptions, and on one’s definition of “interesting,” present-day learning theory gives answers ranging from “no, that would solve hard problems,” to, more recently:</p>
<blockquote><p><strong>Theorem:</strong> Networks with depth between 2 and <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\log(n)"/>,<a class="footnoteRef" href="https://theorydish.blog/feed/#fn1" id="fnref1"><sup>1</sup></a> having standard activation functions,<a class="footnoteRef" href="https://theorydish.blog/feed/#fn2" id="fnref2"><sup>2</sup></a> with weights initialized at random and trained with stochastic gradient descent, learn, in polynomial time, constant degree large margin polynomial thresholds.</p></blockquote>
<p>Learning constant-degree polynomials can also be done simply <em>with a linear predictor</em> over a polynomial embedding, or, in other words, by learning a halfspace. That said, what a linear predictor can do is also <em>essentially the state of the art</em> in PAC learning, so this result pushes neural net learning at least as far as one might hope at first. We will return to this point later, and discuss some limitations of PAC analysis once they are more apparent. In this sense, this post will turn out to be as much an overview of some PAC learning theory as it is about neural networks.</p>
<p>Naturally, there is a wide variety of theoretical perspectives on neural network analysis, especially in the past couple of years. Our goal in this post is not to survey or cover any extensive body of work, but simply to summarize our own recent line (from two papers: <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">DFS’16</a> and <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">D’17</a>), and to highlight the interaction with PAC learning.</p>
<h2 id="neural-network-learning">Neural network learning</h2>
<p>First, let’s define a learning task. To keep things simple, we’ll focus on binary classification over the boolean cube, without noise. Formally:</p>
<blockquote><p><strong>(Binary classification.)</strong> Given examples of the form <img alt="(x,h^*(x))" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Ch%5E%2A%28x%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(x,h^*(x))"/>, where <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/> is sampled from some unknown distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/> on <img alt="\{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{\pm 1\}^n"/>, and <img alt="h^*:\{\pm 1\}^n\to\{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*:\{\pm 1\}^n\to\{\pm 1\}"/> is some unknown function (the one that we wish to learn), find a function <img alt="h:\{\pm 1\}^n\to\{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h:\{\pm 1\}^n\to\{\pm 1\}"/> whose error, <img alt="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h%29+%3D+%5Cmathrm%7BPr%7D_%7Bx%5Csim%5Cmathcal%7BD%7D%7D+%5Cleft%28h%28x%29+%5Cne+h%5E%2A%28x%29%5Cright%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)"/>, is small.</p></blockquote>
<p>Second, define a neural network <img alt="\mathcal N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal N"/> formally as a directed acyclic graph <img alt="(V, E)" class="latex" src="https://s0.wp.com/latex.php?latex=%28V%2C+E%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(V, E)"/> whose vertices <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="V"/> are called neurons. Of them, <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> are input neurons, one is an output neuron, and the rest are called hidden neurons.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn3" id="fnref3"><sup>3</sup></a> A network together with a weight vector <img alt="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" class="latex" src="https://s0.wp.com/latex.php?latex=w+%3D+%5C%7Bw_%7Buv%7D+%3A+uv+%5Cin+E%5C%7D+%5Ccup+%5C%7Bb_v+%3A+v+%5Cin+V+%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}"/> defines a predictor <img alt="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}"/> whose prediction is computed by propagating <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/> forward through the network. Concretely:</p>
<ul>
<li>For an input neuron <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="v"/>, <img alt="h_{v,w}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{v,w}(x)"/> is the corresponding coordinate in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/>.</li>
<li>For a hidden neuron <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="v"/>, define<img alt="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29+%3D+%5Csigma%5Cleft%28+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28v%29%7D+w_%7Buv%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_v+%5Cright%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)."/>The scalar weight <img alt="b_v" class="latex" src="https://s0.wp.com/latex.php?latex=b_v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="b_v"/> is called a “bias.” In this post, the function <img alt="\sigma : \mathbb{R} \to \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%3A+%5Cmathbb%7BR%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sigma : \mathbb{R} \to \mathbb{R}"/> is the ReLU activation <img alt="\sigma(t) = \max\{t, 0\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma%28t%29+%3D+%5Cmax%5C%7Bt%2C+0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sigma(t) = \max\{t, 0\}"/>, though others are possible as well.</li>
<li>For the output neuron <img alt="o" class="latex" src="https://s0.wp.com/latex.php?latex=o&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o"/>, we drop the activation: <img alt="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Bo%2Cw%7D%28x%29+%3D+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28o%29%7D+w_%7Buo%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_o&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o"/>.</li>
</ul>
<p>Finally, let <img alt="h_{\mathcal N, w}(x) = h_{o, w}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D%28x%29+%3D+h_%7Bo%2C+w%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h_{\mathcal N, w}(x) = h_{o, w}(x)"/>. This computes a real-valued function, so where we’d like to use it for classification, we do so by thresholding, and abuse the notation <img alt="\mathrm{Err}(h_w)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(h_w)"/> to mean <img alt="\mathrm{Err}(\mathrm{sign} \circ h_w)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28%5Cmathrm%7Bsign%7D+%5Ccirc+h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(\mathrm{sign} \circ h_w)"/>.</p>
<p>Some intuition for this definition would come from verifying that:</p>
<ul>
<li>Any function <img alt="h : \{\pm 1\}^n \to \{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h : \{\pm 1\}^n \to \{\pm 1\}"/> can be computed by a network of depth two and <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="2^n"/> hidden neurons.</li>
<li>The parity function <img alt="h(x) = \prod_{i=1}^n x_i" class="latex" src="https://s0.wp.com/latex.php?latex=h%28x%29+%3D+%5Cprod_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h(x) = \prod_{i=1}^n x_i"/> can be computed by a network of depth two and <img alt="4n" class="latex" src="https://s0.wp.com/latex.php?latex=4n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="4n"/> hidden neurons. (NB: this one is a bit more challenging.)</li>
</ul>
<p>In practice, the network architecture (this DAG) is designed based on some domain knowledge, and its design can impact the predictor that’s later selected by SGD. One default architecture, useful in the absence of domain knowledge, is the multi-layer perceptron, comprised of layers of complete bipartite graphs:</p>
<figure><img alt="full_con_net" class="  wp-image-1479 aligncenter" height="426" src="https://theorydish.files.wordpress.com/2019/01/full_con_net.png?w=431&amp;h=426" width="431"/>A toy “fully-connected neural network”, a.k.a. a multi-layer perceptronAnother paradigmatic architecture is a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional network</a>:<p/>
</figure>
<figure><img alt="conv_net" class="  wp-image-1478 aligncenter" height="463" src="https://theorydish.files.wordpress.com/2019/01/conv_net.png?w=490&amp;h=463" width="490"/>A toy convolutional neural network</figure>
<p>Convolutional nets capture the notion of spatial input locality in signals such as images and audio.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn4" id="fnref4"><sup>4</sup></a> In the toy example drawn, each clustered triple of neurons is a so-called convolution filter applied to two components below it. In image domains, convolutions filters are two-dimensional and capture responses to spatial 2-D patches of the image or of an intermediate layer.</p>
<p>Training a neural net comprises (i) initialization, and (ii) iterative optimization run until <img alt="\mathrm{sign}(h_w(x)) = h^*(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsign%7D%28h_w%28x%29%29+%3D+h%5E%2A%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{sign}(h_w(x)) = h^*(x)"/> for sufficiently many examples <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/>. The initialization step sets the starting values of the weights <img alt="w^0" class="latex" src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^0"/> at random:</p>
<blockquote><p><strong>(Glorot initialization.)</strong> Draw weights <img alt="\{w^0_{uv}\}_{uv\in E}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bw%5E0_%7Buv%7D%5C%7D_%7Buv%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{w^0_{uv}\}_{uv\in E}"/> from centered Gaussians with variance <img alt="|\mathrm{IN}(v)|^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathrm%7BIN%7D%28v%29%7C%5E%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="|\mathrm{IN}(v)|^{-1}"/> and biases <img alt="\{b^0_{v}\}_{v\in V}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bb%5E0_%7Bv%7D%5C%7D_%7Bv%5Cin+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{b^0_{v}\}_{v\in V}"/> from independent standard Gaussians.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn5" id="fnref5"><sup>5</sup></a></p></blockquote>
<p>While other initialization schemes exists, this one is canonical, simple, and, as the reader can verify, satisfies <img alt="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bw%5E0%7D%5Cleft%5B%28h_%7Bv%2Cw%5E0%7D%28x%29%29%5E2%5Cright%5D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1"/> for every neuron <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="v"/> and input <img alt="x \in \{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \in \{\pm 1\}^n"/>.</p>
<p>The optimization step is essentially a local search method from the initial point, using <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> (SGD) or a variant thereof.<a class="footnoteRef" href="https://theorydish.blog/feed/#fn6" id="fnref6"><sup>6</sup></a> To apply SGD, we need a function suitable for descent, and we’ll use the commonplace logistic loss <img alt="\ell(z) = \log_2(1+e^{-z})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell%28z%29+%3D+%5Clog_2%281%2Be%5E%7B-z%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\ell(z) = \log_2(1+e^{-z})"/>, which bounds the zero-one loss <img alt="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell%5E%7B0-1%7D%28z%29+%3D+%5Cmathbf%7B1%7D%5Bz+%5Cle+0%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\ell^{0-1}(z) = \mathbf{1}[z \le 0]"/> from above:</p>
<figure><img alt="losses" class="  wp-image-1480 aligncenter" height="246" src="https://theorydish.files.wordpress.com/2019/01/losses.png?w=329&amp;h=246" width="329"/>The logistic and zero-one losses</figure>
<p> </p>
<p>Define <img alt="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D%28w%29+%3D+%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathcal+D%7D%5Cleft%5B+%5Cell%28h_w%28x%29h%5E%2A%28x%29%29+%5Cright%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]"/>. Note that <img alt="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29+%5Cle+L_%7B%5Cmathcal+D%7D%28w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)"/>, so finding weights <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w"/> for which the upper bound <img alt="L_{\mathcal D}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{\mathcal D}"/> is small enough implies low error in turn. Meanwhile, <img alt="L_{\mathcal D}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{\mathcal D}"/> is amenable to iterative gradient-based minimization.</p>
<p>Given samples from <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>, stochastic gradient descent creates an unbiased estimate of the gradient at each step <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t"/> by drawing a batch of i.i.d. samples <img alt="S_t" class="latex" src="https://s0.wp.com/latex.php?latex=S_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_t"/> from <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>. The gradient <img alt="\nabla L_{S_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+L_%7BS_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\nabla L_{S_t}"/> at a point <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w"/> can be computed efficiently by the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> algorithm.</p>
<p>In more complete detail, our prototypical neural network training algorithm is as follows. On input a network <img alt="\mathcal N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal N"/>, an iteration count <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/>, a batch size <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="b"/>, and a step size <img alt="\eta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ceta+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\eta &gt; 0"/>:</p>
<p><strong>Algorithm: <em>SGDNN</em></strong></p>
<ol type="1">
<li>Let <img alt="w^0" class="latex" src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^0"/> be random weights sampled per Glorot initialization</li>
<li>For <img alt="t = 1, \ldots, T" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+1%2C+%5Cldots%2C+T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t = 1, \ldots, T"/>:
<ol type="1">
<li>Sample a batch <img alt="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D+%3D+%5C%7B%28x%5Et_1%2C+h%5E%2A%28x%5Et_1%29%29%2C+%5Cldots%2C+%28x%5Et_b%2C+h%5E%2A%28x%5Et_b%29%29%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}"/>, where <img alt="x^t_1, \ldots, x^t_b" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Et_1%2C+%5Cldots%2C+x%5Et_b&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x^t_1, \ldots, x^t_b"/> are i.i.d. samples from <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>.</li>
<li>Update <img alt="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" class="latex" src="https://s0.wp.com/latex.php?latex=w%5Et+%5Cgets+w%5E%7Bt-1%7D+-+%5Ceta+%5Cnabla+L_%7BS_t%7D%28w%5E%7Bt-1%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})"/>, where<img alt="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7BS_t%7D%28w%5E%7Bt-1%7D%29+%3D+b%5E%7B-1%7D+%5Csum_%7Bi%3D1%7D%5Eb+%5Cell%28h_%7Bw%7D%28x%5Et_i%29+h%5E%2A%28x%5Et_i%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))"/>.</li>
</ol>
</li>
<li>Output <img alt="w^T" class="latex" src="https://s0.wp.com/latex.php?latex=w%5ET&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w^T"/></li>
</ol>
<h2 id="pac-learning">PAC learning</h2>
<p>Learning a predictor from example data is a general task, and a hard one in the worst case. We cannot efficiently (i.e. in <img alt="\mathrm{poly}(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{poly}(n)"/> time) compute, let alone learn, general functions from <img alt="\{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{\pm 1\}^n"/> to <img alt="\{\pm 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{\pm 1\}"/>. In fact, any learning algorithm that is guaranteed to succeed in general (i.e. with any target predictor <img alt="h^*" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*"/> over any data distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>) runs, in the worst case, in time exponential in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/>. This is true even for rather weak definitions of “success,” such as finding a predictor with error less than <img alt="1/2 - 2^{-n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2+-+2%5E%7B-n%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1/2 - 2^{-n/2}"/>, i.e. one that slightly outperforms a random guess.</p>
<p>While it is impossible to efficiently learn general functions under general distributions, it might still be possible to learn efficiently under some assumptions on the target <img alt="h^*" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*"/> or the distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>. Charting out such assumptions is the realm of learning theorists: by now, they’ve built up a broad catalog of function classes, and have studied the complexity of learning when the target function is in each such class. Although their primary aim has been to develop theory, the potential guidance for practice is easy to imagine: if one’s application domain happens to be modeled well by one of these easily-learnable function classes, there’s a corresponding learning algorithm to consider as well.</p>
<p>The vanilla PAC model makes no assumptions on the data distribution <img alt="\mathcal D" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal D"/>, but it does assume the target <img alt="h^*" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^*"/> belongs to some simple, predefined class <img alt="\mathcal H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H"/>. Formally, a <em>PAC learning problem</em> is defined by a function class<a class="footnoteRef" href="https://theorydish.blog/feed/#fn7" id="fnref7"><sup>7</sup></a> <img alt="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H+%5Csubset+%5C%7B%5Cpm+1%5C%7D%5E%7B%5C%7B%5Cpm+1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}"/>. A learning algorithm <img alt="\mathcal A" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal A"/> <em>learns</em> the class <img alt="\mathcal H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H"/> if, whenever <img alt="h^* \in \mathcal H" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%2A+%5Cin+%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="h^* \in \mathcal H"/>, and provided <img alt="\epsilon &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\epsilon &gt; 0"/>, it runs in time <img alt="\mathrm{poly}(1/\epsilon, n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%281%2F%5Cepsilon%2C+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{poly}(1/\epsilon, n)"/>, and returns a function of error at most <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\epsilon"/>, with probability at least 0.9. Note that:</p>
<ol type="1">
<li>The learning algorithm need not return a function from the learnt class.</li>
<li>The polynomial-time requirement means in particular that the learning algorithm cannot output a complete truth table, as its size would be exponential. Instead, it must output a short description of a hypothesis that can be evaluated in polynomial time.</li>
</ol>
<p>For a taste of the computational learning theory literature, here are some of the function classes studied by theorists over the years:</p>
<ol type="1">
<li><em>Linear thresholds (halfspaces):</em> functions that map a halfspace to 1 and its complement to -1. Formally, functions of the form <img alt="x \mapsto \theta(\langle w, x \rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Ctheta%28%5Clangle+w%2C+x+%5Crangle%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \mapsto \theta(\langle w, x \rangle)"/> for some <img alt="w \in \mathbb{R}^n" class="latex" src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w \in \mathbb{R}^n"/>, where <img alt="\theta(z) = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\theta(z) = 1"/> when <img alt="z &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=z+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z &gt; 0"/> and <img alt="\theta(z) = -1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\theta(z) = -1"/> when <img alt="z \le 0" class="latex" src="https://s0.wp.com/latex.php?latex=z+%5Cle+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="z \le 0"/>.</li>
<li><em>Large-margin linear thresholds:</em> for<img alt="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho%28z%29+%3D+%5Cbegin%7Bcases%7D+1+%26+z+%5Cge+1+%5C%5C+%2A+%26+-1+%5Cle+z+%5Cle+1+%5C%5C+-1+%26+z+%5Cle+-1+%5Cend%7Bcases%7D%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases},"/>the class<img alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%28%5Clangle+w%2Cx+%5Crangle%29+%5Ctext%7B+with+%7D+%5C%7Cw%5C%7C_2%5E2+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}."/></li>
<li><em>Intersections of halfspaces:</em> functions that map an intersection of polynomially many halfspaces to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1"/> and its complement to <img alt="-1" class="latex" src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="-1"/>.</li>
<li><em>Polynomial threshold functions:</em> thresholds of constant-degree polynomials.</li>
<li><em>Large-margin polynomial threshold functions:</em> the class</li>
</ol>
<p><img alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%5Cleft%28+%5Csum_%7BA+%5Csubset+%5Bn%5D%2C+%7CA%7C+%5Cle+O%281%29%7D+%5Calpha_A+%5Cprod_%7Bi+%5Cin+A%7D+x_i+%5Cright%29+%5C%3B%5Ctext%7B+with+%7D%5C%3B+%5Csum_%7BA%7D+%5Calpha%5E2_A+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}."/></p>
<ol type="1">
<li><em>Decision trees</em>, <em>deterministic automata</em>, and <em><a href="https://en.wikipedia.org/wiki/Disjunctive_normal_form">DNF</a> formulas</em> of polynomial size.</li>
<li><em>Monotone conjunctions:</em> functions that, for some <img alt="A \subset [n]" class="latex" src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A \subset [n]"/> map <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x"/> to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1"/> if <img alt="x_i = 1" class="latex" src="https://s0.wp.com/latex.php?latex=x_i+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i = 1"/> for all <img alt="i \in A" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in A"/>, and to <img alt="-1" class="latex" src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="-1"/> otherwise.</li>
<li><em>Parities:</em> functions of the form <img alt="x \mapsto \prod_{i \in A} x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cprod_%7Bi+%5Cin+A%7D+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \mapsto \prod_{i \in A} x_i"/> for some <img alt="A \subset [n]" class="latex" src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A \subset [n]"/>.</li>
<li><em>Juntas:</em> functions that depend on at most <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\log(n)"/> variables.</li>
</ol>
<p>Learning theorists look at these function classes and work to distinguish those that are efficiently learnable from those that are <em>hard</em> to learn. They establish hardness results by reduction from other computational problems that are conjectured to be hard, such as random XOR-SAT (though none today are conditioned outright on NP hardness); see for example <a href="https://arxiv.org/abs/1404.3378">these</a> <a href="https://arxiv.org/abs/1505.05800">two</a> results. Meanwhile, halfspaces are learnable by linear programming. Parities, or more generally, <img alt="\mathbb{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{F}"/>-linear functions for a field <img alt="\mathbb{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{F}"/>, are learnable by Gaussian elimination. In turn, via reductions, many other classes are efficiently learnable. This includes polynomial thresholds, decision lists, and more. To give an idea of what’s known in the literature, here is an artist’s depiction of some of what’s currently known:</p>
<figure><img alt="classes" class=" size-full wp-image-1477 aligncenter" src="https://theorydish.files.wordpress.com/2019/01/classes.png?w=620"/>Learnable and conjectured hard-to-learn function classes</figure>
<p> </p>
<p>At a high-level, the upshot from all of this—and if you take away just one thing from this quick tour of PAC—is that:</p>
<blockquote><p>Barring a small handful of exceptions, all known efficiently learnable classes can be reduced to halfspaces or <img alt="\mathbb{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathbb{F}"/>-linear functions.</p></blockquote>
<p>Or, to put it more bluntly, <strong>the state of the art in PAC-learnability is essentially linear prediction</strong>.</p>
<h2 id="pac-analyzing-neural-nets">PAC analyzing neural nets</h2>
<p>Research in algorithms and complexity often follows these steps:</p>
<ol type="1">
<li>define a computational problem,</li>
<li>design an algorithm that solves it, and then</li>
<li>establish bounds on the resource requirements of that algorithm.</li>
</ol>
<p>A bound on the algorithm’s performance forms, in turn, a bound on the <em>computational problem’s</em> inherent complexity.</p>
<p>By contrast, we have already decided on our SGDNN algorithm, and we’d like to attain some grasp on its capabilities. So we’d like to do things in a different order:</p>
<ol type="1">
<li>define an <em>algorithm</em> (done),</li>
<li>design a computational problem to which the algorithm can be applied, and then</li>
<li>establish bounds on the resource requirements of the algorithm in solving the problem.</li>
</ol>
<p>Our computational problem will be a PAC learning problem, corresponding to a function class. For SGDNN, an ambitious function class we might consider is the class of all functions realizable by the network. But if we were to follow this approach, we would run up against the same hardness results mentioned before.</p>
<p>So instead, we’ve established the theorem stated at the top of this post. That is, that SGDNN, over a range of network configurations, learns a class that we <em>already know</em> to be learnable: large margin polynomial thresholds. Restated:</p>
<blockquote><p><strong>Theorem, again:</strong> There is a choice of SGDNN step size <img alt="\eta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\eta"/> and number of steps <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/>, as well as a with parameter <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="r"/>, where <img alt="T, r \le \mathrm{poly}(n/\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=T%2C+r+%5Cle+%5Cmathrm%7Bpoly%7D%28n%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T, r \le \mathrm{poly}(n/\epsilon)"/>, such that SGDNN on a multi-layer perceptron of depth between 2 and <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\log(n)"/>, and of width<a class="footnoteRef" href="https://theorydish.blog/feed/#fn8" id="fnref8"><sup>8</sup></a> <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="r"/>, learns large magin polynomials.</p></blockquote>
<p>How rich are large margin polynomials? They contain disjunctions, conjunctions, DNF and <a href="https://en.wikipedia.org/wiki/Conjunctive_normal_form">CNF</a> formulas with a constant many terms, DNF and CNF formulas with a constant many literals in each term. By corollary, SGDNN can PAC learn these classes as well. And at this point, we’ve covered a considerable fraction of the function classes known to be poly-time PAC learnable by <em>any</em> method.</p>
<p>Exceptions include constant-degree polynomial thresholds with no restriction on the coefficients, decision lists, and parities. It is well known that SGDNN cannot learn parities, and in ongoing work with Vitaly Feldman, we show that SGDNN cannot learn decision lists nor constant-degree polynomial thresholds with unrestricted coefficients. So the picture becomes more clear:</p>
<figure><img alt="classes_nn" class=" size-full wp-image-1476 aligncenter" src="https://theorydish.files.wordpress.com/2019/01/classes_nn.png?w=620"/>Conjectured hard-to-learn classes, known learnable classes, and those known to be learnable by SGDNN.</figure>
<p> </p>
<p>The theorem above runs SGDNN with a multi-layer perceptron. What happens if we change the network architecture? It can be shown then that SGDNN learns a qualitatively different function class. For instance, with convolutional networks, the learnable functions include certain polynomials of <em>super-constant</em> degree.</p>
<h3 id="a-word-on-the-proof">A word on the proof</h3>
<p>The path to the theorem traverses two papers. There’s a corresponding outline for the proof.</p>
<p>The first step is to show that, with high probability, the Glorot random initialization renders the network in a state where the final hidden layer (just before the output node) is rich enough to approximate all large-margin polynomial threshold functions (LMPTs). Namely, every LMPT can be approximated by the network up to some setting of the weights that enter the output neuron (all remaining weights random). The tools for this part of the proof include (i) the connection between kernels and random features, (ii) a characterization of symmetric kernels of the sphere, and (iii) a variety of properties of Hermite polynomials. It’s described in our <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">2016 paper</a>.</p>
<p>An upshot of this correspondence is that if we run SGD <em>only on the top layer</em> of a network, leaving the remaining weights as they were randomly initialized, we learn LMPTs. (Remember when we said that we won’t beat what a linear predictor can do? There it is again.) The second step of the proof, then, is to show that the correspondence continues to hold even if we train all the weights. In the assumed setting (e.g. provided at most logarithmic depth, sufficient width, and so forth), what’s represented in the final hidden layer changes sufficiently slowly that, over the course of SGDNN’s iterations, it <em>remains</em> rich enough to approximate all LMPTs. The final layer does the remaining work of picking out the right LMPT. The argument is in Amit’s <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">2017 paper</a>.</p>
<h2 id="pacing-up">PACing up</h2>
<p>To what extent should we be satisfied, knowing that our algorithm of interest (SGDNN) can solve a (computationally) easy problem?</p>
<p>On the positive side, we’ve managed to say something at all about neural network training in the PAC framework. Roughly speaking, some class of non-trivially layered neural networks, trained as they typically are, learns any known learnable function class that isn’t “too sensitive.” It’s also appealing that the function classes vary across different architectures.</p>
<p>On the pessimistic side, we’re confronted to a major limitation on the “function class” perspective, prevalent in PAC analysis and elsewhere in learning theory. All of the classes that SGDNN learns, <em>under the assumptions</em> touched on in this post, are so-called large-margin classes. Large-margin classes are essentially linear predictors over a <em>fixed and data-independent</em> embedding of input examples, as alluded to before. These are inherently “shallow models.”</p>
<p>That seems rather problematic in pursuing any kind of theory for learning layered networks, where the entire working premise is that a deep network uses its hidden layers to learn a representation adapted to the example domain. Our analysis—both its goal and its proof—clash with this intuition: it works out that a “shallow model” can be learned when assumptions imply that “not too much” change takes place in hidden layers. It seems that the representation learning phenomenon is what’s interesting, yet the typical PAC approach, as well as the analysis touched on in this post, all avoid capturing it.</p>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1">Here <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> is the dimension of the instance space.<a href="https://theorydish.blog/feed/#fnref1"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn2">For instance, ReLU activations, of the form <img alt="x \mapsto \max\{x,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cmax%5C%7Bx%2C0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x \mapsto \max\{x,0\}"/>.<a href="https://theorydish.blog/feed/#fnref2"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn3">Recurrent networks allow for cycles, but in this post we stick to DAGs.<a href="https://theorydish.blog/feed/#fnref3"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn4">Convolutional networks often also constrain subsets of their weights to be equal; that turns out not to bear much on this post.<a href="https://theorydish.blog/feed/#fnref4"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn5">Although not essential to the results described, it also simplifies this post to zero the weights on edges incident to the output node as part of the initialization.<a href="https://theorydish.blog/feed/#fnref5"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn6"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants">Variants of SGD</a> are used in practice, including algorithms used elsewhere in optimization (e.g. <a href="https://distill.pub/2017/momentum/">SGD with momentum</a>, <a href="http://www.jmlr.org/papers/v12/duchi11a.html">AdaGrad</a>) or techniques developed more specifically for neural nets (e.g. RMSprop, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="https://arxiv.org/abs/1502.03167">batch norm</a>). We’ll stick to plain SGD.<a href="https://theorydish.blog/feed/#fnref6"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn7">More accurately, a sequence of function classes <img alt="\mathcal H_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathcal H_n"/> for <img alt="n = 1, 2, \ldots" class="latex" src="https://s0.wp.com/latex.php?latex=n+%3D+1%2C+2%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n = 1, 2, \ldots"/>.<a href="https://theorydish.blog/feed/#fnref7"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
<li id="fn8">The width of a multi-layer perceptron is the number of neurons in each hidden layer.<a href="https://theorydish.blog/feed/#fnref8"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li>
</ol>
</section></div>
    </content>
    <updated>2019-01-04T15:14:02Z</updated>
    <published>2019-01-04T15:14:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>amitdanielymailhujiacil</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-01-07T10:21:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42145</id>
    <link href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications" rel="alternate" type="text/html"/>
    <title>Grid-Minor Theorem of Robertson and Seymour and its Algorithmic Applications</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Graph-Minor Theorem of Robertson and Seymour [<a href="https://www.sciencedirect.com/science/article/pii/S0095895684710732" rel="nofollow noreferrer">1</a>] states that if graph G has large treewidth, then it contains a large grid as minor. Most approximation results on general classes of graphs with excluded minors make heavy use of Robertson and Seymour’s structure theory for graphs with excluded minors, especially when the treewidth is large (small treewidth usually makes problem to be easily solved by dynamic programming) [<a href="http://chekuri.cs.illinois.edu/talks/NIPS-Tutorial.pdf" rel="nofollow noreferrer">2</a>]. </p>

<p>However, there are some results are trying to avoid using the grid minor theorem. For example, Chekuri and Chuzhoy [<a href="https://arxiv.org/abs/1304.1577" rel="nofollow noreferrer">3</a>] show a framework for using theorems to bypass the well-known Grid-Minor Theorem of Robertson and Seymour in some applications. In particular, this leads to substantially improved parameters in some Erdos-Posa-type results, and faster running times for algorithms for some fi�xed parameter tractable problems.</p>

<p>Do you know any other examples of problems with large treewidth avoid using the grid minor theorem? </p></div>
    </summary>
    <updated>2019-01-04T09:44:58Z</updated>
    <published>2019-01-04T09:44:58Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="treewidth"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-minor"/>
    <author>
      <name>Rupei Xu</name>
      <uri>https://cstheory.stackexchange.com/users/17918</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42144</id>
    <link href="https://cstheory.stackexchange.com/questions/42144/maximum-weight-independent-set-on-a-changing-graph" rel="alternate" type="text/html"/>
    <title>Maximum Weight Independent Set on a Changing Graph?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose I have an optimal solution to the maximum weight independent/stable set problem on an arbitrary graph. If I were to induce a clique among a subset of its vertices (and perhaps add in some additional nodes that are only adjacent to the nodes of the induced clique), does there exist an efficient way in which I use the original optimal solution (i.e. its structure as a starting solution) to find the new optimal maximum weight independent set in the modified graph??</p></div>
    </summary>
    <updated>2019-01-04T07:48:21Z</updated>
    <published>2019-01-04T07:48:21Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="co.combinatorics"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <author>
      <name>Student</name>
      <uri>https://cstheory.stackexchange.com/users/51578</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7217</id>
    <link href="https://windowsontheory.org/2019/01/03/quantum-games/" rel="alternate" type="text/html"/>
    <title>Quantum Games</title>
    <summary>Nilin Abrahamsen nilin@mit.edu Daniel Alabi alabid@g.harvard.edu Mitali Bafna mitalibafna@g.harvard.edu Emil Khabiboulline ekhabiboulline@g.harvard.edu Juspreet Sandhu jus065@g.harvard.edu Two-prover one-round (2P-1R) games have been the subject of intensive study in classical complexity theory and quantum information theory. In a 2P-1R game, a verifier sends questions privately to each of two collaborating provers , who then aim to respond […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Nilin Abrahamsen <font face="courier new">nilin@mit.edu</font>
</p><p>Daniel Alabi <font face="courier new">alabid@g.harvard.edu</font>
</p><p>Mitali Bafna <font face="courier new">mitalibafna@g.harvard.edu</font>
</p><p>Emil Khabiboulline <font face="courier new">ekhabiboulline@g.harvard.edu</font>
</p><p>Juspreet Sandhu <font face="courier new">jus065@g.harvard.edu</font>

<br/>
<br/>
Two-prover one-round (2P-1R) games have been the subject of intensive study in classical complexity theory and quantum information theory. In a 2P-1R game, a <em>verifier</em> sends questions privately to each of two collaborating <em>provers</em> , who then aim to respond with a compatible pair of answers without communicating with each other. Sharing quantum entanglement allows the provers to improve their strategy without any communication, illustrating an apparent paradox of the quantum postulates. These notes aim to give an introduction to the role of entanglement in nonlocal games, as they are called in the quantum literature. We see how nonlocal games have rich connections within computer science and quantum physics, giving rise to theorems ranging from hardness of approximation to the resource theory of entanglement.
</p><h2>Introduction</h2>
In these notes we discuss 2-prover 1-round games and the classical complexity of approximating the value of such games in the setting where the provers can share entanglement. That is, given the description of a game, we ask how hard it is to estimate the winning <!--recheck prob-->probability of the best winning strategy of the entangled provers. Let us first formally define games and its relation to the label cover <!--recheck prob-->problem. We write <img alt="{ [n]=\{1,\ldots,n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Bn%5D%3D%5C%7B1%2C%5Cldots%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ [n]=\{1,\ldots,n\}}"/>.
<h4>Definition (Label cover)</h4>
<em> A label cover instance <img alt="{ I=(S,T,\Sigma,\Pi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%3D%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I=(S,T,\Sigma,\Pi)}"/> consists of variable sets <img alt="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+S%3D%5C%7Bs_i%5C%7D_%7Bi%5Cin%5Bn%5D%7D%2CT%3D%5C%7Bt_j%5C%7D_%7Bj%5Cin%5Bn%5D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}"/>, alphabet set <img alt="{ \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma}"/>, and a collection <img alt="{ \Pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Pi}"/> of constraints of the form <img alt="{ t_j=f_{i,j}(s_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t_j%3Df_%7Bi%2Cj%7D%28s_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t_j=f_{i,j}(s_i)}"/>. Given an assignment (or coloring) <img alt="{ c : S\cup T \rightarrow \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c+%3A+S%5Ccup+T+%5Crightarrow+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c : S\cup T \rightarrow \Sigma}"/> we define its value to be <img alt="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28c%29%3D%5Cmathbb+P_%7Bf_%7Bij%7D%5Csim%5CPi%7D%5Cbig%28c%28t_j%29%3Df_%7Bij%7D%28c%28s_i%29%29%5Cbig%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}"/>. Define the value of <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/> to be the maximum over all possible assignments, i.e. <img alt="{ \omega(I) = \max_{c} \omega(c)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29+%3D+%5Cmax_%7Bc%7D+%5Comega%28c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(I) = \max_{c} \omega(c)}"/>. </em>

<!--ending definition-->

Many familiar computational <!--recheck prob-->problems can be formulated as a label cover, such as <img alt="{ \textsc{3SAT}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3SAT%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \textsc{3SAT}}"/>, <img alt="{ \textsc{3Lin}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3Lin%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \textsc{3Lin}}"/>, and <img alt="{ \textsc{MaxCut}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7BMaxCut%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \textsc{MaxCut}}"/>.
<figure style="width: 11em; margin: auto;">

<a href="https://windowsontheory.org/?attachment_id=7236"><img alt="" class="attachment-thumbnail size-thumbnail" height="150" src="https://windowsontheory.files.wordpress.com/2019/01/labelcover.png?w=110&amp;h=150" width="110"/></a>
Label cover graph</figure>
<h4>Definition (2-prover 1-round game)</h4>
<em> Let <img alt="{ I = (S,T,\Sigma,\Pi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I+%3D+%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I = (S,T,\Sigma,\Pi)}"/> be a label cover instance. We can then associate the following two-prover one-round game <img alt="{ G(I)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G(I)}"/> with <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/>. Let <img alt="{ P_1,P_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P_1%2CP_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P_1,P_2}"/> be two provers who cannot communicate, and let <img alt="{ V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V}"/> be the verifier. Given the label cover instance <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/>, the verifier uniformly samples a constraint <img alt="{ f_{i,j} \in \Pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bi%2Cj%7D+%5Cin+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ f_{i,j} \in \Pi}"/> and sends <img alt="{ s_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s_i}"/> to <img alt="{ P_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P_1}"/> and <img alt="{ t_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t_j}"/> to <img alt="{ P_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P_2}"/>. The provers then reply with <img alt="{ a \in \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a \in \Sigma}"/> and <img alt="{ b\in\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%5Cin%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b\in\Sigma}"/> respectively to <img alt="{ V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V}"/>. Finally, <img alt="{ V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V}"/> outputs <img alt="{ 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1}"/> if and only if <img alt="{ b = f_{i,j}(a)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b+%3D+f_%7Bi%2Cj%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b = f_{i,j}(a)}"/>. </em>

<!--ending definition-->
<figure style="width: 25em; margin: auto;">
 
<a href="https://windowsontheory.org/?attachment_id=7235"><img alt="" class="attachment-thumbnail size-thumbnail" height="104" src="https://windowsontheory.files.wordpress.com/2019/01/game.png?w=150&amp;h=104" width="150"/></a>


The game view of label cover</figure>
Any coloring of the label cover instance corresponds to a deterministic strategy for the corresponding game. Therefore, with an optimal strategy the provers win the game associated to label cover instance <img alt="{ I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I}"/> with <!--recheck prob-->probability <img alt="{ \omega(I)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(I)}"/>. That is, the value of the game equals that of the label cover instance. However, this is with the assumption that provers can only use deterministic strategies or convex combinations of these (that is, using shared randomness). If the provers share an entangled quantum state, then the provers (who still cannot communicate) can enjoy correlations that allow them to win with a higher <!--recheck prob-->probability than classically. In the quantum literature, these 2P-1R games are known as nonlocal games referring to the fact that the correlations arise without signaling between the provers. We are concerned with the complexity of approximating the winning <!--recheck prob-->probability of this strategy.

We refer to the optimal winning <!--recheck prob-->probability within some class (classical or entangled) of strategies as the classical and quantum value of the game, respectively, and we use the terms quantum strategy and entangled strategy interchangeably.

Fixing different constraint families in the label cover game changes the complexity of finding the (classical and entangled) values of the game. We will show that approximating the entangled value of XOR games, or more generally <em>unique games</em> (to be defined later on), is possible in polynomial time. This is remarkable because a famous conjecture known as the <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture"> <em>unique games conjecture</em> </a> says that approximating the classical value of unique games is NP-hard. In contrast, we will see that for unrestricted edge constraints, it is NP-hard to approximate the entangled value of a nonlocal game. Thus, hardness of approximation of the game’s value, established by the celebrated <em>PCP theorem</em> , still applies in the presence of entanglement. In the quantum world, we have new complexity classes such as QMA (which can be regarded as “quantum NP”), so one may conjecture whether approximating the entangled value of a general game is QMA-hard (the games formulation of the <em>quantum PCP conjecture</em> ). We will indicate progress in this direction but will explicitly demonstrate the NP-hardness result.

Entanglement is often regarded as an expensive resource in quantum information because it is difficult to produce and maintain. Hence, even if sharing entanglement can improve the success <!--recheck prob-->probability of winning a game, the resource consumption may be costly. We will conclude by discussing lower bounds on the number of shared entangled bits required to achieve the optimal value of a game.
<h2>Notation and quantum postulates</h2>
Let us first establish notation and define what is meant by an entangled strategy. In keeping with physics notation we write a column vector as <img alt="{ |{v}\rangle \in\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{v}\rangle \in\mathbb C^d}"/> and its conjugate-transpose (a row vector) as <img alt="{ \langle{v}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{v}| }"/> . More generally the conjugate-transpose (Hermitian conjugate) of a matrix <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> is written <img alt="{ A^\dag}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^\dag}"/>. Then <img alt="{ \langle{v}| w\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+w%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{v}| w\rangle}"/> is the inner product of two vectors (a scalar) and <img alt="{ |{v}\rangle \langle{w}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Clangle%7Bw%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{v}\rangle \langle{w}| }"/> the outer product (a rank-1 matrix). A matrix <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> is said to be <em>Hermitian</em> if <img alt="{ A^\dag=A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%3DA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^\dag=A}"/>. A matrix <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> is <em>positive semidefinite</em> , written <img alt="{ A\succeq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Csucceq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A\succeq 0}"/>, if <img alt="{ A=B^\dag B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%3DB%5E%5Cdag+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A=B^\dag B}"/> for some matrix <img alt="{ B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B}"/>. We write the identity matrix as <img alt="{ {\mathbb{I}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathbb{I}}}"/>, denote by <img alt="{ Herm(\mathbb{C}^d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+Herm%28%5Cmathbb%7BC%7D%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ Herm(\mathbb{C}^d)}"/> the set of <img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/>-by-<img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/> Hermitian matrices.
<h3> Observables, states, and entanglement</h3>
In a quantum theory the <em>observables</em> are Hermitian operators <img alt="{ A\in Herm(\mathbb C^d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Cin+Herm%28%5Cmathbb+C%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A\in Herm(\mathbb C^d)}"/> on a vector space <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/>. It then makes sense to say that a <em>state</em> is a functional <img alt="{ \varphi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \varphi}"/> on the set of observables. That is, to specify the state of a physical system means giving a (expected) value for each observable. It turns out states are <em>linear</em> functionals of the observables, and such functionals can be written <img alt="{ \varphi(A)=\langle A,\rho\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%28A%29%3D%5Clangle+A%2C%5Crho%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \varphi(A)=\langle A,\rho\rangle}"/> for some <img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/>-by-<img alt="{ d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d}"/> matrix <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/>. We call <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> the density matrix and require moreover that <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> is positive semidefinite and has trace <img alt="{ 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1}"/>. Every density matrix is a convex combination of rank-one projections <img alt="{ |\psi\rangle\langle\psi|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Clangle%5Cpsi%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle\langle\psi|}"/> known as pure states. The unit vectors <img alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle\in\mathbb C^d}"/> are also themselves known as pure states.

If the state of one particle is described by a vector in <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/> (referring here to pure states), then two particles are described by a vector in the tensor product <img alt="{ \mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d\otimes\mathbb C^d}"/>. The two particles are entangled if their state is not in the form of a pure tensor <img alt="{ |\phi\rangle\otimes|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cotimes%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle\otimes|\psi\rangle}"/>. We also write product states as <img alt="{ |\phi\rangle|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle|\psi\rangle}"/>, omitting the tensor symbol.
<h3> Quantum measurements</h3>
A quantum measurement can be described in terms of a <em>projection-valued measure</em> (PVM).
<!--blockquote--><b>Definition 1 (PVM)</b> <em><a name="measurement"/> A projection-valued measure on vector space <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/> (where the quantum states live) is a list of projection matrices <img alt="{ A_1,\ldots,A_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_1%2C%5Cldots%2CA_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_1,\ldots,A_k}"/> on <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/> such that <img alt="{ A_iA_j=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_iA_j%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_iA_j=0}"/> for <img alt="{ i\neq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i\neq j}"/> and <img alt="{ \sum_i A_i={\mathbb{I}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_i+A_i%3D%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sum_i A_i={\mathbb{I}}}"/>. The PVM describes a measurement which, on state <img alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle\in\mathbb C^d}"/> outputs measurement outcome <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> with <!--recheck prob-->probability <img alt="{ \langle\psi| A_i|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cpsi%7C+A_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\psi| A_i|\psi\rangle}"/>. The quantum state after obtaining outcome <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> is <img alt="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%5C%7CA_i%7C%5Cpsi%5Crangle%5C%7C%7DA_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}"/>. </em><!--/blockquote-->
When the projections are rank-one projections <img alt="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_i%3D+%7C%7B%5Cbeta_i%7D%5Crangle+%5Clangle%7B%5Cbeta_i%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }"/> we say that we measure in the basis <img alt="{ \{ |{\beta_i}\rangle \}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_i%7D%5Crangle+%5C%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_i}\rangle \}_i}"/>. In this case the <!--recheck prob-->probability of outcome <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> in state <img alt="{ |\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\psi\rangle}"/> is <img alt="{ |\langle\beta_i |{\psi}\rangle |^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_i+%7C%7B%5Cpsi%7D%5Crangle+%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\langle\beta_i |{\psi}\rangle |^2}"/>, and the post-measurement state is simply <img alt="{ |{\beta_i}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_i%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_i}\rangle}"/> .

Applying the measurement <img alt="{ (A_i)_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%29_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (A_i)_i}"/> on the left half of a two-particle state <img alt="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5CPsi%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}"/> means applying the PVM <img alt="{ (A_i\otimes {\mathbb{I}})_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (A_i\otimes {\mathbb{I}})_{i}}"/> on the two-particle state.
<h3> Quantum strategies for nonlocal games</h3>
We now introduce the notion of a quantum strategy for a nonlocal game. Each prover holds a particle, say with state space <img alt="{ \mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^d}"/>, and Alices particle may be entangled with Bob’s. The global state is <img alt="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}"/>. Each player receives a question from the verifier and then chooses a measurement (a PVM) depending on the question. The player applies the measurement to their own particle and responds to the verifier with their measurement outcome. Hence for Alice we specify <img alt="{ n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n}"/> PVM’s <img alt="{ A^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s}"/> where <img alt="{ s\in S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cin+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\in S}"/> is a question, and each PVM is a list <img alt="{ A^s_{a=1},\ldots,A^s_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_%7Ba%3D1%7D%2C%5Cldots%2CA%5Es_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s_{a=1},\ldots,A^s_k}"/>. By definition <a href="https://windowsontheory.org/feed/#measurement">1</a>, given questions <img alt="{ s,t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,t}"/> the <!--recheck prob-->probability that Alice outputs <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and Bob outputs <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> is <a name="Qstrategy"/>

<a name="Qstrategy">
</a><a name="Qstrategy"/>
<p align="center"><a name="Qstrategy"><img alt="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28a%2Cb%7Cs%2Ct%29%3D%5C%7C%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b%29%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5C%7C%5E2%3D+%5Clangle%7B%5Cphi%7D%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)"/></a></p>
<a name="Qstrategy">
</a><a name="Qstrategy"/> where we have used that squaring a projection leaves it unchanged.
<h2>Quantum strategies beat classical ones</h2>
For any 2P-1R game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/>, let <img alt="{ \omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)}"/> be the maximum <!--recheck prob-->probability — over the players’ classical strategies — that the verifier accepts and <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> the maximum <!--recheck prob-->probability that the verifier accepts when the provers use qubits such that player 1’s qubits are entangled with those of player 2.

The game of Clauser, Horne, Shimony, and Holt (CHSH) has the property that the provers can increase their chance of winning by sharing an entangled pair of qubits, even when no messages are exchanged between the players. We show that there’s a characterization of the CHSH game’s value <img alt="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29+%3D+%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}"/> which is better than the classical value <img alt="{ \omega(G)\leq \frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%5Cleq+%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)\leq \frac{3}{4}}"/>. Let us first define XOR games, of which the CHSH game is a special case.
<h4>Definition (XOR game)</h4>
<em> An XOR game is a 2-player classical game (the questions and answers are classical bits) where: </em>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em>
<ol>
 	<li> Questions <img alt="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%5Cin%5C%7B0%2C+1%2C+%5Cldots%2C+n-1%5C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}"/> are asked according to some distribution <img alt="{ \Pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Pi}"/> (e.g. uniform).</li>
 	<li> Answers <img alt="{ a, b\in\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a, b\in\{0, 1\}}"/> are provided by players (call them Alice and Bob).</li>
 	<li> The verifier computes a predicate <img alt="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b%7Cs%2C+t%29+%3D+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}"/> used to decide acceptance/rejection.</li>
</ol>
</em><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em> </em>

<!--ending definition-->
<h4>Definition (CHSH Game)</h4>
<em> An XOR game with <img alt="{ n=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n=2}"/> where <img alt="{ s, t\in\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s, t\in\{0, 1\}}"/> are independent random bits and <img alt="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b+%7C+s%2C+t%29%3D1+%5CLongleftrightarrow+a%5Coplus+b+%3D+s%5Cwedge+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}"/>. </em>

<!--ending definition-->

To win the CHSH game, Alice and Bob need to output bits <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> (from Alice) and <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> (from Bob) that disagree if <img alt="{ s=t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3Dt%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=t=1}"/> and agree otherwise.

If Alice and Bob are classical then they can do no better than by always outputting <img alt="{ 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0}"/>, say, in which case they win in the three out of four cases when one of the questions is <img alt="{ 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0}"/>. Equivalently, <img alt="{ \omega(G)=\frac34}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%3D%5Cfrac34%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)=\frac34}"/> where <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/> is the CHSH game. This is the content of <em>Bell’s inequality</em> :
<h4>Lemma (Bell’s Inequality)</h4>
<em> For any two functions <img alt="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%2C+h%3A+%5C%7B0%2C+1%5C%7D%5Crightarrow%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}"/>, we have </em>

<em>
<img alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D+%5Cleq+%5Cfrac%7B3%7D%7B4%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }"/></em>

<em>
</em><em/><em> where <img alt="{ x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ x}"/> and <img alt="{ y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ y}"/> are independent uniformly random bits. </em>

<!--ending lemma-->

<em><br/><b>Proof.</b></em><!-- remove close em after proof--> The <!--recheck prob-->probability of any event is a multiple of <img alt="{ 1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1/4}"/> so it suffices to show that <img alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D%5Cneq1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}"/>. So assume for contradiction that <img alt="{ g(x)\oplus h(y) = x\wedge y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g(x)\oplus h(y) = x\wedge y}"/> for all pairs <img alt="{ x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+x%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ x,y}"/>. Then we have that <img alt="{ g(0)\oplus h(0) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g(0)\oplus h(0) = 0}"/> and <img alt="{ g(0)\oplus h(1) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%281%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ g(0)\oplus h(1) = 0}"/> which implies that <img alt="{ h(0)=h(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+h%280%29%3Dh%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ h(0)=h(1)}"/>. But then <img alt="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0%3Dg%281%29%5Coplus+h%280%29+%3Dg%281%29%5Coplus+h%281%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}"/> which is a contraction. <!--end proof-->
<div align="right">□</div>
<h3> The strategy</h3>
The entangled strategy for the CHSH game requires that Alice and Bob each hold a qubit, so that their two qubits together are described by a vector in <img alt="{ \mathbb C^2\otimes\mathbb C^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E2%5Cotimes%5Cmathbb+C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^2\otimes\mathbb C^2}"/>. The two qubits together are in the state

<img alt="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B0%7D%5Crangle+_A+%7C%7B0%7D%5Crangle+_B+%2B+%7C%7B1%7D%5Crangle+_A+%7C%7B1%7D%5Crangle+_B%5Cright%29%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }"/>

forming what is known as an EPR (Einstein-Podolsky-Rosen) pair. Now for <img alt="{ \theta\in[-\pi, \pi]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctheta%5Cin%5B-%5Cpi%2C+%5Cpi%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \theta\in[-\pi, \pi]}"/> define <img alt="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Ctheta%29%7D%5Crangle+%3D+%5Ccos%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Csin%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }"/> and <img alt="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Ctheta%29%7D%5Crangle+%3D+-%5Csin%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Ccos%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }"/> <!-- \footnote{ $latex { |{\beta_0(\theta)}\rangle }&amp;fg=000000$ is the rotation of $latex { |{0}\rangle}&amp;fg=000000$ by $latex { \theta}&amp;fg=000000$ in the 2-d real plane spanned by $latex { |{0}\rangle}&amp;fg=000000$ and $latex { |{1}\rangle}&amp;fg=000000$ . Similarly, $latex { |{\beta_1(\theta)}\rangle}&amp;fg=000000$ is the rotation of $latex { |{1}\rangle}&amp;fg=000000$ by $latex { \theta}&amp;fg=000000$ in the 2-d real plane spanned by $latex { |{0}\rangle}&amp;fg=000000$ and $latex { |{1}\rangle}&amp;fg=000000$ . }-->.

Now we describe a (quantum) strategy with winning <!--recheck prob-->probability <img alt="{ \cos^2(\frac{\pi}{8})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\frac{\pi}{8})}"/>. In each case Alice and Bob respond with their measurement outcome, where subscripts of the measurement basis vectors correspond to the answer to be sent back to the verifier.
<ul>
 	<li> If <img alt="{ s=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=0}"/>, Alice measures in basis <img alt="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%280%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%280%29%7D%5Crangle+%5C%7D+%3D+%5C%7B+%7C%7B0%7D%5Crangle+%2C+%7C%7B1%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}"/>. If <img alt="{ s=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=1}"/>, Alice measures in <img alt="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}"/>. Alice answers bit <img alt="{ a = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a = 0}"/> if outcome is <img alt="{ \beta_0(\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cbeta_0%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \beta_0(\cdot)}"/> and answers <img alt="{ a = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a = 1}"/> otherwise.</li>
 	<li> If <img alt="{ t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t=0}"/>, Bob measures in basis <img alt="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}"/>. If <img alt="{ t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t=1}"/>, Bob measures in <img alt="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}"/>.</li>
 	<li> Each player responds with their respective measurement outcome.</li>
</ul>
<!--blockquote--><b>Lemma 2</b> <em><a name="goodstrategy"/> Alice and Bob win the CHSH game with <!--recheck prob-->probability <img alt="{ \cos^2(\frac{\pi}{8})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\frac{\pi}{8})}"/>. </em><!--/blockquote-->
<em><br/><b/>Proof.</em><!-- remove close em after proof--> We will show that for each pair of questions <img alt="{ s,t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,t}"/> the pair of answers <img alt="{ a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a,b}"/> is correct with <!--recheck prob-->probability <img alt="{ \cos^2(\pi/8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\pi/8)}"/>. We can split the pairs of questions into the two cases <img alt="{ s\wedge t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=0}"/> and <img alt="{ s\wedge t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=1}"/>:
<ul>
 	<li> (<img alt="{ s\wedge t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=0}"/>) The three cases <img alt="{ (s,t)=(0,0),(0,1),(1,0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%3D%280%2C0%29%2C%280%2C1%29%2C%281%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s,t)=(0,0),(0,1),(1,0)}"/> are all analogous: in each case Alice an Bob must output the same answer, and in each case Bob’s measurement basis is almost the same as Alice’s except rotated by a small angle <img alt="{ \pm\pi/8}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpm%5Cpi%2F8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \pm\pi/8}"/>.
Of the three above cases we consider the one where <img alt="{ s,t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,t=0}"/> and check that indeed the two measurement outcomes agree with <!--recheck prob-->probability <img alt="{ \cos^2(\pi/8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cos^2(\pi/8)}"/>: When Alice measures her qubit and obtains some bit <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/>, the shared pair <img alt="{ |{\beta}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta}\rangle}"/> collapses to <img alt="{ |{a}\rangle _A |{a}\rangle _B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{a}\rangle _A |{a}\rangle _B}"/>. Indeed, since the question was <img alt="{ s=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=0}"/>, Alice measures her qubit in the basis <img alt="{ \{|0\rangle,|1\rangle\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{|0\rangle,|1\rangle\}}"/>. This means that Alice applies the measurement <img alt="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%5Clangle+0%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%2C%7C1%5Crangle%5Clangle+1%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}"/> on the global state. The post-measurement state is the normalization of

<img alt="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28+%7C%7Ba%7D%5Crangle+%5Clangle%7Ba%7D%7C+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%3D%5Cfrac%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B0%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C0%7D%7D%5Cotimes+%7C+0%5Crangle+%2B+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B1%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C1%7D%7D%5Cotimes+%7C%7B1%7D%5Crangle+%3D%5Cfrac+%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }"/>

because <img alt="{ \langle a |{a'}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle+a+%7C%7Ba%27%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle a |{a'}\rangle}"/> can be viewed as a Kronecker delta of <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and <img alt="{ a'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a'}"/>. In particular, Bob is now in the pure state <img alt="{ |{a}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{a}\rangle}"/> .

Because Bob received question <img alt="{ t=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t=0}"/> he measures in the basis <img alt="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_b%28%5Cpi%2F8%29%7D%5Crangle+%5C%7D_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}"/> Therefore his <!--recheck prob-->probability of correctly outputting <img alt="{ b=a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%3Da%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b=a}"/> is

<img alt="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D%5B%5Ctext%7BBob+gets+outcome+%7Da%5D+%3D+%7C%5Clangle%5Cbeta_a%28%5Ctfrac%7B%5Cpi%7D%7B8%7D%29+%7C%7Ba%7D%5Crangle+%7C%5E2+%3D+%5Ccos%5E2%5Cleft%28%5Cfrac%7B%5Cpi%7D%7B8%7D%5Cright%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }"/>

<!--end align*--></li>
 	<li> (<img alt="{ s\wedge t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s\wedge t=1}"/>)
Now consider the case <img alt="{ s=1,t=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%2Ct%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s=1,t=1}"/> where Alice and Bob are supposed to give different answers. Alice measures in basis consisting of <img alt="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}"/> and <img alt="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B-%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}"/>. If Alice gets outcome <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> then the post-measurement global state is <img alt="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}"/> . Therefore when Bob applies the measurement in basis <img alt="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%5C%7D_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}"/> he mistakenly outputs <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> only with <!--recheck prob-->probability <img alt="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_a%28%5Cfrac%5Cpi4%29+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%7C%5E2%3D%5Csin%5E2%28%5Cfrac%5Cpi8%29%3D1-%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}"/>.</li>
</ul>
<!--end proof-->
<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#goodstrategy">2</a> implies a lower bound on the value of the CHSH game.
<h4>Corollary</h4>
<em> <img alt="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%5Cge%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)\ge\cos^2(\frac\pi8)}"/> </em>

<!--ending corollary--> 
<br/>It turns out that this lower bound is sharp, that is, the strategy just described is optimal.

<h4>Lemma</h4><em> The value of the CHSH game using a quantum strategy is at most <img alt="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+%3D+%5Ccos%5E2%5Cfrac%7B%5Cpi%7D%7B8%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}"/>. </em>

<!--ending lemma-->

<em><b>Proof.</b></em><!-- remove close em after proof-->

We can describe the quantum strategy of Alice and Bob in an XOR game by (i) a shared quantum state <img alt="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}"/> (note that for the CHSH game, <img alt="{ d=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d=2}"/>); (ii) measurements <img alt="{ \{A^0_s, A^1_s\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA%5E0_s%2C+A%5E1_s%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A^0_s, A^1_s\}}"/> for every question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> sent to Alice; (iii) measurements <img alt="{ \{B^0_t, B^1_t\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB%5E0_t%2C+B%5E1_t%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B^0_t, B^1_t\}}"/> for every question <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> sent to Bob.

The <!--recheck prob-->probability of answering <img alt="{ (a, b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a%2C+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a, b)}"/> given questions <img alt="{ (s, t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s, t)}"/> is <img alt="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}"/> . Now let us write <img alt="{ A_s=A^0_s - A^1_s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%3DA%5E0_s+-+A%5E1_s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s=A^0_s - A^1_s}"/> and <img alt="{ B_t=B^0_t - B^1_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_t%3DB%5E0_t+-+B%5E1_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_t=B^0_t - B^1_t}"/> so that for any <img alt="{ a, b\in\{0, 1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a, b\in\{0, 1\}}"/>, we can write

<img alt="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%5Ea+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%2C+B_t%5Eb+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }"/>

Note that since the possible outcomes here are finite, <img alt="{ A_s, B_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s, B_t}"/> are Hermitian and we may assume have bounded norm of 1. Furthermore, we assume that <img alt="{ A_s, B_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s, B_t}"/> are <em>observables</em> so that <img alt="{ A_s^2 = B_t^2 = {\mathbb{I}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_s%5E2+%3D+B_t%5E2+%3D+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_s^2 = B_t^2 = {\mathbb{I}}}"/> <!-- \footnote{ We make this assumption since for a fixed $latex { |{\phi}\rangle}&amp;fg=000000$ and $latex { A_s}&amp;fg=000000$, the quantum game value $latex { \omega^*(G)}&amp;fg=000000$ is linear in the $latex { B_t}&amp;fg=000000$ and by convexity the best choice of the matrix would occur at an extreme point of the unit ball of Hermitian matrices. }-->.

Now denoting <img alt="{ f_{s, t}(a\oplus b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ f_{s, t}(a\oplus b)}"/> as the XOR predicate to be computed, we can write the quantum game value as

<img alt="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " class="latex" src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5Ea%5C%7D%2C+%5C%7BB_t%5Eb%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%28-1%29%5E%7Bab%7D%7D%7B4%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29%7D%7B2%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ "/>

where the summation <img alt="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Ba%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%28%5Ccdot%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}"/> has been evaluated in the last line.

Now note that the first term is independent of the quantum strategy and as a result equals the value of the uniformly random strategy which is 1/2. So we proceed to focus on the second term. Note that for CHSH <img alt="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29+%3D+%28-1%29%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}"/> simplifying the second term to

<img alt="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B8%7D%28+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+-+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+%29.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }"/>

Next, we invoke Tsirelson’s Theorem (See Theorem <a href="https://windowsontheory.org/feed/#thmtsirelson">3</a>) to bound this second term as

<img alt="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1+%2B+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%5C%7C%7B%5Ctextbf%7Bx%7D%7D_0%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7By%7D%7D_1%5C%7C+%2B+%5C%7C%7B%5Ctextbf%7Bx%7D%7D_1%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7By%7D%7D_1%5C%7C%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B8%7D%5Csqrt%7B2%5C%7C%7B%5Ctextbf%7By%7D%7D_0%5C%7C%5E2+%2B+2%5C%7C%7B%5Ctextbf%7By%7D%7D_1%5C%7C%5E2%7D+%5Cleq+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} "/>

where we have used Cauchy-Schwartz and the concavity of the <img alt="{ \sqrt{\cdot}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csqrt%7B%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sqrt{\cdot}}"/> function.

This completes our proof showing the exact characterization of the value (<img alt="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%3D%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}"/>) of the CHSH game using a quantum strategy. This proof is an adaptation of the one in [12]. <!--end proof-->
<div align="right">□</div>
<!--blockquote--><b>Theorem 3 (Tsirelson’s Theorem [1])</b> <em><a name="thmtsirelson"/> For any <img alt="{ n\times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n\times n}"/> matrix <img alt="{ C = (C_{s, t})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C+%3D+%28C_%7Bs%2C+t%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C = (C_{s, t})}"/>, the following are equivalent: </em>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em>
<ol>
 	<li> There exist <img alt="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%5Cin%5Cmathbb%7BN%7D%2C+%7C%7B%5Cphi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5E%7Bd%7D%5Cotimes%5Cmathbb%7BC%7D%5E%7Bd%7D%2C+A_s%2C+B_t%5Cin%5Ctext%7BHerm%7D%28%5Cmathbb%7BC%7D%5Ed%29%2C+A_s%5E2+%3D+B_t%5E2+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}"/> such that for any <img alt="{ s, t\in[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s, t\in[n]}"/> <img alt="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}"/> . Further this would imply that <img alt="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%5Cleq+2%5E%7B%5Clceil%5Cfrac%7Bn%2B2%7D%7B2%7D%5Crceil%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}"/>;</li>
 	<li> There exist real unit vectors <img alt="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%2C+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%5Cin%7B%5Cmathbb%7BR%7D%7D%5E%7Bn%2B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}"/> for <img alt="{ s, t\in [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s, t\in [n]}"/> such that <img alt="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%5Ccdot+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}"/>;</li>
</ol>
</em><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em> </em><!--/blockquote-->
<h2>Entangled unique games are easy</h2>
The CHSH game provides the first example that the entangled value <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> of a nonlocal game can exceed the classical value <img alt="{ \omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)}"/>. XOR-games like the CHSH game are the special case corresponding to alphabet size <img alt="{ k=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k=2}"/> of the class of <em>unique games</em> :
<h4>Definition (Unique Games)</h4>
<em> A 2-prover 1-round game is called a <em>unique game</em> if its constraints are of the form <img alt="{ b=\pi_{ij}(a)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%3D%5Cpi_%7Bij%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b=\pi_{ij}(a)}"/> where <img alt="{ \pi_{ij}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpi_%7Bij%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \pi_{ij}}"/> is a permutation of the alphabet <img alt="{ \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma}"/> for each edge <img alt="{ i\sim j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%5Csim+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i\sim j}"/>. </em>

<!--ending definition--> The famous <em>unique games conjecture</em> (UGC) by Khot says that <img alt="{ \omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G)}"/> is NP-hard to approximate for unique games. Surprisingly, Kempe et al. showed that a natural semidefinite relaxation for unique games yields an approximation to the entangled value <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> which can be computed in polynomial time. In other words the UGC is false for entangled provers, in contrast to the classical case where the conjecture is open.
<!--blockquote--><br/>Theorem 4 <em><a name="efficientUGC"/> There is an efficient (classical) algorithm which takes a description of a nonlocal game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/> as its input and outputs <img alt="{ \hat\omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)}"/> such that </em>

<em>
<img alt="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1-6%281-%5Chat%5Comega%28G%29%29%5Cle%5Comega%5E%2A%28G%29%5Cle%5Chat%5Comega%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }"/></em>

<em>Put differently, if <img alt="{ \omega^*(G)=1-\varepsilon^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D1-%5Cvarepsilon%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)=1-\varepsilon^*}"/> and <img alt="{ \hat\omega(G)=1-\hat\varepsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D1-%5Chat%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)=1-\hat\varepsilon}"/>, then</em>

<em><img alt="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarepsilon%5E%2A%5Cin%5B%5Chat%5Cvarepsilon%2C6%5Chat%5Cvarepsilon%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }"/></em>

<em>
</em><em/><em/><em/><em> </em><!--/blockquote-->
<br/>The algorithm of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> proceeds by relaxing the set of quantum strategies to a larger convex set <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> of <em>pseudo-strategies</em> and maximizing over <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> instead of actual strategies, a much easier task. In approximation theory one often encounters a collection of hypothetical moments not arising from a distribution, known as a pseudo-distribution. In contrast, our pseudo-strategies are actual conditional <!--recheck prob-->probability distributions on answers (conditional on the questions). What makes <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> a set of “pseudo”-strategies rather than actual strategies is that they may enjoy correlations which cannot be achieved without communication.
<h3> Convex relaxation of quantum strategies</h3>
We will define <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> to be a class of conditional <!--recheck prob-->probability distributions <img alt="{ \tilde{P}(a,b|s,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(a,b|s,t)}"/> on answers given questions. We will require that the pseudo-strategies satisfy a positive semidefinite constraint when arranged in matrix form. In particular this matrix has to be symmetric, so we symmetrize the conditional <!--recheck prob-->probability <img alt="{ \tilde{P}(a,b|s,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(a,b|s,t)}"/> by allowing each of <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> to be either a question for Alice or for Bob. That is, we extend the domain of definition for <img alt="{ \tilde{P}(a,b|s,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(a,b|s,t)}"/> from <img alt="{ \Sigma^2\times S\times T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma^2\times S\times T}"/> to <img alt="{ \Sigma^2\times (S\cup T)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \Sigma^2\times (S\cup T)^2}"/> where <img alt="{ S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ S}"/> and <img alt="{ T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ T}"/> are the question sets. So each question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> and answer <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> can be either for Alice or Bob — we indicate this by changing notation from <img alt="{ (s,t)\in S\times T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%5Cin+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s,t)\in S\times T}"/> to <img alt="{ q,q'\in S\cup T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ q,q'\in S\cup T}"/> and for the answers replacing <img alt="{ a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a,b}"/> by <img alt="{ c,c'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c%2Cc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c,c'}"/>.

<!--blockquote--><br/>Definition 5 (Block-matrix form) <em><a name="to_matrix"/> Given a function <img alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}"/> defined on <img alt="{ (S\cup T)^2\times \Sigma^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28S%5Ccup+T%29%5E2%5Ctimes+%5CSigma%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (S\cup T)^2\times \Sigma^2}"/> with <img alt="{ |S|=|T|=n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7CS%7C%3D%7CT%7C%3Dn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |S|=|T|=n}"/> and <img alt="{ |\Sigma|=k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5CSigma%7C%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\Sigma|=k}"/>, define a <img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/>-by-<img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/> matrix <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> whose rows are indexed by pairs <img alt="{ (q,c)\in(S\cup T)\times\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28q%2Cc%29%5Cin%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (q,c)\in(S\cup T)\times\Sigma}"/> and columns by pairs <img alt="{ (q',c')\in (S\cup T)\times\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28q%27%2Cc%27%29%5Cin+%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (q',c')\in (S\cup T)\times\Sigma}"/>, and whose entries are </em>

<em>
<img alt="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28q%2Cc%29%2C%28q%27%2Cc%27%29%7D%3D%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }"/></em>

<em>
</em><em/><em> In other words <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> consists of <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-by-<img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> blocks where the block <img alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{q,q'}}"/> at position <img alt="{ q,q'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ q,q'}"/> contains the entries <img alt="{ \tilde{P}(\cdot\cdot|q,q')}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7Cq%2Cq%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}(\cdot\cdot|q,q')}"/>. </em><!--/blockquote--><br/>
Definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a> is simply a convenient change of notation and we identify <img alt="{ \tilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}}"/> with <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/>, using either notation depending on the context.
<!--blockquote--><br/>Definition 6 (Pseudo-strategies) <em><a name="Sdef"/> Let <img alt="{ S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ S}"/> and <img alt="{ T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ T}"/> be the question sets for Alice and Bob, respectively. We say that <img alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}"/> (or its matrix form <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/>) is a pseudo-strategy if: </em>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em/>

<em>
<ol>
 	<li> <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> is positive semidefinite.<a name="positive"/></li>
 	<li> For any pair of questions <img alt="{ q,q'\in S\cup T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ q,q'\in S\cup T}"/>, <img alt="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Bc%2Cc%27%3D1%7D%5Ek+%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}"/>.<a name="sum1"/></li>
 	<li> The blocks <img alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{q,q'}}"/> on the diagonal are themselves diagonal <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-by-<img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> matrices.<a name="diagonal"/></li>
</ol>
</em><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em/><em> </em><!--/blockquote-->
Define the winning <!--recheck prob-->probability or value of a pseudo-strategy as:

<img alt="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29%3D%5Cmathbb+E_%7B%28s%2Ct%29%5Csim+%5CPi%7D+%5Csum_%7Ba%2Cb%7D+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29V%28a%2Cb%7Cs%2Ct%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }"/>

The algorithm outputs the maximum winning <!--recheck prob-->probability:

<img alt="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }"/>

over pseudo-strategies <img alt="{ \tilde{P}\in \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}\in \mathcal S}"/>. This maximum is efficiently computable using standard semidefinite programming algorithms. As we will see, actual quantum strategies are in <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> which immediately implies <img alt="{ \hat\omega(G)\ge\omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%5Cge%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)\ge\omega^*(G)}"/>. It then remains to show that the optimal pseudo-strategy can be approximated by an actual entangled strategy, thus bounding the gap from <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/> to <img alt="{ \hat\omega(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)}"/>.
<h3> Quantum strategies are in <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/></h3>
Let us establish that <img alt="{ \mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal S}"/> is indeed a relaxation of the class of quantum strategies, that is, it contains the quantum strategies. So suppose we are given a quantum strategy. By equation <a href="https://windowsontheory.org/feed/#Qstrategy">1</a> the <!--recheck prob-->probability of answers <img alt="{ a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a}"/> and <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/> given questions <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> is of the form

<img alt="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%3D%5Clangle%5Cphi%7C%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b+%29%7C%5Cphi%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }"/>

for some PVM’s <img alt="{ A^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s}"/> and <img alt="{ B^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t}"/> and some <img alt="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}"/>. This conditional <!--recheck prob-->probability distibution is not immediately in the form of a pseudo-strategy because we cannot evaluate it on pairs of Alice-questions or pairs of Bob-questions. We therefore have to extend it, as follows: Place all the column vectors <img alt="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}"/>, <img alt="{ (s,a)\in S\times \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ca%29%5Cin+S%5Ctimes+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (s,a)\in S\times \Sigma}"/> side by side, and then append the vectors <img alt="{ I\otimes B^t_b|\phi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+I%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ I\otimes B^t_b|\phi\rangle}"/>, resulting in a <img alt="{ d^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d^2}"/>-by-<img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/> matrix <img alt="{ R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ R}"/>. We then define <img alt="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}"/> through its matrix form (see the comment below definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a>): <a name="eqMp"/>
<p align="center"><a name="eqMp"><img alt="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7BP%7D%3A%3DR%5E%5Cdag+R%3D%5Cbegin%7Bpmatrix%7D+%28%5Clangle%5Cphi%7CA%5Es_a+A%5E%7Bs%27%7D_%7Ba%27%7D%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28s%27%2Ca%27%29%7D+%28%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D+%5C%5C%5C%5C+%28%5Clangle%5Cphi%7CB%5Et_b%5Cotimes+A%5Es_a+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28s%2Ca%29%7D+%28%5Clangle%5Cphi%7C%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_bB%5E%7Bt%27%7D_%7Bb%27%7D+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28t%27%2Cb%27%29%7D+%5Cend%7Bpmatrix%7D+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)"/></a></p>
<a name="eqMp">
</a><a name="eqMp"/>
<!--blockquote--><b>Lemma 7</b> <em><a name="relaxation"/> <img alt="{ M^{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}}"/> defined in <a href="https://windowsontheory.org/feed/#eqMp">2</a> is a pseudo-strategy, that is, <img alt="{ M^{P}\in\mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}\in\mathcal S}"/>. </em><!--/blockquote-->
<em><br/>Proof.</em><!-- remove close em after proof--> We verify the conditions in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a>. Condition <a href="https://windowsontheory.org/feed/#positive">1</a> (<img alt="{ M^{P}\succeq0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Csucceq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}\succeq0}"/>) holds because it is of the form <img alt="{ R^\dag R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+R%5E%5Cdag+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ R^\dag R}"/>. Condition <a href="https://windowsontheory.org/feed/#sum1">2</a> (Each block <img alt="{ M^{P}_{q,q'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{P}_{q,q'}}"/> sums to <img alt="{ 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1}"/>) holds because PVM’s sum to the identity. Condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> (Diagonal blocks <img alt="{ \tilde M=M^{P}_{qq}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DM%5E%7BP%7D_%7Bqq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde M=M^{P}_{qq}}"/> are diagonal) holds because the projections in the PVM <img alt="{ A^q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Eq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^q}"/> are mutually orthogonal, hence <img alt="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Eq_cA%5Eq_%7Bc%27%7D+%7C%7B%5Cphi%7D%5Crangle+%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}"/> if <img alt="{ c\neq c'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c%5Cneq+c%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c\neq c'}"/>. <!--end proof-->
<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#relaxation">7</a> means <img alt="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%7BP%7D%5Cin+%5Cmathcal+S%7D%5Comega%5E%7BP%7D%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}"/> is an (efficiently computable) upper bound for <img alt="{ \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G)}"/>:
<h4>Corollary</h4><em> <img alt="{ \hat\omega\ge \omega^*(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%5Cge+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat\omega\ge \omega^*(G)}"/>. </em>

<!--ending corollary-->

<br/>To finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> we need to show that any pseudo-strategy <img alt="{ \tilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}}"/> can be <em>rounded</em> to an actual quantum strategy with answer <!--recheck prob-->probabilities <img alt="{ {P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}}"/> such that <a name="roundingobjective"/>
<p align="center"><a name="roundingobjective"><img alt="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Comega%5E%7BP%7D%5Cle+6%281-%5Comega%5E%7B%5Ctilde+P%7D%29+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)"/></a></p>
<a name="roundingobjective">
</a><a name="roundingobjective"/> Applying this rounding to the optimal pseudo-strategy implies that

<img alt="{ 1-\omega^*\le 6(1-\hat\omega) }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+1-%5Comega%5E%2A%5Cle+6%281-%5Chat%5Comega%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 1-\omega^*\le 6(1-\hat\omega) }"/>

or <img alt="{ \omega^*\ge 1-6(1-\hat\omega)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%5Cge+1-6%281-%5Chat%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*\ge 1-6(1-\hat\omega)}"/>, which will finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.

<em><br/><b>Proof.</b></em><!-- remove close em after proof-->[Proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>] Let <img alt="{ \tilde{P}\in\mathcal S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}\in\mathcal S}"/> be a pseudo-strategy. We construct a quantum strategy <img alt="{ {P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}}"/> approximating <img alt="{ \tilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{P}}"/>. Since <img alt="{ M^{\tilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}}"/> is positive semidefinite we can write

<img alt="{ \tilde M=R^\dag R }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DR%5E%5Cdag+R+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde M=R^\dag R }"/>

for <em>some</em> matrix <img alt="{ R\in \mathbb C^{r\times 2nk}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+R%5Cin+%5Cmathbb+C%5E%7Br%5Ctimes+2nk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ R\in \mathbb C^{r\times 2nk}}"/> and <img alt="{ r\leq 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+r%5Cleq+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ r\leq 2nk}"/>. Now let us define <img alt="{ 2nk}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 2nk}"/> vectors <img alt="{ |\tilde u^s_a\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+u%5Es_a%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\tilde u^s_a\rangle}"/> and <img alt="{ |\tilde v^t_b\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+v%5Et_b%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\tilde v^t_b\rangle}"/> in <img alt="{ \mathbb C^{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathbb C^{r}}"/>, and let <img alt="{ |{u^s_a}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_a%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{u^s_a}\rangle}"/> and <img alt="{ |{v^t_b}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%5Et_b%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{v^t_b}\rangle}"/> be the same vectors normalized. The strategy is constructed as follows. Alice and Bob share the maximally entangled state

<img alt="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%3D%5Cfrac1%7B%5Csqrt+r%7D%5Csum_%7Bi%3D1%7D%5Er%7Ci%5Crangle%7Ci%5Crangle%5Cin%5Cmathbb+C%5Er%5Cotimes%5Cmathbb+C%5Er+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }"/>

Before deciding on Alice and Bob’s PVM’s <img alt="{ A^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s}"/> and <img alt="{ B^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t}"/> let us see what this choice of shared state means for the conditional distribution on answers (see equation <a href="https://windowsontheory.org/feed/#Qstrategy">(1)</a>).
<p align="center"> <img alt="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cphi%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle+%3D%5Cfrac1r%5Csum_%7Bi%2Cj%3D1%7D%5Er%5Clangle+i+%7C+A%5Es_a%7C+j%5Crangle%5Clangle+i+%7C+B%5Et_b%7C+j%5Crangle+%3D%5Cfrac1r+A%5Es_a%5Ccdot+B%5Et_b%3D%5Cfrac1r%5Clangle+A%5Es_a%2C%5Coverline%7BB%5Et_b%7D%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle"/>, (*)</p>
where the bar represents entrywise complex conjugation, <img alt="{ \cdot}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ccdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \cdot}"/> is the entrywise dot product of matrices, and <img alt="{ \langle\:,\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5C%3A%2C%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\:,\rangle}"/> the entrywise complex inner product (Hilbert-Schmidt inner product).

We now choose the measurements. Given question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/>, Alice measures in the PVM <img alt="{ A^s=(A^s_a)_{a=0}^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%3D%28A%5Es_a%29_%7Ba%3D0%7D%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s=(A^s_a)_{a=0}^k}"/> with

<img alt="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%3D+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%5Ctext%7B+for+%7Da%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DA%5Es_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }"/>

Similarly, Bob on question <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> applies the PVM <img alt="{ B^t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t}"/> with

<img alt="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5Et_b%3D+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%5Ctext%7B+for+%7Db%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DB%5Et_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }"/>

The condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a> ensures that for any question <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/>, the vectors <img alt="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_1%7D%5Crangle+%2C%5Cldots%2C+%7C%7Bu%5Es_1%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}"/> are orthogonal so that this is a valid PVM.

The measurement outcome “<img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>” is interpreted as “fail”, and upon getting this outcome the player attempts the measurement again on their share of a fresh copy of <img alt="{ |\phi\rangle_{AB}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle_{AB}}"/>. This means that the strategy requires many copies of the entangled state to be shared before the game starts. It also leads to the complication of ensuring that with high <!--recheck prob-->probability the players measure the same number of times before outputting their measurement, so that the outputs come from measuring the same entangled state.

By <!--a href="#corr"-->(*)<!--/a-->, at a given round of measurements the conditional distribution of answers is given by

<img alt="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%3D%5Cfrac1r%5CBig%5Clangle+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7B+u%5Es_a%7D%7C+%5C%3A%2C%5C%3A+%7C%7B%7Bv%5Et_b%7D%5Crangle+%7D+%5Clangle%7B+%7Bv%5Et_b%7D%7C+%7D%5CBig%5Crangle%3D%5Cfrac1r%7C%5Clangle+%7Bu%5Es_a%7D%7Cv%5Et_b%5Crangle%7C%5E2%3D%5Cfrac1%7Br%7C%5Ctilde+u%5Es_a%7C%5E2%7C%5Ctilde+v%5Et_b%7C%5E2%7D%5CBig%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29%5E2%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }"/>

We wish to relate the LHS to <img alt="{ M^{\tilde{P}}_{(s,a),(t,b)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{(s,a),(t,b)}}"/>, so to handle the factor <img alt="{ \frac1r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac1r}"/> each prover performs repeated measurements, each time on a fresh copy of <img alt="{ |\phi\rangle_{AB}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |\phi\rangle_{AB}}"/>, until getting an outcome <img alt="{ \neq0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cneq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \neq0}"/>. Moreover, to handle the factor <img alt="{ \frac1{|u^s_a|^2|v^t_b|^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%7Cu%5Es_a%7C%5E2%7Cv%5Et_b%7C%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \frac1{|u^s_a|^2|v^t_b|^2}}"/>, each prover consults public randomness and accepts the answer <img alt="{ a\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a\in[k]}"/> with <!--recheck prob-->probability <img alt="{ |u^a_s|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7Cu%5Ea_s%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |u^a_s|^2}"/> and <img alt="{ |v^b_t|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7Cv%5Eb_t%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |v^b_t|^2}"/> respectively, or rejects and start over depending on the public randomness. Under a few simplifying conditions (more precisely, assuming that the game is <em>uniform</em> meaning that an optimal strategy exists where the marginal distribution on each prover’s answers is uniform), we can let <img alt="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cle+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}"/> for all <img alt="{ s,a,t,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%2Ca%2Ct%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s,a,t,b}"/>, and one can ensure that the conditional <!--recheck prob-->probabilities <img alt="{ {P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {P}}"/> of the final answers satisfy
<p align="center">
<img alt="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+1%2Fk-P%28a%2Cb%7Cs%2Ct%29%5Cle+3%5Cbig%281%2Fk-k%28M%5E%7B%5Ctilde+P%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2%5Cbig%29%2C%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)"/>
<a name="PM"/>

At this stage it is important that we are dealing with a <em>unique game</em> . Indeed, by <a href="https://windowsontheory.org/feed/#PM">(4)</a> we have for every <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/>,

<img alt="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Csum_%7Ba%3D1%7D%5Ek+P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29%3D%5Csum_a+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29+%5CBig%29+%5C%5C+%5Cleq+3%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-k%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2+%5CBig%29+%5C%5C+%5Cleq+6%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D%5Cbig%28%5Cfrac%7B1%7D%7Bk%7D-M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cbig%29%3D6%5CBig%281-%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) "/>

where the last inequality follows from concavity. Taking the expectation over <img alt="{ s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ s}"/> and <img alt="{ t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t}"/> implies the bound <a href="https://windowsontheory.org/feed/#roundingobjective">(3)</a>, thus concluding the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.<!--end proof-->
</p><div align="right">□</div>
<h2>General games are hard</h2>
We just saw that a specific class of games becomes easy in the presence of shared entanglement, in that semidefinite programming allows the entangled value <img alt="{ \omega^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*}"/> to be approximated to within exponential precision in polynomial time. Does this phenomenon hold more generally, so that the value of entangled games can always be efficiently approximated? We answer in the negative, by constructing a game where <img alt="{ \omega^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*}"/> is NP-hard to approximate to within inverse-polynomial factors. The complexity for 2P-1R entangled games can be strengthened to constant-factor NP-hardness, putting it on par with the classical PCP theorem. This result is used to prove (with some conditions) the games formulation of the quantum PCP theorem, which states that the entangled value of general games is QMA-hard to approximate within a constant factor.
<h3> Formulation of game</h3>
Given any instance <img alt="{ \phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi}"/> of a <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-CSP (constraint satisfaction <!--recheck prob-->problem, where <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> is the number of literals), we can define a clause-vs-variable game <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/> (see clause-vs-variable figure):
<ol>
 	<li> The referee (verifier) randomly sends a clause to Alice (first prover) and a variable to Bob (second prover).</li>
 	<li> Alice and Bob reply with assignments.</li>
 	<li> The referee accepts if Alice’s assignment satisfies the clause and Bob’s answer is consistent with Alice’s.</li>
</ol>
To show hardness of approximation, we need to go beyond the usual 2-player construction. In particular, in our game [3] one of the players receives an extra dummy question (see subfigure (a)). Mathematically, the result is very similar to introducing another player and having the referee play the 2-player game with two players chosen randomly [4] (see subfigure (b)). In either variation, the quantum phenomenon of <em>monogamy of entanglement</em> , imposing that only two parties can be maximally entangled to one another, is key to establishing hardness. The players do not know where to use their entanglement, which prevents them from coordinating as well as they could in the standard game.
<figure style="width: 25em; margin: auto;">  
<a href="https://windowsontheory.org/?attachment_id=7233"><img alt="" class="attachment-thumbnail size-thumbnail" height="150" src="https://windowsontheory.files.wordpress.com/2019/01/2player.png?w=107&amp;h=150" width="107"/></a>
<a href="https://windowsontheory.org/?attachment_id=7234"><img alt="" class="attachment-thumbnail size-thumbnail" height="150" src="https://windowsontheory.files.wordpress.com/2019/01/3player.png?w=107&amp;h=150" width="107"/></a>


Two variations of a 2-player clause-vs-variable game; new features are in red and shared entanglement is denoted in blue. In the standard game <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/>, given <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-CSP <img alt="{ \phi=(C_1,\ldots,C_m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%3D%28C_1%2C%5Cldots%2CC_m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi=(C_1,\ldots,C_m)}"/> on <img alt="{ n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n}"/> variables <img alt="{ x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ x_i}"/>, (1) the referee R randomly sends a clause <img alt="{ C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_j}"/> to Alice A and a literal index <img alt="{ t\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t\in[k]}"/> to Bob B, (2) A replies with an assignment <img alt="{ (a_1,\ldots,a_k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a_1,\ldots,a_k)}"/> and B replies with assignment <img alt="{ b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b}"/>, (3) R accepts iff <img alt="{ (a_1,\ldots,a_k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a_1,\ldots,a_k)}"/> satisfies <img alt="{ C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_j}"/> and <img alt="{ a_t=b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a_t%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a_t=b}"/>. In variation (a), R sends an additional dummy index <img alt="{ l\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+l%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ l\in[k]}"/>, so that B replies with an additional assignment <img alt="{ b'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b'}"/>, but he does not know which is the right variable. Equivalently, in (b) a third player Charlie C is introduced, but <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/> is played with two randomly chosen players. Since only parties can be maximally entangled and the players do not know who is playing the game, they cannot coordinate perfectly. </figure>
<h3> NP-hardness of approximating the entangled value</h3>
To prove hardness, we rely on several results from classical complexity theory.
<!--blockquote--><br/>Theorem 8 ([6]) <em> Given an instance of 1-in-3 3SAT (a CSP), it is NP-hard to distinguish whether it is satisfiable or no assignments satisfy more than a constant fraction of clauses. <a name="thmCSP"/> </em><!--/blockquote-->
<!--blockquote--><br/>Theorem 9 ([2]) <em> For a PCP game <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> (emulating the CSP) and its oracularization <img alt="{G'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G'}"/> (transformation to a 2P-1R game), </em>

<p align="center"><em><img alt="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%28G%29%5Cleq+%5Comega%28G%27%29%5Cleq+1-%5Cfrac%7B1-%5Comega%28G%29%7D%7B3%7D%5C%2C.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)"/></em></p>
<em>
</em><em> <a name="thmMIP"/> </em><!--/blockquote-->
Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a> establishes the CSP variant of the classical PCP theorem: distinguishing between <img alt="{ \omega(\phi)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)=1}"/> and <img alt="{ \omega(\phi)\leq 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)\leq 1/2}"/> is NP-hard for some <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/>-CSP. Here, <img alt="{ \omega(\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)}"/> denotes the maximum fraction of clauses that are simultaneously satisfiable. Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> relates the general game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/> obtained from the CSP to a two-player one-round game <img alt="{ G'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G'}"/>, in terms of the value (<!--recheck prob-->probability of winning) the game. The first inequality, equivalently saying <img alt="{ \omega(\phi)\leq \omega(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)\leq \omega(G_\phi)}"/>, is achieved since the players can answer the questions in the game <img alt="{ G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G_\phi}"/> to satisfy the clauses in <img alt="{ \phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi}"/>. These theorems together imply that <img alt="{ \omega(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(G_\phi)}"/> is NP-hard to approximate to within constant factors.

Allowing the two players to share entanglement can increase the game value to <img alt="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%5Cgeq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G_\phi)\geq \omega(G_\phi)}"/>. Classical results do not necessarily carry over, but exploiting monogamy of entanglement allows us to limit the power of entangled strategies. One can show the following lemma, which is weaker than what we have classically.
<!--blockquote--><br/><b>Lemma 10 ([3])</b> <em> There exists a constant <img alt="{c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c&gt;0}"/> such that for a CSP <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>, </em>
<p align="center"><em><img alt="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)"/></em></p>
<em>
</em><em> where <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is the number of variables. <a name="lemmaIto"/> </em><!--/blockquote-->
Combining Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> and Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a>, we have

<img alt="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }"/>

Using Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a>, approximating <img alt="{ \omega^*(G_\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \omega^*(G_\phi)}"/> is NP-hard to within inverse polynomial factors. Proving Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a> takes some work in keeping track of approximations. For simplicity, we will show a less quantitative statement and indicate where the approximations come in.
<!--blockquote--><br/>Proposition 11 (adapted from [13]) <em> <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> is satisfiable iff <img alt="{\omega^*(G_\phi)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega%5E%2A%28G_%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\omega^*(G_\phi)=1}"/>. <a name="proposition"/> </em><!--/blockquote-->
<h3> Proof of Proposition <a href="https://windowsontheory.org/feed/#proposition">11</a></h3>
The forward direction is straightforward: If <img alt="{ \phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \phi}"/> is satisfiable, then there exists a perfect winning strategy where the questions are answered according to the satisfying assignment.

For the reverse direction, suppose there exists a strategy that succeeds with <!--recheck prob-->probability 1, specified by a shared entangled state <img alt="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}"/> and measurements <img alt="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%29_%7Ba_1%2C%5Cldots%2Ca_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}"/> for Alice and <img alt="{ (B^{t,l}_{b,b'})_{b,b'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%29_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (B^{t,l}_{b,b'})_{b,b'}}"/> for Bob, where the questions <img alt="{ j\in[m]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ j\in[m]}"/>, <img alt="{ t,l\in[k]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t%2Cl%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t,l\in[k]}"/> and the answers <img alt="{ a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a,b}"/> are from the CSP’s alphabet. Since one of the questions/answers for Bob corresponds to a dummy variable that is irrelevant to the game, trace over the dummy variable to define a new measurement operator <img alt="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5Et_b%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl%2Cb%27%7D+B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}"/>. We can introduce a distribution on assignments to the <img alt="{ n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ n}"/> relevant variables,

<a name="eqpB"/>
<p align="center"><a name="eqpB"><img alt="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D%5Ccdots%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C.++%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)"/></a></p>
<a name="eqpB">
</a><a name="eqpB"/> If we show that the distribution for assignments <img alt="{a_{i_1},\ldots,a_{i_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{i_1},\ldots,a_{i_k}}"/> on variables <img alt="{x_{i_1},\ldots,x_{i_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cldots%2Cx_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i_1},\ldots,x_{i_k}}"/> in any clause <img alt="{C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_j}"/> is <a name="eqpA"/>
<p align="center"><a name="eqpA"><img alt="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)"/></a></p>
<a name="eqpA">
</a><a name="eqpA"/> then, since the players win with certainty, <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> has a satisfying assignment. To transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a>, we need a relation between the <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{\tilde{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{B}}"/> measurement operators and a way to commute the <img alt="{\tilde{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{B}}"/> operators.

The success <!--recheck prob-->probability of the players’ strategy is expressed as

<img alt="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%5Cin%5Bm%5D%7D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%5Cin+C_j%7D+%5Csum_%7B%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D+%5Clangle%7B%5Cpsi%7D%7C+A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%2C%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }"/>

where <img alt="{ i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i}"/> is the index of one of the <img alt="{ k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ k}"/> variables on which <img alt="{ C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ C_j}"/> acts, and <img alt="{ (a_1,\ldots,a_k)\vdash C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (a_1,\ldots,a_k)\vdash C_j}"/> indicates that the assignment satisfies the clause. By positivity and summation to identity of the measurement operators <img alt="{ A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A}"/> and <img alt="{ \tilde{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}}"/>, each term is at most 1; for our hypothesis <img alt="{ P=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P=1}"/>, each has to be 1. Hence, using orthogonality of the vectors <img alt="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%5Cotimes%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}"/> for different <img alt="{ a_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a_i}"/>, we have <a name="eqrelation"/>
<p align="center"><a name="eqrelation"><img alt="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7B%5Csubstack%7B%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5Cvdash+C_j+%5C%5C+a_i%3Db%7D%7D+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%3D+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D%7C%5Cpsi%5Crangle%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)"/></a></p>
<a name="eqrelation">
</a><a name="eqrelation"/> for any <img alt="{ j\in[m]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ j\in[m]}"/> and <img alt="{ i\in C_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+i%5Cin+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ i\in C_j}"/>.

We now demonstrate that two different <img alt="{ \tilde{B}^{t_1}_{b_1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}^{t_1}_{b_1}}"/>, <img alt="{ \tilde{B}^{t_2}_{b_2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \tilde{B}^{t_2}_{b_2}}"/> commute, so that Bob can match any satisfied clause/variable.

<img alt="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%3D++%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_1%2Cb_1%27%7D+B%5E%7Bt_1%2Cl_1%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_2%2Cb_2%27%7D+B%5E%7Bt_2%2Cl_2%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_2%2Cb_1%27%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_1%2Cb_2%27%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle "/>

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate the measurements. The third line follows by the orthogonality of <img alt="{ B^{t_1,t_2}_{b_1,b_2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B^{t_1,t_2}_{b_1,b_2}}"/> for different <img alt="{ b_1,b_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+b_1%2Cb_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ b_1,b_2}"/>. For the fourth equation, we simply swap <img alt="{ t_1,t_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+t_1%2Ct_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ t_1,t_2}"/> since the questions are indistinguishable to Bob. Thus, we can see how the dummy variable comes into play. If we had assumed <img alt="{ P=1-\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%3D1-%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P=1-\epsilon}"/> and kept track of approximations, we would find <a name="eqcommutation"/>
<p align="center"><a name="eqcommutation"><img alt="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Cb_1%7D%5Csum_%7Bt_2%2Cb_2%7D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%28%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+-+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%29+%7C%5Cpsi%5Crangle+%5CrVert%5E2+%3D+O%28%5Cepsilon%29%5C%2C.++%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)"/></a></p>
<a name="eqcommutation">
</a><a name="eqcommutation"/> This approximate commutativity results in the hardness of approximation holding only to within inverse poly<img alt="{ (n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (n)}"/> factors.

Now we are ready to transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a> to conclude the proof.

<img alt="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " class="latex" src="https://s0.wp.com/latex.php?latex=p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D+%5Cldots+%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bi_1%7D_%7Ba_%7Bi_1%7D%7D+%5Cldots+%5Ctilde%7BB%7D%5E%7Bi_k%7D_%7Ba_%7Bi_k%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3Dp%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5C%2C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. "/>

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqcommutation">10</a>) to commute the measurement operators, along with their properties of orthogonality and summation to identity. For the third equality, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate Bob’s measurements to Alice’s, along with orthogonality of <img alt="{ A^j_{a_{i_1,\ldots,i_k}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A%5Ej_%7Ba_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A^j_{a_{i_1,\ldots,i_k}}}"/> for different <img alt="{ a_{i_1,\ldots,i_k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+a_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ a_{i_1,\ldots,i_k}}"/>. <!--end proof-->
<div align="right">□</div>
<h3> Constant-factor NP-hardness</h3>
The weakness in the above two-player game carries over from the original three-player variant. Thus, to achieve constant-factor NP-hardness of approximation, we could start with a different multiplayer game. Vidick [11] establishes the soundness of the “plane-vs-point” low-degree test (checking that the restriction of a low-degree polynomial to a plane matches its value at some point) in the presence of shared entanglement. <em> Soundness </em>, in the eponymous probabilistically checkable proof (PCP) formulation of the PCP theorem, refers to the verifier accepting a wrong proof with some bounded probability; bounding with a constant maps to constant-factor hardness of approximation. Here, soundness comes from a strong bound on error accumulation, similar to our approximate commutativity, but relies on the players’ Hilbert space being decomposable into three parts (i.e., there being three players). The particular game is constructed by combining the low-degree test with the 3-SAT test (encoding satisfying assignments in a low-degree polynomial), which can be reduced to the three-player QUADEQ test (testing satisfiability of a system of quadratic equations in binary variables, which is NP-complete). By the strong soundness result, the entangled value is NP-hard to approximate to within constant factors. Natarajan et al. [7] show that soundness holds even for two players, using a semidefinite program. They then construct a two-player game in a way similar to what we demonstrated.
<h3> Constant-factor QMA-hardness</h3>
The above can be thought of as the games formulation of the classical PCP theorem holding under shared entanglement. A true quantum PCP theorem states that the entangled value of general games is QMA-hard to approximate to within constant factors. Natarajan et al. [8] establish such a theorem, but under randomized reductions. This requirement stems from the lack of a sufficiently strong QMA-hardness result for local Hamiltonians (the quantum analog of CSPs). The soundness of the two-player low-degree test above is one instrumental component in the proof.
<h2>How much entanglement is needed?</h2>
We now focus on the question of quantifying exactly how much entanglement is needed to play XOR games optimally. As we shall see, the answer depends on the size of the question sets posed to Alice &amp; Bob in the game. The previous bound given by Tsirelson [10] (see table below) is tight for certain families of games, but is not tight for other families of games (such as a generalization of the CHSH game). The reason for this discrepancy is closely tied in with the the properties of the representation of the Observables that form the Optimal Strategy (<img alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}"/>). Slofstra [9] shows that if the Observables constitute a Clifford Algebra (that is, the solutions are pair-wise anti-commutative), then the strategy is minimally entangled (uses the least number of entangled bits) iff the strategy is a unique solution to the SDP rounding <!--recheck prob-->problem. As a trivial corollary, if the SDP rounding <!--recheck prob-->problem does not have a unique solution (and a correspondingly unique strategy), then there exists a Non-Clifford optimal strategy that uses (atleast) <img alt="{ |T|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |T|}"/> bits of entanglement less than the Clifford strategy. Slofstra further states that minimally entangled <img alt="{ \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon}"/>-optimal strategies may be constructed for XOR games where the optimal strategies have ‘stable’ representations. For the purposes of this post, we will analyze the exact result and merely state the approximate result.
<h3> Main Results</h3>
<h4><u>EXACT</u></h4>
For the exact realm, the table below summarizes Slofstra and Tsirelson’s main results.
<table border="1px">
<tbody>
<tr>
<th>Person</th>
<th> Strategy</th>
<th> Bound(entangled bits)</th>
</tr>
<tr>
<td> Slofstra</td>
<td> (Possibly) Non-Clifford</td>
<td> <img alt="{ \log_{2}(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \log_{2}(N)}"/></td>
</tr>
<tr>
<td> Tsirelson</td>
<td>Clifford</td>
<td><img alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}"/></td>
</tr>
</tbody>
</table>
Here, <img alt="{ r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ r}"/> is the largest integer such that <img alt="{ \binom{r + 1}{2} &lt; |S| + |T|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cbinom%7Br+%2B+1%7D%7B2%7D+%3C+%7CS%7C+%2B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \binom{r + 1}{2} &lt; |S| + |T|}"/> and corresponds to the maximum-rank of an extremal point in the quantum correlation matrix corresponding to an optimal strategy.
<img alt="{ N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ N}"/> is the minimum dimension of the representations of the Operators (<img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/>).
<h4><u>APPROXIMATE</u></h4>
In the approximate realm, the minimum entanglement dimension of the representation of the Operators from an <img alt="{ \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon}"/>-Optimal Strategy is: min(<img alt="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BO%7D%28%5Cepsilon%5E%7B%5Cfrac%7B-1%7D%7B12%7D%7D%29%2C+2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}"/>).

As we shall see, Slofstra’s theorem allows us to recover Tsirelson’s bound easily by using a fact from Representation Theory about the irreducible representations of Clifford Algebras, but stands as a more general lower bound for solutions that aren’t Clifford.
<h3> Marginals and Solution Algebras</h3>
We’ll begin by introducing 3 key ideas:
i) Degeneracy <img alt="{ \leftrightarrow}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cleftrightarrow%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \leftrightarrow}"/> Non-Degeneracy
ii) Existence of Marginals
iii) Solution Algebra

Once these ideas are defined and their notions made clear, we will be in a position to state the main result and sketch a proof for it.
<h4>Definition (Marginal Strategy)</h4>
<em> Given an Optimal Quantum Strategy (<img alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}"/>), a marginal constitutes <img alt="{ \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}_{j \in T}}"/>, and the partial trace of <img alt="{ \psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \psi}"/> with respect to <img alt="{ H_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{A}}"/> (<img alt="{ \rho_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho_{B}}"/>). </em>

<!--ending definition--> It is also possible to dualize the definition for obtaining <img alt="{ \{A_{i}\}_{i \in S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A_{i}\}_{i \in S}}"/> and <img alt="{ \rho_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho_{A}}"/>.
We now define the notion of degeneracy, which is critical when proving the main theorem. The main point to drive home is that a degenerate optimal quantum strategy can be reduced to a unique, non-degenerate optimal quantum strategy.
<h4>Definition (Degenerate Quantum Strategy)</h4>
<em> A quantum strategy (<img alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}"/>) is said to be degenerate if <img alt="{ \exists (P \in H_A)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cexists+%28P+%5Cin+H_A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \exists (P \in H_A)}"/>, <img alt="{ (Q \in H_B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28Q+%5Cin+H_B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (Q \in H_B)}"/> such that:
i) <img alt="{ P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ P}"/> commutes with all <img alt="{ A_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_i}"/> and <img alt="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28P+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}"/>
ii) <img alt="{ Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ Q}"/> commutes with all <img alt="{ B_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_j}"/> and <img alt="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+Q%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}"/> </em>

<!--ending definition--> Since we can efficiently construct for any degenerate Optimal Quantum Strategy a unique, non-degenerate Optimal Quantum Strategy, we will now assume WLOG that every Optimal Quantum Strategy is non-degenerate (and unique).

We now define the (unique) existence of marginal biases, which correspond to constants for the rows of the quantum correlation matrix (which is a generalization of the classical pay-off). An equivalent statement can be made for columns (<img alt="{ d_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d_{j}}"/>) by dualizing the existence of row marginals. These constants can be thought of as representing the (expected) optimum-payoff possible for a set of operator choices by one player, given that the other player’s choice is fixed. Intuitively, this can be seen as “collapsing” the quantum correlation matrix into a column, by summing over the rows (or collapsing into a row, by summing over the columns).
<!--blockquote--><br/><b>Lemma 12 (Existence of Marginals)</b> <em> For all <img alt="{m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times n}"/> XOR games G, <img alt="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexists+%5C%7Bc_%7Bi%7D+%5Cgeq+0+%5Chspace%7B1mm%7D+%7C+%5Chspace%7B1mm%7D+i+%5Cin+%7CS%7C%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}"/>, such that, if <img alt="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bu_%7Bi%7D%5C%7D_%7Bi+%5Cin+%7CS%7C%7D%2C+%5C%7Bv_%7Bj%7D%5C%7D_%7Bj+%5Cin+%7CT%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}"/> form an <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>-optimal vector strategy where <img alt="{\epsilon \leq \frac{1}{4(m+n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Cleq+%5Cfrac%7B1%7D%7B4%28m%2Bn%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon \leq \frac{1}{4(m+n)}}"/>,
<a name="eqmarginale"/></em>
<p align="center"><em><a name="eqmarginale"><img alt="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+-+c_%7Bi%7Du_%7Bi%7D%5C%7C+%5Cleq+%5Csqrt%7B10%7D%28m+%2B+n%29%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%5Cepsilon%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)"/></a></em></p>
<em><a name="eqmarginale">
</a></em><em><a name="eqmarginale"/> <a name="lemma"/> </em><!--/blockquote-->
If <img alt="{ \epsilon = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon = 0}"/> and our strategy is perfectly optimal, we recover an exact estimation of the marginal biases: <a name="eqmarginal"/>
<p align="center"><a name="eqmarginal"><img alt="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+%3D+c_%7Bi%7Du_%7Bi%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2812%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)"/></a></p>
<a name="eqmarginal">
</a><a name="eqmarginal"/> The proof for the above lemma provided by Slofstra relies on using techniques to analyze the structure of the SDP program that pertains to quantum marginals. In particular, conducting trace analysis on SDP matrices that correspond to using the game matrix as off-diagonal elements leads us to the construction of the desired marginal biases.
It is also critical to note that a dual statement allows us to recover the column biases <img alt="{ d_{j} \geq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ d_{j} \geq 0}"/>: <a name="eqmarginalc"/>
<p align="center"><a name="eqmarginalc"><img alt="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%5Cin%5B%7CS%7C%5D%7DG_%7Bij%7Du_%7Bi%7D+%3D+d_%7Bj%7Dv_%7Bj%7D%2C+%5Cforall+j++%5C+%5C+%5C+%5C+%5C+%2813%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)"/></a></p>
<a name="eqmarginalc">
</a><a name="eqmarginalc"/> We now move on to defining the notion of a solution algebra.
<!--blockquote--><br/>Definition 13 (Solution Algebra) <em> A solution algebra <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/> consists of self-adjoint (Hermitian) operators <img alt="{X_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{j}}"/> that satisfy the following predicates:  <a name="eqhermit"/></em>
<p align="center"><em><a name="eqhermit"><img alt="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bj%7D%5E%7B2%7D+%3D+%5Cmathbb%7BI%7D%2C+%5Cforall+1+%5Cleq+j+%5Cleq+n++%5C+%5C+%5C+%5C+%5C+%2814%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)"/></a></em></p>
<em><a name="eqhermit">
</a><a name="eqhermit"/> <a name="eqbiasespay"/>
</em>
<p align="center"><em><a name="eqbiasespay"><img alt="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Csum_%7Bj%5Cin%5B%7CT%7C%5D%7DG_%7Bij%7DX_%7Bj%7D%29%5E%7B2%7D+%3D+%28c_%7Bi%7D%29%5E%7B2%7D%5Ccdot%5Cmathbb%7BI%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2815%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)"/></a></em></p>
<em>
</em><em><a name="eqbiasespay">
</a></em><em><a name="eqbiasespay"/> </em><!--/blockquote-->
The definition above merely enforces the property that our unknown marginal operators be Hermitian <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a> and that they respect the optimal marginal biases (or payoffs) <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> we saw in <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a>, so that they correspond to being constructed from an optimal vector strategy. These unknown operators will be mapped to operators that are the marginal strategy corresponding to the optimal quantum strategy. This is at the heart of the main theorem we will now state:
<!--blockquote--><b>Theorem 14 (Slofstra, 2010)</b> <em> Given a <img alt="{m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times n}"/> XOR game G (with no zero rows or columns) and a solution algebra <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/>, a collection of Linear Operators <img alt="{\{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{B_{j}\}}"/> and density matrix <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> are the marginal of an optimal strategy iff the map <img alt="{X_{j} \rightarrow B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{j} \rightarrow B_{j}}"/> induces a density-matrix representation of <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/> and <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> commutes with <img alt="{im(\mathcal{A})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bim%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{im(\mathcal{A})}"/>. <a name="th20"/> </em><!--/blockquote-->
Put simply, the theorem states that our unknown self-adjoint operators map to an optimal marginal strategy iff the density matrix (traced from the joint Hilbert-Space) commutes with all the mapped operators (<img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/>). The result we desire on the lower bound for the number of entangled bits, given a mapping from these indeterminate operators to the marginal of an optimal strategy, comes from a corollary to <a href="https://windowsontheory.org/feed/#th20">(14)</a>.
<!--blockquote--><br/>Corollary 15 <em> Given a <img alt="{m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times n}"/> XOR game G (with no zero rows or columns) and a solution algebra <img alt="{\mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{A}}"/> with minimum dimension <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> among non-zero representations, the strategy for minimum entanglement uses <img alt="{\log_{2}(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log_{2}(N)}"/> entangled bits. <a name="co21"/> </em><!--/blockquote-->
The proof for this corollary follows from the eigenspace decomposition of the joint Hilbert Space <img alt="{ H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H}"/> in terms of <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/>, which is preserved by the action of <img alt="{ im(\mathcal{A})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ im(\mathcal{A})}"/>. As a result, each eigenspace decomposes into a finite sum of irreducible representations of <img alt="{ \mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{A}}"/>. The minimum entanglement is realized when there is exactly one invariant subspace (with one irreducible representation). The entanglement used by such a representation is <img alt="{ \log_{2}(\text{dim}\,H)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28%5Ctext%7Bdim%7D%5C%2CH%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \log_{2}(\text{dim}\,H)}"/>.
<h3> Proof of Theorem 20</h3>
The rest of the section is dedicated to sketching a brief (but formal) proof for Theorem <a href="https://windowsontheory.org/feed/#th20">(14)</a>, and then using a simple fact about the representations of a Clifford Algebra to show how Slofstra’s result subsumes Tsirelson’s bound.

For this section, <img alt="{ |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle}"/> refers to an arbitrary state in <img alt="{ H = H_{A} \otimes H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H+%3D+H_%7BA%7D+%5Cotimes+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H = H_{A} \otimes H_{B}}"/> (the joint Hilbert space). We can write <img alt="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Csum_%7Bi%7D+%7C%7Bi%7D%5Crangle+%5Clambda+%7C%7Bi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}"/> over some basis <img alt="{ \{{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{{i}\}}"/>, where <img alt="{ \lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda}"/> is a linear map. Then, the partial trace of <img alt="{ \psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \psi}"/> over <img alt="{ H_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{A}}"/> is given by <img alt="{ \rho = \lambda\lambda^{*}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho+%3D+%5Clambda%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho = \lambda\lambda^{*}}"/>.
Let <img alt="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BB%7D_%7BA%7D%2C+%5Cmathcal%7BB%7D_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{B}_{A}, \mathcal{B}_{B}}"/> denote the algebra generated by <img alt="{ A_{1},..,A_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_%7B1%7D%2C..%2CA_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_{1},..,A_{m}}"/> and <img alt="{ B_{1},..,B_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7B1%7D%2C..%2CB_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{1},..,B_{n}}"/>. Here, the generating elements are the observables of an optimal quantum strategy.

To arrive at a proof for the theorem, we will rely on 2 additional lemmas which we will not prove but state.
<!--blockquote--><br/>Lemma 16 <em> Given Hermitian operators <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>, <img alt="{B \in H_{A}, H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Cin+H_%7BA%7D%2C+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \in H_{A}, H_{B}}"/>,
<a name="eqfrob"/></em>
<p align="center"><em><a name="eqfrob"><img alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5C%7C%5Clambda%5Coverline%7BA%7D+-+B%5Clambda%5C%7C_%7BF%7D++%5C+%5C+%5C+%5C+%5C+%2816%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)"/></a></em></p>
<em><a name="eqfrob">
</a><a name="eqfrob"/> This allows us to conclude that,
<a name="eqcomm"/>
</em>
<p align="center"><em><a name="eqcomm"><img alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5Cepsilon+%5Cimplies+%5C%7C%5Crho%28B%29+-+B%5Crho%5C%7C_%7BF%7D+%5Cleq+2%5Cepsilon++%5C+%5C+%5C+%5C+%5C+%2817%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)"/></a></em></p>
<em>
</em><em><a name="eqcomm">
</a></em><em><a name="eqcomm"/> <a name="lecomm"/> </em><!--/blockquote-->
<!--blockquote--><b>Lemma 17</b> <em> The optimal strategy in question is non-degenerate iff <a name="eqcl1"/></em>
<p align="center"><em><a name="eqcl1"><img alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+closure%28%5Cmathcal%7BB%7D_%7BA%7D%5Clambda%5E%7B%2A%7DH_%7BB%7D%29.+%5C%5C++%5C+%5C+%5C+%5C+%5C+%2818%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)"/></a></em></p>
<em><a name="eqcl1">
</a><a name="eqcl1"/> As a special case:
<a name="eqcl2"/>
</em>
<p align="center"><em><a name="eqcl2"><img alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+H_%7BB%7D+%5Cleftrightarrow+closure%28%5Crho+H_%7BB%7D%29+%3D+H_%7BB%7D++%5C+%5C+%5C+%5C+%5C+%2819%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)"/></a></em></p>
<em>
</em><em><a name="eqcl2">
</a></em><em><a name="eqcl2"/> <a name="lecl"/> </em><!--/blockquote-->
<b> Forward direction </b>:
We use the first lemma to prove commutativity of <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\rho"/> with all <img alt="B_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B_{j}"/>, and we use the second lemma to show that the closure of <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\rho"/> is <img alt="{ H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{B}}"/>.
We first show the forward direction:
Suppose we are given an optimal quantum strategy (<img alt="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}"/>) for a game <img alt="{ G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ G}"/>. Then, we fix our optimal vector strategy as:
<a name="eqrs"/>
<p align="center"><b><a name="eqrs"><img alt="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u_%7Bi%7D+%3D+%28A_%7Bi%7D+%5Cotimes+%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2820%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)"/></a></b></p>
<b><a name="eqrs">
</a><a name="eqrs"/> <a name="eqcs"/>
</b>
<p align="center"><b><a name="eqcs"><img alt="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v_%7Bj%7D+%3D+%28%5Cmathbb%7BI%7D+%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2821%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)"/></a></b></p>
<a name="eqcs">
</a><a name="eqcs"/>

We can now use Equations <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a> and <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> to establish our optimal marginal biases to write a relationship between them and <img alt="{ |{\psi}\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ |{\psi}\rangle}"/> , and apply Lemma <a href="https://windowsontheory.org/feed/#lecomm">(16)</a> to show commutativity and Lemma <a href="https://windowsontheory.org/feed/#lecl">(17)</a> to show that <img alt="{ im(\mathcal{A})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ im(\mathcal{A})}"/> = cyclic(<img alt="{ B_{j}, \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}, \rho}"/>).
Using <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> with <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a>, we have:
<a name="eqqs1"/>
<p align="center"><a name="eqqs1"><img alt="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d_%7Bj%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bi%7DG_%7Bij%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2822%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)"/></a></p>
<a name="eqqs1">
</a><a name="eqqs1"/> We can now use <a href="https://windowsontheory.org/feed/#eqcomm">(17)</a> with <img alt="{ \epsilon = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \epsilon = 0}"/> on <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> to see that <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> commutes with every <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>.
Additionally, as the terms in <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> constitute linear combinations of <img alt="{ A_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_{i}}"/> and <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>, we can compute the closure of their actions on <img alt="{ \lambda H_{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda H_{A}}"/> and <img alt="{ \lambda^{*} H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%5E%7B%2A%7D+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda^{*} H_{B}}"/>, which will be equivalent. Therefore, <img alt="{ im(\rho)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Crho%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ im(\rho)}"/> = <img alt="{ H_{B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H_{B}}"/>, which follows from the special case of <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a>.
For the dual case, we substitute <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a> into <a href="https://windowsontheory.org/feed/#eqmarginal">(12)</a>:
<a name="eqdn"/>
<p align="center"><a name="eqdn"><img alt="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c_%7Bi%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj%7DG_%7Bij%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle"/> </a></p>
<a name="eqdn"/>

<a name="eqdn">
</a><a name="eqdn"/><a name="eqdn"/> On taking the norm of the above on both sides and using a little algebra, we finally obtain the fact that <img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/> satisfy predicate <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> making them the representations of <img alt="{ X_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ X_{j}}"/>:

<img alt="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%28%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%29%5E%7B2%7D+%3D+c_%7Bi%7D%5E%7B2%7D%7B%5Cmathbb%7BI%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }"/>

This shows that the map from <img alt="{ X_{j} \rightarrow B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ X_{j} \rightarrow B_{j}}"/> computes a density matrix representation of <img alt="{ \mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{A}}"/>, where <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> commutes with all <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>.

<br/><b> Backward Direction </b>:
The proof for the backward direction is much less involved:
If we knew that <img alt="{ \{B_{j}\}, \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}, \rho}"/> constituted the cyclic representation of <img alt="{ \mathcal{A}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \mathcal{A}}"/> with commutativity (with <img alt="{ B_{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ B_{j}}"/>), then we can use Lemma <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a> to conclude that the image of <img alt="{ \rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \rho}"/> on <img alt="{ H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ H}"/> would form a subspace of <img alt="{ \lambda H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \lambda H}"/>. We define:

<img alt="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Coverline%7BA%7D_%7Bi%7D+%3D+%5Cfrac%7B%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%7D%7Bc_%7Bi%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }"/>

allowing us to recover our original marginal biases <img alt="{ c_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+c_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ c_{i}}"/> that satisfy <a href="https://windowsontheory.org/feed/#eqdn">(23)</a> and therefore correspond to the optimal strategy. This shows us that <img alt="{ \{A_{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A_{i}\}}"/>, <img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/> would constitute an optimal quantum strategy. <!--end proof-->
<div align="right">□</div>
Having proved this theorem, we now obtain Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, which is the main desired result. To see how it subsumes Tsirelson’s result as a special case, we use a simple fact from Representation Theory:
<br/><!--blockquote--><b>Lemma 18</b> <em> For a Clifford Algebra generated by <img alt="{X_{1},..,X_{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1%7D%2C..%2CX_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1},..,X_{r}}"/>, there exist one or two irreducible representations of dimension <img alt="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}"/> <a name="lecr"/> </em><!--/blockquote-->
Plugging Lemma <a href="https://windowsontheory.org/feed/#lecr">18</a> into Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, we simply recover the fact that the number of entangled bits of a solution algebra that is Clifford is <img alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}"/>. However, note that being Clifford means an extra constraint:
<img alt="{ X_{i}X_{j} = -X_{j}X_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bi%7DX_%7Bj%7D+%3D+-X_%7Bj%7DX_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ X_{i}X_{j} = -X_{j}X_{i}}"/>, <img alt="{ \forall i, j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Cforall+i%2C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \forall i, j}"/>

The constraints on the Solution Algebra <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a>, <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> given by Slofstra do \textit{not} necessarily mean that the solution is Clifford. In fact, when an optimal quantum strategy with minimal entanglement is Clifford, <img alt="{ \{A_{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{A_{i}\}}"/>, <img alt="{ \{B_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{B_{j}\}}"/> are constructed from a unique set of <img alt="{ \{u_{i}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bu_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{u_{i}\}}"/>, <img alt="{ \{v_{j}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bv_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{v_{j}\}}"/>.
To end, we write down a lemma that shows there exist XOR games where the optimal strategy is not unique and for minimal entanglement, a solution generated by a Non-Clifford algebra must be used:
<h4>Lemma (Existence of XOR games with Non-Clifford optimal strategies)</h4>
<em> There exist a family of <img alt="{ m \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+m+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ m \times n}"/> XOR games <img alt="{ \{G\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BG%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \{G\}}"/> that correspond to generalizations of the CHSH games (<img alt="{CL_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BCL_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{CL_{n}}"/>), such that, the optimal strategy of minimal entanglement is Non-Clifford. </em>

<!--ending lemma-->
<h2>References</h2>
<p>[1] David Avis, Sonoko Moriyama, and Masaki Owari. From bell inequalities to tsirelson’s theorem. IEICE Transactions, 92-A(5):1254–1267, 2009.

</p><p>[2] Lance Fortnow, John Rompel, and Michael Sipser. On the power of multi-prover interactive protocols. Theoretical Computer Science, 134(2):545 – 557, 1994.

</p><p>[3] T. Ito, H. Kobayashi, and K. Matsumoto. Oracularization and Two-Prover One-Round Interactive Proofs against Nonlocal Strategies. ArXiv e-prints, October 2008.

</p><p>[4] J. Kempe, H. Kobayashi, K. Matsumoto, B. Toner, and T. Vidick. Entangled games are hard to approximate. ArXiv e-prints, April 2007.

</p><p>[5] Julia Kempe, Oded Regev, and Ben Toner. Unique games with entangled provers are easy. SIAM Journal on Computing, 39(7):3207– 3229, 2010.

</p><p>[6] S. Khanna, M. Sudan, L. Trevisan, and D. Williamson. The approximability of constraint satisfaction problems. SIAM Journal on Computing, 30(6):1863–1920, 2001.

</p><p>[7] Anand Natarajan and Thomas Vidick. Two-player entangled games are NP-hard. arXiv e-prints, page arXiv:1710.03062, October 2017.

</p><p>[8] Anand Natarajan and Thomas Vidick. Low-degree testing for quantum states, and a quantum entangled games PCP for QMA. arXiv e-prints, page arXiv:1801.03821, January 2018.

</p><p>[9] William Slofstra. Lower bounds on the entanglement needed to play xor non-local games. CoRR, abs/1007.2248, 2010.

</p><p>[10] B.S. Tsirelson. Quantum analogues of the bell inequalities. the case of two spatially separated domains. Journal of Soviet Mathematics, 36(4):557–570, 1987.

</p><p>[11] Thomas Vidick. Three-player entangled XOR games are NP-hard to approximate. arXiv e-prints, page arXiv:1302.1242, February 2013.

</p><p>[12] Thomas Vidick. Cs286.2 lecture 15: Tsirelson’s characterization of xor games. Online, December 2014. Lecture Notes.

</p><p>[13] Thomas Vidick. Cs286.2 lecture 17: Np-hardness of computing <img alt="\omega^*(G)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\omega^*(G)"/>. Online, December 2014. Lecture Notes.



</p><p/></div>
    </content>
    <updated>2019-01-04T04:58:48Z</updated>
    <published>2019-01-04T04:58:48Z</published>
    <category term="physics"/>
    <author>
      <name>mitalibafna</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-01-07T10:21:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42140</id>
    <link href="https://cstheory.stackexchange.com/questions/42140/explanation-of-monadic-second-order-logic" rel="alternate" type="text/html"/>
    <title>Explanation of Monadic Second Order Logic [on hold]</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am reading Wolfgang's Book <a href="https://drona.csa.iisc.ac.in/~deepakd/atc-common/wolfgang-aat.pdf" rel="nofollow noreferrer">Applied Automata Theory </a>, wherein, I came across what Monadic Second Order Logic means. </p>

<blockquote>
  <p>MSO stands for “monadic second-order”:
  Second-order because it allows quantification not only over (first-order) position
  variables but also over (second-order) set variables.
  Monadic because quantification is allowed at most over unary (monadic) relations,
  namely sets.</p>
</blockquote>

<p>I have a fundamental question , how do position variables become first order variables, and how are set variables second order? I am not able to go further, since I cannot wrap my head around this. </p></div>
    </summary>
    <updated>2019-01-03T13:49:09Z</updated>
    <published>2019-01-03T13:49:09Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="lo.logic"/>
    <author>
      <name>GermanShepherd</name>
      <uri>https://cstheory.stackexchange.com/users/30360</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3027987398928428578</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3027987398928428578/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/today-is-thirdsday-enjoy-it-while-you.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3027987398928428578" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3027987398928428578" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/today-is-thirdsday-enjoy-it-while-you.html" rel="alternate" type="text/html"/>
    <title>Today is Thirdsday!  Enjoy it while you can!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Fellow Blogger James Propp has come up with a new Math holiday:<br/>
<br/>
<b>Thirsdsday!</b><br/>
<br/>
The day is Jan 3 (1-3 in America, though 3-1 in ... Everywhere else?) but only when Jan 3 is a Thursday.<br/>
<br/>
It is a day where we celebrate the magic of the number 1/3.<br/>
<br/>
0) For other math days to celebrate see <a href="https://stemjobs.com/math-holidays/">here</a><br/>
<br/>
1/3) James Propp's blog about Thirdsday on Monday Dec 31. Really ???   : <a href="https://mathenchant.wordpress.com/2018/12/31/introducing-thirdsday/#more-2632">here</a><br/>
<br/>
2/3) Evelyn Lamb blogged about Thirdsday on Tuesday Jan 1. Really ??? : <a href="https://blogs.scientificamerican.com/roots-of-unity/how-to-celebrate-thirdsday/">here</a><br/>
<br/>
3/3) Ben Orlin blogged about Thirsdsday on Wedensday Jan 2. Really??? <a href="https://mathwithbaddrawings.com/2019/01/02/thirdsday-the-holiday-thats-33-33-better-than-any-other/">here</a><br/>
<br/>
(Added ON Thirdsday: Matt Foreman has a video about Thirdsday: <a href="https://www.youtube.com/watch?v=NinrTW1Bx2Y&amp;feature=youtu.be">here</a> and a blog post <a href="https://www.think-maths.co.uk/celebrating-thirdsday">here</a>)<br/>
<br/>
 How come I'm the only one blogged  about Thirdsday on Thursday Jan 3 ??? (Added later- not quite true anymore, Matt Foreman also waited until Thirdsday to post on Thirdsday).<br/>
I asked Jim Propp about this. He said that he want to help prepare teachers and other eduators for the excitment of Thirdsday! If they already know the wonders of 1/3 they can prepare and lecture on it! Kudos to him! I assume that Evelyn and Ben are similar! Kudos to them! And Ben blogged ON Thirdsday so Kudos to him!<br/>
<br/>
2) Darling asked me `<i>is it a real day like Pi-Day?'</i>  Is Pi-Day real? Is any Holiday real? All holidays are made up until they are accepted and become real. The distinction between <i>real holidays</i> and  <i>made up holidays</i>  is ... nonexistent.  One can talk of <i>accepted </i>and <i>not-accepted</i> holidays.  How long did Pi-day take to be accepted? This is prob not a well defined question.<br/>
<br/>
3) James Propp's and Evelyn Lamb's  blog has many math properties of 1/3.  One educational property: I think it is the first number that students see that is an infinite decimal. My favorite unbiased use of 1/3: The Cantor Set: Uncountable subset of [0,1] that has measure 0. Really!!! My favorite biased use: its important in Muffin Math. If m&gt;s and you want to divide and distribute m muffins to s students, there is always a way to do this with smallest piece at least 1/3. (Usually you can do better but this is sometimes the best you can do.)<br/>
<br/>
4) When will the next Thirdsday come?<br/>
<br/>
2019: Jan 3 is a Thursday, so YES<br/>
<br/>
2020: Jan 3 is a Friday, so NO<br/>
<br/>
2021: Jan 3 is a Sunday (why no Saturday? Leap year. Great- it will come sooner!)  so NO<br/>
<br/>
2022: Jan 3 is a Monday, so NO<br/>
<br/>
2023: Jan 3 is a Tuesday  so NO<br/>
<br/>
2024: Jan 3 is a Wednesday  so NO<br/>
<br/>
2025: Jan 3 is a Friday. WHAT! Why no Thirdsday?  Darn leap year! So NO.<br/>
<br/>
2026: Jan 3 is a Saturday, so NO<br/>
<br/>
2027: Jan 3 is a Sunday so NO<br/>
<br/>
2028: Jan 3 is a Monday so NO<br/>
<br/>
2029: Jan 3 is a Wedensday (Why no Tuesday? Leap year), so NO<br/>
<br/>
2030: Jan 3 is a Thursday (Leap Year helped!), so YES FINALLY!<br/>
<br/>
(Exercise: find a formula: if 2019 was the first Thirdsday, find the year for TD(i), the ith Thirdsday.)<br/>
<br/>
So enjoy Thirdsday in 2019 when spellcheck still flags it.<br/>
<br/>
In 2030 it will be an accepted holiday and spellcheck will think it's fine.<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-01-03T05:04:00Z</updated>
    <published>2019-01-03T05:04:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-01-07T09:37:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42138</id>
    <link href="https://cstheory.stackexchange.com/questions/42138/the-definition-of-weakest-precondition-for-a-non-deterministic-language" rel="alternate" type="text/html"/>
    <title>The definition of weakest precondition for a non-deterministic language</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the classical IMP language, the definition of weakest precondition is:</p>

<pre><code>definition "wp c Q s ≡ ∃t. (c,s) ⇒ t ∧ Q t"
</code></pre>

<p>This is stating that from state s, after executing c we get to a state satisfying Q. My question comes when handling the selection construct in the language of guarded commands (see selection command in <a href="https://en.wikipedia.org/wiki/Predicate_transformer_semantics" rel="nofollow noreferrer">Wikipedia</a>). My guess is that in this case one needs to define:</p>

<pre><code>definition "wp c Q s ≡ ∃t. (c,s) ⇒ t ∧ (∀ t'. (c,s) ⇒ t' ⟶ Q t)"
</code></pre>

<p>I wonder if this is correct. Currently, I'm having problems proving the weakest precondition definition for the sequential composition of commands:</p>

<pre><code>"wp (c1;;c2) Q s = wp c1 (wp c2 Q) s" 
</code></pre>

<p>So, I'm beginning to think my definition is wrong.</p>

<p>Does anybody see what am I doing wrong?</p></div>
    </summary>
    <updated>2019-01-02T21:05:32Z</updated>
    <published>2019-01-02T21:05:32Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="pl.programming-languages"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="semantics"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="formal-methods"/>
    <author>
      <name>Javier</name>
      <uri>https://cstheory.stackexchange.com/users/36456</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-07T10:21:12Z</updated>
    </source>
  </entry>
</feed>
