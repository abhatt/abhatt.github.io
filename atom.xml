<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-05T16:21:35Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02513</id>
    <link href="http://arxiv.org/abs/1907.02513" rel="alternate" type="text/html"/>
    <title>Locally Private k-Means Clustering</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stemmer:Uri.html">Uri Stemmer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02513">PDF</a><br/><b>Abstract: </b>We design a new algorithm for the Euclidean $k$-means problem that operates
in the local model of differential privacy. Unlike in the non-private
literature, differentially private algorithms for the $k$-means incur both
additive and multiplicative errors. Our algorithm significantly reduces the
additive error while keeping the multiplicative error the same as in previous
state-of-the-art results. Specifically, on a database of size $n$, our
algorithm guarantees $O(1)$ multiplicative error and $\approx n^{1/2+a}$
additive error for an arbitrarily small constant $a$, whereas all previous
algorithms in the local model on had additive error $\approx n^{2/3+a}$.
</p>
<p>We give a simple lower bound showing that additive error of $\approx\sqrt{n}$
is necessary for $k$-means algorithms in the local model (at least for
algorithms with a constant number of interaction rounds, which is the setting
we consider in this paper).
</p></div>
    </summary>
    <updated>2019-07-05T01:27:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02369</id>
    <link href="http://arxiv.org/abs/1907.02369" rel="alternate" type="text/html"/>
    <title>Expansion Testing using Quantum Fast-Forwarding and Seed Sets</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Apers:Simon.html">Simon Apers</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02369">PDF</a><br/><b>Abstract: </b>Expansion testing aims to decide whether an $n$-node graph has expansion at
least $\Phi$, or is far from any such graph. We propose a quantum expansion
tester with complexity $\widetilde{O}(n^{1/3}\Phi^{-1})$. This accelerates the
$\widetilde{O}(n^{1/2}\Phi^{-2})$ classical tester by Goldreich and Ron
[Algorithmica '02], and combines the $\widetilde{O}(n^{1/3}\Phi^{-2})$ and
$\widetilde{O}(n^{1/2}\Phi^{-1})$ quantum speedups by Ambainis, Childs and Liu
[RANDOM '11] and Apers and Sarlette [QIC '19], respectively. The latter
approach builds on a quantum fast-forwarding scheme, which we improve upon by
initially growing a seed set in the graph. To grow this seed set we borrow a
so-called evolving set process from the graph clustering literature, which
allows to grow an appropriately local seed set.
</p></div>
    </summary>
    <updated>2019-07-05T01:25:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02353</id>
    <link href="http://arxiv.org/abs/1907.02353" rel="alternate" type="text/html"/>
    <title>Fixed-parameter tractability of counting small minimum $(S,T)$-cuts</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berg=eacute=:Pierre.html">Pierre Berg√©</a>, Benjamin Mouscadet, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rimmel:Arpad.html">Arpad Rimmel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomasik:Joanna.html">Joanna Tomasik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02353">PDF</a><br/><b>Abstract: </b>The parameterized complexity of counting minimum cuts stands as a natural
question because Ball and Provan showed its #P-completeness. For any undirected
graph $G=(V,E)$ and two disjoint sets of its vertices $S,T$, we design a
fixed-parameter tractable algorithm which counts minimum edge $(S,T)$-cuts
parameterized by their size $p$. Our algorithm operates on a transformed graph
instance. This transformation, called drainage, reveals a collection of at most
$n=\left| V \right|$ successive minimum $(S,T)$-cuts $Z_i$. We prove that any
minimum $(S,T)$-cut $X$ contains edges of at least one cut $Z_i$. This
observation, together with Menger's theorem, allows us to build the algorithm
counting all minimum $(S,T)$-cuts with running time $2^{O(p^2)}n^{O(1)}$.
Initially dedicated to counting minimum cuts, it can be modified to obtain an
FPT sampling of minimum edge $(S,T)$-cuts.
</p></div>
    </summary>
    <updated>2019-07-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02320</id>
    <link href="http://arxiv.org/abs/1907.02320" rel="alternate" type="text/html"/>
    <title>Optimal transport on large networks a practitioner guide</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charpentier:Arthur.html">Arthur Charpentier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galichon:Alfred.html">Alfred Galichon</a>, Lucas Vernet <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02320">PDF</a><br/><b>Abstract: </b>This article presents a set of tools for the modeling of a spatial allocation
problem in a large geographic market and gives examples of applications. In our
settings, the market is described by a network that maps the cost of travel
between each pair of adjacent locations. Two types of agents are located at the
nodes of this network. The buyers choose the most competitive sellers depending
on their prices and the cost to reach them. Their utility is assumed additive
in both these quantities. Each seller, taking as given other sellers prices,
sets her own price to have a demand equal to the one we observed. We give a
linear programming formulation for the equilibrium conditions. After formally
introducing our model we apply it on two examples: prices offered by petrol
stations and quality of services provided by maternity wards. These examples
illustrate the applicability of our model to aggregate demand, rank prices and
estimate cost structure over the network. We insist on the possibility of
applications to large scale data sets using modern linear programming solvers
such as Gurobi. In addition to this paper we released a R toolbox to implement
our results and an online tutorial (<a href="http://optimalnetwork.github.io">this http URL</a>)
</p></div>
    </summary>
    <updated>2019-07-05T01:29:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02319</id>
    <link href="http://arxiv.org/abs/1907.02319" rel="alternate" type="text/html"/>
    <title>The Complexity of Approximately Counting Retractions to Square-Free Graphs</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Focke:Jacob.html">Jacob Focke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, Stanislav ≈Ωivn√Ω <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02319">PDF</a><br/><b>Abstract: </b>A retraction is a homomorphism from a graph $G$ to an induced subgraph $H$ of
$G$ that is the identity on $H$. In a long line of research, retractions have
been studied under various algorithmic settings. Recently, the problem of
approximately counting retractions was considered. We give a complete
trichotomy for the complexity of approximately counting retractions to all
square-free graphs (graphs that do not contain a cycle of length $4$). It turns
out there is a rich and interesting class of graphs for which this problem is
complete in the class $\#\mathrm{BIS}$. As retractions generalise
homomorphisms, our easiness results extend to the important problem of
approximately counting homomorphisms. By giving new $\#\mathrm{BIS}$-easiness
results we now settle the complexity of approximately counting homomorphisms
for a whole class of non-trivial graphs which were previously unresolved.
</p></div>
    </summary>
    <updated>2019-07-05T01:22:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02308</id>
    <link href="http://arxiv.org/abs/1907.02308" rel="alternate" type="text/html"/>
    <title>The Alternating BWT: an algorithmic perspective</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giancarlo:Raffaele.html">Raffaele Giancarlo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzini:Giovanni.html">Giovanni Manzini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Restivo:Antonio.html">Antonio Restivo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosone:Giovanna.html">Giovanna Rosone</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sciortino:Marinella.html">Marinella Sciortino</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02308">PDF</a><br/><b>Abstract: </b>The Burrows-Wheeler Transform (BWT) is a word transformation introduced in
1994 for Data Compression. It has become a fundamental tool for designing
self-indexing data structures, with important applications in several area in
science and engineering. The Alternating Burrows-Wheeler Transform (ABWT) is
another transformation recently introduced in [Gessel et al. 2012] and studied
in the field of Combinatorics on Words. It is analogous to the BWT, except that
it uses an alternating lexicographical order instead of the usual one. Building
on results in [Giancarlo et al. 2018], where we have shown that BWT and ABWT
are part of a larger class of reversible transformations, here we provide a
combinatorial and algorithmic study of the novel transform ABWT. We establish a
deep analogy between BWT and ABWT by proving they are the only ones in the
above mentioned class to be rank-invertible, a novel notion guaranteeing
efficient invertibility. In addition, we show that the backward-search
procedure can be efficiently generalized to the ABWT; this result implies that
also the ABWT can be used as a basis for efficient compressed full text
indices. Finally, we prove that the ABWT can be efficiently computed by using a
combination of the Difference Cover suffix sorting algorithm
[K\"{a}rkk\"{a}inen et al., 2006] with a linear time algorithm for finding the
minimal cyclic rotation of a word with respect to the alternating
lexicographical order.
</p></div>
    </summary>
    <updated>2019-07-05T01:25:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02274</id>
    <link href="http://arxiv.org/abs/1907.02274" rel="alternate" type="text/html"/>
    <title>Min-Cost Flow in Unit-Capacity Planar Graphs</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karczmarz:Adam.html">Adam Karczmarz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankowski:Piotr.html">Piotr Sankowski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02274">PDF</a><br/><b>Abstract: </b>In this paper we give an $\widetilde{O}((nm)^{2/3}\log C)$ time algorithm for
computing min-cost flow (or min-cost circulation) in unit capacity planar
multigraphs where edge costs are integers bounded by $C$. For planar
multigraphs, this improves upon the best known algorithms for general graphs:
the $\widetilde{O}(m^{10/7}\log C)$ time algorithm of Cohen et al. [SODA 2017],
the $O(m^{3/2}\log(nC))$ time algorithm of Gabow and Tarjan [SIAM J. Comput.
1989] and the $\widetilde{O}(\sqrt{n}m \log C)$ time algorithm of Lee and
Sidford [FOCS 2014]. In particular, our result constitutes the first known
fully combinatorial algorithm that breaks the $\widetilde{O}(m^{3/2})$ time
barrier for min-cost flow problem in planar graphs.
</p>
<p>To obtain our result we first give a very simple successive shortest paths
based scaling algorithm for unit-capacity min-cost flow problem that does not
explicitly operate on dual variables. This algorithm also runs in
$\widetilde{O}(m^{3/2}\log{C})$ time for general graphs, and, to the best of
our knowledge, it has not been described before. We subsequently show how to
implement this algorithm faster on planar graphs using well-established tools:
$r$-divisions and efficient algorithms for computing (shortest) paths in
so-called dense distance graphs.
</p></div>
    </summary>
    <updated>2019-07-05T01:27:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02266</id>
    <link href="http://arxiv.org/abs/1907.02266" rel="alternate" type="text/html"/>
    <title>Reliable Hubs for Partially-Dynamic All-Pairs Shortest Paths in Directed Graphs</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karczmarz:Adam.html">Adam Karczmarz</a>, Jakub ≈ÅƒÖcki <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02266">PDF</a><br/><b>Abstract: </b>We give new partially-dynamic algorithms for the all-pairs shortest paths
problem in weighted directed graphs. Most importantly, we give a new
deterministic incremental algorithm for the problem that handles updates in
$\widetilde{O}(mn^{4/3}\log{W}/\epsilon)$ total time (where the edge weights
are from $[1,W]$) and explicitly maintains a $(1+\epsilon)$-approximate
distance matrix. For a fixed $\epsilon&gt;0$, this is the first deterministic
partially dynamic algorithm for all-pairs shortest paths in directed graphs,
whose update time is $o(n^2)$ regardless of the number of edges. Furthermore,
we also show how to improve the state-of-the-art partially dynamic randomized
algorithms for all-pairs shortest paths [Baswana et al. STOC'02, Bernstein
STOC'13] from Monte Carlo randomized to Las Vegas randomized without increasing
the running time bounds (with respect to the $\widetilde{O}(\cdot)$ notation).
</p>
<p>Our results are obtained by giving new algorithms for the problem of
dynamically maintaining hubs, that is a set of $\widetilde{O}(n/d)$ vertices
which hit a shortest path between each pair of vertices, provided it has
hop-length $\Omega(d)$. We give new subquadratic deterministic and Las Vegas
algorithms for maintenance of hubs under either edge insertions or deletions.
</p></div>
    </summary>
    <updated>2019-07-05T01:26:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02251</id>
    <link href="http://arxiv.org/abs/1907.02251" rel="alternate" type="text/html"/>
    <title>Hardness of Bichromatic Closest Pair with Jaccard Similarity</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagh:Rasmus.html">Rasmus Pagh</a>, Nina Stausholm, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorup:Mikkel.html">Mikkel Thorup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02251">PDF</a><br/><b>Abstract: </b>Consider collections $\mathcal{A}$ and $\mathcal{B}$ of red and blue sets,
respectively. Bichromatic Closest Pair is the problem of finding a pair from
$\mathcal{A}\times \mathcal{B}$ that has similarity higher than a given
threshold according to some similarity measure. Our focus here is the classic
Jaccard similarity $|\textbf{a}\cap \textbf{b}|/|\textbf{a}\cup \textbf{b}|$
for $(\textbf{a},\textbf{b})\in \mathcal{A}\times \mathcal{B}$.
</p>
<p>We consider the approximate version of the problem where we are given
thresholds $j_1&gt;j_2$ and wish to return a pair from $\mathcal{A}\times
\mathcal{B}$ that has Jaccard similarity higher than $j_2$ if there exists a
pair in $\mathcal{A}\times \mathcal{B}$ with Jaccard similarity at least $j_1$.
The classic locality sensitive hashing (LSH) algorithm of Indyk and Motwani
(STOC '98), instantiated with the MinHash LSH function of Broder et al., solves
this problem in $\tilde O(n^{2-\delta})$ time if $j_1\ge j_2^{1-\delta}$. In
particular, for $\delta=\Omega(1)$, the approximation ratio
$j_1/j_2=1/j_2^{\delta}$ increases polynomially in $1/j_2$.
</p>
<p>In this paper we give a corresponding hardness result. Assuming the
Orthogonal Vectors Conjecture (OVC), we show that there cannot be a general
solution that solves the Bichromatic Closest Pair problem in
$O(n^{2-\Omega(1)})$ time for $j_1/j_2=1/j_2^{o(1)}$. Specifically, assuming
OVC, we prove that for any $\delta&gt;0$ there exists an $\varepsilon&gt;0$ such that
Bichromatic Closest Pair with Jaccard similarity requires time
$\Omega(n^{2-\delta})$ for any choice of thresholds $j_2&lt;j_1&lt;1-\delta$, that
satisfy $j_1\le j_2^{1-\varepsilon}$.
</p></div>
    </summary>
    <updated>2019-07-05T01:20:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02245</id>
    <link href="http://arxiv.org/abs/1907.02245" rel="alternate" type="text/html"/>
    <title>Optimizing micro-tiles in micro-structures as a design paradigm</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Antolin:Pablo.html">Pablo Antolin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buffa:Annalisa.html">Annalisa Buffa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Elaine.html">Elaine Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dannenhoffer:John_F=.html">John F. Dannenhoffer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elber:Gershon.html">Gershon Elber</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elgeti:Stefanie.html">Stefanie Elgeti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haimes:Robert.html">Robert Haimes</a>, Richard Riesenfeld <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02245">PDF</a><br/><b>Abstract: </b>In recent years, new methods have been developed to synthesize complex porous
and micro-structured geometry in a variety of ways. In this work, we take these
approaches one step further and present these methods as an efficacious design
paradigm. Specifically, complex micro-structure geometry can be synthesized
while optimizing certain properties such as maximal heat exchange in heat
exchangers, or minimal weight under stress specifications. By being able to
adjust the geometry, the topology and/or the material properties of individual
tiles in the micro-structure, possibly in a gradual way, a porous object can be
synthesized that is optimal with respect to the design specifications. As part
of this work, we exemplify this paradigm on a variety of diverse applications.
</p></div>
    </summary>
    <updated>2019-07-05T01:30:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02218</id>
    <link href="http://arxiv.org/abs/1907.02218" rel="alternate" type="text/html"/>
    <title>Sampling Sketches for Concave Sublinear Functions of Frequencies</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Edith.html">Edith Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Geri:Ofir.html">Ofir Geri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02218">PDF</a><br/><b>Abstract: </b>We consider massive distributed datasets that consist of elements modeled as
key-value pairs and the task of computing statistics or aggregates where the
contribution of each key is weighted by a function of its frequency (sum of
values of its elements). This fundamental problem has a wealth of applications
in data analytics and machine learning, in particular, with concave sublinear
functions of the frequencies that mitigate the disproportionate effect of keys
with high frequency. The family of concave sublinear functions includes low
frequency moments ($p \leq 1$), capping, logarithms, and their compositions. A
common approach is to sample keys, ideally, proportionally to their
contributions and estimate statistics from the sample. A simple but costly way
to do this is by aggregating the data to produce a table of keys and their
frequencies, apply our function to the frequency values, and then apply a
weighted sampling scheme. Our main contribution is the design of composable
sampling sketches that can be tailored to any concave sublinear function of the
frequencies. Our sketch structure size is very close to the desired sample size
and our samples provide statistical guarantees on the estimation quality that
are very close to that of an ideal sample of the same size computed over
aggregated data. Finally, we demonstrate experimentally the simplicity and
effectiveness of our methods.
</p></div>
    </summary>
    <updated>2019-07-05T01:27:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02211</id>
    <link href="http://arxiv.org/abs/1907.02211" rel="alternate" type="text/html"/>
    <title>Optimal Decision Trees for the Algorithm Selection Problem: Integer Programming Based Approaches</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Matheus Guedes Vilas Boas, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santos:Haroldo_Gambini.html">Haroldo Gambini Santos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Merschmann:Luiz_Henrique_de_Campos.html">Luiz Henrique de Campos Merschmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berghe:Greet_Vanden.html">Greet Vanden Berghe</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02211">PDF</a><br/><b>Abstract: </b>Even though it is well known that for most relevant computational problems
different algorithms may perform better on different classes of problem
instances, most computational experiments still focus on determining a single
best algorithm configuration based on aggregate results such as the average. In
this paper, we propose Integer Programming based approaches to build decision
trees for the Algorithm Selection Problem. These techniques allow to
automatically: (i) find the most important problem features to determine
problem classes; (ii) group the problems into classes and (iii) select the best
algorithm configuration for each class. To evaluate this new approach,
extensive computational experiments were executed using the linear programming
algorithms implemented in the COIN-OR Branch &amp; Cut solver in a comprehensive
set of instances, including all MIPLIB benchmark instances. The results
exceeded our initial expectations. While the single best parameter setting
discovered decreased the total running time by 22%, our approach decreased the
total running time by 40% in average in 10-fold cross validation experiments.
These results indicate that our method generalizes quite well and does not
overfit.
</p></div>
    </summary>
    <updated>2019-07-05T01:29:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02171</id>
    <link href="http://arxiv.org/abs/1907.02171" rel="alternate" type="text/html"/>
    <title>Sketched MinDist</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Jeff_M=.html">Jeff M. Phillips</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Pingfan.html">Pingfan Tang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02171">PDF</a><br/><b>Abstract: </b>We consider sketch vectors of geometric objects $J$ through the \mindist
function \[ v_i(J) = \inf_{p \in J} \|p-q_i\| \] for $q_i \in Q$ from a point
set $Q$. Collecting the vector of these sketch values induces a simple,
effective, and powerful distance: the Euclidean distance between these sketched
vectors. This paper shows how large this set $Q$ needs to be under a variety of
shapes and scenarios. For hyperplanes we provide direct connection to the
sensitivity sample framework, so relative error can be preserved in $d$
dimensions using $Q = O(d/\varepsilon^2)$. However, for other shapes, we show
we need to enforce a minimum distance parameter $\rho$, and a domain size $L$.
For $d=2$ the sample size $Q$ then can be $\tilde{O}((L/\rho) \cdot
1/\varepsilon^2)$. For objects (e.g., trajectories) with at most $k$ pieces
this can provide stronger \emph{for all} approximations with
$\tilde{O}((L/\rho)\cdot k^3 / \varepsilon^2)$ points. Moreover, with similar
size bounds and restrictions, such trajectories can be reconstructed exactly
using only these sketch vectors.
</p></div>
    </summary>
    <updated>2019-07-05T01:29:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02145</id>
    <link href="http://arxiv.org/abs/1907.02145" rel="alternate" type="text/html"/>
    <title>Linear Size Sparsifier and the Geometry of the Operator Norm Ball</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Victor Reis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rothvoss:Thomas.html">Thomas Rothvoss</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02145">PDF</a><br/><b>Abstract: </b>The Matrix Spencer Conjecture asks whether given $n$ symmetric matrices in
$\mathbb{R}^{n \times n}$ with eigenvalues in $[-1,1]$ one can always find
signs so that their signed sum has singular values bounded by $O(\sqrt{n})$.
The standard approach in discrepancy requires proving that the convex body of
all good fractional signings is large enough. However, this question has
remained wide open due to the lack of tools to certify measure lower bounds for
rather small non-polyhedral convex sets.
</p>
<p>A seminal result by Batson, Spielman and Srivastava from 2008 shows that any
undirected graph admits a linear size spectral sparsifier. Again, one can
define a convex body of all good fractional signings. We can indeed prove that
this body is close to most of the Gaussian measure. This implies that a
discrepancy algorithm by the second author can be used to sample a linear size
sparsifer. In contrast to previous methods, we require only a logarithmic
number of sampling phases.
</p></div>
    </summary>
    <updated>2019-07-05T01:24:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02120</id>
    <link href="http://arxiv.org/abs/1907.02120" rel="alternate" type="text/html"/>
    <title>Towards improving Christofides algorithm for half-integer TSP</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haddadan:Arash.html">Arash Haddadan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Newman:Alantha.html">Alantha Newman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02120">PDF</a><br/><b>Abstract: </b>We study the traveling salesman problem (TSP) in the case when the objective
function of the subtour linear programming relaxation is minimized by a
half-cycle point: $x_e \in \{ 0 ,1/2 , 1 \}$ where the half-edges form a
2-factor and the 1-edges form a perfect matching. Such points are sufficient to
resolve half-integer TSP in general and they have been conjectured to
demonstrate the largest integrality gap for the subtour relaxation.
</p>
<p>For half-cycle points, the best-known approximation guarantee is $3/2$ due to
Christofides famous algorithm. Proving an integrality gap of $\alpha$ for the
subtour relaxation is equivalent to showing that $\alpha x$ can be written as a
convex combination of tours, where $x$ is any feasible solution for this
relaxation. To beat Christofides bound, our goal is to show that
$(2-\epsilon)x$ can be written as a convex combination of tours for some
positive constant $\epsilon$. Let $y_e = 2-\epsilon$ when $x_e=1$ and $y_e=
3/4$ when $x_e = 1/2$. As a first step towards this goal, our main result is to
show that $y$ can be written as a convex combination of tours. In other words,
we show that we can save on 1-edges, which has several applications. Among
them, it gives an alternative algorithm for the recently studied uniform cover
problem. Our main new technique is a procedure to glue tours over proper 3-edge
cuts that are tight with respect to $x$ , thus reducing the problem to a base
case in which such cuts do not occur.
</p></div>
    </summary>
    <updated>2019-07-05T01:28:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01617</id>
    <link href="http://arxiv.org/abs/1907.01617" rel="alternate" type="text/html"/>
    <title>A Short Proof of the Toughness of Delaunay Triangulations</title>
    <feedworld_mtime>1562284800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biniaz:Ahmad.html">Ahmad Biniaz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01617">PDF</a><br/><b>Abstract: </b>We present a self-contained short proof of the seminal result of Dillencourt
(SoCG 1987 and DCG 1990) that Delaunay triangulations, of planar point sets in
general position, are 1-tough. An important implication of this result is that
Delaunay triangulations have perfect matchings.
</p></div>
    </summary>
    <updated>2019-07-05T00:00:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4233</id>
    <link href="https://www.scottaaronson.com/blog/?p=4233" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4233#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4233" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">John Wright joins UT Austin</title>
    <summary xml:lang="en-US">I‚Äôm delighted to announce that quantum computing theorist John Wright will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. John made an appearance on this blog a few months ago, when I wrote about the new breakthrough by him and Anand Natarajan: namely, [‚Ä¶]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter"><img alt="" class="wp-image-4244" src="https://www.scottaaronson.com/blog/wp-content/uploads/2019/07/image-1.png"/></figure></div>



<p>I‚Äôm delighted to announce that quantum computing theorist <a href="http://www.mit.edu/~jswright/">John Wright</a> will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. </p>



<p>John made an appearance on this blog a few months ago, when I <a href="https://www.scottaaronson.com/blog/?p=4172">wrote about</a> the <a href="https://arxiv.org/abs/1904.05870">new breakthrough</a> by him and <a href="http://www.its.caltech.edu/~anataraj/">Anand Natarajan</a>: namely, that MIP* (multi-prover interactive proofs with entangled provers) contains NEEXP (nondeterministic double-exponential time).  Previously, MIP* had only been known to contain NEXP (nondeterministic <em>single</em> exponential time).  So, this is an exponential expansion in the power of entangled provers over what was previously known and believed, and the first proof that entanglement actually <em>increases</em> the power of multi-prover protocols, rather than decreasing it (as it could‚Äôve done a priori).  Even more strikingly, there seems to be no natural stopping point: MIP* might soon swallow up arbitrary towers of exponentials or even the halting problem (!).  For more, see for example <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">this <em>Quanta</em> article</a>, or <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">this post by Thomas Vidick</a>, or <a href="http://www.henryyuen.net/post/alice-and-bob-visit/">this short story [sic] by Henry Yuen</a>.</p>



<p>John grew up in Texas, so he‚Äôs no stranger to BBQ brisket or scorching weather.  He did his undergrad in computer science at UT Austin‚Äîmy colleagues remember him as a star‚Äîand then completed his PhD with Ryan O‚ÄôDonnell at Carnegie Mellon, followed by a postdoc at MIT.  Besides the work on MIP*, John is also well-known for his <a href="https://arxiv.org/abs/1508.01907">2015 work with O‚ÄôDonnell</a> pinning down the sample complexity of quantum state tomography.  Their important result, a version of which was independently obtained by <a href="https://arxiv.org/abs/1508.01797">Haah et al.</a>, says that if you want to learn an unknown d-dimensional quantum mixed state œÅ to a reasonable precision, then ~d<sup>2</sup> copies of œÅ are both necessary and sufficient.  This solved a problem that had personally interested me, and already plays a role in, e.g., my work on <a href="https://arxiv.org/abs/1711.01053">shadow tomography</a> and <a href="https://www.scottaaronson.com/papers/dpgentle.pdf">gentle measurements</a>.</p>



<p>Our little <a href="https://www.cs.utexas.edu/~qic/">quantum information center</a> at UT Austin is growing rapidly.  <a href="http://sites.utexas.edu/shyamshankar/">Shyam Shankar</a>, a superconducting qubits guy who previously worked in Rob Schoelkopf‚Äôs lab at Yale, will also be joining UT‚Äôs Electrical and Computer Engineering department this fall.  I‚Äôll have two new postdocs‚Äî<a href="https://twitter.com/a_rocchetto?lang=en">Andrea Rocchetto</a> and <a href="http://www.cs.huji.ac.il/~yosiat/">Yosi Atia</a>‚Äîas well as new PhD students.  We‚Äôll continue recruiting this coming year, with potential opportunities for students, postdocs, faculty, and research scientists across the CS, physics, and ECE departments as well as the Texas Advanced Computing Center (TACC).  I hope you‚Äôll consider applying to join us.</p>



<p>With no evaluative judgment attached, I can honestly say that this is an unprecedented time for quantum computing as a field.  Where once faculty applicants struggled to make a case for quantum computing (physics departments: ‚Äúbut isn‚Äôt this really CS?‚Äù / CS departments: ‚Äúisn‚Äôt it really physics?‚Äù / everyone: ‚Äúcouldn‚Äôt this whole QC thing, like, all blow over in a year?‚Äù), today departments are vying with each other and with industry players and startups to recruit talented people.  In such an environment, we‚Äôre fortunate to be doing as well as we are.  We hope to continue to expand.</p>



<p>Meanwhile, this was an <a href="https://www.nytimes.com/2019/01/24/technology/computer-science-courses-college.html">unprecedented year for CS hiring at UT Austin</a> more generally.  John Wright is one of at least four new faculty (probably more) who will be joining us.  It‚Äôs a good time to be in CS.</p>



<p>A huge welcome to John, and hook ‚Äôem Hadamards!</p>



<p>(And for US readers: have a great 4<sup>th</sup>!  Though how could any fireworks match the proof of the Sensitivity Conjecture?)</p></div>
    </content>
    <updated>2019-07-04T01:08:54Z</updated>
    <published>2019-07-04T01:08:54Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-05T04:22:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02056</id>
    <link href="http://arxiv.org/abs/1907.02056" rel="alternate" type="text/html"/>
    <title>Variance Reduction for Matrix Games</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmon:Yair.html">Yair Carmon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yujia.html">Yujia Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Kevin.html">Kevin Tian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02056">PDF</a><br/><b>Abstract: </b>We present a randomized primal-dual algorithm that solves the problem
$\min_{x} \max_{y} y^\top A x$ to additive error $\epsilon$ in time
$\mathrm{nnz}(A) + \sqrt{\mathrm{nnz}(A)n}/\epsilon$, for matrix $A$ with
larger dimension $n$ and $\mathrm{nnz}(A)$ nonzero entries. This improves on
Nemirovski's mirror-prox method by a factor of $\sqrt{\mathrm{nnz}(A)/n}$ and
is faster than stochastic gradient methods in the accurate and/or sparse regime
$\epsilon \le \sqrt{n/\mathrm{nnz}(A)}$. Our results hold for $x,y$ in the
simplex (matrix games, linear programming) and for $x$ in an $\ell_2$ ball and
$y$ in the simplex (perceptron / SVM, minimum enclosing ball). Our algorithm
combines the mirror-prox method and a novel variance-reduced gradient estimator
based on "sampling from the difference" between the current iterate and a
reference point.
</p></div>
    </summary>
    <updated>2019-07-04T23:30:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02053</id>
    <link href="http://arxiv.org/abs/1907.02053" rel="alternate" type="text/html"/>
    <title>Evaluation of a Flow-Based Hypergraph Bipartitioning Algorithm</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gottesb=uuml=ren:Lars.html">Lars Gottesb√ºren</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamann:Michael.html">Michael Hamann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Dorothea.html">Dorothea Wagner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02053">PDF</a><br/><b>Abstract: </b>In this paper, we propose HyperFlowCutter, an algorithm for balanced
hypergraph bipartitioning. It is based on minimum S-T hyperedge cuts and
maximum flows. It computes a sequence of bipartitions that optimize cut size
and balance in the Pareto sense, being able to trade one for the other.
HyperFlowCutter builds on the FlowCutter algorithm for partitioning graphs. We
propose additional features, such as handling disconnected hypergraphs, novel
methods for obtaining starting S,T pairs as well as an approach to refine a
given partition with HyperFlowCutter. Our main contribution is ReBaHFC, a new
algorithm which obtains an initial partition with the fast multilevel
hypergraph partitioner PaToH and then improves it using HyperFlowCutter as a
refinement algorithm. ReBaHFC is able to significantly improve the solution
quality of PaToH at little additional running time. The solution quality is
only marginally worse than that of the best-performing hypergraph partitioners
KaHyPar and hMETIS, while being one order of magnitude faster. Thus ReBaHFC
offers a new time-quality trade-off in the current spectrum of hypergraph
partitioners. For the special case of perfectly balanced bipartitioning, only
the much slower plain HyperFlowCutter yields slightly better solutions than
ReBaHFC, while only PaToH is faster than ReBaHFC.
</p></div>
    </summary>
    <updated>2019-07-04T23:39:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01980</id>
    <link href="http://arxiv.org/abs/1907.01980" rel="alternate" type="text/html"/>
    <title>Triangles and Girth in Disk Graphs and Transmission Graphs</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klost:Katharina.html">Katharina Klost</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roditty:Liam.html">Liam Roditty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seiferth:Paul.html">Paul Seiferth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharir:Micha.html">Micha Sharir</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01980">PDF</a><br/><b>Abstract: </b>Let $S \subset \mathbb{R}^2$ be a set of $n$ sites, where each $s \in S$ has
an associated radius $r_s &gt; 0$. The disk graph $D(S)$ is the undirected graph
with vertex set $S$ and an undirected edge between two sites $s, t \in S$ if
and only if $|st| \leq r_s + r_t$, i.e., if the disks with centers $s$ and $t$
and respective radii $r_s$ and $r_t$ intersect. Disk graphs are used to model
sensor networks. Similarly, the transmission graph $T(S)$ is the directed graph
with vertex set $S$ and a directed edge from a site $s$ to a site $t$ if and
only if $|st| \leq r_s$, i.e., if $t$ lies in the disk with center $s$ and
radius $r_s$.
</p>
<p>We provide algorithms for detecting (directed) triangles and, more generally,
computing the length of a shortest cycle (the girth) in $D(S)$ and in $T(S)$.
These problems are notoriously hard in general, but better solutions exist for
special graph classes such as planar graphs. We obtain similarly efficient
results for disk graphs and for transmission graphs. More precisely, we show
that a shortest (Euclidean) triangle in $D(S)$ and in $T(S)$ can be found in
$O(n \log n)$ expected time, and that the (weighted) girth of $D(S)$ can be
found in $O(n \log n)$ expected time. For this, we develop new tools for
batched range searching that may be of independent interest.
</p></div>
    </summary>
    <updated>2019-07-04T23:47:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01815</id>
    <link href="http://arxiv.org/abs/1907.01815" rel="alternate" type="text/html"/>
    <title>Circular Pattern Matching with $k$ Mismatches</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charalampopoulos:Panagiotis.html">Panagiotis Charalampopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kociumaka:Tomasz.html">Tomasz Kociumaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pissis:Solon_P=.html">Solon P. Pissis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Radoszewski:Jakub.html">Jakub Radoszewski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rytter:Wojciech.html">Wojciech Rytter</a>, Juliusz Straszy≈Ñski, Tomasz Wale≈Ñ, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zuba:Wiktor.html">Wiktor Zuba</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01815">PDF</a><br/><b>Abstract: </b>The $k$-mismatch problem consists in computing the Hamming distance between a
pattern $P$ of length $m$ and every length-$m$ substring of a text $T$ of
length $n$, if this distance is no more than $k$. In many real-world
applications, any cyclic shift of $P$ is a relevant pattern, and thus one is
interested in computing the minimal distance of every length-$m$ substring of
$T$ and any cyclic shift of $P$. This is the circular pattern matching with $k$
mismatches ($k$-CPM) problem. A multitude of papers have been devoted to
solving this problem but, to the best of our knowledge, only average-case upper
bounds are known. In this paper, we present the first non-trivial worst-case
upper bounds for the $k$-CPM problem. Specifically, we show an $O(nk)$-time
algorithm and an $O(n+\frac{n}{m}\,{\small k^5})$-time algorithm. The latter
algorithm applies in an extended way a technique that was very recently
developed for the $k$-mismatch problem [Bringmann et al., SODA 2019].
</p></div>
    </summary>
    <updated>2019-07-04T23:25:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01773</id>
    <link href="http://arxiv.org/abs/1907.01773" rel="alternate" type="text/html"/>
    <title>Accelerating Deconvolution on Unmodified CNN Accelerators for Generative Adversarial Networks -- A Software Approach</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tu:Kaijie.html">Kaijie Tu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01773">PDF</a><br/><b>Abstract: </b>Generative Adversarial Networks (GANs) are the emerging machine learning
technology that can learn to automatically create labeled datasets in massive
application domains such as speech, image, video and texts. A GAN typically
includes a generative model that is taught to generate any distribution of
data, and a discriminator trained to distinguish the synthetic data from
real-world data. Both convolutional and deconvolutional layers are the major
source of performance overhead for GANs and directly impacts the efficiency of
GAN-based systems. There are many prior works investigating specialized
hardware architectures that can accelerate convolution and deconvolution
simultaneously, but they entail intensive hardware modifications to the
existing CNN accelerators or processors that focus on convolution acceleration.
In contrast, this work proposes a novel deconvolution layer implementation with
a software approach and enables fast and efficient generative network inference
on the legacy Convolutional Neural Networks (CNNs) accelerators. Our proposed
method reorganizes the computation of deconvolutional layer and allows the CNN
accelerators to treat it as the standard convolutional layer after we split the
original deconvolutional filters into multiple small filters. The proposed data
flow is implemented on representative CNN accelerators including dot-production
array and regular 2D PE array architectures. Compared to the prior baseline
acceleration scheme, the implemented acceleration scheme achieves 2.4X - 4.3X
performance speedup and reduces the energy consumption by 27.7% - 54.5% on a
set of realistic benchmarks.
</p></div>
    </summary>
    <updated>2019-07-04T23:25:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01766</id>
    <link href="http://arxiv.org/abs/1907.01766" rel="alternate" type="text/html"/>
    <title>Algorithms for Competitive Division of Chores</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Br=acirc=nzei:Simina.html">Simina Br√¢nzei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandomirskiy:Fedor.html">Fedor Sandomirskiy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01766">PDF</a><br/><b>Abstract: </b>We study the problem of allocating divisible bads (chores) among multiple
agents with additive utilities, when money transfers are not allowed. The
competitive rule is known to be the best mechanism for goods with additive
utilities and was recently extended to chores by Bogomolnaia et al (2017). For
both goods and chores, the rule produces Pareto optimal and envy-free
allocations. In the case of goods, the outcome of the competitive rule can be
easily computed. Competitive allocations solve the Eisenberg-Gale convex
program; hence the outcome is unique and can be approximately found by standard
gradient methods. An exact algorithm that runs in polynomial time in the number
of agents and goods was given by Orlin.
</p>
<p>In the case of chores, the competitive rule does not solve any convex
optimization problem; instead, competitive allocations correspond to local
minima, local maxima, and saddle points of the Nash Social Welfare on the
Pareto frontier of the set of feasible utilities. The rule becomes multivalued
and none of the standard methods can be applied to compute its outcome.
</p>
<p>In this paper, we show that all the outcomes of the competitive rule for
chores can be computed in strongly polynomial time if either the number of
agents or the number of chores is fixed. The approach is based on a combination
of three ideas: all consumption graphs of Pareto optimal allocations can be
listed in polynomial time; for a given consumption graph, a candidate for a
competitive allocation can be constructed via explicit formula; and a given
allocation can be checked for being competitive using a maximum flow
computation as in Devanur et al (2002).
</p>
<p>Our algorithm immediately gives an approximately-fair allocation of
indivisible chores by the rounding technique of Barman and Krishnamurthy
(2018).
</p></div>
    </summary>
    <updated>2019-07-04T23:23:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01745</id>
    <link href="http://arxiv.org/abs/1907.01745" rel="alternate" type="text/html"/>
    <title>Generalized Assignment via Submodular Optimization with Reserved Capacity</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulik:Ariel.html">Ariel Kulik</a>, Kanthi Sarpatwar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schieber:Baruch.html">Baruch Schieber</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shachnai:Hadas.html">Hadas Shachnai</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01745">PDF</a><br/><b>Abstract: </b>We study a variant of the \emph{generalized assignment problem} ({\sf GAP})
with group constraints. An instance of {\sf Group GAP} is a set $I$ of items,
partitioned into $L$ groups, and a set of $m$ uniform (unit-sized) bins. Each
item $i \in I$ has a size $s_i &gt;0$, and a profit $p_{i,j} \geq 0$ if packed in
bin $j$. A group of items is \emph{satisfied} if all of its items are packed.
The goal is to find a feasible packing of a subset of the items in the bins
such that the total profit from satisfied groups is maximized. We point to
central applications of {\sf Group GAP} in Video-on-Demand services, mobile
Device-to-Device network caching and base station cooperation in 5G networks.
</p>
<p>Our main result is a $\frac{1}{6}$-approximation algorithm for {\sf Group
GAP} instances where the total size of each group is at most $\frac{m}{2}$. At
the heart of our algorithm lies an interesting derivation of a submodular
function from the classic LP formulation of {\sf GAP}, which facilitates the
construction of a high profit solution utilizing at most half the total bin
capacity, while the other half is \emph{reserved} for later use. In particular,
we give an algorithm for submodular maximization subject to a knapsack
constraint, which finds a solution of profit at least $\frac{1}{3}$ of the
optimum, using at most half the knapsack capacity, under mild restrictions on
element sizes. Our novel approach of submodular optimization subject to a
knapsack \emph{with reserved capacity} constraint may find applications in
solving other group assignment problems.
</p></div>
    </summary>
    <updated>2019-07-04T23:24:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01700</id>
    <link href="http://arxiv.org/abs/1907.01700" rel="alternate" type="text/html"/>
    <title>Shortest Reconfiguration of Perfect Matchings via Alternating Cycles</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ito:Takehiro.html">Takehiro Ito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kakimura:Naonori.html">Naonori Kakimura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamiyama:Naoyuki.html">Naoyuki Kamiyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Okamoto:Yoshio.html">Yoshio Okamoto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01700">PDF</a><br/><b>Abstract: </b>Motivated by adjacency in perfect matching polytopes, we study the shortest
reconfiguration problem of perfect matchings via alternating cycles. Namely, we
want to find a shortest sequence of perfect matchings which transforms one
given perfect matching to another given perfect matching such that the
symmetric difference of each pair of consecutive perfect matchings is a single
cycle. The problem is equivalent to the combinatorial shortest path problem in
perfect matching polytopes. We prove that the problem is NP-hard even when a
given graph is planar or bipartite, but it can be solved in polynomial time
when the graph is outerplanar.
</p></div>
    </summary>
    <updated>2019-07-04T23:30:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01683</id>
    <link href="http://arxiv.org/abs/1907.01683" rel="alternate" type="text/html"/>
    <title>SkeletonNet: Shape Pixel to Skeleton Pixel</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sabari Nathan, Priya Kansal <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01683">PDF</a><br/><b>Abstract: </b>Deep Learning for Geometric Shape Understating has organized a challenge for
extracting different kinds of skeletons from the images of different objects.
This competition is organized in association with CVPR 2019. There are three
different tracks of this competition. The present manuscript describes the
method used to train the model for the dataset provided in the first track. The
first track aims to extract skeleton pixels from the shape pixels of 89
different objects. For the purpose of extracting the skeleton, a U-net model
which is comprised of an encoder-decoder structure has been used. In our
proposed architecture, unlike the plain decoder in the traditional Unet, we
have designed the decoder in the format of HED architecture, wherein we have
introduced 4 side layers and fused them to one dilation convolutional layer to
connect the broken links of the skeleton. Our proposed architecture achieved
the F1 score of 0.77 on test data.
</p></div>
    </summary>
    <updated>2019-07-04T23:42:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01631</id>
    <link href="http://arxiv.org/abs/1907.01631" rel="alternate" type="text/html"/>
    <title>Cache-Friendly Search Trees; or, In Which Everything Beats std::set</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jeffrey Barratt, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Brian.html">Brian Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01631">PDF</a><br/><b>Abstract: </b>While a lot of work in theoretical computer science has gone into optimizing
the runtime and space usage of data structures, such work very often neglects a
very important component of modern computers: the cache. In doing so, very
often, data structures are developed that achieve theoretically-good runtimes
but are slow in practice due to a large number of cache misses. In 1999, Frigo
et al. introduced the notion of a cache-oblivious algorithm: an algorithm that
uses the cache to its advantage, regardless of the size or structure of said
cache. Since then, various authors have designed cache-oblivious algorithms and
data structures for problems from matrix multiplication to array sorting. We
focus in this work on cache-oblivious search trees; i.e. implementing an
ordered dictionary in a cache-friendly manner. We will start by presenting an
overview of cache-oblivious data structures, especially cache-oblivious search
trees. We then give practical results using these cache-oblivious structures on
modern-day machinery, comparing them to the standard std::set and other
cache-friendly dictionaries such as B-trees.
</p></div>
    </summary>
    <updated>2019-07-04T23:39:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01630</id>
    <link href="http://arxiv.org/abs/1907.01630" rel="alternate" type="text/html"/>
    <title>Computing k-Modal Embeddings of Planar Digraphs</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Juan Jose Besa, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lozzo:Giordano_Da.html">Giordano Da Lozzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01630">PDF</a><br/><b>Abstract: </b>Given a planar digraph $G$ and a positive even integer $k$, an embedding of
$G$ in the plane is k-modal, if every vertex of $G$ is incident to at most $k$
pairs of consecutive edges with opposite orientations, i.e., the incoming and
the outgoing edges at each vertex are grouped by the embedding into at most k
sets of consecutive edges with the same orientation. In this paper, we study
the $k$-Modality problem, which asks for the existence of a $k$-modal embedding
of a planar digraph. This combinatorial problem is at the very core of a
variety of constrained embedding questions for planar digraphs and flat
clustered networks.
</p></div>
    </summary>
    <updated>2019-07-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01624</id>
    <link href="http://arxiv.org/abs/1907.01624" rel="alternate" type="text/html"/>
    <title>Efficient Circuit Simulation in MapReduce</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frei:Fabian.html">Fabian Frei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wada:Koichi.html">Koichi Wada</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01624">PDF</a><br/><b>Abstract: </b>The MapReduce framework has firmly established itself as one of the most
widely used parallel computing platforms for processing big data on tera- and
peta-byte scale. Approaching it from a theoretical standpoint has proved to be
notoriously difficult, however. In continuation of Goodrich et al.'s early
efforts, explicitly espousing the goal of putting the MapReduce framework on
footing equal to that of long-established models such as the PRAM, we
investigate the obvious complexity question of how the computational power of
MapReduce algorithms compares to that of combinational Boolean circuits
commonly used for parallel computations. Relying on the standard MapReduce
model introduced by Karloff et al. a decade ago, we develop an intricate
simulation technique to show that any problem in NC (i.e., a problem solved by
a logspace-uniform family of Boolean circuits of polynomial size and a depth
polylogarithmic in the input size) can be solved by a MapReduce computation in
O(T(n)/ log n) rounds, where n is the input size and T(n) is the depth of the
witnessing circuit family. Thus, we are able to closely relate the standard,
uniform NC hierarchy modeling parallel computations to the deterministic
MapReduce hierarchy DMRC by proving that NC^(i+1) is contained in DMRC^i for
all natural i, including 0. Besides the theoretical significance, this result
that has important applied aspects as well. In particular, we show for all
problems in NC^1---many practically relevant ones, such as integer
multiplication and division and the parity function, being among these---how to
solve them in a constant number of deterministic MapReduce rounds.
</p></div>
    </summary>
    <updated>2019-07-04T23:23:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01619</id>
    <link href="http://arxiv.org/abs/1907.01619" rel="alternate" type="text/html"/>
    <title>Learning from satisfying assignments under continuous distributions</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Cl√©ment L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/De:Anindya.html">Anindya De</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Servedio:Rocco_A=.html">Rocco A. Servedio</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01619">PDF</a><br/><b>Abstract: </b>What kinds of functions are learnable from their satisfying assignments?
Motivated by this simple question, we extend the framework of De, Diakonikolas,
and Servedio [DDS15], which studied the learnability of probability
distributions over $\{0,1\}^n$ defined by the set of satisfying assignments to
"low-complexity" Boolean functions, to Boolean-valued functions defined over
continuous domains. In our learning scenario there is a known "background
distribution" $\mathcal{D}$ over $\mathbb{R}^n$ (such as a known normal
distribution or a known log-concave distribution) and the learner is given
i.i.d. samples drawn from a target distribution $\mathcal{D}_f$, where
$\mathcal{D}_f$ is $\mathcal{D}$ restricted to the satisfying assignments of an
unknown low-complexity Boolean-valued function $f$. The problem is to learn an
approximation $\mathcal{D}'$ of the target distribution $\mathcal{D}_f$ which
has small error as measured in total variation distance.
</p>
<p>We give a range of efficient algorithms and hardness results for this
problem, focusing on the case when $f$ is a low-degree polynomial threshold
function (PTF). When the background distribution $\mathcal{D}$ is log-concave,
we show that this learning problem is efficiently solvable for degree-1 PTFs
(i.e.,~linear threshold functions) but not for degree-2 PTFs. In contrast, when
$\mathcal{D}$ is a normal distribution, we show that this learning problem is
efficiently solvable for degree-2 PTFs but not for degree-4 PTFs. Our hardness
results rely on standard assumptions about secure signature schemes.
</p></div>
    </summary>
    <updated>2019-07-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01600</id>
    <link href="http://arxiv.org/abs/1907.01600" rel="alternate" type="text/html"/>
    <title>Approximate Similarity Search Under Edit Distance Using Locality-Sensitive Hashing</title>
    <feedworld_mtime>1562198400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McCauley:Samuel.html">Samuel McCauley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01600">PDF</a><br/><b>Abstract: </b>Edit distance similarity search, also called approximate pattern matching, is
a fundamental problem with widespread applications. The goal of the problem is
to preprocess n strings of length d to quickly answer queries q of the form: if
there is a database string within edit distance r of q, return a database
string within edit distance cr of q. A data structure solving this problem is
analyzed using two criteria: the amount of extra space used in preprocessing,
and the expected time to answer a query.
</p>
<p>Previous approaches to this problem have either used trie-based methods,
which give exact solutions at the cost of expensive queries, or embeddings,
which only work for large (superconstant) values of c.
</p>
<p>In this work we achieve the first bounds for any approximation factor c, via
a simple and easy-to-implement hash function. This gives a running time of
$\tilde{O}(d3^rn^{1/c})$, with space $\tilde{O}(3^r n^{1 + 1/c} + dn)$. We show
how to apply these ideas to the closely-related Approximate Nearest Neighbor
problem for edit distance, obtaining similar time bounds.
</p></div>
    </summary>
    <updated>2019-07-04T23:42:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at National University of Singapore (apply by November 30, 2019)</title>
    <summary>Multiple post-doctoral research positions available in the project on ‚ÄúProvably Verified and Explainable Probabilistic Reasoning,‚Äù led by the Principle Investigator, Kuldeep S. Meel. The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods. Website: https://meelgroup.github.io/files/postdoc.html Email: meel+postdoc@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple post-doctoral research positions available in the project on ‚ÄúProvably Verified and Explainable Probabilistic Reasoning,‚Äù led by the Principle Investigator, Kuldeep S. Meel.</p>
<p>The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods.</p>
<p>Website: <a href="https://meelgroup.github.io/files/postdoc.html">https://meelgroup.github.io/files/postdoc.html</a><br/>
Email: meel+postdoc@comp.nus.edu.sg</p></div>
    </content>
    <updated>2019-07-03T19:39:18Z</updated>
    <published>2019-07-03T19:39:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-07-05T16:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16070</id>
    <link href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/" rel="alternate" type="text/html"/>
    <title>Mathematics of Gerrymandering</title>
    <summary>Can theory help? source; art by Bill Hennessy John Roberts is the Chief Justice of the United States. Today I will discuss the recent Supreme Court decision on gerrymandering. The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can theory help?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/unknown-124/" rel="attachment wp-att-16073"><img alt="" class="alignright size-full wp-image-16073" src="https://rjlipton.files.wordpress.com/2019/07/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://nonperele.com/john-biskupic-how-john-roberts-controls-the-us-supreme-court/">source</a>; art by Bill Hennessy</font></td>
</tr>
</tbody>
</table>
<p>
John Roberts is the Chief Justice of the United States.</p>
<p>
Today I will discuss the recent Supreme Court <a href="https://www.scotusblog.com/case-files/cases/rucho-v-common-cause-2/">decision</a> on gerrymandering.</p>
<p>
The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that it was hard, if not impossible, for courts to determine whether districts were reasonably drawn. That is, whether partisan motives dominated when they were created.</p>
<p>
I will explain what <a href="https://en.wikipedia.org/wiki/Gerrymandering">gerrymandering</a> is, and how computational methods may play a role. I must add a takeaway: </p>
<blockquote><p><b> </b> <em> <i>The current view of computational methods to avoid gerrymandering may be based on incorrect assumptions.</i> </em>
</p></blockquote>
<p>More on this later.</p>
<p>
</p><p/><h2> How It Works </h2><p/>
<p/><p>
You probably know that gerrymandering is used, negatively, to describe creating voting districts that do not reflect the voters will. The term was coined as part of an attack on the then Governor of Massachusetts in 1812. The shape of one particularly contrived district looked like a salamander. Since his name was Elbridge Gerry, it became a <i>gerrymander</i>. He was a Democratic-Republican and was not re-elected. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/gerry/" rel="attachment wp-att-16071"><img alt="" class="aligncenter size-full wp-image-16071" src="https://rjlipton.files.wordpress.com/2019/07/gerry.png?w=600"/></a></p>
<p>
Here is a figure from our friends at Wikipedia that presents examples of gerrymandering. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/divide/" rel="attachment wp-att-16072"><img alt="" class="aligncenter  wp-image-16072" src="https://rjlipton.files.wordpress.com/2019/07/divide.png?w=270" width="270"/></a></p>
<p>
By redistricting in the above, one can achieve anything from districts all won by the majority, to most won by the majority. These examples, show how the party who controls the districts can control the outcome.</p>
<p>
Well that is an overstatement. They can control the believed leanings of the voters in the districts. In the above example, they can control how yellow a district is. Real life is complicated by other factors: </p>
<ol>
<li>
A candidate may win because they are just more popular. That is a green candidate could still win in a yellow district. <p/>
</li><li>
A candidate may win because of random fluctuations. If the voter margin is small enough, random fluctuations could change the ‚Äúexpected‚Äù outcome.
</li></ol>
<p>
The latter is a danger for gerrymanderers. This <a href="https://www.brennancenter.org/blog/what-is-extreme-gerrymandering">site</a> on gerrymandering says: </p>
<blockquote><p><b> </b> <em> The trick is not to spread your voters out so much that districts become vulnerable to flipping to the other party in the normal give and take of electoral politics. </em>
</p></blockquote>
<p>
</p><p/><h2> How We Model It </h2><p/>
<p/><p>
Since Roberts is not our intended audience we will use mathematical definitions. I am sure Roberts and the rest of the Supreme Court justices are smart, but we have our own methods. We do not use legal jargon such as ‚Äúprima facie‚Äù and suspect they do not use math jargon like ‚Äúprime‚Äù numbers.</p>
<p>
So let the yellow party have <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> fraction of the voters. Suppose the voters have to be divided into <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> districts of the same size. A division is just a vector <img alt="{y=(y_{1},\dots,y_{d})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%3D%28y_%7B1%7D%2C%5Cdots%2Cy_%7Bd%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y=(y_{1},\dots,y_{d})}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{1} + \cdots + y_{d} = 1, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7B1%7D+%2B+%5Ccdots+%2B+y_%7Bd%7D+%3D+1%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{1} + \cdots + y_{d} = 1, "/></p>
<p>and each <img alt="{y_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_{i}}"/> is non-negative. For such a vector <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> the number that yellow <i>wins</i> is the number of indices <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{k} \ge \frac{1}{2d}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7Bk%7D+%5Cge+%5Cfrac%7B1%7D%7B2d%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{k} \ge \frac{1}{2d}. "/></p>
<p>Note, we assume that <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> of the voters makes a district a win. We can change this to strictly larger than <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/>, but will leave it for now.</p>
<blockquote><p><b>Definition 1</b> <em> Define <img alt="{{\rm MaxWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha)}"/> to the maximum over all <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/> of the number of wins; and define <img alt="{{\rm MinWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha)}"/> to be the minimum number of wins. </em>
</p></blockquote>
<p>Note, we do not care who is doing the redistricting. Nor do we care about the geometry. For example 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%285%2C+0.60%29+%3D+5+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%285%2C+0.60%29+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. "/></p>
<p>What can we say about these functions? Here are some simple observations.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha \ge 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cge+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha \ge 0.5}"/>, then <img alt="{{\rm MaxWin}(d, \alpha) = d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha) = d}"/>. Just place <img alt="{\alpha }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha }"/> fraction of the voters in each district.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha &gt; 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha &gt; 0.5}"/>, then <img alt="{{\rm MinWin}(d, \alpha) \ge 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%5Cge+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha) \ge 1}"/>. No matter how the districts are drawn there must be at least one where yellow has a majority. </p>
<p>
An advantage of these functions is that now we can discuss growth rates, not just present examples. A strength of theory is that we have replaced statements like ‚Äúthis algorithm is fast‚Äù by formulas for their running time. Another advantage is that these functions are <i>independent of geometry</i>. Previously I thought the dominating issue was how regions looked. Now I believe the issue is how close one gets to the best and worst case: <img alt="{\rm MaxWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MaxWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MaxWin}"/> and <img alt="{\rm MinWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MinWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MinWin}"/>. </p>
<blockquote><p><b>Lemma 2</b> <em> Suppose that <img alt="{\alpha &gt; 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+1%2F2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha &gt; 1/2}"/>. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-%5Clfloor+2%281-%5Calpha%29+d+%5Crfloor+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\beta = 1-\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta+%3D+1-%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta = 1-\alpha}"/>. Let‚Äôs create the arrangement that makes green win as many districts as possible. If <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> regions are mostly green then that takes <img alt="{\frac{g}{2d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bg%7D%7B2d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{g}{2d}}"/> of the <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> green voters. This implies that 	</p>
<p align="center"><img alt="\displaystyle  \frac{g}{2d} \le \beta. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bg%7D%7B2d%7D+%5Cle+%5Cbeta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{g}{2d} \le \beta. "/></p>
<p>So it follows 	</p>
<p align="center"><img alt="\displaystyle  g \le 2\beta d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g+%5Cle+2%5Cbeta+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g \le 2\beta d. "/></p>
<p>This proves that <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is equal to <img alt="{\lfloor 2\beta d \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clfloor+2%5Cbeta+d+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lfloor 2\beta d \rfloor}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
It may help to set <img alt="{\alpha = 1/2 + \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3D+1%2F2+%2B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha = 1/2 + \epsilon}"/> where <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/>. Let‚Äôs agree to ignore the rounding off and delete the floor and ceiling functions. Then 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-2%281-%5Calpha%29+d+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d "/></p>
<p>and so 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+2%5Cepsilon+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. "/></p>
<p>Thus for <img alt="{\epsilon = 1/10}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+1%2F10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon = 1/10}"/> we get that 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+0.2d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. "/></p>
<p>This says that independent of any geometry if yellow has a ten percent majority, then best case if they set the districts they could win all, and if green sets the districts the worst they can get is twenty percent of the districts.</p>
<p>
</p><p/><h2> How Algorithms Can Help </h2><p/>
<p/><p>
There is long-term and continuing interest in algorithms that automate redistricting. The hope is that automated systems will be able to create districts that are fair. A trouble with this research is that there is no universal notion of what makes districts fair. The mantra is: </p>
<blockquote><p><b> </b> <em> <i>A redistricting is fair if and only if the districts collectively satisfy some geometric criterion</i>. </em>
</p></blockquote>
<p>An explicit statement of such a criterion, from a <a href="https://bdistricting.com/about.html">site</a> on such algorithms, is: </p>
<blockquote><p><b> </b> <em> <i>The best district map is the one where people have the lowest average distance to the center of their district</i>. </em>
</p></blockquote>
<p>Of course the name ‚Äúgerrymandering‚Äù came from how districts looked. Somehow this enshrined the notion that districts must look right. I feel this could be wrong.</p>
<p>
Here is a quote from a recent <a href="http://district.cs.brown.edu">paper</a> on an algorithm for redistricting. </p>
<blockquote><p><b> </b> <em> We propose a method for redistricting, decomposing a geographical area into subareas, called districts, so that the populations of the districts are as close as possible and the districts are compact and contiguous. Each district is the intersection of a polygon with the geographical area. The polygons are convex and the average number of sides per polygon is less than six. </em>
</p></blockquote>
<p>The authors are Philip Klein and Neal Young, who are well known researchers on various aspects of algorithms. They do interesting work, their paper is interesting, but the assumption that geometry is the key I do not get.</p>
<p>
</p><p/><h2> How To Do Better? </h2><p/>
<p/><p>
I think that we need to go beyond geometry to understand and avoid gerrymandering. The connection between geometry and fairness is driven‚ÄîI believe‚Äîby tradition. Voters in the same district probably want to be near each other. In the past being near each other was probably important, since travel was so difficult. Perhaps today location is less of an issue then it was before cars, phones, cell phones, internet access, and email. Perhaps districts can be fair and yet do not look good. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
An analogy to <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting">cake cutting</a> may occur to you. Recall in the cake cutting problem success is <i>not</i> measured in how the pieces of the cake look. It is only measured by whether the parties cutting the cake are happy. Is there some way to push this analogy? I just came across a <a href="https://arxiv.org/pdf/1710.08781.pdf">paper</a> using the cake cutting method: <i>A Partisan Districting Protocol With Provably Nonpartisan Outcomes</i> by Wesley Pegden, Ariel Procaccia, and Dingli Yu. More in the future.</p>
<p>
Can algorithmic methods help? Is geometry the fundamental issue? </p>
<p/><p><br/>
[sourced photo, other word edits]</p></font></font></div>
    </content>
    <updated>2019-07-03T13:51:13Z</updated>
    <published>2019-07-03T13:51:13Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="cake-cutting"/>
    <category term="districts"/>
    <category term="fair"/>
    <category term="geometry"/>
    <category term="gerrymander"/>
    <category term="gerrymandering"/>
    <category term="reasonable"/>
    <category term="voters"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>G√∂del‚Äôs Lost Letter and P=NP</title>
      <updated>2019-07-05T16:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1136</id>
    <link href="https://ptreview.sublinear.info/?p=1136" rel="alternate" type="text/html"/>
    <title>News for June 2019</title>
    <summary>We‚Äôve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling. On the Complexity of Estimating the Effective Support Size, by Oded Goldreich (ECCC). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of Valiant-Valiant, [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We‚Äôve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling.</p>



<p><strong>On the Complexity of Estimating the Effective Support Size</strong>, by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2019/088/">ECCC</a>). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of <a href="http://theory.stanford.edu/~valiant/papers/VV_stoc11.pdf">Valiant-Valiant</a>, the complexity of this problem is \(\Theta(n/\log n)\). This paper raises the question of approximating the ‚Äúeffective‚Äù support, and that too with more than just samples from the distribution. The \(\epsilon\)-support of discrete distribution \(\mathcal{D}\) is the smallest support among any distribution \(\mathcal{D}‚Äô\) such that \(\|\mathcal{D} ‚Äì \mathcal{D}‚Äô\|_1 \leq \epsilon\) (or TV-distance). Denote this as \(supp_\epsilon(\mathcal{D})\). One can also consider a bicriteria version. Given approximation parameter \(f\) and thresholds \(\epsilon_1 &lt; \epsilon_2\), we need to provide a number in the range \([supp_{\epsilon_2}(\mathcal{D}), f\cdot supp_{\epsilon_1}(\mathcal{D})]\). The primary model studied allows for random samples and evaluation queries (where one gets the probability of any known element of the domain). In this model, for arbitrary \(\epsilon_1, \epsilon_2\), there is a continuum of algorithms, trading off query complexity with approximation. At one end, for \(f = O(\log n)\), the query complexity is \(\widetilde{O}(1/\epsilon_1)\). At the other end, for \(f=1\), the query complexity is \(O(\log^* n)\). (Here, \(n = supp_{\epsilon_1}(\mathcal{D})\).) There are lower bounds showing the necessity of evaluation queries for subpolynomial query complexities.</p>



<p><strong>Communication and Memory Efficient Testing of Discrete Distributions</strong>, by Ilias Diakonikolas,¬†Themis Gouleakis,¬†Daniel M. Kane,¬†and Sankeerth Rao (<a href="https://arxiv.org/abs/1906.04709">arXiv</a>). This paper adds additional computational constraints to the distribution testing problem. In the streaming setting, the algorithm is only allowed a single pass over the random samples. It has \(m\) bits of storage, much smaller than \(n\), the distribution size. The aim is to minimize the number of samples required for uniformity (and closeness) testing. For uniformity testing in the streaming setting, the paper gives an algorithm that uses \(\widetilde{O}(m + n/m)\) samples. The standard collision algorithm requires \(\Theta(\sqrt{n})\) storage (to store the samples), while this result gives a non-trivial bound for \(m \ll \sqrt{n}\). There are lower bounds showing that these bounds are basically tight. In the distributed distribution testing problem, there are a number of processors, each holding \(\ell\) samples. A referee asks a question to the processor, whose answers are broadcast to everyone. The aim is to minimize communication cost. For uniformity testing in this setting, there is a protocol using \(O(\sqrt{n\log n/\ell})\) bits of communication. As a sanity check, note that for \(\ell = \sqrt{n}\), one processor could simply run the collision algorithm locally to report the result. </p>



<p><strong>Querying a Matrix through Matrix-Vector Products</strong> by Xiaoming Sun,¬†David P. Woodruff,¬†Guang Yang,¬†and Jialin Zhang (<a href="https://arxiv.org/pdf/1906.05736.pdf">arXiv</a>). Consider \(n \times d\) matrix \(M\) over some field \(\mathbb{F}\). One gets access to this matrix through matrix-vector products, and wishes to test some matrix property. This is a natural model in many settings, and generalizes the classic setting of query access. A subtle point is that one can only right multiply with ‚Äúquery‚Äù vectors, and there are problems where left multiplication can change the complexity. (A nice example in the paper is testing if a square matrix is symmetric. With both left and right multiplications, this is easy, since we can directly access rows and columns. By only accessing columns, this is non-trivial.) This paper studies a number of problems, broadly classified as linear algebra problems, statistics problems, and graph problems. Some highlights are: testing symmetry can be done in \(O(1)\) queries, and the maximum eigenvalue can be approximated in \(O(\log n)\) queries adaptively (but there is an \(\Omega(n)\) non-adaptive lower bound). For graph problems, here‚Äôs an interesting discovery. If \(M\) is the adjacency matrix, connectivity requires \(\Omega(n/\log n)\) queries. But if \(M\) is the signed edge-vertex matrix, then this can be done in \(poly(\log n)\) queries. This paper provides a number of interesting directions and problems to study.</p>



<p><strong>The Adversarial Robustness of Sampling</strong> by Omri Ben-Eliezer and¬†Eylon Yogev (arXiv). This isn‚Äôt a property testing paper, but how can one ignore a paper on understanding the power of sampling? It‚Äôs convenient to think of the following setting. An algorithm gets a stream of \(n\) numbers, and has to answer some questions about the stream (say, the median or other quantiles). The simplest strategy is to take a small random sample of the stream. But what if an adversary was generating the stream, depending on the current sample? Under what circumstances is the sample still ‚Äúrepresentative‚Äù of the stream? The specific results of this paper require getting into set systems and VC dimension, which I‚Äôll leave for the sake of simplicity. Let‚Äôs go back to the median question. To get an approximate median, a constant number of samples suffice. A consequence of the main result is that if one takes \(O(\log n)\) samples, then this is robust to adversarial streams. On the other hand, lower bounds show that constant sized samples can be fooled by an adversary. The paper is a really interesting read, and is a nice take on ‚Äústandard facts‚Äù that we take for granted.</p>



<p/></div>
    </content>
    <updated>2019-07-03T00:54:36Z</updated>
    <published>2019-07-03T00:54:36Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-07-05T00:02:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8952301722851173857</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8952301722851173857/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html" rel="alternate" type="text/html"/>
    <title>Local Kid Makes History</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
</div>
<a href="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s1600/Huang.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s200/Huang.jpg" width="163"/></a>The <a href="https://www.scottaaronson.com/blog/?p=4229">blogosphere</a> is <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">blowing</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">up</a>¬†over Hao Huang's just <a href="https://arxiv.org/abs/1907.00847">posted proof</a> of the sensitivity conjecture, what was one of the more <a href="https://blog.computationalcomplexity.org/2017/12/razors-edge.html">frustrating open questions</a> in complexity.<br/>
<br/>
Huang, an assistant professor in the math department at Emory, settled an open question about the hypercube. The hypercube is a graph on N=2<sup>n</sup> vertices where each vertex corresponds to an n-bit string and their are edges between vertices corresponding to strings that differ in a single bit. Think of the set of the strings of odd parity, N/2 vertices with no edges between them. Add any other vertex and it would have n neighbors. Huang showed that no matter how you placed those N/2+1 vertices in the hypercube, some vertex will have at least n<sup>1/2</sup> neighbors. By an <a href="https://doi.org/10.1016/0097-3165(92)90060-8">old result</a> of Gotsman and Linial, Huang's theorem implies the sensitivity conjecture.<br/>
<br/>
I won't go through the shockingly simple proof, the <a href="https://arxiv.org/abs/1907.00847">paper</a> is well written, or you can read the blogs I linked to above or even just Ryan O'Donnell's <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>.<br/>
<br/>
I have nothing more to say than wow, just wow.</div>
    </content>
    <updated>2019-07-02T17:05:00Z</updated>
    <published>2019-07-02T17:05:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-05T09:13:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7530</id>
    <link href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/" rel="alternate" type="text/html"/>
    <title>Sensitivity conjecture proved!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-jetpack-markdown"><p>In a recent breakthrough, <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> gave a <a href="https://arxiv.org/abs/1907.00847">6 page paper</a> proving the longstanding sensitivity conjecture. (Hat tip, <a href="https://www.scottaaronson.com/blog/?p=4229">Scott Aaronson</a> and <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Gil Kalai</a>. See this <a href="https://cstheory.stackexchange.com/questions/27714/sensitivity-block-sensitivity-conjecture-implications">stackexchange post</a> and <a href="https://eccc.weizmann.ac.il/report/2016/062/">this paper of Avishai</a> for some links to the literature on this.)</p>
<p>The proof is beautiful and simple. I will write a few words here, but it is probably easier for you to just read the <a href="https://arxiv.org/abs/1907.00847">paper</a>. The sensitivity conjecture <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">was known</a> to follow from the following statement: let <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> be the <em>Boolean Cube</em> which is the degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph on <img alt="N=2^n" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^n"/> vertices identified with <img alt="\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}^n"/> such that for every <img alt="x,y\in \{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^n"/>, <img alt="x \sim y" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Csim+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \sim y"/> if their Hamming distance is one. Then, the maximum degree of every subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> of size <img alt="&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&gt;N/2"/> is at least <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt{n}"/>.</p>
<p>Hao proves the above statement by showing that there is a <em>signing</em> of the <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> that turns it into a matrix with <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/> and <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="-\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=-%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-\sqrt{n}"/>. That is, he shows (using a simple but clever inductive argument, see the 5 line proof of his Lemma 2.2) that there is an <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> with entries in <img alt="\{ 0, \pm 1 \}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B+0%2C+%5Cpm+1+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{ 0, \pm 1 \}"/> whose nonzero entries correspond to the edges of the Boolean cube, and such that all the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/> and they sum up to zero. (Note that this makes sense since <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> should have the same <em>Frobenius norm</em> as  the adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/>. The Frobenius norm squared is both the sum of squares of entries, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> for <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> which is a degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph, and also equal to the sum of squares of the eigenvalues, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> if all eigenvalues are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/>.)</p>
<p>Once you have such a signing, the result follows from <a href="https://en.wikipedia.org/wiki/Min-max_theorem#Cauchy_interlacing_theorem">Cauchy‚Äôs Interlace Theorem</a> that says that for every <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and any <img alt="M\times M" class="latex" src="https://s0.wp.com/latex.php?latex=M%5Ctimes+M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M\times M"/> matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> that is a principle sub-matrix of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>,</p>
<p><img alt="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_%7B1%2BN-M%7D%28A%29+%5Cleq+%5Clambda_1%28B%29+%5Cleq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)"/></p>
<p>where <img alt="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29+%5Cgeq+%5Clambda_2%28A%29+%5Ccdots+%5Cgeq+%5Clambda_N%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)"/> are the eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="\lambda_1(B)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B)"/> is the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>. A corollary of this (which is the only fact we need) is that if <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> has its top eigenvalue <img alt="\lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)"/> with multiplicity <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (i.e., <img alt="\lambda_1(A)=\lambda_K(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29%3D%5Clambda_K%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)=\lambda_K(A)"/>), then every principle sub-matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of order larger than <img alt="N-K" class="latex" src="https://s0.wp.com/latex.php?latex=N-K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N-K"/> will satisfy <img alt="\lambda_1(B) = \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%3D+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) = \lambda_1(A)"/>. (In fact, we only need <img alt="\lambda_1(B) \geq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_1(A)"/>.)</p>
<p>Indeed, suppose that <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a subgraph of the Boolean cube of size <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/>. Then the principle submatrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> corresponding to the vertices of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> satisfies <img alt="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_%7B1%2BN-M%7D%28A%29+%3D+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}"/> (since <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/> and the first <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/>).
But it‚Äôs easy to show that for every matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is upper bounded by the maximum <img alt="\ell_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_1"/> norm of its rows, which in our case is the maximum degree of the graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</p>
</div></div>
    </content>
    <updated>2019-07-02T16:18:34Z</updated>
    <published>2019-07-02T16:18:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-07-05T16:21:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3401</id>
    <link href="https://agtb.wordpress.com/2019/07/02/papafest-september-6-8-columbia/" rel="alternate" type="text/html"/>
    <title>PapaFest (September 6-8 @ Columbia)</title>
    <summary>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.¬† Registration is free.¬† Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,¬† Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala. More details¬†here. Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.¬† Registration is free.¬† Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,¬† Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala.</p>
<p>More details¬†<a href="http://papafest.cs.columbia.edu/">here.</a></p></div>
    </content>
    <updated>2019-07-02T12:47:57Z</updated>
    <published>2019-07-02T12:47:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-07-05T16:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/</id>
    <link href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/" rel="alternate" type="text/html"/>
    <title>The Autumn school on Machine Learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">October 3-11, 2019 Tbilisi, Georgia https://cte.ibsu.edu.ge/autumn/ Registration deadline: October 3, 2019 The school will be organized by the International Black Sea University with the support of Shota Rustaveli National Science Foundation of Georgia (SRNSFG). The intended audience of the autumn school includes BSc, MSc and PhD students, researchers as well as industry professionals from the ‚Ä¶ <a class="more-link" href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/">Continue reading <span class="screen-reader-text">The Autumn school on Machine¬†Learning</span></a></div>
    </summary>
    <updated>2019-07-02T09:09:23Z</updated>
    <published>2019-07-02T09:09:23Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-05T16:21:18Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6337479962158243575</id>
    <link href="http://processalgebra.blogspot.com/feeds/6337479962158243575/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6337479962158243575" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/07/phd-position-at-tu-wirn-formal-methods.html" rel="alternate" type="text/html"/>
    <title>PhD position at TU Wirn: Formal methods applied to the specification and monitoring of large-scale, spatially-distributed, stochastic systems</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_3b"><i>Interesting PhD position at TU Wien with <a class="profileLink" href="http://www.eziobartocci.com/" title="Ezio Bartocci">Ezio Bartocci</a> and <a href="https://lauranenzi.github.io/">Laura Nenzi</a>. Spread the news!¬†</i><br/><br/> The <a href="http://ti.tuwien.ac.at/">Institute of Computer Engineering</a> at the Technische Universit√§t Wien (TU Wien) is seeking a candidate for a  research assistant position (PhD student, 4 years). The position is  available from September (a starting date until Fall 2019 is intended)  and the successful candidate will be a PhD student of the <a href="https://logic-cs.at/phd/">LogiCS Doctoral Program</a> and she/he will be supervised by Prof. Ezio Bartocci &lt;<a href="https://l.facebook.com/l.php?u=http%3A%2F%2Fwww.eziobartocci.com%2F%3Ffbclid%3DIwAR0DbRlQ3WbZCS1HzoZXYIRYXBsRDz2tCxE2G_6APz6K76RRDmLVMIkgBOg&amp;h=AT3xOIDKhxhBw2_daqAKot9Y3qtCNlITUpSxTEttEVYsbYoofL5LKQ7MD72mx8Nf3f0zPGNE5AY-FvqTQsTVZMllhO6DR94ug3vsjG3H84L4h8RDLdPWJxht8otBFNix1De-G1NEeihv6M6l-3cp" rel="noopener nofollow" target="_blank">http://www.eziobartocci.com/</a>&gt; and co-supervised by Dr. Laura Nenzi &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flauranenzi.github.io%2F%3Ffbclid%3DIwAR0O-FIXoCWcyMBVUqn5K-Ejd0vxQQJFYQ7ni1qBAdy9Ez01d6CDolZcb6U&amp;h=AT1RfdebNNlmUThAy2WWm6AclixjQ6sGfMnjrc5C-e4EbEglPtsVHAvYqJHIPfOZfHtYPGxz__so98GKEhDQZkGKQWB2z2fBom5MdlaCvrImUyjEZ5wotHeR5-w6sF4BkAIL-PGzihR9ZVsmSasc" rel="noopener nofollow" target="_blank">https://lauranenzi.github.io/</a>&gt;<br/> The successful applicant will carry out his/her PhD in the research  area of formal methods applied to the specification and monitoring of  large-scale, spatially-distributed, stochastic systems.<br/> The position in funded by the √ñAW and the FWF &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fm.fwf.ac.at%2Fen%2Fresearch-funding%2Fpersonnel-costs%2F%3Ffbclid%3DIwAR10rZDtpakXdwSo_WXE4A9GuFDbfkJoVYoCTgpZuBDmCMPVOmC8ZAo7Cyg&amp;h=AT13vFq0Svw4kLAe0VMNoonNMZyo8o6gdfK_-O0_LFJNhJavAH7Zt2YCyKMEKHuymeDiRrW6PggMAbBH0FyhcksLJJ0py3YWXi5vgwUwD0r_i3SFPvATFXhyZukxJL770ABLvhkdvgFQyiFvm5I8" rel="noopener nofollow" target="_blank">https://m.fwf.ac.at/en/research-funding/personnel-costs/</a>&gt;  for the recently acquired YIRG grant: ‚ÄúHigh-dimensional statistical  learning: new methods to advance economic and sustainability policies‚Äù,  an interdisciplinary project to be led for the TU part by PhD Laura  Nenzi.<br/> TASK DESCRIPTION (leader Laura Nenzi):   <br/> Formal  methods provide precise formal specification languages that can be  easily interpreted by humans and verification algorithms that can check  in an automatic way the value of satisfaction of interesting properties.  One of the main problems of such techniques is the curse of  dimensionality. A possibility to treat the problem is to use approximate  methods such as statistical model checking. However, even these  methodologies can be unfeasible for very-large-scale stochastic systems.  A new research line consists of exploiting machine learning techniques  and Bayesian inference to identify relevant data and decrease the  computational cost, permitting the application of such powerful formal  analysis on very complex systems. An important aspect that will be  covered in the study is the spatial configuration of such systems, a key  feature in several real case studies that are considering in the  project. The methodology will be principally applied to tackle questions  related to sustainable urban mobility and thus responsible consumption.<br/> APPLICATION<br/> Please apply your application following  the instructions in the DK LogiCS admission portal. <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flogic-cs.at%2Fphd%2Fadmission%2F%3Ffbclid%3DIwAR3oZZ1EmwtB7RHLErRrlbfY-HBeprkDbr8y-WyttxBelPGVrFY46hZuy3o&amp;h=AT2erabItYmdcemt5VHuXftBV82JOmliZPV-SIiYfhedKPgLyH9PR_pf1dJ3EHa-SQgsBTWJqgjsgzUJPauzRI4h_2t1t8Ci_NW6DannlCzLkriOSguTjs3IfU4p0eBWTTEvJmljKFMYpbZ36tKn" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a> &lt;<a href="https://logic-cs.at/phd/admission/?fbclid=IwAR1rL9Zavpr2JH9oOonuC0OZ0wPUsoFxWi0usVFZPXQJzSJeSQr97rk490c" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a>&gt;,  by indicating in the application form: Prof. Ezio Bartocci and Dr.  Laura Nenzi as supervisors. While it is not necessary to have the Master  degree at the moment of the application, it is instead mandatory to  complete it before starting the PhD.<br/> CONTACT DETAILS<br/> For  further information and inquiries about this post please contact Laura  Nenzi, e-mail: laura.nenzi@gmail.com  .</div></div>
    </content>
    <updated>2019-07-02T08:47:00Z</updated>
    <published>2019-07-02T08:47:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-07-02T12:00:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/</id>
    <link href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/" rel="alternate" type="text/html"/>
    <title>PapaFest for Christos‚Äô 70th birthday</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 6-8, 2019 Columbia University http://papafest.cs.columbia.edu/ We are happy to invite you to Columbia University to celebrate Christos Papadimitriou‚Äôs contributions to science on the occasion of his 70th birthday, through a mix of talks, panels, and fun activities. One of world‚Äôs leading computer scientists, Christos is best known for his work in computational complexity, helping ‚Ä¶ <a class="more-link" href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/">Continue reading <span class="screen-reader-text">PapaFest for Christos‚Äô 70th¬†birthday</span></a></div>
    </summary>
    <updated>2019-07-02T08:32:49Z</updated>
    <published>2019-07-02T08:32:49Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-05T16:21:18Z</updated>
    </source>
  </entry>
</feed>
