<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-15T12:21:37Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16778</id>
    <link href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/" rel="alternate" type="text/html"/>
    <title>Itai Benjamini and Jeremie Brieussel: Noise Sensitivity Meets Group Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The final  version of my ICM 2018 paper Three puzzles on mathematics computation and games is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to … <a href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The final  version of my ICM 2018 paper <a href="https://gilkalai.files.wordpress.com/2019/07/main-pf.pdf">Three puzzles on mathematics computation and games</a> is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to advertise one problem that I mentioned in the paper. You can read more about it in the paper  by Itai Benjamini and  Jeremie Brieussel  <a href="https://arxiv.org/abs/1901.03617">Noise sensitivity of random walks on groups</a> and learn about it also from the videotaped lecture by Jeremie. BTW, the name of my ICM paper is a tribute to Avi Wigdeson’s great book <strong><a href="https://www.math.ias.edu/files/Website03-25-19.pdf#page=1" target="&#x201D;_blank&#x201D;">Mathematics and Computation</a> </strong>(see <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this post</a>). Click on the title for an  almost final draft of Avi’s book (March, 25, 2019) soon to be published by Princeton University Press<strong>. </strong>(We are negotiating with Avi on showing here first how the cover of his book will look like.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png"><img alt="" class="alignnone size-full wp-image-17590" height="381" src="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png?w=640&amp;h=381" width="640"/></a></p>
<p><a href="http://friendsofnoise.org/about/">source</a></p>
<h2>The problem of Benjamini and Brieussel and their conjecture</h2>
<p> </p>
<p/>
<p>Consider an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-step simple random walk (SRW) <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> on a Cayley graph of a finitely generated infinite group <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/>. Refresh independently each step with probability <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, to get <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> from <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Are there groups for which at time <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> the positions <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are asymptotically independent? That is, does the <img alt="l_1" class="latex" src="https://s0.wp.com/latex.php?latex=l_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l_1"/> (total variation) distance between the chain <img alt="(X_n, Y_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X_n%2C+Y_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X_n, Y_n)"/> and two independent copies <img alt="(X'_n, X''_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X%27_n%2C+X%27%27_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X'_n, X''_n)"/> go to 0, as <img alt="n \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \to \infty"/>?</p>
<p>Note that on the line <img alt="\mathbb Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z"/>, they are uniformally correlated, and therefore also on any group with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>, or on any group that has a finite index subgroup with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>. On the free group and for any non-Liouville group, <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are correlated as well, but for a different reason: both <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> have a nontrivial correlation with <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/>.</p>
<p>Itai Benjamini and Jeremie Brieussel conjecture that these are the only ways not to be noise sensitive. That is, if a Cayley graph is Liouville and the group does not have a finite index subgroup with a homomorphism to the reals, then the Cayley graph is noise sensitive for the simple random walk. In particular, the Grigorchuk group is noise sensitive for the simple random walk!</p>
<h3>A paragraph of philosophical nature from Benjamini and Brieussel’s paper.</h3>
<p>“Physically, an <em>ℓ</em><img alt="^1" class="latex" src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="^1"/>-noise sensitive process can somewhat not be observed, since the observation <img alt="Y^\rho_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y%5E%5Crho_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y^\rho_n"/> does not provide any significant information on the actual output <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Speculatively, this could account for the rarity of Liouville groups in natural science. Indeed besides virtually nilpotent ones, all known Liouville groups are genuinely mathematical objects .”</p>
<h3>Polytope integrality gap: An update</h3>
<p>An update on polytope integrality gap:  In my ICM paper and also in <a href="https://gilkalai.wordpress.com/2018/01/21/hardness-of-approximating-vertex-cover-polytope-integrality-gap-the-alswede-kachaterian-theorem-and-more/">this post</a>  I asked the beautiful problem that I learned from Anna Karlin if for vertex cover for every graph G and every vector of weights, there is an efficient algorithm achieving the “polytope integrality gap”.  Anna Karlin kindly informed me that <a href="https://www2.isye.gatech.edu/~msingh94/publications.html">Mohit Singh</a> got in touch with her after seeing the conjecture on my blog and pointed out that the hope for approximating the polytope integrality gap for vertex cover is unlikely to be possible because of its relationship to fractional chromatic number. Mohit noted that fractional chromatic number is hard to approximate even when it is constant assuming UGC. I still think that  the notion of polytope integrality gap for vertex cover as well as for more general problems is important and worth further study.</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-15T08:13:08Z</updated>
    <published>2019-07-15T08:13:08Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Itai Benjamini"/>
    <category term="Jeremie Brieussel"/>
    <category term="Noise-sensitivity"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-15T12:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4254868758435665114</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4254868758435665114/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4254868758435665114" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4254868758435665114" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html" rel="alternate" type="text/html"/>
    <title>Two infinite hat problem and a question about what is ``well known''</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
This is a joint post with David Marcus. You will see how he is involved in my next post.<br/>
<br/>
Two infinite hat problems based on one scenario. I am also curious if they are well known.<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions  and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (I have blogged about a variant of this one a while back.)<br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong. (My students would say <i>the answer has to be YES or he</i> <i>wouldn't ask it</i>. They don't realize that I work on upper AND lower bounds!)<br/>
<br/>
Q3: How well known is problem Q1 and the solution?  Q2 and the solution? I've seen Q1 and its solution around (not sure where), but the only source on Q2 that I know of is CAN'T TELL YOU IN THIS POST, WILL IN THE NEXT POST. So, please leave a comment telling me if you have seen Q1 or Q2 and solutions. And if so then where.<br/>
<br/>
Feel free to leave any comments you want; however, I warn readers who want to solve it themselves to not look at the comments, or at my next post.<br/></div>
    </content>
    <updated>2019-07-15T03:12:00Z</updated>
    <published>2019-07-15T03:12:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-15T11:44:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05870</id>
    <link href="http://arxiv.org/abs/1907.05870" rel="alternate" type="text/html"/>
    <title>On a Generalization of the Marriage Problem</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lenchner:Jonathan.html">Jonathan Lenchner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05870">PDF</a><br/><b>Abstract: </b>We present a generalization of the marriage problem underlying Hall's famous
Marriage Theorem to what we call the Symmetric Marriage Problem, a problem that
can be thought of as a special case of Maximal Weighted Bipartite Matching. We
show that there is a solution to the Symmetric Marriage Problem if and only if
a variation on Hall's Condition holds on each of the bipartitions. We prove
both finite and infinite versions of this result and provide applications.
</p></div>
    </summary>
    <updated>2019-07-15T01:38:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05816</id>
    <link href="http://arxiv.org/abs/1907.05816" rel="alternate" type="text/html"/>
    <title>Towards Optimal Moment Estimation in Streaming and Distributed Models</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05816">PDF</a><br/><b>Abstract: </b>One of the oldest problems in the data stream model is to approximate the
$p$-th moment $\|\mathcal{X}\|_p^p = \sum_{i=1}^n |\mathcal{X}_i|^p$ of an
underlying vector $\mathcal{X} \in \mathbb{R}^n$, which is presented as a
sequence of poly$(n)$ updates to its coordinates. Of particular interest is
when $p \in (0,2]$. Although a tight space bound of $\Theta(\epsilon^{-2} \log
n)$ bits is known for this problem when both positive and negative updates are
allowed, surprisingly there is still a gap in the space complexity when all
updates are positive. Specifically, the upper bound is $O(\epsilon^{-2} \log
n)$ bits, while the lower bound is only $\Omega(\epsilon^{-2} + \log n)$ bits.
Recently, an upper bound of $\tilde{O}(\epsilon^{-2} + \log n)$ bits was
obtained assuming that the updates arrive in a random order.
</p>
<p>We show that for $p \in (0, 1]$, the random order assumption is not needed.
Namely, we give an upper bound for worst-case streams of
$\tilde{O}(\epsilon^{-2} + \log n)$ bits for estimating $\|\mathcal{X}\|_p^p$.
Our techniques also give new upper bounds for estimating the empirical entropy
in a stream. On the other hand, we show that for $p \in (1,2]$, in the natural
coordinator and blackboard communication topologies, there is an
$\tilde{O}(\epsilon^{-2})$ bit max-communication upper bound based on a
randomized rounding scheme. Our protocols also give rise to protocols for heavy
hitters and approximate matrix product. We generalize our results to arbitrary
communication topologies $G$, obtaining an $\tilde{O}(\epsilon^{2} \log d)$
max-communication upper bound, where $d$ is the diameter of $G$. Interestingly,
our upper bound rules out natural communication complexity-based approaches for
proving an $\Omega(\epsilon^{-2} \log n)$ bit lower bound for $p \in (1,2]$ for
streaming algorithms. In particular, any such lower bound must come from a
topology with large diameter.
</p></div>
    </summary>
    <updated>2019-07-15T01:32:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05725</id>
    <link href="http://arxiv.org/abs/1907.05725" rel="alternate" type="text/html"/>
    <title>Space Efficient Approximation to Maximum Matching Size from Uniform Edge Samples</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Norouzi=Fard:Ashkan.html">Ashkan Norouzi-Fard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tardos:Jakab.html">Jakab Tardos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05725">PDF</a><br/><b>Abstract: </b>Given a source of iid samples of edges of an input graph $G$ with $n$
vertices and $m$ edges, how many samples does one need to compute a constant
factor approximation to the maximum matching size in $G$? Moreover, is it
possible to obtain such an estimate in a small amount of space? We show that,
on the one hand, this problem cannot be solved using a nontrivially sublinear
(in $m$) number of samples: $m^{1-o(1)}$ samples are needed. On the other hand,
a surprisingly space efficient algorithm for processing the samples exists:
$O(\log^2 n)$ bits of space suffice to compute an estimate.
</p>
<p>Our main technical tool is a new peeling type algorithm for matching that we
simulate using a recursive sampling process that crucially ensures that local
neighborhood information from `dense' regions of the graph is provided at
appropriately higher sampling rates. We show that a delicate balance between
exploration depth and sampling rate allows our simulation to not lose precision
over a logarithmic number of levels of recursion and achieve a constant factor
approximation. The previous best result on matching size estimation from random
samples was a $\log^{O(1)} n$ approximation [Kapralov et al'14].
</p>
<p>Our algorithm also yields a constant factor approximate local computation
algorithm (LCA) for matching with $O(d\log n)$ exploration starting from any
vertex. Previous approaches were based on local simulations of randomized
greedy, which take $O(d)$ time {\em in expectation over the starting vertex or
edge} (Yoshida et al'09, Onak et al'12), and could not achieve a better than
$d^2$ runtime. Interestingly, we also show that unlike our algorithm, the local
simulation of randomized greedy that is the basis of the most efficient prior
results does take $\wt{\Omega}(d^2)\gg O(d\log n)$ time for a worst case edge
even for $d=\exp(\Theta(\sqrt{\log n}))$.
</p></div>
    </summary>
    <updated>2019-07-15T01:34:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05568</id>
    <link href="http://arxiv.org/abs/1907.05568" rel="alternate" type="text/html"/>
    <title>A Quantum-inspired Classical Algorithm for Separable Non-negative Matrix Factorization</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zhihuai Chen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yinan.html">Yinan Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuan:Pei.html">Pei Yuan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05568">PDF</a><br/><b>Abstract: </b>Non-negative Matrix Factorization (NMF) asks to decompose a (entry-wise)
non-negative matrix into the product of two smaller-sized nonnegative matrices,
which has been shown intractable in general. In order to overcome this issue,
the separability assumption is introduced which assumes all data points are in
a conical hull. This assumption makes NMF tractable and is widely used in text
analysis and image processing, but still impractical for huge-scale datasets.
In this paper, inspired by recent development on dequantizing techniques, we
propose a new classical algorithm for separable NMF problem. Our new algorithm
runs in polynomial time in the rank and logarithmic in the size of input
matrices, which achieves an exponential speedup in the low-rank setting.
</p></div>
    </summary>
    <updated>2019-07-15T01:35:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05548</id>
    <link href="http://arxiv.org/abs/1907.05548" rel="alternate" type="text/html"/>
    <title>The Projection Games Conjecture and the Hardness of Approximation of SSAT and related problems</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Priyanka.html">Priyanka Mukhopadhyay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05548">PDF</a><br/><b>Abstract: </b>The Super-SAT or SSAT problem was introduced by Dinur, Kindler, Raz and
Safra[2002,2003] to prove the NP-hardness of approximation of two popular
lattice problems - Shortest Vector Problem (SVP) and Closest Vector Problem
(CVP). They conjectured that SSAT is NP-hard to approximate to within factor
$n^c$ for some constant $c&gt;0$, where $n$ is the size of the SSAT instance. In
this paper we prove this conjecture assuming the Projection Games Conjecture
(PGC), given by Moshkovitz[2012]. This implies hardness of approximation of SVP
and CVP within polynomial factors, assuming the Projection Games Conjecture.
</p>
<p>We also reduce SSAT to the Nearest Codeword Problem (NCP) and Learning
Halfspace Problem (LHP), as considered by Arora, Babai, Stern and
Sweedyk[1997]. This proves that both these problems are NP-hard to approximate
within factor $N^{c'/\log\log n}$ for some constant $c'&gt;0$ where $N$ is the
size of the instances of the respective problems. Assuming the Projection Games
Conjecture these problems are proved to be NP-hard to approximate within
polynomial factors.
</p></div>
    </summary>
    <updated>2019-07-15T01:20:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05515</id>
    <link href="http://arxiv.org/abs/1907.05515" rel="alternate" type="text/html"/>
    <title>Spherical Discrepancy Minimization and Algorithmic Lower Bounds for Covering the Sphere</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jones:Chris.html">Chris Jones</a>, Matt McPartlon <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05515">PDF</a><br/><b>Abstract: </b>Inspired by the boolean discrepancy problem, we study the following
optimization problem which we term \textsc{Spherical Discrepancy}: given $m$
unit vectors $v_1, \dots, v_m$, find another unit vector $x$ that minimizes
$\max_i \langle x, v_i\rangle$. We show that \textsc{Spherical Discrepancy} is
APX-hard and develop a multiplicative weights-based algorithm that achieves
nearly optimal worst-case error bounds. We use our algorithm to give the first
non-trivial lower bounds for the problem of covering a hypersphere by
hyperspherical caps of uniform volume at least $2^{-o(\sqrt{n})}$, and to give
a lower bound for covering a Gaussian random variable by equal-sized
halfspaces. Up to a log factor, our lower bounds match known upper bounds in
this regime. Finally, we show how to modify our algorithm to solve a natural
version of the Koml{\'o}s problem for the spherical setting.
</p></div>
    </summary>
    <updated>2019-07-15T01:20:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05473</id>
    <link href="http://arxiv.org/abs/1907.05473" rel="alternate" type="text/html"/>
    <title>Geometry of Scheduling on Multiple Machines</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bansal:Nikhil.html">Nikhil Bansal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Batra:Jatin.html">Jatin Batra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05473">PDF</a><br/><b>Abstract: </b>We consider the following general scheduling problem: there are $m$ identical
machines and $n$ jobs all released at time $0$. Each job $j$ has a processing
time $p_j$, and an arbitrary non-decreasing function $f_j$ that specifies the
cost incurred for $j$, for each possible completion time. The goal is to find a
preemptive migratory schedule of minimum cost. This models several natural
objectives such as weighted norm of completion time, weighted tardiness and
much more.
</p>
<p>We give the first $O(1)$ approximation algorithm for this problem, improving
upon the $O(\log \log nP)$ bound due to Moseley (2019). To do this, we first
view the job-cover inequalities of Moseley geometrically, to reduce the problem
to that of covering demands on a line by rectangular and triangular capacity
profiles. Due to the non-uniform capacities of triangles, directly using
quasi-uniform sampling loses a $O(\log \log P)$ factor, so a second idea is to
adapt it to our setting to only lose an $O(1)$ factor. Our ideas for covering
points with non-uniform capacity profiles (which have not been studied before)
may be of independent interest.
</p></div>
    </summary>
    <updated>2019-07-15T01:37:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05457</id>
    <link href="http://arxiv.org/abs/1907.05457" rel="alternate" type="text/html"/>
    <title>Schatten Norms in Matrix Streams: Hello Sparsity, Goodbye Dimension</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnan:Aditya.html">Aditya Krishnan</a>, Roi Sinoff <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05457">PDF</a><br/><b>Abstract: </b>The spectrum of a matrix contains important structural information about the
underlying data, and hence there is considerable interest in computing various
functions of the matrix spectrum. A fundamental example for such functions is
the $l_p$-norm of the spectrum, called the Schatten $p$-norm of the matrix.
Large matrices representing real-world data are often \emph{sparse} (most
entries are zeros) or \emph{doubly sparse}, i.e., sparse in both rows and
columns. These large matrices are usually accessed as a \emph{stream} of
updates, typically organized in \emph{row-order}. In this setting, where space
(memory) is the limiting resource, computing spectral functions is an expensive
task and known algorithms require space that is polynomial in the dimension of
the matrix, even for sparse matrices. Thus, it is highly desirable to design
algorithms requiring significantly smaller space.
</p>
<p>We answer this challenge by providing the first algorithm that uses space
\emph{independent of the matrix dimension} to compute the Schatten $p$-norm of
a doubly-sparse matrix presented in row order. Instead, our algorithm uses
space polynomial in the sparsity parameter $k$ and makes $O(p)$ passes over the
data stream. We further prove that multiple passes are unavoidable in this
setting and show several extensions of our primary technique, including
stronger upper bounds for special matrix families, algorithms for the more
difficult turnstile model, and a trade-off between space requirements and
number of passes.
</p></div>
    </summary>
    <updated>2019-07-15T01:23:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05445</id>
    <link href="http://arxiv.org/abs/1907.05445" rel="alternate" type="text/html"/>
    <title>Eccentricity function in distance-hereditary graphs</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dragan:Feodor_F=.html">Feodor F. Dragan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guarnera:Heather_M=.html">Heather M. Guarnera</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05445">PDF</a><br/><b>Abstract: </b>A graph $G = (V,E)$ is distance hereditary if every induced path of $G$ is a
shortest path. In this paper, we show that the eccentricity function $e(v) =
\max\{d(v, u) : u \in V \}$ in any distance-hereditary graph $G$ is almost
unimodal, that is, every vertex $v$ with $e(v) &gt; rad(G) + 1$ has a neighbor
with smaller eccentricity. Here, $rad(G) = \min\{e(v) : v \in V \}$ is the
radius of graph $G$. Moreover, we use this result to characterize the centers
of distance-hereditary graphs and provide a linear time algorithm to find a
large subset of central vertices, and in some cases, all central vertices. We
introduce two new algorithmic techniques to approximate all eccentricities in
distance-hereditary graphs, including a linear time additive 1-approximation.
</p></div>
    </summary>
    <updated>2019-07-15T01:36:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05087</id>
    <link href="http://arxiv.org/abs/1907.05087" rel="alternate" type="text/html"/>
    <title>Optimal Space-Depth Trade-Off of CNOT Circuits in Quantum Logic Synthesis</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Jiaqing.html">Jiaqing Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Teng:Shang=Hua.html">Shang-Hua Teng</a>, Bujiao Wu, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Kewen.html">Kewen Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05087">PDF</a><br/><b>Abstract: </b>Due to the decoherence of the state-of-the-art physical implementations of
quantum computers, it is essential to parallelize the quantum circuits to
reduce their depth. Two decades ago, Moore et al. demonstrated that additional
qubits (or ancillae) could be used to design "shallow" parallel circuits for
quantum operators. They proved that any $n$-qubit CNOT circuit could be
parallelized to $O(\log n)$ depth, with $O(n^2)$ ancillae. However, the
near-term quantum technologies can only support limited amount of qubits,
making space-depth trade-off a fundamental research subject for quantum-circuit
synthesis.
</p>
<p>In this work, we establish an asymptotically optimal space-depth trade-off
for the design of CNOT circuits. We prove that for any $m\geq0$, any $n$-qubit
CNOT circuit can be parallelized to $O\left(\max \left\{\log n,
\frac{n^{2}}{(n+m)\log (n+m)}\right\} \right)$ depth, with $O(m)$ ancillae. We
show that this bound is tight by a counting argument, and further show that
even with arbitrary two-qubit quantum gates to approximate CNOT circuits, the
depth lower bound still meets our construction, illustrating the robustness of
our result. Our work improves upon two previous results, one by Moore et al.
for $O(\log n)$-depth quantum synthesis, and one by Patel et al. for $m = 0$:
for the former, we reduce the need of ancillae by a factor of $\log^2 n$ by
showing that $m=O(n^2/\log^2 n)$ additional qubits suffice to build $O(\log
n)$-depth, $O(n^2/\log n)$ size --- which is asymptotically optimal --- CNOT
circuits; for the later, we reduce the depth by a factor of $n$ to the
asymptotically optimal bound $O(n/\log n)$. Our results can be directly
extended to stabilizer circuits using an earlier result by Aaronson et al. In
addition, we provide relevant hardness evidences for synthesis optimization of
CNOT circuits in term of both size and depth.
</p></div>
    </summary>
    <updated>2019-07-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05083</id>
    <link href="http://arxiv.org/abs/1907.05083" rel="alternate" type="text/html"/>
    <title>Cake Cutting on Graphs: A Discrete and Bounded Proportional Protocol</title>
    <feedworld_mtime>1563148800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bei:Xiaohui.html">Xiaohui Bei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Hao.html">Hao Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhijie.html">Zhijie Zhang</a>, Wei Zi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05083">PDF</a><br/><b>Abstract: </b>The classical cake cutting problem studies how to find fair allocations of a
heterogeneous and divisible resource among multiple agents. Two of the most
commonly studied fairness concepts in cake cutting are proportionality and
envy-freeness. It is well known that a proportional allocation among $n$ agents
can be found efficiently via simple protocols [16]. For envy-freeness, in a
recent breakthrough, Aziz and Mackenzie [5] proposed a discrete and bounded
envy-free protocol for any number of players. However, the protocol suffers
from high multiple-exponential query complexity and it remains open to find
simpler and more efficient envy-free protocols.
</p>
<p>In this paper we consider a variation of the cake cutting problem by assuming
an underlying graph over the agents whose edges describe their acquaintance
relationships, and agents evaluate their shares relatively to those of their
neighbors. An allocation is called locally proportional if each agent thinks
she receives at least the average value over her neighbors. Local
proportionality generalizes proportionality and is in an interesting middle
ground between proportionality and envy-freeness: its existence is guaranteed
by that of an envy-free allocation, but no simple protocol is known to produce
such a locally proportional allocation for general graphs. Previous works
showed locally proportional protocols for special classes of graphs, and it is
listed in both [1] and [8] as an open question to design simple locally
proportional protocols for more general classes of graphs. In this paper we
completely resolved this open question by presenting a discrete and bounded
locally proportional protocol for any given graphs. Our protocol has a query
complexity of only single exponential, which is significantly smaller than the
six towers of $n$ query complexity of the envy-free protocol given in [5].
</p></div>
    </summary>
    <updated>2019-07-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05401</id>
    <link href="http://arxiv.org/abs/1907.05401" rel="alternate" type="text/html"/>
    <title>Computational Concentration of Measure: Optimal Bounds, Reductions, and More</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Etesami:Omid.html">Omid Etesami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahloujifar:Saeed.html">Saeed Mahloujifar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahmoody:Mohammad.html">Mohammad Mahmoody</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05401">PDF</a><br/><b>Abstract: </b>Product measures of dimension $n$ are known to be concentrated in Hamming
distance: for any set $S$ in the product space of probability $\epsilon$, a
random point in the space, with probability $1-\delta$, has a neighbor in $S$
that is different from the original point in only
$O(\sqrt{n\ln(1/(\epsilon\delta))})$ coordinates. We obtain the tight
computational version of this result, showing how given a random point and
access to an $S$-membership oracle, we can find such a close point in
polynomial time. This resolves an open question of [Mahloujifar and Mahmoody,
ALT 2019]. As corollaries, we obtain polynomial-time poisoning and (in certain
settings) evasion attacks against learning algorithms when the original
vulnerabilities have any cryptographically non-negligible probability.
</p>
<p>We call our algorithm MUCIO ("MUltiplicative Conditional Influence
Optimizer") since proceeding through the coordinates, it decides to change each
coordinate of the given point based on a multiplicative version of the
influence of that coordinate, where influence is computed conditioned on
previously updated coordinates.
</p>
<p>We also define a new notion of algorithmic reduction between computational
concentration of measure in different metric probability spaces. As an
application, we get computational concentration of measure for high-dimensional
Gaussian distributions under the $\ell_1$ metric.
</p>
<p>We prove several extensions to the results above: (1) Our computational
concentration result is also true when the Hamming distance is weighted. (2) We
obtain an algorithmic version of concentration around mean, more specifically,
McDiarmid's inequality. (3) Our result generalizes to discrete random
processes, and this leads to new tampering algorithms for collective coin
tossing protocols. (4) We prove exponential lower bounds on the average running
time of non-adaptive query algorithms.
</p></div>
    </summary>
    <updated>2019-07-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05391</id>
    <link href="http://arxiv.org/abs/1907.05391" rel="alternate" type="text/html"/>
    <title>Walking Randomly, Massively, and Efficiently</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jakub Łącki, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onak:Krzysztof.html">Krzysztof Onak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankowski:Piotr.html">Piotr Sankowski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05391">PDF</a><br/><b>Abstract: </b>We introduce an approach that enables for efficiently generating many
independent random walks in big graph models, such as the Massive Parallel
Computation (MPC) model. We consider the case where the space per machine is
strongly sublinear in the number of vertices. In this case, many natural
approaches for graph problems struggle to overcome the $\Theta(\log n)$ MPC
round complexity barrier. We design a PageRank algorithm that break this
barrier even for directed graphs, and also show how to break this barrier for
bipartiteness and expansion testing.
</p>
<p>In the undirected case we start our random walks from the stationary
distribution, so we approximately know the empirical distribution of their next
steps. This way we can use doubling approach to prepare continuations of
sampled walks in advance. Our approach enables generating multiple random walks
of length $l$ in $\Theta(\log l)$ rounds on MPC. Moreover, we show that under
\textsc{2-Cycle} conjecture this round complexity is asymptotically tight. One
of the most important application of random walks is PageRank computation. We
show how to use our approach to compute approximate PageRank w.h.p. for
constant damping factor in $O(\log \log n)$ rounds on undirected graphs (with
$\tilde{O}(m)$ total space), and $\tilde{O}(\log \log n)$ rounds on directed
graphs (with $\tilde{O}(m+n^{1+o(1)})$ total space).
</p>
<p>Building on our random-walk primitive and traditional property testing
algorithms, we also show how to approximately test bipartiteness and expansion
in $O(\log\log(n))$ MPC rounds.
</p></div>
    </summary>
    <updated>2019-07-14T23:44:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05378</id>
    <link href="http://arxiv.org/abs/1907.05378" rel="alternate" type="text/html"/>
    <title>Quantum and Classical Algorithms for Approximate Submodular Function Minimization</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamoudi:Yassine.html">Yassine Hamoudi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rebentrost:Patrick.html">Patrick Rebentrost</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosmanis:Ansis.html">Ansis Rosmanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santha:Miklos.html">Miklos Santha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05378">PDF</a><br/><b>Abstract: </b>Submodular functions are set functions mapping every subset of some ground
set of size $n$ into the real numbers and satisfying the diminishing returns
property. Submodular minimization is an important field in discrete
optimization theory due to its relevance for various branches of mathematics,
computer science and economics. The currently fastest strongly polynomial
algorithm for exact minimization [LSW15] runs in time $\widetilde{O}(n^3 \cdot
\mathrm{EO} + n^4)$ where $\mathrm{EO}$ denotes the cost to evaluate the
function on any set. For functions with range $[-1,1]$, the best
$\epsilon$-additive approximation algorithm [CLSW17] runs in time
$\widetilde{O}(n^{5/3}/\epsilon^{2} \cdot \mathrm{EO})$. In this paper we
present a classical and a quantum algorithm for approximate submodular
minimization. Our classical result improves on the algorithm of [CLSW17] and
runs in time $\widetilde{O}(n^{3/2}/\epsilon^2 \cdot \mathrm{EO})$. Our quantum
algorithm is, up to our knowledge, the first attempt to use quantum computing
for submodular optimization. The algorithm runs in time
$\widetilde{O}(n^{5/4}/\epsilon^{5/2} \cdot \log(1/\epsilon) \cdot
\mathrm{EO})$. The main ingredient of the quantum result is a new method for
sampling with high probability $T$ independent elements from any discrete
probability distribution of support size $n$ in time $O(\sqrt{Tn})$. Previous
quantum algorithms for this problem were of complexity $O(T\sqrt{n})$.
</p></div>
    </summary>
    <updated>2019-07-14T23:45:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05350</id>
    <link href="http://arxiv.org/abs/1907.05350" rel="alternate" type="text/html"/>
    <title>Competitive Analysis with a Sample and the Secretary Problem</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naori:David.html">David Naori</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Danny.html">Danny Raz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05350">PDF</a><br/><b>Abstract: </b>We extend the standard online worst-case model to accommodate past experience
which is available to the online player in many practical scenarios. We do this
by revealing a random sample of the adversarial input to the online player
ahead of time. The online player competes with the expected optimal value on
the part of the input that arrives online. Our model bridges between existing
online stochastic models (e.g., items are drawn i.i.d. from a distribution) and
the online worst-case model. We also extend in a similar manner (by revealing a
sample) the online random-order model.
</p>
<p>We study the classical secretary problem in our new models. In the worst-case
model we present a simple online algorithm with optimal competitive-ratio for
any sample size. In the random-order model, we also give a simple online
algorithm with an almost tight competitive-ratio for small sample sizes.
Interestingly, we prove that for a large enough sample, no algorithm can be
simultaneously optimal both in the worst-cast and random-order models.
</p></div>
    </summary>
    <updated>2019-07-14T23:30:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05309</id>
    <link href="http://arxiv.org/abs/1907.05309" rel="alternate" type="text/html"/>
    <title>State-of-The-Art Sparse Direct Solvers</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bollh=ouml=fer:Matthias.html">Matthias Bollhöfer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schenk:Olaf.html">Olaf Schenk</a>, Radim Janalík, Steve Hamm, Kiran Gullapalli <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05309">PDF</a><br/><b>Abstract: </b>In this chapter we will give an insight into modern sparse elimination
methods. These are driven by a preprocessing phase based on combinatorial
algorithms which improve diagonal dominance, reduce fill-in, and improve
concurrency to allow for parallel treatment. Moreover, these methods detect
dense submatrices which can be handled by dense matrix kernels based on
multithreaded level-3 BLAS. We will demonstrate for problems arising from
circuit simulation, how the improvements in recent years have advanced direct
solution methods significantly.
</p></div>
    </summary>
    <updated>2019-07-14T23:33:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05296</id>
    <link href="http://arxiv.org/abs/1907.05296" rel="alternate" type="text/html"/>
    <title>Simplification of Polyline Bundles</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spoerhase:Joachim.html">Joachim Spoerhase</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Storandt:Sabine.html">Sabine Storandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zink:Johannes.html">Johannes Zink</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05296">PDF</a><br/><b>Abstract: </b>We propose and study generalizations to the well-known problem of polyline
simplification. Instead of a single polyline, we are given a set of polylines
possibly sharing some line segments and bend points. The simplification of
those shared parts has to be consistent among the polylines. We consider two
optimization goals: either minimizing the number of line segments or minimizing
the number of bend points in the simplification. By reduction from
Minimum-Independent-Dominating-Set, we show that both of these optimization
problems are NP-hard to approximate within a factor $n^{1/3 - \varepsilon}$ for
any $\varepsilon &gt; 0$ where $n$ is the number of bend points in the polyline
bundle. Moreover, we outline that both problems remain NP-hard even if the
input is planar. On the positive side, we give a polynomial-size integer linear
program and show fixed-parameter tractability in the number of shared bend
points.
</p></div>
    </summary>
    <updated>2019-07-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05257</id>
    <link href="http://arxiv.org/abs/1907.05257" rel="alternate" type="text/html"/>
    <title>Stick Graphs with Length Constraints</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kindermann:Philipp.html">Philipp Kindermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Andre.html">Andre Löffler</a>, Florian Thiele, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a>, Alexander Zaft, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zink:Johannes.html">Johannes Zink</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05257">PDF</a><br/><b>Abstract: </b>Stick graphs are intersection graphs of horizontal and vertical line segments
that all touch a line of slope -1 and lie above this line. De Luca et al.
[GD'18] considered the recognition problem of stick graphs for the case that
the ordering of either one of the two sets (STICK_A) is given and for the case
that the ordering of both sets is given (STICK_AB). They showed how to solve
both cases efficiently. In this paper, we improve the running times of their
algorithms and consider new variants of STICK, where no ordering is given,
STICK_A, and STICK_AB where the lengths of the sticks are given as input. We
show that all new problem variants are NP-complete and give an efficient
solution for STICK_AB with fixed stick lengths if there are no isolated
vertices.
</p></div>
    </summary>
    <updated>2019-07-14T23:48:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05135</id>
    <link href="http://arxiv.org/abs/1907.05135" rel="alternate" type="text/html"/>
    <title>Perturbed Greedy on Oblivious Matching Problems</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Zhihao_Gavin.html">Zhihao Gavin Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaowei.html">Xiaowei Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yuhao.html">Yuhao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05135">PDF</a><br/><b>Abstract: </b>We study the maximum matching problem in the oblivious setting, i.e. the edge
set of the graph is unknown to the algorithm. The existence of an edge is
revealed upon the probe of this pair of vertices. Further, if an edge exists
between two probed vertices, then the edge must be included in the matching
irrevocably. For unweighted graphs, the \textsf{Ranking} algorithm by Karp et
al.~(STOC 1990) achieves approximation ratios $0.696$ for bipartite graphs and
$0.526$ for general graphs. For vertex-weighted graphs, Chan et al. (TALG 2018)
proposed a $0.501$-approximate algorithm. In contrast, the edge-weighted
version only admits the trivial $0.5$-approximation by Greedy.
</p>
<p>In this paper, we propose the \textsf{Perturbed Greedy} algorithm for the
edge-weighted oblivious matching problem and prove that it achieves a $0.501$
approximation ratio. Besides, we show that the approximation ratio of our
algorithm on unweighted graphs is $0.639$ for bipartite graphs, and $0.531$ for
general graphs. The later improves the state-of-the-art result by Chan et al.
(TALG 2018). Furthermore, our algorithm can be regarded as a robust version of
the \textsf{Modified Randomized Greedy} (MRG) algorithm. By implication, our
$0.531$ approximation ratio serves as the first analysis of the MRG algorithm
beyond the $(1/2+\epsilon)$ regime.
</p></div>
    </summary>
    <updated>2019-07-14T23:27:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05121</id>
    <link href="http://arxiv.org/abs/1907.05121" rel="alternate" type="text/html"/>
    <title>Approximate Model Counting, Sparse XOR Constraints and Minimum Distance</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boreale:Michele.html">Michele Boreale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorla:Daniele.html">Daniele Gorla</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05121">PDF</a><br/><b>Abstract: </b>The problem of counting the number of models of a given Boolean formula has
numerous applications, including computing the leakage of deterministic
programs in Quantitative Information Flow. Model counting is a hard,
#P-complete problem. For this reason, many approximate counters have been
developed in the last decade, offering formal guarantees of confidence and
accuracy. A popular approach is based on the idea of using random XOR
constraints to, roughly, successively halving the solution set until no model
is left: this is checked by invocations to a SAT solver. The effectiveness of
this procedure hinges on the ability of the SAT solver to deal with XOR
constraints, which in turn crucially depends on the length of such constraints.
We study to what extent one can employ sparse, hence short, constraints,
keeping guarantees of correctness. We show that the resulting bounds are
closely related to the geometry of the set of models, in particular to the
minimum Hamming distance between models. We evaluate our theoretical results on
a few concrete formulae. Based on our findings, we finally discuss possible
directions for improvements of the current state of the art in approximate
model counting.
</p></div>
    </summary>
    <updated>2019-07-14T23:26:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05094</id>
    <link href="http://arxiv.org/abs/1907.05094" rel="alternate" type="text/html"/>
    <title>Analysis of Ward's Method</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gro=szlig=wendt:Anna.html">Anna Großwendt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/R=ouml=glin:Heiko.html">Heiko Röglin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Melanie.html">Melanie Schmidt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05094">PDF</a><br/><b>Abstract: </b>We study Ward's method for the hierarchical $k$-means problem. This popular
greedy heuristic is based on the \emph{complete linkage} paradigm: Starting
with all data points as singleton clusters, it successively merges two clusters
to form a clustering with one cluster less. The pair of clusters is chosen to
(locally) minimize the $k$-means cost of the clustering in the next step.
</p>
<p>Complete linkage algorithms are very popular for hierarchical clustering
problems, yet their theoretical properties have been studied relatively little.
For the Euclidean $k$-center problem, Ackermann et al. show that the
$k$-clustering in the hierarchy computed by complete linkage has a worst-case
approximation ratio of $\Theta(\log k)$. If the data lies in $\mathbb{R}^d$ for
constant dimension $d$, the guarantee improves to $\mathcal{O}(1)$, but the
$\mathcal{O}$-notation hides a linear dependence on $d$. Complete linkage for
$k$-median or $k$-means has not been analyzed so far.
</p>
<p>In this paper, we show that Ward's method computes a $2$-approximation with
respect to the $k$-means objective function if the optimal $k$-clustering is
well separated. If additionally the optimal clustering also satisfies a balance
condition, then Ward's method fully recovers the optimum solution. These
results hold in arbitrary dimension. We accompany our positive results with a
lower bound of $\Omega((3/2)^d)$ for data sets in $\mathbb{R}^d$ that holds if
no separation is guaranteed, and with lower bounds when the guaranteed
separation is not sufficiently strong. Finally, we show that Ward produces an
$\mathcal{O}(1)$-approximative clustering for one-dimensional data sets.
</p></div>
    </summary>
    <updated>2019-07-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05000</id>
    <link href="http://arxiv.org/abs/1907.05000" rel="alternate" type="text/html"/>
    <title>ADDMC: Exact Weighted Model Counting with Algebraic Decision Diagrams</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudek:Jeffrey_M=.html">Jeffrey M. Dudek</a>, Vu H. N. Phan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05000">PDF</a><br/><b>Abstract: </b>We compute exact literal-weighted model counts of CNF formulas. Our algorithm
employs dynamic programming, with Algebraic Decision Diagrams as the primary
data structure. This technique is implemented in ADDMC, a new model counter. We
empirically evaluate various heuristics that can be used with ADDMC. We also
compare ADDMC to state-of-the-art exact model counters (Cachet, c2d, d4,
miniC2D, and sharpSAT) on the two largest CNF model counting benchmark families
(BayesNet and Planning). ADDMC solves the most benchmarks in total within the
given timeout.
</p></div>
    </summary>
    <updated>2019-07-14T23:34:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04904</id>
    <link href="http://arxiv.org/abs/1907.04904" rel="alternate" type="text/html"/>
    <title>A Resource-Aware Approach to Collaborative Loop Closure Detection with Provable Performance Guarantees</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Yulun.html">Yulun Tian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khosoussi:Kasra.html">Kasra Khosoussi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/How:Jonathan_P=.html">Jonathan P. How</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04904">PDF</a><br/><b>Abstract: </b>This paper presents resource-aware algorithms for distributed inter-robot
loop closure detection for applications such as collaborative simultaneous
localization and mapping (CSLAM) and distributed image retrieval. In real-world
scenarios, this process is resource-intensive as it involves exchanging many
observations and geometrically verifying a large number of potential matches.
This poses severe challenges for small-size and low-cost robots with various
operational and resource constraints that limit, e.g., energy consumption,
communication bandwidth, and computation capacity. This paper proposes a
framework in which robots first exchange compact queries to identify a set of
potential loop closures. We then seek to select a subset of potential
inter-robot loop closures for geometric verification that maximizes a monotone
submodular performance metric without exceeding budgets on computation (number
of geometric verifications) and communication (amount of exchanged data for
geometric verification). We demonstrate that this problem is in general
NP-hard, and present efficient approximation algorithms with provable
performance guarantees. The proposed framework is extensively evaluated on real
and synthetic datasets. A natural convex relaxation scheme is also presented to
certify the near-optimal performance of the proposed framework in practice.
</p></div>
    </summary>
    <updated>2019-07-14T23:28:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04889</id>
    <link href="http://arxiv.org/abs/1907.04889" rel="alternate" type="text/html"/>
    <title>Computing Minimal Persistent Cycles: Polynomial and Hard Cases</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Tamal_K=.html">Tamal K. Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hou:Tao.html">Tao Hou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mandal:Sayan.html">Sayan Mandal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04889">PDF</a><br/><b>Abstract: </b>Persistent cycles, especially the minimal ones, are useful geometric features
functioning as augmentations for the intervals in the purely topological
persistence diagrams (also termed as barcodes). In our earlier work, we showed
that computing minimal 1-dimensional persistent cycles (persistent 1-cycles)
for finite intervals is NP-hard while the same for infinite intervals is
polynomially tractable. In this paper, we address this problem for general
dimensions with $Z_2$ coefficients. In addition to proving that it is NP-hard
to compute minimal persistent d-cycles (d&gt;1) for both types of intervals given
arbitrary simplicial complexes, we identify two interesting cases which are
polynomially tractable. These two cases assume the complex to be a certain
generalization of manifolds which we term as weak pseudomanifolds. For finite
intervals from the d-th persistence diagram of a weak (d+1)-pseudomanifold, we
utilize the fact that persistent cycles of such intervals are null-homologous
and reduce the problem to a minimal cut problem. Since the same problem for
infinite intervals is NP-hard, we further assume the weak (d+1)-pseudomanifold
to be embedded in $\mathbb{R}^{d+1}$ so that the complex has a natural dual
graph structure and the problem reduces to a minimal cut problem. Experiments
with both algorithms on scientific data indicate that the minimal persistent
cycles capture various significant features of the data.
</p></div>
    </summary>
    <updated>2019-07-14T23:46:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04565</id>
    <link href="http://arxiv.org/abs/1907.04565" rel="alternate" type="text/html"/>
    <title>Progressive Wasserstein Barycenters of Persistence Diagrams</title>
    <feedworld_mtime>1563062400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jules Vidal, Joseph Budin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tierny:Julien.html">Julien Tierny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04565">PDF</a><br/><b>Abstract: </b>This paper presents an efficient algorithm for the progressive approximation
of Wasserstein barycenters of persistence diagrams, with applications to the
visual analysis of ensemble data. Given a set of scalar fields, our approach
enables the computation of a persistence diagram which is representative of the
set, and which visually conveys the number, data ranges and saliences of the
main features of interest found in the set. Such representative diagrams are
obtained by computing explicitly the discrete Wasserstein barycenter of the set
of persistence diagrams, a notoriously computationally intensive task. In
particular, we revisit efficient algorithms for Wasserstein distance
approximation [12,51] to extend previous work on barycenter estimation [94]. We
present a new fast algorithm, which progressively approximates the barycenter
by iteratively increasing the computation accuracy as well as the number of
persistent features in the output diagram. Such a progressivity drastically
improves convergence in practice and allows to design an interruptible
algorithm, capable of respecting computation time constraints. This enables the
approximation of Wasserstein barycenters within interactive times. We present
an application to ensemble clustering where we revisit the k-means algorithm to
exploit our barycenters and compute, within execution time constraints,
meaningful clusters of ensemble data along with their barycenter diagram.
Extensive experiments on synthetic and real-life data sets report that our
algorithm converges to barycenters that are qualitatively meaningful with
regard to the applications, and quantitatively comparable to previous
techniques, while offering an order of magnitude speedup when run until
convergence (without time constraint). Our algorithm can be trivially
parallelized to provide additional speedups in practice on standard
workstations. [...]
</p></div>
    </summary>
    <updated>2019-07-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4253</id>
    <link href="https://www.scottaaronson.com/blog/?p=4253" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4253#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4253" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On two blog posts of Jerry Coyne</title>
    <summary xml:lang="en-US">A few months ago, I got to know Jerry Coyne, the recently-retired biologist at the University of Chicago who writes the blog “Why Evolution Is True.” The interaction started when Jerry put up a bemused post about my thoughts on predictability and free will, and if I pointed out that if he wanted to engage […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I got to know <a href="https://en.wikipedia.org/wiki/Jerry_Coyne">Jerry Coyne</a>, the recently-retired biologist at the University of Chicago who writes the blog <a href="https://whyevolutionistrue.wordpress.com/">“Why Evolution Is True.”</a>  The interaction started when Jerry put up a <a href="https://whyevolutionistrue.wordpress.com/2019/01/15/a-computer-scientist-finds-the-question-of-free-will-uninteresting-for-bad-reasons/">bemused post about my thoughts on predictability and free will</a>, and if I pointed out that if he wanted to engage me on those topics, there was <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">more to go on</a> than an 8-minute YouTube video.  I told Coyne that it would be a shame to get off on the wrong foot with him, since perusal of his blog made it obvious that whatever he and I disputed, it was dwarfed by our areas of agreement.  He and I exchanged more emails and had lunch in Chicago.</p>



<p>By way of explaining how he hadn’t read <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">“The Ghost in the Quantum Turing Machine,”</a> Coyne emphasized the difference in my and his turnaround times: while these days I update my blog only a couple times per month, Coyne often updates multiple times per <em>day</em>.  Indeed the sheer volume of material he posts, on subjects from biology to culture wars to <a href="https://whyevolutionistrue.wordpress.com/2019/02/27/the-chicago-hot-dog-museum-and-our-wonderful-hot-dogs/">Chicago hot dogs</a>, would take months to absorb.</p>



<p>Today, though, I want to comment on just two posts of Jerry’s.</p>



<p>The <a href="https://whyevolutionistrue.wordpress.com/2019/05/17/computer-scientist-david-gelertner-drinks-the-academic-kool-aid-buys-into-intelligent-design/">first post</a>, from back in May, concerns <a href="https://en.wikipedia.org/wiki/David_Gelernter">David Gelernter</a>, the computer science professor at Yale who was infamously injured in a 1993 attack by the Unabomber, and who’s now mainly known as a right-wing commentator.  I don’t know Gelernter, though I did once attend a small interdisciplinary workshop in the south of France that Gelernter also attended, wherein I gave a talk about quantum computing and computational complexity in which Gelernter showed no interest.  Anyway, Gelernter, in an <a href="https://www.claremont.org/crb/article/giving-up-darwin/">essay in May for the <em>Claremont Review of Books</em></a>, argued that recent work has definitively disproved Darwinism as a mechanism for generating new species, and until something better comes along, Intelligent Design is the best available alternative.</p>



<p>Curiously, I think that Gelernter’s argument falls flat not for detailed reasons of biology, but mostly just because it indulges in <em>bad math and computer science</em>—in fact, in precisely the sorts of arguments that I was trying to answer in <a href="https://www.scottaaronson.com/blog/?p=1487">my segment on Morgan Freeman’s </a><em><a href="https://www.scottaaronson.com/blog/?p=1487">Through the Wormhole</a></em> (see also Section 3.2 of <a href="https://www.scottaaronson.com/papers/philos.pdf">Why Philosophers Should Care About Computational Complexity</a>).  Gelernter says that</p>



<ol><li>a random change to an amino acid sequence will pretty much always make it worse,</li><li>the probability of finding a useful new such sequence by picking one at random is at most ~1 in 10<sup>77</sup>, and</li><li>there have only been maybe ~10<sup>40</sup> organisms in earth’s history.</li></ol>



<p>Since 10<sup>77</sup> &gt;&gt; 10<sup>40</sup>, Darwinism is thereby refuted—not in principle, but as an explanation for life on earth.  QED. </p>



<p>The most glaring hole in the above argument, it seems to me, is that it simply ignores <em>intermediate</em> possible numbers of mutations.  How hard would it be to change, not 1 or 100, but 5 amino acids in a given protein to get a usefully different one—as might happen, for example, with local optimization methods like simulated annealing run at nonzero temperature?  And how many chances were there for <em>that</em> kind of mutation in the earth’s history?</p>



<p>Gelernter can’t personally see how a path could cut through the exponentially large solution space in a polynomial amount of time, so he asserts that it’s impossible.  Many of the would-be P≠NP provers who email me every week do the same.  But this particular kind of “argument from incredulity” has an abysmal track record: it would’ve applied equally well, for example, to problems like maximum matching that turned out to have efficient algorithms.  This is why, in CS, we demand better evidence of hardness—like completeness results or black-box lower bounds—neither of which seem however to apply to the case at hand.  Surely Gelernter understands all this, but had he not, he could’ve learned it from my lecture at the workshop in France!</p>



<p>Alas, online debate, as it’s wont to do, focused less on Gelernter’s actual arguments and the problems with them, than on the tiresome questions of “standing” and “status.”  In particular: does Gelernter’s authority, as a noted computer science professor, somehow lend new weight to Intelligent Design?  Or conversely: does the very fact that a computer scientist endorsed ID prove that computer science itself isn’t a real science at all, and that its practitioners should never be taken seriously in any statements about the real world?</p>



<p>It’s hard to say which of these two questions makes me want to bury my face deeper into my hands.  <a href="https://en.wikipedia.org/wiki/Serge_Lang">Serge Lang</a>, the famous mathematician and textbook author, spent much of his later life fervently denying the connection between HIV and AIDS.  <a href="https://en.wikipedia.org/wiki/Lynn_Margulis">Lynn Margulis</a>, the discoverer of the origin of mitochondria (and Carl Sagan’s first wife), died a 9/11 truther.  What broader lesson should we draw from any of this?  And anyway, what percentage of computer scientists actually do doubt evolution, and how does it compare to the percentage in other academic fields and other professions?  Isn’t the question of how divorced we computer scientists are from the real world an … ahem … <strong>empirical</strong> matter, one hard to answer on the basis of armchair certainties and anecdotes?</p>



<p>Speaking of empiricism, if you check Gelernter’s <a href="https://dblp.uni-trier.de/pers/hd/g/Gelernter:David">publication list on DBLP</a> and his <a href="https://scholar.google.ca/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=david+gelernter&amp;btnG=&amp;oq=david+geler">Google Scholar page</a>, you’ll find that he did influential work in programming languages, parallel computing, and other areas from 1981 through 1997, and then in the past 22 years published a grand total of … <strong>two</strong> papers in computer science.  One with four coauthors, the other a review/perspective piece about his earlier work.  So it seems fair to say that, some time after receiving tenure in a CS department, Gelernter pivoted (to put it mildly) away from CS and toward conservative punditry.  His recent offerings, in case you’re curious, include the book <a href="https://www.amazon.com/America-Lite-Imperial-Academia-Dismantled-Obamacrats/dp/1594036063/ref=sr_1_1?keywords=david+gelernter&amp;qid=1563047627&amp;s=gateway&amp;sr=8-1">America-Lite: How Imperial Academia Dismantled Our Culture (and Ushered In the Obamacrats)</a>.</p>



<p>Some will claim that this case underscores what’s wrong with the tenure system itself, while others will reply that it’s precisely what tenure was designed for, even if in this instance you happen to disagree with what Gelernter uses his tenured freedom to say.  The point I wanted to make is different, though.  It’s that the question “what kind of a field is computer science, anyway, that a guy can do high-level CS research on Monday, and then on Tuesday reject Darwinism and unironically use the word ‘Obamacrat’?”—well, even if I accepted the immense weight this question places on one atypical example (which I don’t), and even if I dismissed the power of compartmentalization (which I again don’t), the question <em>still</em> wouldn’t arise in Gelernter’s case, since getting from “Monday” to “Tuesday” seems to have taken him 15+ years.</p>



<p>Anyway, the second post of Coyne’s that I wanted to talk about is <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">from just yesterday</a>, and is about Jeffrey Epstein—the financier, science philanthropist, and confessed sex offender, whose appalling crimes you’ll have read all about this week if you weren’t on a long sea voyage without Internet or something.</p>



<p>For the benefit of my many fair-minded friends on Twitter, I should clarify that I’ve never met Jeffrey Epstein, let alone accepted any private flights to his sex island or whatever.  I doubt he has any clue who I am either—even if he did once claim to be <a href="https://web.archive.org/web/20101112131000/http://www.jeffreyepsteinscience.com/2010/10/the-value-of-quantum-computing-to-jeffrey-epstein/">“intrigued”</a> by quantum information.</p>



<p>I do know a few of the scientists who Epstein once hung out with, including Seth Lloyd and Steven Pinker.  Pinker, in particular, is now facing vociferous attacks on Twitter, similar in magnitude perhaps to what I faced in the comment-171 affair, for having been photographed next to Epstein at a 2014 luncheon that was hosted by Lawrence Krauss (a physicist who later faced sexual harassment allegations of his own).  By the evidentiary standards of social media, this photo suffices to convict Pinker as basically a child molester himself, and is <em>also</em> a devastating refutation of any data that Pinker might have adduced in his books about the Enlightenment’s contributions to human flourishing.</p>



<p>From my standpoint, what’s surprising is not that Pinker is up against this, but that it <em>took this long</em> to happen, given that Pinker’s pro-Enlightenment, anti-blank-slate views have had the effect of painting a giant red target on his back.  Despite the near-inevitability, though, you can’t blame Pinker for wanting to defend himself, as I did when it was my turn for the struggle session.</p>



<p>Thus, in response to an emailed inquiry by Jerry Coyne, Pinker shared some detailed reflections about Epstein; Pinker then gave Coyne permission to post those reflections on his blog (though they were originally meant for Coyne only).  Like everything Pinker writes, they’re <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">worth reading in full</a>.  Here’s the opening paragraph:</p>



<blockquote class="wp-block-quote"><p>The annoying irony is that I could never stand the guy [Epstein], never took research funding from him, and always tried to keep my distance. Friends and colleagues described him to me as a quantitative genius and a scientific sophisticate, and they invited me to salons and coffee klatches at which he held court. But I found him to be a kibitzer and a dilettante — he would abruptly change the subject ADD style, dismiss an observation with an adolescent wisecrack, and privilege his own intuitions over systematic data.</p></blockquote>



<p>Pinker goes on to discuss his record of celebrating, and extensively documenting, the forces of modernity that led to dramatic reductions in violence against women and that have the power to continue doing so.  On Twitter, Pinker had <a href="https://twitter.com/sapinker/status/1149154274787627010">already written</a>: “Needless to say I condemn Epstein’s crimes in the strongest terms.”</p>



<p>I probably should’ve predicted that Pinker would then be attacked again—this time, for having prefaced his condemnation with the phrase “needless to say.”  The argument, as best I can follow, runs like this: given all the isms of which woke Twitter has already convicted Pinker—scientism, neoliberalism, biological determinism, etc.—how could Pinker’s being against Epstein’s crimes (which we recently learned probably include the <a href="https://www.cnn.com/videos/us/2019/07/10/jeffrey-epstein-accuser-speaks-out-today-show-nbc-intv-sot-newday-vpx.cnn">rape</a>, and not only statutorily, of a 15-year-old) <em>possibly</em> be assumed as a given?</p>



<p>For the record, just as Epstein’s friends and enablers weren’t confined to one party or ideology, so the public condemnation of Epstein strikes me as a matter that is (or should be) beyond ideology, with all reasonable dispute now confined to the space between “very bad” and “extremely bad,” between “lock away for years” and “lock away for life.”</p>



<p>While I didn’t need Pinker to tell me <em>that</em>, one reason I personally appreciated his comments is that they helped to answer a question that had bugged me, and that none of the mountains of other condemnations of Epstein had given me a clear sense about.  Namely: supposing, hypothetically, that I’d met Epstein around 2002 or so—without, of course, knowing about his crimes—would I have been as taken with him as many other academics seem to have been?  (Would <em>you</em> have been?  How sure are you?)</p>



<p>Over the last decade, I’ve had the opportunity to meet some titans and semi-titans of finance and business, to discuss quantum computing and other nerdy topics.  For a few (by no means all) of these titans, my overriding impression was <em>precisely</em> their unwillingness to concentrate on any one point for more than about 20 seconds—as though they wanted the crust of a deep intellectual exchange without the meat filling.  My experience with them fit Pinker’s description of Epstein to a T (though I hasten to add that, as far as I know, none of these others ran teenage sex rings).</p>



<p>Anyway, given all the anger at Pinker for having intersected with Epstein, it’s ironic that I could easily imagine Pinker’s comments rattling Epstein the most of anyone’s, if Epstein hears of them from his prison cell.  It’s like: Epstein must have developed a skin like a rhinoceros’s by this point about being called a child abuser, a creep, and a thousand similar (and similarly deserved) epithets.  But “a kibitzer and a dilettante” who merely lured famous intellectuals into his living room, with wads of cash not entirely unlike the ones used to lure teenage girls to his massage table?  Ouch!</p>



<p>OK, but what about Alan Dershowitz—the man who apparently used to be Epstein’s close friend, who still is Pinker’s friend, and who played a crucial role in securing Epstein’s 2008 plea bargain, the one now condemned as a travesty of justice?  I’m not sure how I feel about Dershowitz.  It’s like: I understand that our system requires attorneys willing to mount a vociferous defense even for clients who they privately know or believe to be guilty—and even to get those clients off on technicalities or bargaining whenever they can.  I’m also incredibly grateful that I chose CS rather than law school, because I don’t think I could last an hour advocating causes that I knew to be unjust.  Just like my fellow CS professor, the intelligent design advocate David Gelernter, I have the privilege and the burden of speaking only for myself.</p></div>
    </content>
    <updated>2019-07-13T23:33:12Z</updated>
    <published>2019-07-13T23:33:12Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-14T19:20:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal</id>
    <link href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html" rel="alternate" type="text/html"/>
    <title>Connectivity and finiteness in modal graph logic</title>
    <summary>I read with interest Joel David Hamkins’ recent blog post on modal model theory. This week, on a long plane flight home from Italy, I was inspired to play with the modal logic of graphs, in which one describes properties of graphs by simpler properties of their (induced) supergraphs. My interest is less in what this says about set theory and model theory, and more in how expressive this language is: which graph properties can it describe? Joel showed in his post how to describe -colorability in this theory, but I thought it would be of interest to start with something simpler than an -complete problem. And what could be simpler for graphs than testing whether a graph is connected or finite?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I read with interest Joel David Hamkins’ recent blog post on <a href="http://jdh.hamkins.org/modal-model-theory/">modal model theory</a>.
This week, on a long plane flight home from Italy, I was inspired to play with the modal logic of graphs, in which one describes properties of graphs by simpler properties of their (induced) supergraphs. My interest is less in what this says about set theory and model theory, and more in how expressive this language is: which graph properties can it describe? Joel showed in his post how to describe -colorability in this theory, but I thought it would be of interest to start with something simpler than an -complete problem. And what could be simpler for graphs than testing whether a graph is connected or finite?</p>

<h1 id="the-basics-of-modal-graph-logic">The basics of modal graph logic</h1>

<p><a href="https://en.wikipedia.org/wiki/Modal_logic">Modal logic</a> is a logic of “possible worlds” with two operators on formulas,  (it is possible for  to be true, in at least one possible world) and  (it is necessary for  to be true, in all possible worlds).
Modal graph logic applies this idea to the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a>, in which one can quantify over variables that represent graph vertices and use a binary predicate  representing adjacency of pairs of vertices. I’ll assume here that all graphs are simple and undirected (i.e.,  is irreflexive and commutative). A given graph  models a given first-order formula  (written as ) if the formula becomes true when you evaluate it in the obvious way for the given graph. In the modal logic of graphs, the possible worlds are graphs containing  as an induced subgraph. So  means that it is possible for  to be modeled by one of these larger graphs and  means that it is necessary for  to be modeled by all of these larger graphs. If we apply a modal operator to a formula  that is itself modal, the possible worlds of the modal operators within  are supergraphs of these larger graphs, in the same way (in modal logic terminology, we are assuming S4 accessibility of possible worlds).</p>

<p>In some ways this is enormously powerful: the class of all graphs containing  is so big that it’s not even a set, and it can encode arbitrarily complicated structures. In other ways this is more highly constrained than other graph logics like monadic second-order logic (in which one can describe and quantify sets of vertices or edges, but not more complicated structures like sequences of vertices or strategy trees over games defined on the graph). The issue is that in a possible world, one can’t tell the vertices that were part of the base graph apart from the ones that were added later, except possibly for a finite set of vertices named in variables outside the modal operator. So while the possible worlds that model a given formula can be very large and complicated, it can be difficult to anchor these castles in the air to the base graph that you started with.</p>

<p>Joel’s description of how to express -colorability suggests a path around this difficulty: Suppose we want to test a hereditary property  of graphs (one that extends from any graph to its induced subgraphs) such as colorability. Then we should look for a family of self-verifyingly- graphs: a family of graphs with property  such that membership in the family can be tested by a first-order formula  and such that every graph with property  is an induced subgraph of a larger graph in this family. If we can find such a family and first-order formula , then  will describe property  itself. For instance, for colorability, the self-verifyingly--colorable graphs are graphs in which each color class has a universal vertex, every vertex is adjacent to all but one of the universal vertices, and no two adjacent vertices are both non-adjacent to the same universal vertex.</p>

<p>Similar ideas can also work when the property is not hereditary (for instance, a graph has chromatic number 3 when it is 3-colorable but not 2-colorable) or when checking membership in the family of self-verifying graphs itself involves modal logic (as we’ll see for testing finiteness).</p>

<h1 id="connectivity">Connectivity</h1>

<p>Connectivity is not hereditary: every connected graph is part of a larger disconnected graph and vice versa. But the property that some particular pair of vertices  is separated is hereditary: if  is separated from , the two vertices remain separated in any induced subgraph that contains them both. And while it’s not possible to verify this directly in a first order formula, for all graphs, it is possible in a special family of disconnected graphs, the ones containing a <em>transitive vertex</em>, one whose neighborhood forms a connected component of the graph. We can define a formula</p>



<p>which characterizes these transitive vertices. (Here I am using  to mean syntactic equivalence of formulas or definition of the name of a formula, rather than its meaning in Joel’s post, equivalence of models.) Then we can test whether  is separated from  by the formula</p>



<p>(Here, the instance of “transitive” on the right hand side is not a unary predicate, even though it looks like one; it should be expanded by the definition of the “transitive” formula to produce the resulting “separated” formula. Think of it as being like a C preprocessor macro.)
If  is indeed separated from , there is a possible world modeling the formula, in which we add an extra vertex  to the starting graph, adjacent to everything in the connected component of . And in any possible world modeling the formula,  is separated from , and this must remain true in every induced subgraph of this possible world, including the base graph. Finally, a graph is connected if and only if it has no separated pair:</p>



<p>In MSO logic, one of the standard tools is the <em>method of syntactic interpretations</em>. This allows you to modify your base graph  to form a different graph  (for any of certain standard types of modification) and test whether the resulting graph models a given formula . To do this, you instead modify the formula (in certain purely mechanical ways derived from how you were modifying ) and test whether your original graph models the modified formula . The same thing works in first-order logic and in modal logic, and allows such modifications as adding or removing an edge between given vertices, removing any given vertex, restricting to a logically-specified induced subgraph, or adding a new vertex with a logically-specified adjacency relation. I’ll write  for the modified formula that simulates formula  on the modified graph . We can use this idea to extend connectedness to other properties; for instance, a graph is a forest if it has no cycle, and this is true if every edge removal disconnects it:</p>



<h1 id="finiteness">Finiteness</h1>

<p>Following the earlier outline,
I’d like to find a simple family of finite graphs for which their finiteness is
so obvious that it can be tested by a simple logical formula, and then embed
every finite graph into one of these simple finite graphs.</p>

<p>The first natural choice of such a family is the family of paths.
We can define a path to be a connected graph with exactly two degree-one vertices in which all remaining vertices have degree two. Checking the degrees is first order, but I’ll spare you the messy details of the formula. All such graphs are finite, because a graph is connected if and only if every two vertices are a finite distance apart, and when the endpoints of a path are a finite distance apart there can be only finitely many other degree-two vertices between them. Any other vertices outside of this finite set must belong to a different component.</p>

<p>Not every finite graph can be embedded into a path. However, every finite graph has a perfect matching to the vertices of a path. To check the existence of an induced perfect matching between two sets of vertices in a graph, it’s helpful to have an extra vertex  that is not part of the matching, but that distinguishes one side of the matching (the neighbors of ) from the other side:</p>



<p>Here,  is shorthand for the <a href="https://en.wikipedia.org/wiki/Uniqueness_quantification">existence of exactly one thing</a>. With this test for an induced perfect matching in hand, we can check for a perfect matching to a finite path by</p>



<p>where  denotes the open neighborhood of , the graph induced by the vertices adjacent to .</p>

<p>I don’t think it’s possible to test finiteness in the same way in MSO.
We can define paths in MSO, and force them to have a perfect induced matching to the remaining vertices. But the recipe above breaks down at the point where it embeds the given graph into a supergraph, not generally possible in MSO. More generally I don’t think it’s possible in MSO to distinguish the family of finite complete graphs from their limit, the countable complete graph.</p>

<h1 id="additional-properties">Additional properties</h1>

<p>The same technology of paths and matchings can also be used to formulate not-very-natural properties of finite graphs that are definitely not expressible in MSO. For instance, we can check whether a graph  is the disjoint union of two equal-length paths, by first checking that it is a forest with four degree-one vertices and the rest degree-two, and then checking that both paths can be simultaneously perfectly matched to a third path of remaining vertices (with an additional vertex used to distinguish the sides of the matching as above). When this structure exists, the whole graph forms a polyhedron in the form of a  grid with the sides of the grid connected to the distinguishing vertex, and this polyhedral structure can be used to prove that we cannot trick the formula by adding new paths connecting the original path endpoints. In contrast, MSO cannot express equality of path lengths, because (per <a href="https://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle’s theorem</a>) it can only express properties of path-like graphs that can be expressed as regular languages (over bounded-width path-decompositions of the graph), and equality of length is context-free but not regular for path-decompositions that concatenate the two paths separately.</p>

<p>It’s also possible to express that the <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)">degeneracy of a graph</a> is at most some constant  in modal logic. As special cases, the graphs of degeneracy zero are the independent sets (first-order expressible) and the graphs of degeneracy one are the forests, which we’ve already seen how to express. Otherwise, we can represent sequences of vertices by <em>ladders</em>, paths of degree-three vertices matched to independent sets of degree-two vertices, with the represented sequence being the other endpoints of these degree-two vertices. Adding a ladder to a graph of degeneracy at least two doesn’t change its degeneracy, and we can express the existence of a degeneracy ordering of a finite graph (a sequence of the vertices such that all vertices have at most  neighbors that are later in the sequence) by the addition of a ladder with a designated starting vertex that touches all non-ladder vertices.
Each non-ladder vertex  should have at most  neighbors with the property that, within the ladder, the ladder vertex nearest  separates the top of the ladder from the ladder vertices nearest these neighbors.</p>

<p>We can <a href="https://11011110.github.io/blog/2019/01/17/orientations-infinite-graphs.html">extend the concept of degeneracy from finite to infinite graphs</a>
by requiring that every finite subgraph have degeneracy at most .
With this definition, we can identify a finite subgraph as the neighbors of a ladder, and then use the formula for finite-graph degeneracy on these neighbors.
This leads to a modal logic expression for infinite graph degeneracy in which the overall structure of the formula is that it is necessary that, whenever a vertex  forms the start of a ladder, it should be possible for there to exist another ladder defining a degeneracy ordering for ’s ladder and its neighbors.</p>

<p>I suspect, although I haven’t worked out all the details, that planarity testing is also expressible in modal logic. Here’s the outline of an idea for proving this. First, we can check that the graph is finite, to avoid complications of which infinite graphs should be considered to be planar or what a drawing of an infinite planar graph might look like. Next, a graph is planar if and only if it is an induced subgraph of a maximal planar graph, one in which all edges belong to exactly two <a href="https://en.wikipedia.org/wiki/Peripheral_cycle">peripheral triangles</a>. A graph with this two-peripheral-triangle property is planar if and only if one can partition its edges into two subsets, one of which forms a spanning tree for the graph and the other of which forms a spanning tree for the dual graph of the peripheral cycles. (The two-peripheral-triangle property defines a surface embedding which, if non-planar, would have some leftover edges that are neither part of a spanning tree nor a complementary dual spanning tree; see my paper “<a href="https://www.ics.uci.edu/~eppstein/pubs/p-dyngen.html">Dynamic generators of topologically embedded graphs</a>”.) And it should be possible to describe this partition in a planarity-preserving way by decorating the edges on one side of the partition by additional small planar graphs (maybe even just attaching a triangle to each decorated edge). So all we need to check is that it’s possible for the given graph to be part of a larger graph
that looks like a maximal planar graph with some decorated edges (ignoring the decorations, each edge belongs to two peripheral triangles) and that the decorations describe a spanning tree and a dual spanning tree. We already know how to describe spanning trees and dual spanning trees should also be possible using similar logic.</p>

<p>One natural and simple property that I don’t see how to express in modal logic is regularity. One can ask: do each two vertices have the same degree? And equality of sets of vertices can be checked by the existence of perfect matchings, as in the two-equal-paths example. But how do we know, in a possible world, which neighbors of two given vertices are original and which are added? For the same reason, the property of having a perfect matching seems difficult to express in modal logic, even though it is easy in MSO. Again, it seems difficult to impose any extra structure on a supergraph without losing too much information about which parts of the graph are original.</p>

<h1 id="standard-and-nonstandard-models">Standard and nonstandard models</h1>

<p>I have been (deliberately) naive here about what kind of set theory I am using to define my graphs, what “all induced supergraphs” means (do I consider graphs only over some set of candidate vertices, or the proper class of all graphs in some set theory), and whether there is always a “correct” value of  that our models of modal graph logic should produce for a given graph and formula. If these naive assumptions are not valid, the description of what these formulas express may be inaccurate.</p>

<p>In particular, the claim that a graph is connected if and only if every two vertices are a finite distance apart uses concepts of distance that go beyond the first-order theory of graphs. In non-standard models of set theory, or in standard models of set theory but with non-standard collections of possible worlds that are not really the collection of all induced supergraphs of a given graph, that claim may fail to be true. In such cases, the finiteness formula may determine that an infinite graph (one that models the first-order logical formulas stating that there exist at least  distinct vertices, for every finite integer ) is finite. It’s not a bug in the formula, just an indication that you need to be careful about your models. Or in computer science terms, <a href="https://en.wikipedia.org/wiki/Garbage_in,_garbage_out">GIGO</a>.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102438063877916451">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-13T21:57:00Z</updated>
    <published>2019-07-13T21:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-14T17:52:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16085</id>
    <link href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Tools and Sensitivity</title>
    <summary>Cutting right through a 30-year-old conjecture Cropped from Emory homepage Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a paper of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 paper by Noam Nisan and Mario Szegedy. Today we discuss […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Cutting right through a 30-year-old conjecture</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/haohuangcropped/" rel="attachment wp-att-16086"><img alt="" class="alignright wp-image-16086" height="212" src="https://rjlipton.files.wordpress.com/2019/07/haohuangcropped.jpg?w=148&amp;h=212" width="148"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Emory <a href="http://www.mathcs.emory.edu/~hhuan30/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">paper</a> of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a> by Noam Nisan and Mario Szegedy.</p>
<p>
Today we discuss his brilliant proof and what it means for sensitivity of the <em>tools</em> one employs.</p>
<p>
Several of our blogging friends have <a href="https://www.scottaaronson.com/blog/?p=4229">covered</a> this <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">news</a> in <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posts</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">already</a>, and Ryan O’Donnell even summarized the proof in one <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>. Scott Aaronson’s thread includes a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">comment</a> by Huang on how he came by his proof. </p>
<p>
We will try to draw implications for the related matter of how <em>you</em> might come by proofs of <em>other</em> conjectures. We have previously <a href="https://rjlipton.wordpress.com/2016/04/09/missing-mate-in-ten/">discussed</a> the possibility of overlooking short solutions to major problems. Here we will discuss how to <em>find</em> them.</p>
<p>
</p><p/><h2> A Graph Puzzle </h2><p/>
<p/><p>
To get a flavor of what Huang proved, consider the graph of an ordinary <a href="https://commons.wikimedia.org/wiki/File:Cube_graph.png">cube</a>:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph/" rel="attachment wp-att-16087"><img alt="" class="aligncenter wp-image-16087" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
The question is, <em>can you color 5 vertices red so that no red node has 3 red neighbors?</em> Your first impulse might be to color 4 nodes red according to parity so that none has a red neighbor, per below left:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_tries/" rel="attachment wp-att-16088"><img alt="" class="aligncenter wp-image-16088" height="175" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_tries.png?w=450&amp;h=175" width="450"/></a></p>
<p/><p><br/>
But then any 5th node will have 3 red neighbors. Another “greedy” idea is to pack a subgraph of the allowed degree 2 into half the cube, as at right. Any 5th node will again create a degree-3 vertex in the subgraph induced by the red nodes.</p>
<p>
The answer is that actually one can pack 6 nodes that induce a simple cycle:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_solved/" rel="attachment wp-att-16089"><img alt="" class="aligncenter wp-image-16089" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_solved.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
Now let’s up the dimension by one—that is, take <img alt="{n = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4}"/> and <img alt="{N = 2^n = 16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En+%3D+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n = 16}"/>. How many nodes can we color red and keep the induced degree 2? </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph/" rel="attachment wp-att-16091"><img alt="" class="aligncenter wp-image-16091" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph-1.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
Again the parity trick gives us degree 0 with 8 nodes, but then we can’t add a 9th. We can greedily try to pack the outer cube with our 6-node solution, but then—perhaps surprisingly—we can add only 2 more red nodes from the inner cube. So we can only do 5 from the outer cube. We can get 9 overall by:</p>
<p><a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph_try10/" rel="attachment wp-att-16092"><img alt="" class="aligncenter wp-image-16092" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph_try10.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
The fact that one red node is isolated seems to give room to improve, but there is no way to make 10. </p>
<p>
</p><p/><h2> The Theorem </h2><p/>
<p/><p>
The calculations have left an interesting jump from degree 0 with eight red nodes and degree 2 with nine. How about degree 1? Can we do that with 9 nodes? We can pack four disjoint edges but then there is nowhere to stick an isolated node. </p>
<p>
So for 9 nodes, which is <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/>, the best we can do is degree 2, which is <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. This is what Huang proved:</p>
<blockquote><p><b>Theorem 1</b> <em><a name="graphs"/> Every subgraph induced by <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-dimensional hypercube graph has a node of degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
This is completely tight. When <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is a perfect square there is a way to achieve <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> as the maximum degree (shown <a href="https://pdfs.semanticscholar.org/3917/3e0cb4e028c94328f1355bf02febea132127.pdf">here</a>). Otherwise the least integer above <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> is best. Thus every subgraph of the <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/>-cube induced by 17 nodes has a node with three neighbors, but you can go as high as 257 nodes in the <img alt="{9}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B9%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{9}"/>-cube while keeping the maximum degree to 3.</p>
<p>
We will mention the relation to Boolean sensitivity only briefly. The nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube correspond to truth assignments in <img alt="{\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^n}"/>. Since every red node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> neighbors in the cube but at most <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> red neighbors, the color function is highly sensitive to bitflips. But every flip also changes the parity of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. Hence the <em>exclusive-or</em> of the color function with the parity function has <em>low</em> sensitivity. </p>
<p>
But not too low: Huang proved it is at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. That was enough to prove the conjecture. I’ve cut two sections on Boolean sensitivity from this post’s <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">original draft</a>—let’s just say the connection to the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube and graph degree was known since this 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a>. Here we’ll focus on what it took to prove this theorem.</p>
<p>
</p><p/><h2> The Proof </h2><p/>
<p/><p>
From my undergrad days I’ve kept an interest in spectral graph theory. One of the basic facts is that the degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is always at least as great as the largest eigenvalue <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> of its adjacency matrix <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_G}"/>. For a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>-regular graph they are equal. Huang’s first trick is to note that the classic proof of this also allows <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> values on edges:</p>
<blockquote><p><b>Lemma 2</b> <em> Let <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> be a symmetric matrix obtained from <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_G}"/> by multiplying some entries by <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{-1}"/> and <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> any of its eigenvalues. Then <img alt="{d(G) \geq |\lambda|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%7C%5Clambda%7C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq |\lambda|}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Choose an eigenvector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> such that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/> and take an index <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> that maximizes <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/>. Then </p>
<p align="center"><img alt="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_i%7C+%3D+%7C%28A+v%29_i%7C+%3D+%7C%5Csum_j+A_%7Bi%2Cj%7D+v_j%7C+%5Cleq+%7C%5Csum_j+A_%7Bi%2Cj%7D%7C+%5Ccdot+%7Cv_i%7C+%5Cleq+%5Csum_%7B%28i%2Cj%29+%5Cin+E%28G%29%7D+%7CA_%7Bi%2Cj%7D%7C%5Ccdot+%7Cv_i%7C+%5Cleq+d%28G%29%7Cv_i%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. "/></p>
<p>Dividing out <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/> gives the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p/><p><br/>
So now what we want to do is find conditions that force <img alt="{\lambda = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda = \sqrt{n}}"/> when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is a <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>-vertex subgraph of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube with <img alt="{m \geq \frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Cgeq+%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \geq \frac{N}{2} + 1}"/>, where <img alt="{N = 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n}"/>. The trick that Huang realized is that he could do this by making <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> sit inside a matrix <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> with at least <img alt="{\frac{N}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2}}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. </p>
<p>
To see how, form <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> by knocking out the last row and column of <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>. Since <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> and <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> are both real and symmetric, their eigenvalues are real, so we can order them <img alt="{\lambda_1,\dots,\lambda_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cdots%2C%5Clambda_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1,\dots,\lambda_N}"/> and <img alt="{\mu_1,\dots,\mu_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu_1%2C%5Cdots%2C%5Cmu_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu_1,\dots,\mu_{N-1}}"/> in nonincreasing order. The basic fact is that they always <em>interlace</em>: </p>
<p align="center"><img alt="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1+%5Cgeq+%5Cmu_1+%5Cgeq+%5Clambda_2+%5Cgeq+%5Cmu_2+%5Cgeq+%5Clambda_3+%5Cgeq+%5Ccdots+%5Cgeq+%5Cmu_%7BN-1%7D+%5Cgeq+%5Clambda_N.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. "/></p>
<p>See <a href="https://arxiv.org/pdf/math/0502408.pdf">this</a> for a one-page proof. The neat point is that you can repeat this: if you get <img alt="{A''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A''}"/> by knocking out another row and corresponding column, and <img alt="{[\nu_i]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cnu_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\nu_i]}"/> are its eigenvalues in order, then </p>
<p align="center"><img alt="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Cmu_2+%5Cgeq+%5Cnu_2+%5Cgeq+%5Cmu_3+%5Ccdots.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. "/></p>
<p>It follows that <img alt="{\lambda_1 \geq \nu_1 \geq \lambda_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Clambda_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1 \geq \nu_1 \geq \lambda_3}"/>. If you do this again, you get a matrix whose leading eigenvalue is still at least as big as <img alt="{\lambda_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_4}"/>. Do it <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> times inside <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>, and you’re still above <img alt="{\lambda_{N/2}(A_N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7BN%2F2%7D%28A_N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_{N/2}(A_N)}"/>, which we just said we will arrange to be <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. Thus if we knock out the <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> white nodes, we will get the graph on the red nodes with adjacency matrix <img alt="{A_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_m}"/> and conclude: </p>
<p align="center"><img alt="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1%28A_N%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) "/></p>
<p>Plugging into the lemma gives: </p>
<p align="center"><img alt="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28G%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+%3D+%5Csqrt%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. "/></p>
<p>(In fact, as also <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">noted</a> on Scott’s blog, this case of interlacing can be inferred from simpler reasoning—but our point is that the interlacing theorem was in Huang’s bag of tricks.) </p>
<p>
</p><p/><h2> Building the Matrix </h2><p/>
<p/><p>
Finally, how do we lay hands on <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>? We want a matrix of trace zero such that <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/>. Then all its eigenvalues are <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/> and <img alt="{-\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-\sqrt{n}}"/>.  They come in equal numbers because they sum to the trace which is zero. So we will have <img alt="{N/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N/2}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>, as needed. And we would want <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> to be the matrix of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube but that doesn’t work: each <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> entry of its square counts all paths of length 2 from node <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> to node <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and that number can be nonzero.</p>
<p>
This is where the trick of putting <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> on edges comes in, and we can explain it in a way familiar from quantum. We arrange that every 4-cycle of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube has exactly one edge with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/>. Then the pairs of paths from one corner to the opposite corner will always <em>cancel</em>, leaving <img alt="{A^2_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = 0}"/> whenever <img alt="{i \neq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i \neq j}"/>. And <img alt="{A^2_{i,j} = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = n}"/> because there are <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> ways to go out and come back along the same edge, always contributing <img alt="{1\cdot 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Ccdot+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1\cdot 1}"/> or <img alt="{(-1)\cdot(-1) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5Ccdot%28-1%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)\cdot(-1) = 1}"/> either way. Huang defines the needed labeling explicitly by the recursion: </p>
<p align="center"><img alt="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_2+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C%5Cquad%5Ctext%7Band+for+%7D+N+%3E+2%2C%5Cquad+A_N+%3D+%5Cbegin%7Bbmatrix%7D+A_%7BN%2F2%7D+%26+I+%5C%5C+I+%26+-A_%7BN%2F2%7D+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. "/></p>
<p>This puts a <img alt="{-}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-}"/> sign on exactly one-fourth of the entries in the needed way. OK, we changed Huang’s subscripts for consistency with “<img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>” above and also to note that the basis could be <img alt="{A_1 = [0]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1+%3D+%5B0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1 = [0]}"/>.  Anyway, he verifies <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/> directly by simple algebra and induction.  That’s it—that’s the proof.</p>
<p>
Why was it hard to spot? Dick and I believe it was the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> trick. In the 1980s, I thought about ways to convert undirected graphs into directed ones by putting arrows on the edges, but not <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> signs. The chance of thinking of it maybe rises with knowing quantum ideas such as interference and amplification. Now we can see, OK, <img alt="{A_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_2}"/> is the quantum NOT gate and the recursion treats signs in similar fashion to the recursion defining Hadamard matrices.  The matrix <img alt="{\frac{1}{\sqrt{n}}A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{\sqrt{n}}A_N}"/> is unitary, so it defines a quantum operator. This all goes to our main point about having tools at one’s command—the more tools, the better. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Huang’s theorem still leaves a gap between a quadratic lower bound and his 4th-power upper bound (my longer <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">draft</a> lays this out).  Can this gap be closed?  In discussing this, Huang notes that his spectral methods need not be confined to sub-matrices of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube, and our thoughts of involving quantum are similar. Can quantum tools improve the results even further?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-12T10:51:42Z</updated>
    <published>2019-07-12T10:51:42Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="complexity"/>
    <category term="concrete complexity"/>
    <category term="eigenvalues"/>
    <category term="Hao Huang"/>
    <category term="linear algebra"/>
    <category term="matrices"/>
    <category term="quantum"/>
    <category term="spectral methods"/>
    <category term="tricks"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-15T12:20:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1705625191398821823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1705625191398821823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html" rel="alternate" type="text/html"/>
    <title>Degree and Sensitivity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Hao Huang's <a href="https://arxiv.org/abs/1907.00847">proof of the sensitivity conjecture</a> that I <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posted on last week</a> relied on a 1992 <a href="https://doi.org/10.1016/0097-3165(92)90060-8">result of Gotsman and Linial</a>. Let's talk about that result.<br/>
<br/>
Consider the set S={-1,1}<sup>n</sup>. The hypercube of dimension n is the graph with vertex set S and an edge between x = (x<sub>1</sub>,…,x<sub>n</sub>) and y = (y<sub>1</sub>,…,y<sub>n</sub>) in S if there is exactly one i such that x<sub>i</sub> ≠ y<sub>i</sub>. Every vertex has degree n.<br/>
<br/>
We say a vertex x is odd if x has an odd number of -1 coordinates, even otherwise. Every edge joins an odd and even vertex.<br/>
<br/>
Let f be a function mapping S to {-1,1}. The sensitivity of f on x is the number of i such that f(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) ≠ f(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>). The sensitivity of f is the maximum over all x in S of the sensitivity of f on x.<br/>
<br/>
Let g be the same function as f except that we flip the value on all odd vertices. Notice now that the sensitivity of f on x is the number of i such that g(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) = g(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>).<br/>
<br/>
Let G be the induced subgraph of vertices of x such that g(x)=-1 and H be induced subgraph on the set of x such that g(x)=1. The sensitivity of f is the maximum number of neighbors of any vertex in G or H.<br/>
<br/>
Consider f as a multilinear polynomial over the reals. The sensitivity conjecture states there is some α&gt;0 such that if f has degree n then f has sensitivity at least n<sup>α</sup>.<br/>
<br/>
Note g(x<sub>1</sub>,…,x<sub>n</sub>)=f(x<sub>1</sub>,…,x<sub>n</sub>)x<sub>1</sub>⋯x<sub>n</sub>. If f has a degree n term, the variables in that term cancel out on S (since x<sub>i</sub><sup>2</sup>=1) and the constant of the degree n term of f becomes the constant term of g. The constant term is just the expected value, so f has full degree iff g is unbalanced.<br/>
<br/>
GL Assumption: Suppose you have a partition of the hypercube into sets A and B with |A| ≠ |B|, and let G and H be the induced subgraphs of A and B. Then there is some constant α&gt;0 such that there is a node of A or B with at least n<sup>α</sup> neighbors.<br/>
<br/>
The above argument, due to Gotsman and Linial, shows that the GL assumption is equivalent to the sensitivity conjecture.<br/>
<br/>
Huang proved that given any subset A of the vertices of a hypercube with |A|&gt;2<sup>n</sup>/2 the induced subgraph has a node of degree at least n<sup>1/2</sup>. Since either A or B in the GL assumption has size greater than 2<sup>n</sup>/2, Huang's result gives the sensitivity conjecture.</div>
    </content>
    <updated>2019-07-11T17:54:00Z</updated>
    <published>2019-07-11T17:54:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-15T11:44:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=656</id>
    <link href="https://emanueleviola.wordpress.com/2019/07/10/non-abelian-combinatorics-and-communication-complexity/" rel="alternate" type="text/html"/>
    <title>Non-abelian combinatorics and communication complexity</title>
    <summary>Below and here in pdf is a survey I am writing for SIGACT, due next week.  Comments would be very helpful. Finite groups provide an amazing wealth of problems of interest to complexity theory. And complexity theory also provides a useful viewpoint of group-theoretic notions, such as what it means for a group to be […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Below and <a href="http://www.ccs.neu.edu/home/viola/papers/viola-sigact-snafu.pdf">here in pdf</a> is a survey I am writing for SIGACT, due next week.  Comments would be very helpful.</p>
<hr/>
<p style="text-align: justify;">Finite groups provide an amazing wealth of problems of interest to complexity theory. And complexity theory also provides a useful viewpoint of group-theoretic notions, such as what it means for a group to be “far from abelian.” The general problem that we consider in this survey is that of computing a <em>group product</em> <img alt="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dx_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}"/> over a finite group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Several variants of this problem are considered in this survey and in the literature, including in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKrohnMR66">KMR66</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBarrington89">Bar89</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBen-OrC92">BC92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XImmermanL95">IL95</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBGKL03">BGKL03</a>, <a href="https://emanueleviola.wordpress.com/feed/#XPRS97">PRS97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainis96">Amb96</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainisL00">AL00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaz00">Raz00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMiles14">Mil14</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<p style="text-align: justify;">Some specific, natural computational problems related to <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> are, from hardest to easiest:</p>
<p style="text-align: justify;">(1) Computing <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>,</p>
<p style="text-align: justify;">(2) Deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/>, where <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> is the identity element of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, and</p>
<p style="text-align: justify;">(3) Deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> under the promise that either <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> or <img alt="g=h" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=h"/> for a fixed <img alt="h\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\ne 1_{G}"/>.</p>
<p style="text-align: justify;">Problem (3) is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>. The focus of this survey is on (2) and (3).</p>
<p style="text-align: justify;">We work in the model of <em>communication complexity </em><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XYao79">Yao79</a>]</span>, with which we assume familiarity. For background see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKuN97">KN97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaoY2019">RY19</a>]</span>. Briefly, the terms <img alt="x_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}"/> in a product <img alt="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}"/> will be partitioned among collaborating parties – in several ways – and we shall bound the number of bits that the parties need to exchange to solve the problem.</p>
<p style="text-align: justify;"><b>Organization</b>.</p>
<p style="text-align: justify;">We begin in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2<!--tex4ht:ref: sec:Two-parties --></a> with two-party communication complexity. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a> we give a streamlined proof, except for a step that is only sketched, of a result of Gowers and the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-2">GVb</a>]</span> about interleaved group products. In particular we present an alternative proof, communicated to us by Will Sawin, of a lemma from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. We then consider two models of three-party communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-70004">4<!--tex4ht:ref: sec:Three-parties,-number-in-hand --></a> we consider number-in-hand protocols, and we relate the communication complexity to so-called <em>quasirandom groups</em> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span>. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-140006">6<!--tex4ht:ref: sec:Three-parties,-number-on-forehea --></a> we consider number-in-hand protocols, and specifically the problem of separating deterministic and randomized communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-150007">7<!--tex4ht:ref: sec:The-corners-theorem --></a> we give an exposition of a result by Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, and show that it implies a separation that matches the state-of-the-art <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span> but applies to a different problem.</p>
<p style="text-align: justify;">Some of the sections follow closely a set of lectures by the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-special-topics17">Vio17</a>]</span>; related material can also be found in the blog posts <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>. One of the goals of this survey is to present this material in a more organized matter, in addition to including new material.</p>
<h3 class="sectionHead"><span class="titlemark">2 </span> <a id="x1-20002"/>Two parties</h3>
<p style="text-align: justify;">Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group and let us start by considering the following basic communication task. Alice gets an element <img alt="x\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in G"/> and Bob gets an element <img alt="y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\in G"/> and their goal is to check if <img alt="x\cdot y=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y=1_{G}"/>. How much communication do they need? Well, <img alt="x\cdot y=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y=1_{G}"/> is equivalent to <img alt="x=y^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=y^{-1}"/>. Because Bob can compute <img alt="y^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y^{-1}"/> without communication, this problem is just a rephrasing of the <em>equality</em> problem, which has a randomized protocol with constant communication. This holds for any group.</p>
<p style="text-align: justify;">The same is true if Alice gets two elements <img alt="x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}"/> and <img alt="x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}"/> and they need to check if <img alt="x_{1}\cdot y\cdot x_{2}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y%5Ccdot+x_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y\cdot x_{2}=1_{G}"/>. Indeed, it is just checking equality of <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> and <img alt="x_{1}^{-1}\cdot x_{2}^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5E%7B-1%7D%5Ccdot+x_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}^{-1}\cdot x_{2}^{-1}"/>, and again Alice can compute the latter without communication.</p>
<p style="text-align: justify;">Things get more interesting if both Alice and Bob get two elements and they need to check if the <em>interleaved product</em> of the elements of Alice and Bob equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>, that is, if</p>
<div style="text-align: center;"><img alt="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}"/></div>
<p style="text-align: justify;">Now the previous transformations don’t help anymore. In fact, the complexity depends on the group. If it is abelian then the elements can be reordered and the problem is equivalent to checking if <img alt="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%5Ccdot+x_%7B2%7D%29%5Ccdot+%28y_%7B1%7D%5Ccdot+y_%7B2%7D%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}"/>. Again, Alice can compute <img alt="x_{1}\cdot x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot x_{2}"/> without communication, and Bob can compute <img alt="y_{1}\cdot y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1}\cdot y_{2}"/> without communication. So this is the same problem as before and it has a constant communication protocol.</p>
<p style="text-align: justify;">For non-abelian groups this reordering cannot be done, and the problem seems hard. This can be formalized for a class of groups that are “far from abelian” – or we can take this result as a definition of being far from abelian. One of the groups that works best in this sense is the following, first constructed by Galois in the 1830’s.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2001r1"/> Definition 1. </span>The<em> special linear group </em><img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> is the group of <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/> invertible matrices over the field <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> with determinant <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The following result was asked in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span> and was proved in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-2002r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> and let <img alt="h\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\ne 1_{G}"/>. Suppose Alice receives <img alt="x_{1},x_{2}\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2}\in G"/> and Bob receives <img alt="y_{1},y_{2}\in G" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2}\in G"/>. They are promised that <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication <img alt="\Omega (\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log |G|)"/>.</p>
<p style="text-align: justify;">This bound is tight as Alice can send her input, taking <img alt="O(\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log |G|)"/> bits. We present the proof of this theorem in the next section.</p>
<p style="text-align: justify;">Similar results are known for other groups as well, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. For example, one group that is “between” abelian groups and <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> is the following.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2003r2"/> Definition 2. </span>The<em> alternating group</em> <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> is the group of even permutations of <img alt="1,2,\ldots ,n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2C2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1,2,\ldots ,n"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">If we work over <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> instead of <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> in Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> then the communication complexity is <img alt="\Omega (\log \log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. The latter bound is tight <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>: with knowledge of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>, the parties can agree on an element <img alt="a\in {1,2,\ldots ,n}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Cin+%7B1%2C2%2C%5Cldots+%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\in {1,2,\ldots ,n}"/> such that <img alt="h(a)\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(a)\ne a"/>. Hence they only need to keep track of the image <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>. This takes communication <img alt="O(\log n)=O(\log \log |A_{n}|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+n%29%3DO%28%5Clog+%5Clog+%7CA_%7Bn%7D%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log n)=O(\log \log |A_{n}|)"/> because <img alt="|A_{n}|=n!/2." class="latex" src="https://s0.wp.com/latex.php?latex=%7CA_%7Bn%7D%7C%3Dn%21%2F2.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A_{n}|=n!/2."/> In more detail, the protocol is as follows. First Bob sends <img alt="y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{2}(a)"/>. Then Alice sends <img alt="x_{2}y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}y_{2}(a)"/>. Then Bob sends <img alt="y_{1}x_{2}y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1}x_{2}y_{2}(a)"/> and finally Alice can check if <img alt="x_{1}y_{1}x_{2}y_{2}(a)=a" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7Dy_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}y_{1}x_{2}y_{2}(a)=a"/>.</p>
<p style="text-align: justify;">Interestingly, to decide if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> without the promise a stronger lower bound can be proved for many groups, including <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>, see Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3<!--tex4ht:ref: cor:A_n-bound --></a> below.</p>
<p style="text-align: justify;">In general, it seems an interesting open problem to try to understand for which groups Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> applies. For example, is the communication large for every quasirandom group <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>?</p>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> and the corresponding results for other groups also scale with the length of the product: for example deciding if <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdots+x_%7Bn%7D%5Ccdot+y_%7Bn%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}"/> over <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> requires communication <img alt="\Omega (n\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n\log |G|)"/> which is tight.</p>
<p style="text-align: justify;">A strength of the above results is that they hold for any choice of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> in the promise. This makes them equivalent to certain <img alt="mixing" class="latex" src="https://s0.wp.com/latex.php?latex=mixing&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="mixing"/> results, discussed below in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-120005.0.1">5.0.1<!--tex4ht:ref: subsec:-mixing --></a>. Next we prove two other lower bounds that do not have this property and can be obtained by reduction from <em>disjointness</em>. First we show that for any non-abelian group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> there exists an element <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> such that deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> or <img alt="g=h" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=h"/> requires communication linear in the length of the product. Interestingly, the proof works for any non-abelian group. The choice of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> is critical, as for some <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> the problem is easy. For example: take any group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and consider <img alt="H:=G\times \mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=H%3A%3DG%5Ctimes+%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H:=G\times \mathbb {Z}_{2}"/> where <img alt="\mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{2}"/> is the group of integers with addition modulo <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>. Distinguishing between <img alt="1_{H}=(1_{G},0)" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BH%7D%3D%281_%7BG%7D%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{H}=(1_{G},0)"/> and <img alt="h=(1_{G},1)" class="latex" src="https://s0.wp.com/latex.php?latex=h%3D%281_%7BG%7D%2C1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h=(1_{G},1)"/> amounts to computing the parity of (the <img alt="\mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{2}"/> components of) the input, which takes constant communication. <a id="x1-2004r2"/></p>
<p style="text-align: justify;"><b>Theorem 2.</b> Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a non-abelian group. There exists <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/> such that the following holds. Suppose Alice receives <img alt="x_{1},x_{2},\ldots ,x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2},\ldots ,x_{n}"/> and receives <img alt="y_{1},y_{2},\ldots ,y_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%2C%5Cldots+%2Cy_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2},\ldots ,y_{n}"/>. They are promised that <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D%5Ccdot+y_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We reduce from <em>unique set-disjointness</em>, defined below. For the reduction we encode the And of two bits <img alt="s,t\in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s,t\in \{0,1\}"/> as a group product. This encoding is similar to the famous puzzle that asks to hang a picture on a wall with two nails in such a way that the picture falls if either one of the nails is removed. Since <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is non-abelian, there exist <img alt="a,b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,b\in G"/> such that <img alt="a\cdot b\neq b\cdot a" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Cneq+b%5Ccdot+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot b\neq b\cdot a"/>, and in particular <img alt="a\cdot b\cdot a^{-1}\cdot b^{-1}=h" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Ccdot+a%5E%7B-1%7D%5Ccdot+b%5E%7B-1%7D%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot b\cdot a^{-1}\cdot b^{-1}=h"/> with <img alt="h\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\neq 1"/>. We can use this fact to encode the And of <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> and <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> as</p>
<div style="text-align: center;"><img alt="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7Bs%7D%5Ccdot+b%5E%7Bt%7D%5Ccdot+a%5E%7B-s%7D%5Ccdot+b%5E%7B-t%7D%3D%5Cbegin+%7Bcases%7D+1%7E%7E%5Ctext+%7Bif+And%5Censuremath+%7B%28s%2Ct%29%3D0%7D%7D%5C%5C+h%7E%7E%5Ctext+%7Botherwise%7D+%5Cend+%7Bcases%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}"/></div>
<p style="text-align: justify;">In the disjointness problem Alice and Bob get inputs <img alt="x,y\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^{n}"/> respectively, and they wish to check if there exists an <img alt="i\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in [n]"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/>. If you think of <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> as characteristic vectors of sets, this problem is asking if the sets have a common element or not. The communication of this problem is <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span>. Moreover, in the “unique” variant of this problem where the number of such <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>’s is 0 or 1, the same lower bound <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> still applies. This follows from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span> – see also Proposition 3.3 in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAMS99">AMS99</a>]</span>. For more on disjointness see the surveys <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XSherstov14-35years">She14</a>, <a href="https://emanueleviola.wordpress.com/feed/journals/sigact/ChattopadhyayP10">CP10</a>]</span>.</p>
<p style="text-align: justify;">We will reduce unique disjointness to group products. For <img alt="x,y\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^{n}"/> we produce inputs for the group problem as follows:</p>
<div style="text-align: center;"><img alt="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x+%26+%5Crightarrow+%28a%5E%7Bx_%7B1%7D%7D%2Ca%5E%7B-x_%7B1%7D%7D%2C%5Cldots+%2Ca%5E%7Bx_%7Bn%7D%7D%2Ca%5E%7B-x_%7Bn%7D%7D%29%5C%5C+y+%26+%5Crightarrow+%28b%5E%7By_%7B1%7D%7D%2Cb%5E%7B-y_%7B1%7D%7D%2C%5Cldots+%2Cb%5E%7By_%7Bn%7D%7D%2Cb%5E%7B-y_%7Bn%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}"/></div>
<p style="text-align: justify;">The group product becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cunderbrace+%7Ba%5E%7Bx_%7B1%7D%7D%5Ccdot+b%5E%7By_%7B1%7D%7D%5Ccdot+a%5E%7B-x_%7B1%7D%7D%5Ccdot+b%5E%7B-y_%7B1%7D%7D%7D_%7B%5Ctext+%7B1+bit%7D%7D%5Ccdots+%5Ccdots+a%5E%7Bx_%7Bn%7D%7D%5Ccdot+b%5E%7By_%7Bn%7D%7D%5Ccdot+a%5E%7B-x_%7Bn%7D%7D%5Ccdot+b%5E%7B-y_%7Bn%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}"/></div>
<p style="text-align: justify;">If there isn’t an <img alt="i\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in [n]"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/>, then for each <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> the term <img alt="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%7Bx_%7Bi%7D%7D%5Ccdot+b%5E%7By_%7Bi%7D%7D%5Ccdot+a%5E%7B-x_%7Bi%7D%7D%5Ccdot+b%5E%7B-y_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}"/> is <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>, and thus the whole product is 1.</p>
<p style="text-align: justify;">Otherwise, there exists a unique <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/> and thus the product will be <img alt="1\cdots 1\cdot h\cdot 1\cdots 1=h" class="latex" src="https://s0.wp.com/latex.php?latex=1%5Ccdots+1%5Ccdot+h%5Ccdot+1%5Ccdots+1%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1\cdots 1\cdot h\cdot 1\cdots 1=h"/>, with <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> being in the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th position. If Alice and Bob can check if the above product is equal to 1, they can also solve the unique set disjointness problem, and thus the lower bound applies for the former. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">We required the uniqueness property, because otherwise we might get a product <img alt="h^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h^{c}"/> that could be equal to 1 in some groups.</p>
<p style="text-align: justify;">Next we prove a result for products of length just <img alt="4" class="latex" src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="4"/>; it applies to non-abelian groups of the form <img alt="G=H^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=H^{n}"/> and not with the promise. <a id="x1-2005r3"/></p>
<p style="text-align: justify;"><b>Theorem 3.</b> Let <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> be a non-abelian group and consider <img alt="G=H^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=H^{n}"/>. Suppose Alice receives <img alt="x_{1},x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2}"/> and Bob receives <img alt="y_{1},y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2}"/>. Deciding if <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}"/> requires randomized communication <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>The proof is similar to the proof of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2004r2">2<!--tex4ht:ref: thm:for-every-non-abelian --></a>. We use coordinate <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> to encode bit <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of the disjointness instance. If there is no intersection in the latter, the product will be <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>. Otherwise, at least some coordinate will be <img alt="\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ne 1_{G}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">As a corollary we can prove a lower bound for <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2006r3"/> Corollary 3. </span>Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a> holds for <img alt="G=A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DA_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=A_{n}"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Note that <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> contains <img alt="(A_{4})^{\lfloor n/4\rfloor }" class="latex" src="https://s0.wp.com/latex.php?latex=%28A_%7B4%7D%29%5E%7B%5Clfloor+n%2F4%5Crfloor+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A_{4})^{\lfloor n/4\rfloor }"/> and that <img alt="A_{4}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{4}"/> is not abelian. Apply Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a> is tight for constant-size <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. We do not know if Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3<!--tex4ht:ref: cor:A_n-bound --></a> is tight. The trivial upper bound is <img alt="O(\log |A_{n}|)=O(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CA_%7Bn%7D%7C%29%3DO%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log |A_{n}|)=O(n\log n)"/>.</p>
<h3 class="sectionHead"><span class="titlemark">3 </span> <a id="x1-30003"/>Proof of Theorem 1</h3>
<p style="text-align: justify;">Several related proofs of this theorem exist, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>, <a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. As in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>, the proof that we present can be broken down in three steps. First we reduce the problem to a statement about conjugacy classes. Second we reduce this to a statement about trace maps. Third we prove the latter. We present the first step in a way that is similar but slightly different from the presentation in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. The second step is only sketched, but relies on classical results about <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> and can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. For the third we present a proof that was communicated to us by Will Sawin. We thank him for his permission to include it here.</p>
<h4 class="subsectionHead"><span class="titlemark">3.1 </span> <a id="x1-40003.1"/>Step 1</h4>
<p style="text-align: justify;">We would like to rule out randomized protocols, but it is hard to reason about them directly. Instead, we are going to rule out deterministic protocols on random inputs. First, for any group element <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we define the distribution on quadruples <img alt="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x_%7B1%7D%2Cy_%7B1%7D%2Cx_%7B2%7D%2C%28x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)"/>, where <img alt="x,y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in G"/> are uniformly random elements. Note the product of the elements in <img alt="D_{g}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}"/> is always <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>.</p>
<p style="text-align: justify;">Towards a contradiction, suppose we have a randomized protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> such that</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5BP%28D_%7B1%7D%29%3D1%5D%5Cgeq+%5Cmathbb%7BP%7D+%5BP%28D_%7Bh%7D%29%3D1%5D%2B%5Cfrac+%7B1%7D%7B10%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}"/></div>
<p>This implies a deterministic protocol with the same gap, by fixing the randomness.</p>
<p style="text-align: justify;">We reach a contradiction by showing that for every deterministic protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> using little communication, we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}"/></div>
<p style="text-align: justify;">We start with the following standard lemma, which describes a protocol using product sets.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-4001r4"/> Lemma 4. </span>(The set of accepted inputs of) A deterministic <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol for a function <img alt="f:X\times Y\to Z" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AX%5Ctimes+Y%5Cto+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:X\times Y\to Z"/> can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> rectangles, where a rectangle is a set of the form <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> with <img alt="A\subseteq X" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq X"/> and <img alt="B\subseteq Y" class="latex" src="https://s0.wp.com/latex.php?latex=B%5Csubseteq+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B\subseteq Y"/> and where <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is constant.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>(sketch) For every communication transcript <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, let <img alt="S_{t}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_{t}\subseteq G^{2}"/> be the set of inputs giving transcript <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. The sets <img alt="S_{t}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_{t}"/> are disjoint since an input gives only one transcript, and their number is <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/>: one for each communication transcript of the protocol. The rectangle property can be proven by induction on the protocol tree. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Next, we show that any rectangle <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> cannot distinguish <img alt="D_{1},D_{h}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1},D_{h}"/>. The way we achieve this is by showing that for every <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> the probability that <img alt="(A\times B)(D_{g})=1" class="latex" src="https://s0.wp.com/latex.php?latex=%28A%5Ctimes+B%29%28D_%7Bg%7D%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A\times B)(D_{g})=1"/> is roughly the same for every <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>, and is roughly the density of the rectangle. (Here we write <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> for the characteristic function of the set <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/>.) Without loss of generality we set <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/>. Let <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> have density <img alt="\alpha " class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha "/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> have density <img alt="\beta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta "/>. We aim to bound above</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29B%28b_%7B1%7D%2Cb_%7B2%7D%29-%5Calpha+%5Cbeta+%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}"/></div>
<p>where note the distribution of <img alt="a_{1},b_{1},a_{2},b_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1},b_{1},a_{2},b_{2}"/> is the same as <img alt="D_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1}"/>.</p>
<p style="text-align: justify;">Because the distribution of <img alt="(b_{1},b_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28b_%7B1%7D%2Cb_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(b_{1},b_{2})"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>, the above can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%5E%7B2%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Cbeta+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%2Ca_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7D%27%2Ca_%7B2%7D%27%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27b_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7D%27%2Ca_%7B2%7D%27%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}"/></div>
<p style="text-align: justify;">The inequality is Cauchy-Schwarz, and the step after that is obtained by expanding the square and noting that <img alt="(a_{1},a_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28a_%7B1%7D%2Ca_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a_{1},a_{2})"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>, so that the expectation of the term <img alt="A(a_{1},a_{2})\alpha " class="latex" src="https://s0.wp.com/latex.php?latex=A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(a_{1},a_{2})\alpha "/> is <img alt="\alpha ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha ^{2}"/>.</p>
<p style="text-align: justify;">Now we do several transformations to rewrite the distribution in the last expectation in a convenient form. First, right-multiplying by <img alt="b_{2}^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=b_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b_{2}^{-1}"/> we can rewrite the distribution as the uniform distribution on tuples such that</p>
<div style="text-align: center;"><img alt="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}"/></div>
<p style="text-align: justify;">The last equation is equivalent to <img alt="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'" class="latex" src="https://s0.wp.com/latex.php?latex=b_%7B1%7D%5E%7B-1%7D%28a_%7B1%7D%27%29%5E%7B-1%7Da_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B2%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'"/>.</p>
<p style="text-align: justify;">We can now do a transformation setting <img alt="a_{1}'" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1}'"/> to be <img alt="a_{1}x^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7Dx%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1}x^{-1}"/> to rewrite the distribution of the four-tuple as</p>
<div style="text-align: center;"><img alt="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}"/></div>
<p>where we use <img alt="C(x)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)"/> to denote a uniform element from the conjugacy class of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, that is <img alt="b^{-1}xb" class="latex" src="https://s0.wp.com/latex.php?latex=b%5E%7B-1%7Dxb&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b^{-1}xb"/> for a uniform <img alt="b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=b%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b\in G"/>.</p>
<p style="text-align: justify;">Hence it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}"/></div>
<p>where all the variables are uniform and independent.</p>
<p style="text-align: justify;">With a similar derivation as above, this can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Cmathbb%7BE%7D+%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca%7B%7D_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Bx%7D%5E%7B2%7D%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Calpha+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}"/></div>
<p style="text-align: justify;">Here each occurrence of <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> denotes a uniform and independent conjugate. Hence it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}"/></div>
<p style="text-align: justify;">We can now replace <img alt="a_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{2}"/> with <img alt="C(x)^{-1}a_{2}." class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7Da_%7B2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)^{-1}a_{2}."/> Because <img alt="C(x)^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)^{-1}"/> has the same distribution of <img alt="C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x^{-1})"/>, it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29C%28x%5E%7B-1%7D%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}"/></div>
<p style="text-align: justify;">For this, it is enough to show that with high probability <img alt="1-1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1-1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1-1/|G|^{\Omega (1)}"/> over <img alt="x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'"/> and <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, the distribution of <img alt="C(x')C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x')C(x^{-1})"/>, over the choice of the two independent conjugates, has statistical distance <img alt="\le 1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cle+1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\le 1/|G|^{\Omega (1)}"/> from uniform.</p>
<h4 class="subsectionHead"><span class="titlemark">3.2 </span> <a id="x1-50003.2"/>Step 2</h4>
<p style="text-align: justify;">In this step we use information on the conjugacy classes of the group to reduce the latter task to one about the equidistribution of the trace map. Let <img alt="Tr" class="latex" src="https://s0.wp.com/latex.php?latex=Tr&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr"/> be the Trace map:</p>
<div style="text-align: center;"><img alt="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cbegin+%7Bpmatrix%7Da_%7B1%7D+%26+a_%7B2%7D%5C%5C+a_%7B3%7D+%26+a_%7B4%7D+%5Cend+%7Bpmatrix%7D%3Da_%7B1%7D%2Ba_%7B4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}"/></div>
<p style="text-align: justify;">We state the lemma that we want to show.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-5001r5"/> Lemma 5. </span>Let <img alt="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=a%3A%3D%5Cbegin+%7Bpmatrix%7D0+%26+1%5C%5C+1+%26+w+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}"/> and <img alt="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=b%3A%3D%5Cbegin+%7Bpmatrix%7Dv+%26+1%5C%5C+1+%26+0+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}"/>. For all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="w\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=w%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w\in \mathbb{F} _{q}"/> and <img alt="v\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=v%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v\in \mathbb{F} _{q}"/>, the distribution of</p>
<div style="text-align: center;"><img alt="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cleft+%28au%5E%7B-1%7Dbu%5Cright+%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}"/></div>
<p>is <img alt="O(1/q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q)"/> close to uniform over <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> in statistical distance.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">To give some context, in <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> the conjugacy class of an element is essentially determined by the trace. Moreover, we can think of <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> and <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> as generic elements in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. So the lemma can be interpreted as saying that for typical <img alt="a,b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,b\in G"/>, taking a uniform element from the conjugacy class of <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> and multiplying it by <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> yields an element whose conjugacy class is uniform among the classes of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Using that essentially all conjugacy classes are equal, and some of the properties of the trace map, one can show that the above lemma implies that for typical <img alt="x,x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cx%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,x'"/> the distribution of <img alt="C(x')C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x')C(x^{-1})"/> is close to uniform. For more on how this fits we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<h4 class="subsectionHead"><span class="titlemark">3.3 </span> <a id="x1-60003.3"/>Step 3</h4>
<p style="text-align: justify;">We now present a proof of Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-5001r5">5<!--tex4ht:ref: lem:trace --></a>. The high-level argument of the proof is the same as in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> (Lemma 5.5), but the details may be more accessible and in particular the use of the Lang-Weil theorem <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XLangWeil54">LW54</a>]</span> from algebraic geometry is replaced by a more elementary argument. For simplicity we shall only cover the case where <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> is prime. We will show that for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="v,w,c\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=v%2Cw%2Cc%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v,w,c\in \mathbb{F} _{q}"/>, the probability over <img alt="u" class="latex" src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u"/> that <img alt="Tr(au^{-1}bu)=c" class="latex" src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr(au^{-1}bu)=c"/> is within <img alt="O(1/q^{2})" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q^{2})"/> of <img alt="1/q" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fq&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/q"/>, and for the others it is at most <img alt="O(1/q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q)"/>. Summing over <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> gives the result.</p>
<p style="text-align: justify;">We shall consider elements <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> whose trace is unique to the conjugacy class of <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/>. (This holds for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> conjugacy classes – see for example <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> for details.) This means that the distribution of <img alt="u^{-1}bu" class="latex" src="https://s0.wp.com/latex.php?latex=u%5E%7B-1%7Dbu&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u^{-1}bu"/> is that of a uniform element in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> conditioned on having trace <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/>. Hence, we can write the probability that <img alt="Tr(au^{-1}bu)=c" class="latex" src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr(au^{-1}bu)=c"/> as the number of solutions in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> to the following three equations (divided by the size of the group, which is <img alt="q^{3}-q" class="latex" src="https://s0.wp.com/latex.php?latex=q%5E%7B3%7D-q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q^{3}-q"/>):</p>
<div style="text-align: center;"><img alt="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B3%7D%2Bx_%7B2%7D%2Bwx_%7B4%7D+%26+%3Dc+%26+%5Chspace+%7B1cm%7D%28Tr%28ax%29%3Dc%29%2C%5C%5C+x_%7B1%7D%2Bx_%7B4%7D+%26+%3Dv+%26+%5Chspace+%7B1cm%7D%28Tr%28x%29%3DTr%28b%29%29%2C%5C%5C+x_%7B1%7Dx_%7B4%7D-x_%7B3%7Dx_%7B3%7D+%26+%3D1+%26+%5Chspace+%7B1cm%7D%28Det%28x%29%3D1%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}"/></div>
<p style="text-align: justify;">We use the second one to remove <img alt="x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}"/> and the first one to remove <img alt="x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}"/> from the last equation. This gives</p>
<div style="text-align: center;"><img alt="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28v-x_%7B4%7D%29x_%7B4%7D-%28c-x_%7B3%7D-wx_%7B4%7D%29x_%7B3%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}"/></div>
<p style="text-align: justify;">This is an equation in two variables. Write <img alt="x=x_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x_{3}"/> and <img alt="y=x_{4}" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Dx_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y=x_{4}"/> and use distributivity to rewrite the equation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-cx%2Bx%5E%7B2%7D%2Bwxy%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}"/></div>
<p style="text-align: justify;">At least since Lagrange it has been known how to reduce this to a Pell equation <img alt="x^{2}+dy^{2}=e" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}+dy^{2}=e"/>. This is done by applying an invertible affine transformation, which does not change the number of solutions. First set <img alt="x=x-wy/2" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx-wy%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x-wy/2"/>. Then the equation becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-c%28x-wy%2F2%29%2B%28x-wy%2F2%29%5E%7B2%7D%2Bw%28x-wy%2F2%29y%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}"/></div>
<p style="text-align: justify;">Equivalently, the cross-term has disappeared and we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2By%28v%2Bcw%2F2%29%2Bx%5E%7B2%7D-cx%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}"/></div>
<p style="text-align: justify;">Now one can add constants to <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> to remove the linear terms, changing the constant term. Specifically, let <img alt="h:=(v+cw/2)/2" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%3D%28v%2Bcw%2F2%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h:=(v+cw/2)/2"/> and set <img alt="y=y-h" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Dy-h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y=y-h"/> and <img alt="x=x+c/2" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx%2Bc%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x+c/2"/>. The equation becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28y-h%29%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2B%28y-h%292h%2B%28x%2Bc%2F2%29%5E%7B2%7D-c%28x%2Bc%2F2%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}"/></div>
<p style="text-align: justify;">The linear terms disappear, the coefficients of <img alt="x^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}"/> and <img alt="y^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y^{2}"/> do not change and the equation can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2Bh%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29-2h%5E%7B2%7D%2Bx%5E%7B2%7D%2B%28c%2F2%29%5E%7B2%7D-c%5E%7B2%7D%2F2%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}"/></div>
<p style="text-align: justify;">So this is now a Pell equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}"/></div>
<p style="text-align: justify;">where <img alt="d:=(-1-w^{2}/4)" class="latex" src="https://s0.wp.com/latex.php?latex=d%3A%3D%28-1-w%5E%7B2%7D%2F4%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d:=(-1-w^{2}/4)"/> and</p>
<div style="text-align: center;"><img alt="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+e%3A%3D1%2Bh%5E%7B2%7D%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D%3D1%2B%28v%5E%7B2%7D%2B%28cw%2F2%29%5E%7B2%7D%2Bcvw%29%281%2F4%29%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}"/></div>
<p style="text-align: justify;">For all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w"/> we have that <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is non-zero. Moreover, for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="v,w" class="latex" src="https://s0.wp.com/latex.php?latex=v%2Cw&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v,w"/> the term <img alt="e" class="latex" src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e"/> is a non-zero polynomial in <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. (Specifically, for any <img alt="v\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=v%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v\ne 0"/> and any <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w"/> such that <img alt="3+w^{2}/4\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=3%2Bw%5E%7B2%7D%2F4%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3+w^{2}/4\ne 0"/>.) So we only consider the values of <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> that make it non-zero. Those where <img alt="e=0" class="latex" src="https://s0.wp.com/latex.php?latex=e%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e=0"/> give <img alt="O(q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(q)"/> solutions, which is fine. We conclude with the following lemma.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-6001r6"/> Lemma 6. </span>For <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> and <img alt="e" class="latex" src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e"/> non-zero, and prime <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/>, the number of solutions over <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> to the Pell equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}"/></div>
<p style="text-align: justify;">is within <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> of <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">This is a basic result from algebraic geometry that can be proved from first principles.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>If <img alt="d=-f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%3D-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d=-f^{2}"/> for some <img alt="f\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in \mathbb{F} _{q}"/>, then we can replace <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> with <img alt="fy" class="latex" src="https://s0.wp.com/latex.php?latex=fy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="fy"/> and we can count instead the solutions to the equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D-y%5E%7B2%7D%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}"/></div>
<p style="text-align: justify;">Because <img alt="x^{2}-y^{2}=(x-y)(x+y)" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D-y%5E%7B2%7D%3D%28x-y%29%28x%2By%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}-y^{2}=(x-y)(x+y)"/> we can set <img alt="x':=x-y" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%3A%3Dx-y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x':=x-y"/> and <img alt="y':=x+y" class="latex" src="https://s0.wp.com/latex.php?latex=y%27%3A%3Dx%2By&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y':=x+y"/>, which preserves the number of solutions, and rewrite the equation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} x'y'=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%27y%27%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x'y'=e. \end{aligned}"/></div>
<p style="text-align: justify;">Because <img alt="e\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=e%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e\ne 0"/>, this has <img alt="q-1" class="latex" src="https://s0.wp.com/latex.php?latex=q-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q-1"/> solutions: for every non-zero <img alt="y'" class="latex" src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y'"/> we have <img alt="x'=e/y'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%3De%2Fy%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'=e/y'"/>.</p>
<p style="text-align: justify;">So now we can assume that <img alt="d\ne -f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne -f^{2}"/> for any <img alt="f\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in \mathbb{F} _{q}"/>. Because the number of squares is <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>, the range of <img alt="x^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}"/> has size <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>. Similarly, the range of <img alt="e-dy^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=e-dy%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e-dy^{2}"/> also has size <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>. Hence these two ranges intersect, and there is a solution <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>.</p>
<p style="text-align: justify;">We take a line passing through <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>: for parameters <img alt="s,t\in \mathbb{F} " class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5Cmathbb%7BF%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s,t\in \mathbb{F} "/> we consider pairs <img alt="(a+t,b+st)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Bt%2Cb%2Bst%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a+t,b+st)"/>. There is a bijection between such pairs with <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/> and the points <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> with <img alt="x\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\ne a"/>. Because the number of solutions with <img alt="x=a" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=a"/> is <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>, using that <img alt="d\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne 0"/>, it suffices to count the solutions with <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/>.</p>
<p style="text-align: justify;">The intuition is that this line has two intersections with the curve <img alt="x^{2}+dy^{2}=e" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}+dy^{2}=e"/>. Because one of them, <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>, lies in <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/>, the other has to lie as well there. Algebraically, we can plug the pair in the expression to obtain the equivalent equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7B2%7D%2Bt%5E%7B2%7D%2B2at%2Bd%28b%5E%7B2%7D%2Bs%5E%7B2%7Dt%5E%7B2%7D%2B2bst%29%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}"/></div>
<p style="text-align: justify;">Using that <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/> is a solution this becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5E%7B2%7D%2B2at%2Bds%5E%7B2%7Dt%5E%7B2%7D%2B2dbst%3D0+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}"/></div>
<p style="text-align: justify;">We can divide by <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/>. Obtaining</p>
<div style="text-align: center;"><img alt="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%281%2Bds%5E%7B2%7D%29%2B2a%2B2dbs%3D0.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}"/></div>
<p style="text-align: justify;">We can now divide by <img alt="1+ds^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bds%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1+ds^{2}"/> which is non-zero by the assumption <img alt="d\ne -f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne -f^{2}"/>. This yields</p>
<div style="text-align: center;"><img alt="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%3D%28-2a-2dbs%29%2F%281%2Bds%5E%7B2%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}"/></div>
<p style="text-align: justify;">Hence for every value of <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> there is a unique <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> giving a solution. This gives <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> solutions. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h3 class="sectionHead"><span class="titlemark">4 </span> <a id="x1-70004"/>Three parties, number-in-hand</h3>
<p style="text-align: justify;">In this section we consider the following three-party number-in-hand problem: Alice gets <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, Bob gets <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/>, Charlie gets <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/>, and they want to know if <img alt="x\cdot y\cdot z=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z=1_{G}"/>. The communication depends on the group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. We present next two efficient protocols for abelian groups, and then a communication lower bound for other groups.</p>
<h4 class="subsectionHead"><span class="titlemark">4.1 </span> <a id="x1-80004.1"/>A randomized protocol for the hypercube</h4>
<p style="text-align: justify;">We begin with the simplest setting. Let <img alt="G=(\mathbb {Z}_{2})^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%28%5Cmathbb+%7BZ%7D_%7B2%7D%29%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=(\mathbb {Z}_{2})^{n}"/>, that is <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-bit strings with bit-wise addition modulo 2. The parties want to check if <img alt="x+y+z=0^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0^{n}"/>. They can do so as follows. First, they pick a hash function <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> that is linear: <img alt="h(x+y)=h(x)+h(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h%28x%2By%29%3Dh%28x%29%2Bh%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(x+y)=h(x)+h(y)"/>. Specifically, for a uniformly random <img alt="a\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\in \{0,1\}^{n}"/> define <img alt="h_{a}(x):=\sum a_{i}x_{i}\mod 2" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3A%3D%5Csum+a_%7Bi%7Dx_%7Bi%7D%5Cmod+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x):=\sum a_{i}x_{i}\mod 2"/>. Then, the protocol is as follows.</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img alt="h_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)"/>,</li>
<li class="itemize">Bob send <img alt="h_{a}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(y)"/>,</li>
<li class="itemize">Charlie accepts if and only if <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3D0s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s"/>.</li>
</ul>
<p style="text-align: justify;">The hash function outputs 1 bit, so the communication is constant. By linearity, the protocol accepts iff <img alt="h_{a}(x+y+z)=0" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)=0"/>. If <img alt="x+y+z=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0"/> this is always the case, otherwise it happens with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>.</p>
<h4 class="subsectionHead"><span class="titlemark">4.2 </span> <a id="x1-90004.2"/>A randomized protocol for <img alt="\mathbb {Z}_{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{N}"/></h4>
<p style="text-align: justify;">This protocol is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. For simplicity we only consider the case <img alt="N=2^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^{n}"/> here – the protocol for general <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> is in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. Again, the parties want to check if <img alt="x+y+z=0\mod N" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5Cmod+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0\mod N"/>. For this group, there is no 100% linear hash function but there are almost linear hash functions <img alt="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%5Cmathbb+%7BZ%7D_%7BN%7D%5Crightarrow+%5Cmathbb+%7BZ%7D_%7B2%5E%7B%5Cell+%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}"/> that satisfy the following properties. Note that the inputs to <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> are interpreted modulo <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> and the outputs modulo <img alt="2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{\ell }"/>.</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9002x1">for all <img alt="a,x,y" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cx%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,x,y"/> there is <img alt="c\in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1\}"/> such that <img alt="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3Dh_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c"/>,</li>
<li class="enumerate" id="x1-9004x2">for all <img alt="x\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\neq 0"/> we have <img alt="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7Ba%7D%5Bh_%7Ba%7D%28x%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D%5D%5Cleq+O%281%2F2%5E%7B%5Cell+%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })"/>,</li>
<li class="enumerate" id="x1-9006x3"><img alt="h_{a}(0)=0" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%280%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(0)=0"/>.</li>
</ol>
<p style="text-align: justify;">Assuming some random hash function <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> that satisfies the above properties the protocol works similarly to the previous one:</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img alt="h_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)"/>,</li>
<li class="itemize">Bob sends <img alt="h_{a}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(y)"/>,</li>
<li class="itemize">Charlie accepts if and only if <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}"/>.</li>
</ul>
<p style="text-align: justify;">We can set <img alt="\ell =O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell+%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell =O(1)"/> to achieve constant communication and constant error.</p>
<p style="text-align: justify;">To prove correctness of the protocol, first note that <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3Dh_%7Ba%7D%28x%2By%2Bz%29-c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c"/> for some <img alt="c\in \{0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1,2\}"/>. Then consider the following two cases:</p>
<ul class="itemize1">
<li class="itemize">if <img alt="x+y+z=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0"/> then <img alt="h_{a}(x+y+z)-c=h_{a}(0)-c=-c," class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%3Dh_%7Ba%7D%280%29-c%3D-c%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)-c=h_{a}(0)-c=-c,"/> and the protocol is always correct.</li>
<li class="itemize">if <img alt="x+y+z\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z\neq 0"/> then the probability that <img alt="h_{a}(x+y+z)-c\in \{-2,-1,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)-c\in \{-2,-1,0\}"/> for some <img alt="c\in \{0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1,2\}"/> is at most the probability that <img alt="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}"/> which is <img alt="\leq 2^{-\Omega (\ell )}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleq+2%5E%7B-%5COmega+%28%5Cell+%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\leq 2^{-\Omega (\ell )}"/>; so the protocol is correct with high probability.</li>
</ul>
<p style="text-align: justify;"><b>The hash function.</b>.</p>
<p style="text-align: justify;">For the hash function we can use a function analyzed in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XDietzfelbingerHKP97">DHKP97</a>]</span>. Let <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> be a random odd number modulo <img alt="2^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n}"/>. Define</p>
<div style="text-align: center;"><img alt="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+h_%7Ba%7D%28x%29%3A%3D%28a%5Ccdot+x%5Cgg+n-%5Cell+%29%5Cmod+2%5E%7B%5Cell+%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}"/></div>
<p>where the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/> is integer multiplication, and <img alt="\gg " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgg+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gg "/> is bit-shift. In other words we output the bits <img alt="n-\ell +1,n-\ell +2,\ldots ,n" class="latex" src="https://s0.wp.com/latex.php?latex=n-%5Cell+%2B1%2Cn-%5Cell+%2B2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n-\ell +1,n-\ell +2,\ldots ,n"/> of the integer product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/>.</p>
<p style="text-align: justify;">We now verify that the above hash function family satisfies the three properties we required above.</p>
<p style="text-align: justify;">Property (3) is trivially satisfied.</p>
<p style="text-align: justify;">For property (1) we have the following. Let <img alt="s=a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=s%3Da%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s=a\cdot x"/> and <img alt="t=a\cdot y" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%5Ccdot+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a\cdot y"/> and <img alt="u=n-\ell " class="latex" src="https://s0.wp.com/latex.php?latex=u%3Dn-%5Cell+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u=n-\ell "/>. To recap, by definition we have:</p>
<ul class="itemize1">
<li class="itemize"><img alt="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell }," class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3D%28%28s%2Bt%29%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell },"/></li>
<li class="itemize"><img alt="h_{a}(x)=(s\gg u)\mod 2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28s%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)=(s\gg u)\mod 2^{\ell }"/>,</li>
<li class="itemize"><img alt="h_{a}(x)=(t\gg u)\mod 2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28t%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)=(t\gg u)\mod 2^{\ell }"/>.</li>
</ul>
<p style="text-align: justify;">Notice that if in the addition <img alt="s+t" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Bt&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s+t"/> the carry into the <img alt="u+1" class="latex" src="https://s0.wp.com/latex.php?latex=u%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u+1"/> bit is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>, then</p>
<div style="text-align: center;"><img alt="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}"/></div>
<p>otherwise</p>
<div style="text-align: center;"><img alt="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%2B1%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}"/></div>
<p>which concludes the proof for property (1).</p>
<p style="text-align: justify;">Finally, we prove property (2). We start by writing <img alt="x=s\cdot 2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Ds%5Ccdot+2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=s\cdot 2^{c}"/> where <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> is odd. So the binary representation of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> looks like</p>
<div style="text-align: center;"><img alt="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ccdots+%5Ccdots+1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}"/></div>
<p>The binary representation of the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/> for a uniformly random <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> looks like</p>
<div style="text-align: center;"><img alt="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ctextit+%7Buniform%7D%7E1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}"/></div>
<p>We consider the two following cases for the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/>:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9008x1">If <img alt="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x%3D%28%5Cunderbrace+%7B%5Ctextit+%7Buniform%7D%7E1%5Coverbrace+%7B00%7D%5E%7B2%7Ebits%7D%7D_%7B%5Cell+%7Ebits%7D%5Ccdots+0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)"/>, or equivalently <img alt="c\geq n-\ell +2" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cgeq+n-%5Cell+%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\geq n-\ell +2"/>, the output never lands in the bad set <img alt="\{-2,-1,0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{-2,-1,0,1,2\}"/>;</li>
<li class="enumerate" id="x1-9010x2">Otherwise, the hash function output has <img alt="\ell -O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell+-O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell -O(1)"/> uniform bits. For any set <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, the probability that the output lands in <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is at most <img alt="|B|\cdot 2^{-\ell +O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CB%7C%5Ccdot+2%5E%7B-%5Cell+%2BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|B|\cdot 2^{-\ell +O(1)}"/>.</li>
</ol>
<h4 class="subsectionHead"><span class="titlemark">4.3 </span> <a id="x1-100004.3"/>Quasirandom groups</h4>
<p style="text-align: justify;">What happens in other groups? The hash function used in the previous result was fairly non-trivial. Do we have an almost linear hash function for <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/> matrices? The answer is negative. For <img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/> and <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> the problem is hard, even under the promise. For a group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> the complexity can be expressed in terms of a parameter <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> which comes from representation theory. We will not formally define this parameter here, but several qualitatively equivalent formulations can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>. Instead the following table shows the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>’s for the groups we’ve introduced.</p>
<div style="text-align: center;">
<div class="tabular">
<table cellpadding="0" cellspacing="0" class="tabular" id="TBL-1">
<colgroup id="TBL-1-1g">
<col id="TBL-1-1"/></colgroup>
<colgroup id="TBL-1-2g">
<col id="TBL-1-2"/></colgroup>
<colgroup id="TBL-1-3g">
<col id="TBL-1-3"/></colgroup>
<colgroup id="TBL-1-4g">
<col id="TBL-1-4"/></colgroup>
<colgroup id="TBL-1-5g">
<col id="TBL-1-5"/></colgroup>
<tbody>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-1-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-1-1" style="white-space: nowrap; text-align: center;"><img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/></td>
<td class="td11" id="TBL-1-1-2" style="white-space: nowrap; text-align: center;">:</td>
<td class="td11" id="TBL-1-1-3" style="white-space: nowrap; text-align: center;">abelian</td>
<td class="td11" id="TBL-1-1-4" style="white-space: nowrap; text-align: center;"><img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/></td>
<td class="td11" id="TBL-1-1-5" style="white-space: nowrap; text-align: center;"><img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/></td>
</tr>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-2-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-2-1" style="white-space: nowrap; text-align: center;"><img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/></td>
<td class="td11" id="TBL-1-2-2" style="white-space: nowrap; text-align: center;">:</td>
<td class="td11" id="TBL-1-2-3" style="white-space: nowrap; text-align: center;"><img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/></td>
<td class="td11" id="TBL-1-2-4" style="white-space: nowrap; text-align: center;"><img alt="\Omega (\frac {\log |G|}{\log \log |G|})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Cfrac+%7B%5Clog+%7CG%7C%7D%7B%5Clog+%5Clog+%7CG%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\frac {\log |G|}{\log \log |G|})"/></td>
<td class="td11" id="TBL-1-2-5" style="white-space: nowrap; text-align: center;"><img alt="|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|G|^{\Omega (1)}"/></td>
</tr>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-3-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-3-1" style="white-space: nowrap; text-align: center;"/>
</tr>
</tbody>
</table>
</div>
<p>.</p>
</div>
<p> </p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group, and let <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/>. Let <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> be the minimum dimension of any irreducible representation of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Suppose Alice, Bob, and Charlie receive <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, y, and <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> respectively. They are promised that <img alt="x\cdot y\cdot z" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication complexity <img alt="\Omega (\log d)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+d%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log d)"/>.</p>
<p style="text-align: justify;">This result is tight for the groups we have discussed so far. The arguments are the same as before. Specifically, for <img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/> the communication is <img alt="\Omega (\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log |G|)"/>. This is tight up to constants, because Alice and Bob can send their elements. For <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> the communication is <img alt="\Omega (\log \log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)"/>. This is tight as well, as the parties can again just communicate the images of an element <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> such that <img alt="h(a)\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(a)\ne a"/>, as discussed in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a>. This also gives a computational proof that <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> cannot be too large for <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>, i.e., it is at most <img alt="(\log |G|)^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Clog+%7CG%7C%29%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\log |G|)^{O(1)}"/>. For abelian groups we get nothing, matching the efficient protocols given above.</p>
<h3 class="sectionHead"><span class="titlemark">5 </span> <a id="x1-110005"/>Proof of Theorem 1</h3>
<p style="text-align: justify;">First we discuss several “mixing” lemmas for groups, then we come back to protocols and see how to apply one of them there.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.1 </span> <a id="x1-120005.0.1"/><img alt="XY" class="latex" src="https://s0.wp.com/latex.php?latex=XY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="XY"/> mixing</h5>
<p style="text-align: justify;">We want to consider “high entropy” distributions over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, and state a fact showing that the multiplication of two such distributions “mixes” or in other words increases the entropy. To define entropy we use the norms <img alt="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7Bc%7D%3D%5Cleft+%28%5Csum+_%7Bx%7DA%28x%29%5E%7Bc%7D%5Cright+%29%5E%7B%5Cfrac+%7B1%7D%7Bc%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}"/>. Our notion of (non-)entropy will be <img alt="\lVert A\rVert _{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}"/>. Note that <img alt="\lVert A\rVert _{2}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}^{2}"/> is exactly the <em>collision probability</em> <img alt="\mathbb{P} [A=A']" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5BA%3DA%27%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [A=A']"/> where <img alt="A'" class="latex" src="https://s0.wp.com/latex.php?latex=A%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A'"/> is independent and identically distributed to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. The smaller this quantity, the higher the entropy of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. For the uniform distribution <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> we have <img alt="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%3D%5Cfrac+%7B1%7D%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}"/> and so we can think of <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/> as maximum entropy. If <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> is uniform over <img alt="\Omega (|G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (|G|)"/> elements, we have <img alt="\lVert A\rVert _{2}^{2}=O(1/|G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D%3DO%281%2F%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}^{2}=O(1/|G|)"/> and we think of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> as having “high” entropy.</p>
<p style="text-align: justify;">Because the entropy of <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is small, we can think of the distance between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> in the 2-norm as being essentially the entropy of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>:</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+A-U%5CrVert+_%7B2%7D%5E%7B2%7D+%26+%3D%5Csum+_%7Bx%5Cin+G%7D%5Cleft+%28A%28x%29-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5Cright+%29%5E%7B2%7D%5C%5C+%26+%3D%5Csum+_%7Bx%5Cin+G%7DA%28x%29%5E%7B2%7D-2A%28x%29%5Cfrac+%7B1%7D%7B%7CG%7C%7D%2B%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B2%7D%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%5C%5C+%26+%5Capprox+%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}"/></div>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-12001r7"/> Lemma 7. </span><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span> If <img alt="X,Y" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y"/> are independent over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, then</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}"/></div>
<p>where <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is the minimum dimension of an irreducible representation of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">By this lemma, for high entropy distributions <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>, we get <img alt="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7B%7CG%7Cd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}"/>. The factor <img alt="1/\sqrt {|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Csqrt+%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\sqrt {|G|}"/> allows us to pass to <em>statistical distance </em><img alt="\lVert .\rVert _{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+.%5CrVert+_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert .\rVert _{1}"/> using Cauchy-Schwarz:</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B1%7D%5Cleq+%5Csqrt+%7B%7CG%7C%7D%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7Bd%7D%7D.%7E%7E%7E%7E%281%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}"/></div>
<p style="text-align: justify;">This is the way in which we will use the lemma.</p>
<p style="text-align: justify;">Another useful consequence of this lemma, which however we will not use directly, is this. Suppose now you have <img alt="three" class="latex" src="https://s0.wp.com/latex.php?latex=three&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="three"/> independent, high-entropy variables <img alt="X,Y,Z" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y,Z"/>. Then for every <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX%5Ccdot+Y%5Ccdot+Z%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5ClVert+Z%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D.%7E%7E%7E%7E%282%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}"/></div>
<p style="text-align: justify;">To show this, set <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> without loss of generality and rewrite the left-hand-side as</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Csum+_%7Bh%5Cin+G%7D%5Cmathbb%7BP%7D+%5BX%3Dh%5D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}"/></div>
<p>By Cauchy-Schwarz this is at most</p>
<div style="text-align: center;"><img alt="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csqrt+%7B%5Csum+_%7Bh%7D%5Cmathbb%7BP%7D+%5E%7B2%7D%5BX%3Dh%5D%7D%5Csqrt+%7B%5Csum+_%7Bh%7D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%5E%7B2%7D%7D%3D%5ClVert+X%5ClVert+_%7B2%7D%5ClVert+YZ-U%5ClVert+_%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}"/></div>
<p>and we can conclude by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>. Hence the product of three high-entropy distributions is close to uniform in a point-wise sense: each group element is obtained with roughly probability <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/>.</p>
<p style="text-align: justify;">At least over <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/>, there exists an alternative proof of this fact that does not mention representation theory (see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>).</p>
<p style="text-align: justify;">With this notation in hand, we conclude by stating a “mixing” version of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2<!--tex4ht:ref: sec:Two-parties --></a>. For more on this perspective we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-12002r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/>. Let <img alt="X=(X_{1},X_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D%28X_%7B1%7D%2CX_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X=(X_{1},X_{2})"/> and <img alt="Y=(Y_{1},Y_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=Y%3D%28Y_%7B1%7D%2CY_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y=(Y_{1},Y_{2})"/> be two distributions over <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>. Suppose <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> is independent from <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. Let <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/>. We have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}"/></div>
<p style="text-align: justify;">For example, when <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> have high entropy over <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/> (that is, are uniform over <img alt="\Omega (|G|^{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (|G|^{2})"/> pairs), we have <img alt="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5CrVert+_%7B2%7D%5Cle+%5Csqrt+%7BO%281%29%2F%7CG%7C%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}"/>, and so <img alt="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Cle+1%2F%7CG%7C%5E%7B1%2B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}"/>. In particular, <img alt="X_{1}Y_{1}X_{2}Y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=X_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_{1}Y_{1}X_{2}Y_{2}"/> is <img alt="1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{\Omega (1)}"/> close to uniform over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> in statistical distance.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.2 </span> <a id="x1-130005.0.2"/>Back to protocols</h5>
<p style="text-align: justify;">As in the beginning of Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a>, for any group element <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we define the distribution on triples <img alt="D_{g}:=(x,y,(x\cdot y)^{-1}g)" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x%2Cy%2C%28x%5Ccdot+y%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}:=(x,y,(x\cdot y)^{-1}g)"/>, where <img alt="x,y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in G"/> are uniform and independent. Note the product of the elements in <img alt="D_{g}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}"/> is always <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>. Again as in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a>, it suffices to show that for every <em>deterministic</em> protocols <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> using little communication we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}"/></div>
<p style="text-align: justify;">Analogously to Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4<!--tex4ht:ref: lem:prot-rect --></a>, the following lemma describes a protocol using rectangles. The proof is nearly identical and is omitted.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13001r8"/> Lemma 8. </span>(The set of accepted inputs of) A deterministic <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit number-in-hand protocol with three parties can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> “rectangles,” that is sets of the form <img alt="A\times B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B\times C"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Next we show that these product sets cannot distinguish these two distributions <img alt="D_{1},D_{h}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1},D_{h}"/>, via a straightforward application of lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13002r9"/> Lemma 9. </span>For all <img alt="A,B,C\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=A%2CB%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A,B,C\subseteq G"/> we have <img alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+1%2Fd%5E%7B%5COmega+%281%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}."/></p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Pick any <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/> and let <img alt="x,y,z" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z"/> be the inputs of Alice, Bob, and Charlie respectively. Then</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%3D%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Ccdot+%5Cmathbb%7BP%7D+%5B%28x%5Ccdot+y%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%7C%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%2C%7E%7E%7E%7E%283%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}"/></div>
<p>where <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>. If either <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> or <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is small, that is <img alt="\mathbb{P} [x\in A]\leq \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [x\in A]\leq \epsilon "/> or <img alt="\mathbb{P} [y\in B]\leq \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [y\in B]\leq \epsilon "/>, then also <img alt="\mathbb{P} [(x,y)\in A\times B]\le \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Cle+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [(x,y)\in A\times B]\le \epsilon "/> and hence (??) is at most <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> as well. This holds for every <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>, so we also have <img alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cepsilon+.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ."/> We will choose <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> later.</p>
<p style="text-align: justify;">Otherwise, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> are large: <img alt="\mathbb{P} [x\in A]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [x\in A]&gt;\epsilon "/> and <img alt="\mathbb{P} [y\in B]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [y\in B]&gt;\epsilon "/>. Let <img alt="(x',y')" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x',y')"/> be the distribution of <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> conditioned on <img alt="(x,y)\in A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)\in A\times B"/>. We have that <img alt="x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'"/> and <img alt="y'" class="latex" src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y'"/> are independent and each is uniform over at least <img alt="\epsilon |G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon |G|"/> elements. By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a> this implies <img alt="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}"/>, where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is the uniform distribution. As mentioned after the lemma, by Cauchy–Schwarz we obtain</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B1%7D%5Cleq+%7CG%7C%5Ccdot+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B1%7D%7Bd%7D%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}"/></div>
<p>where the last inequality follows from the fact that <img alt="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+x%5CrVert+_%7B2%7D%2C%5ClVert+y%5CrVert+_%7B2%7D%5Cleq+%5Csqrt+%7B%5Cfrac+%7B1%7D%7B%5Cepsilon+%7CG%7C%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}"/>.</p>
<p style="text-align: justify;">This implies that <img alt="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}"/> and <img alt="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}"/>, because taking inverses and multiplying by <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> does not change the distance to uniform. These two last inequalities imply that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Cin+C%5D-%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29%3B+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}"/></div>
<p>and thus we get that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}"/></div>
<p>Picking <img alt="\epsilon =1/d^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon =1/d^{1/4}"/> completes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Returning to arbitrary deterministic protocols <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> (as opposed to rectangles), write <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> as a union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> disjoint rectangles by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8<!--tex4ht:ref: lem:prot-nih-rect --></a>. Applying Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13002r9">9<!--tex4ht:ref: lem:NIH-rect --></a> and summing over all rectangles we get that the distinguishing advantage of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is at most <img alt="2^{c}/d^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}/d^{1/4}"/>. For <img alt="c\leq (1/100)\log d" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cleq+%281%2F100%29%5Clog+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\leq (1/100)\log d"/> the advantage is at most <img alt="1/100" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F100&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/100"/>, concluding the proof.</p>
<h3 class="sectionHead"><span class="titlemark">6 </span> <a id="x1-140006"/>Three parties, number-on-forehead</h3>
<p style="text-align: justify;">In number-on-forehead (NOH) communication complexity <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XCFL83">CFL83</a>]</span> with <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> parties, the input is a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-tuple <img alt="(x_{1},\dotsc ,x_{k})" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%2C%5Cdotsc+%2Cx_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_{1},\dotsc ,x_{k})"/> and each party <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> sees all of it except <img alt="x_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}"/>. For background, it is not known how to prove negative results for <img alt="k\ge \log n" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\ge \log n"/> parties.</p>
<p style="text-align: justify;">We mention that Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> can be extended to the multiparty setting, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. Several questions arise here, such as whether this problem remains hard for <img alt="k\ge \log n" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\ge \log n"/>, and what is the minimum length of an interleaved product that is hard for <img alt="k=3" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=3"/> parties (the proof in <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> gives a large constant).</p>
<p style="text-align: justify;">However in this survey we shall instead focus on the problem of separating deterministic and randomized communication. For <img alt="k=2" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=2"/>, we know the optimal separation: The equality function requires <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> communication for deterministic protocols, but can be solved using <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> communication if we allow the protocols to use public coins. For <img alt="k=3" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=3"/>, the best known separation between deterministic and randomized protocol is <img alt="\Omega (\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log n)"/> vs <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>. In the following we give a new proof of this result, for a different function: <img alt="f(x,y,z)=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x,y,z)=1_{G}"/> if and only if <img alt="x\cdot y\cdot z=1" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z=1"/> for <img alt="x,y,z\in SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz%5Cin+SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z\in SL(2,q)"/>. As is true for some functions in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>, a stronger separation could hold for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. For context, let us state and prove the upper bound for randomized communication.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14001r10"/> Claim 10. </span><img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has randomized communication complexity <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>In the number-on-forehead model, computing <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> reduces to two-party equality with no additional communication: Alice computes <img alt="y\cdot z=:w" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Ccdot+z%3D%3Aw&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\cdot z=:w"/> privately, then Alice and Bob check if <img alt="x=w^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dw%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=w^{-1}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">To prove the lower bound for deterministic protocols we reduce the communication problem to a combinatorial problem.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14002r11"/> Definition 11. </span>A <em>corner</em> in a group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is a set <img alt="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}"/>, where <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> are arbitrary group elements and <img alt="z\neq 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1_{G}"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">For intuition, if <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is the abelian group of real numbers with addition, a corner becomes <img alt="\{(x,y),(x+z,y),(x,y+z)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28x%2Bz%2Cy%29%2C%28x%2Cy%2Bz%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(x+z,y),(x,y+z)\}"/> for <img alt="z\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 0"/>, which are the coordinates of an isosceles triangle. We now state the theorem that connects corners and lower bounds.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14003r12"/> Lemma 12. </span>Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group and <img alt="\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta "/> a real number. Suppose that every subset <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/> with <img alt="|A|/|G^{2}|\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G^{2}|\ge \delta "/> contains a corner. Then the deterministic communication complexity of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> (defined as <img alt="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1%5Ciff+x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}"/>) is <img alt="\Omega (\log (1/\delta ))" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%281%2F%5Cdelta+%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log (1/\delta ))"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">It is known that <img alt="\delta \ge 1/\mathrm {polyloglog}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolyloglog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\mathrm {polyloglog}|G|"/> implies a corner for certain abelian groups <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMR2289954">LM07</a>]</span> for the best bound and pointers to the history of the problem. For <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> a stronger result is known: <img alt="\delta \ge 1/\mathrm {polylog}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolylog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\mathrm {polylog}|G|"/> implies a corner <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. This in turn implies communication <img alt="\Omega (\log \log |G|)=\Omega (\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29%3D%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)=\Omega (\log n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We saw already twice that a number-in-hand <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> rectangles (Lemmas <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4<!--tex4ht:ref: lem:prot-rect --></a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8<!--tex4ht:ref: lem:prot-nih-rect --></a>). Likewise, a number-on-forehead <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> cylinder intersections <img alt="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}" class="latex" src="https://s0.wp.com/latex.php?latex=C_%7Bi%7D%3A%3D%5C%7B%28x%2Cy%2Cz%29%3Af_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29%3D1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}"/> for some <img alt="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f_%7Bi%7D%2Cg_%7Bi%7D%2Ch_%7Bi%7D%5Ccolon+G%5E%7B2%7D%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}"/>:</p>
<div style="text-align: center;"><img alt="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%28x%2Cy%2Cz%29%3D%5Csum+_%7Bi%3D1%7D%5E%7B2%5E%7Bc%7D%7Df_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}"/></div>
<p>The proof idea of the above fact is to consider the <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> transcripts of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, then one can see that the inputs giving a fixed transcript are a cylinder intersection.</p>
<p style="text-align: justify;">Let <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> be a <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol. Consider the inputs <img alt="\{(x,y,(xy)^{-1})\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y,(xy)^{-1})\}"/> on which <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> accepts. Note that at least <img alt="2^{-c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{-c}"/> fraction of them are accepted by some cylinder intersection <img alt="C=f\cdot g\cdot h" class="latex" src="https://s0.wp.com/latex.php?latex=C%3Df%5Ccdot+g%5Ccdot+h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C=f\cdot g\cdot h"/>. Let <img alt="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3A%3D%5C%7B%28x%2Cy%29%3A%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}"/>. Since the first two elements in the tuple determine the last, we have <img alt="|A|/|G^{2}|\ge 2^{-c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G^{2}|\ge 2^{-c}"/>.</p>
<p style="text-align: justify;">Now suppose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> contains a corner <img alt="\{(x,y),(xz,y),(x,zy)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)\}"/>. Then</p>
<div style="text-align: center;"><img alt="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2Cy%29%5Cin+A+%26+%5Cimplies+%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+h%28x%2Cy%29%3D1%2C%5C%5C+%28xz%2Cy%29%5Cin+A+%26+%5Cimplies+%28xz%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+f%28y%2C%28xyz%29%5E%7B-1%7D%29%3D1%2C%5C%5C+%28x%2Czy%29%5Cin+A+%26+%5Cimplies+%28x%2Czy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+g%28x%2C%28xyz%29%5E%7B-1%7D%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}"/></div>
<p>This implies <img alt="(x,y,(xzy)^{-1})\in C" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y,(xzy)^{-1})\in C"/>, which is a contradiction because <img alt="z\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1"/> and so <img alt="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+%28xzy%29%5E%7B-1%7D%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h3 class="sectionHead"><span class="titlemark">7 </span> <a id="x1-150007"/>The corners theorem for quasirandom groups</h3>
<p style="text-align: justify;">In this section we prove the corners theorem for quasirandom groups, following Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. Our exposition has several minor differences with that in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, which may make it more computer-science friendly. Possibly a proof can also be obtained via certain local modifications and simplifications of Green’s exposition <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGre04-finite">Gre05b</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGreen-supplement">Gre05a</a>]</span> of an earlier proof for the abelian case. We focus on the case <img alt="G=\textit {SL}(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=\textit {SL}(2,q)"/> for simplicity, but the proof immediately extends to other quasirandom groups (with corresponding parameters). <a id="x1-15001r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=\textit {SL}(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=\textit {SL}(2,q)"/>. Every subset <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/> of density <img alt="|A|/|G|^{2}\geq 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cgeq+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G|^{2}\geq 1/\log ^{a}|G|"/> contains a corner <img alt="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%7E%7C%7Ez%5Cneq+1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}"/>.</p>
<h4 class="subsectionHead"><span class="titlemark">7.1 </span> <a id="x1-160007.1"/>Proof idea</h4>
<p style="text-align: justify;">For intuition, suppose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> is a product set, i.e., <img alt="A=B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=B\times C"/> for <img alt="B,C\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=B%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B,C\subseteq G"/>. Let’s look at the quantity</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BA%28x%2Cy%29A%28xz%2Cy%29A%28x%2Czy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}"/></div>
<p>where <img alt="A(x,y)=1" class="latex" src="https://s0.wp.com/latex.php?latex=A%28x%2Cy%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(x,y)=1"/> iff <img alt="(x,y)\in A" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)\in A"/>. Note that the random variable in the expectation is equal to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> exactly when <img alt="x,y,z" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z"/> form a corner in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. We’ll show that this quantity is greater than <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/>, which implies that <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> contains a corner (where <img alt="z\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1"/>). Since we are taking <img alt="A=B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=B\times C"/>, we can rewrite the above quantity as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28y%29B%28x%29C%28zy%29%5D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28zy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28z%29C%28x%5E%7B-1%7Dzy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}"/></div>
<p>where the last line follows by replacing <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> with <img alt="x^{-1}z" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}z"/> in the uniform distribution. If <img alt="|A|/|G|^{2}\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G|^{2}\ge \delta "/>, then both |B|/|G|<img alt="\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \delta "/> and <img alt="|B|/|G|\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CB%7C%2F%7CG%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|B|/|G|\ge \delta "/>. Condition on <img alt="x\in B" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in B"/>, <img alt="y\in C" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\in C"/>, <img alt="z\in B" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\in B"/>. Then the distribution <img alt="x^{-1}zy" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}zy"/> is a product of three independent distributions, each uniform on a set of density <img alt="\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \delta "/>. (In fact, two distributions would suffice for this.) By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>, <img alt="x^{-1}zy" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}zy"/> is <img alt="\delta ^{-1}/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5E%7B-1%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta ^{-1}/|G|^{\Omega (1)}"/> close to uniform in statistical distance. This implies that the above expectation equals</p>
<div style="text-align: center;"><img alt="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7B%7CA%7C%7D%7B%7CG%7C%5E%7B2%7D%7D%5Ccdot+%5Cfrac+%7B%7CB%7C%7D%7B%7CG%7C%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7B%7CC%7C%7D%7B%7CG%7C%7D%5Cpm+%5Cfrac+%7B%5Cdelta+%5E%7B-1%7D%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29+%26+%5Cgeq+%5Cdelta+%5E%7B2%7D%5Cleft+%28%5Cdelta+-%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29%5Cgeq+%5Cdelta+%5E%7B3%7D%2F2%3E1%2F%7CG%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}"/></div>
<p style="text-align: justify;">for <img alt="\delta &gt;1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta &gt;1/|G|^{c}"/> for a small enough constant <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. Hence, product sets of density polynomial in <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/> contain corners.</p>
<p style="text-align: justify;">Given the above, it is natural to try to decompose an arbitrary set <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into product sets. We will make use of a more general result.</p>
<h4 class="subsectionHead"><span class="titlemark">7.2 </span> <a id="x1-170007.2"/>Weak Regularity Lemma</h4>
<p style="text-align: justify;">Let <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> be some universe (we will take <img alt="U=G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=U%3DG%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U=G^{2}"/>) and let <img alt="f:U\rightarrow [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:U\rightarrow [-1,1]"/> be a function (for us, <img alt="f=1_{A}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3D1_%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=1_{A}"/>). Let <img alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D\subseteq \{d:U\rightarrow [-1,1]\}"/> be some set of functions, which can be thought of as “easy functions” or “distinguishers” (these will be rectangles or closely related to them). The next theorem shows how to decompose <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> into a linear combination <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> of the <img alt="d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}"/> up to an error which is polynomial in the length of the combination. More specifically, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> will be indistinguishable from <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> by the <img alt="d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-17001r13"/> Lemma 13. </span>Let <img alt="f:U\rightarrow [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:U\rightarrow [-1,1]"/> be a function and <img alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D\subseteq \{d:U\rightarrow [-1,1]\}"/> a set of functions. For all <img alt="\epsilon &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon &gt;0"/>, there exists a function <img alt="g:=\sum _{i\le s}c_{i}\cdot d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3A%3D%5Csum+_%7Bi%5Cle+s%7Dc_%7Bi%7D%5Ccdot+d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g:=\sum _{i\le s}c_{i}\cdot d_{i}"/> where <img alt="d_{i}\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}\in D"/>, <img alt="c_{i}\in \mathbb {R}" class="latex" src="https://s0.wp.com/latex.php?latex=c_%7Bi%7D%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_{i}\in \mathbb {R}"/> and <img alt="s=1/\epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=s%3D1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s=1/\epsilon ^{2}"/> such that for all <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/></p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bf%28x%29%5Ccdot+d%28x%29%5D-%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bg%28x%29%5Ccdot+d%28x%29%5D%5Cright+%7C%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}"/></div>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">A different way to state the conclusion, which we will use, is to say that we can write <img alt="f=g+h" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g+h"/> so that <img alt="\mathbb{E} [h(x)\cdot d(x)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+%5Bh%28x%29%5Ccdot+d%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{E} [h(x)\cdot d(x)]"/> is small.</p>
<p style="text-align: justify;">The lemma is due to Frieze and Kannan <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/conf/focs/FriezeK96">FK96</a>]</span>. It is called “weak” because it came after Szemerédi’s regularity lemma, which has a stronger distinguishing conclusion. However, the lemma is also “strong” in the sense that Szemerédi’s regularity lemma has <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> as a tower of <img alt="1/\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon "/> whereas here we have <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> polynomial in <img alt="1/\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon "/>. The weak regularity lemma is also simpler. There also exists a proof <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XTao2017-szemerediproof">Tao17</a>]</span> of Szemerédi’s theorem (on arithmetic progressions), which uses weak regularity as opposed to the full regularity lemma used initially.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will construct the approximation <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> through an iterative process producing functions <img alt="g_{0},g_{1},\dots ,g" class="latex" src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%2Cg_%7B1%7D%2C%5Cdots+%2Cg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_{0},g_{1},\dots ,g"/>. We will show that <img alt="||f-g_{i}||_{2}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7Bi%7D%7C%7C_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||f-g_{i}||_{2}^{2}"/> decreases by <img alt="\ge \epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \epsilon ^{2}"/> each iteration.</p>
<p style="text-align: justify;"><b>Start</b>: Define <img alt="g_{0}=0" class="latex" src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_{0}=0"/> (which can be realized setting <img alt="c_{0}=0" class="latex" src="https://s0.wp.com/latex.php?latex=c_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_{0}=0"/>).</p>
<p style="text-align: justify;"><b>Iterate</b>: If not done, there exists <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/> such that <img alt="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%7C%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon "/>. Assume without loss of generality <img alt="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon "/>.</p>
<p style="text-align: justify;"><b>Update</b>: <img alt="g':=g+\lambda d" class="latex" src="https://s0.wp.com/latex.php?latex=g%27%3A%3Dg%2B%5Clambda+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g':=g+\lambda d"/> where <img alt="\lambda \in \mathbb {R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda \in \mathbb {R}"/> shall be picked later.</p>
<p style="text-align: justify;">Let us analyze the progress made by the algorithm.</p>
<div style="text-align: center;"><img alt="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7Cf-g%27%7C%7C_%7B2%7D%5E%7B2%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%27%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g-%5Clambda+d%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5E%7B2%7D%5D%2B%5Cmathbb+%7BE%7D_%7Bx%7D%5B%5Clambda+%5E%7B2%7Dd%5E%7B2%7D%28x%29%5D-2%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5Ccdot+%5Clambda+d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cepsilon+%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D-%5Cepsilon+%5E%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}"/></div>
<p>where the last line follows by taking <img alt="\lambda =\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda =\epsilon "/>. Therefore, there can only be <img alt="1/\epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon ^{2}"/> iterations because <img alt="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7B0%7D%7C%7C_%7B2%7D%5E%7B2%7D%3D%7C%7Cf%7C%7C_%7B2%7D%5E%7B2%7D%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h4 class="subsectionHead"><span class="titlemark">7.3 </span> <a id="x1-180007.3"/>Getting more for rectangles</h4>
<p style="text-align: justify;">Returning to the main proof, we will use the weak regularity lemma to approximate the indicator function for arbitrary <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> by rectangles. That is, we take <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> to be the collection of indicator functions for all sets of the form <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> for <img alt="S,T\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=S%2CT%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S,T\subseteq G"/>. The weak regularity lemma shows how to decompose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into a linear combination of rectangles. These rectangles may overlap. However, we ideally want <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to be a linear combination of <em>non-overlapping</em> rectangles. In other words, we want a <em>partition </em>of rectangles. It is possible to achieve this at the price of exponentiating the number of rectangles. Note that an exponential loss is necessary even if <img alt="S=G" class="latex" src="https://s0.wp.com/latex.php?latex=S%3DG&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S=G"/> in every <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> rectangle; or in other words in the uni-dimensional setting. This is one step where the terminology “rectangle” may be misleading – the set <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is not necessarily an interval. If it was, a polynomial rather than exponential blow-up would have sufficed to remove overlaps.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18001r14"/> Claim 14. </span>Given a decomposition of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into rectangles from the weak regularity lemma with <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> functions, there exists a decomposition with <img alt="2^{O(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}"/> rectangles which don’t overlap.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Exercise. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">In the above decomposition, note that it is natural to take the coefficients of rectangles to be the density of points in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> that are in the rectangle. This gives rise to the following claim.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18002r15"/> Claim 15. </span>The weights of the rectangles in the above claim can be the average of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> in the rectangle, at the cost of doubling the error.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Consequently, we have that <img alt="f=g+h" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g+h"/>, where <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> is the sum of <img alt="2^{O(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}"/> non-overlapping rectangles <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> with coefficients <img alt="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7B%28x%2Cy%29%5Cin+S%5Ctimes+T%7D%5Bf%28x%2Cy%29%3D1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Let <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> be a partition decomposition with arbitrary weights. Let <img alt="g'" class="latex" src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'"/> be a partition decomposition with weights being the average of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. It is enough to show that for all rectangle distinguishers <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/></p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}"/></div>
<p>By the triangle inequality, we have that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C%2B%7C%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}"/></div>
<p>To bound <img alt="\mathbb {E}[(g-g')d]|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(g-g')d]|"/>, note that the error is maximized for a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> that respects the decomposition in non-overlapping rectangles, i.e., <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is the union of some non-overlapping rectangles from the decomposition. This can be argued using that, unlike <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>, the value of <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> and <img alt="g'" class="latex" src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'"/> on a rectangle <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> from the decomposition is fixed. But, from the point of “view” of such <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, <img alt="g'=f" class="latex" src="https://s0.wp.com/latex.php?latex=g%27%3Df&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'=f"/>! More formally, <img alt="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%3D%5Cmathbb+%7BE%7D%5B%28g-f%29d%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]"/>. This gives</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+2%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}"/></div>
<p>and concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">We need to get still a little more from this decomposition. In our application of the weak regularity lemma above, we took the set of distinguishers to be characteristic functions of rectangles. That is, distinguishers that can be written as <img alt="U(x)\cdot V(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(y)"/> where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> map <img alt="G\to \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G\to \{0,1\}"/>. We will use that the same guarantee holds for <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>, up to a constant factor loss in the error. Indeed, let <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> have range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. Write <img alt="U=U_{+}-U_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U%3DU_%7B%2B%7D-U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U=U_{+}-U_{-}"/> where <img alt="U_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}"/> and <img alt="U_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}"/> have range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/>, and the same for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/>. The error for distinguisher <img alt="U\cdot V" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Ccdot+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\cdot V"/> is at most the sum of the errors for distinguishers <img alt="U_{+}\cdot V_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}\cdot V_{+}"/>, <img alt="U_{+}\cdot V_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}\cdot V_{-}"/>, <img alt="U_{-}\cdot V_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}\cdot V_{+}"/>, and <img alt="U_{-}\cdot V_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}\cdot V_{-}"/>. So we can restrict our attention to distinguishers <img alt="U(x)\cdot V(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(y)"/> where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> have range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/>. In turn, a function <img alt="U(x)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)"/> with range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/> can be written as an expectation <img alt="\mathbb{E} _{a}U_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{E} _{a}U_{a}(x)"/> for functions <img alt="U_{a}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Ba%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{a}"/> with range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>, and the same for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/>. We conclude by observing that</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29%5Ccdot+%5Cmathbb%7BE%7D+_%7Bb%7DV_%7Bb%7D%28y%29%5D%5Cle+%5Cmax+_%7Ba%2Cb%7D%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29U_%7Ba%7D%28x%29%5Ccdot+V_%7Bb%7D%28y%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}"/></div>
<h4 class="subsectionHead"><span class="titlemark">7.4 </span> <a id="x1-190007.4"/>Proof</h4>
<p style="text-align: justify;">Let us now finish the proof by showing a corner exists for sufficiently dense sets <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/>. We’ll use three types of decompositions for <img alt="f:G^{2}\rightarrow \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AG%5E%7B2%7D%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:G^{2}\rightarrow \{0,1\}"/>, with respect to the following three types of distinguishers, where <img alt="U_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{i}"/> and <img alt="V_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=V_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V_{i}"/> have range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-19002x1"><img alt="U_{1}(x)\cdot V_{1}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B1%7D%28x%29%5Ccdot+V_%7B1%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{1}(x)\cdot V_{1}(y)"/>,</li>
<li class="enumerate" id="x1-19004x2"><img alt="U_{2}(xy)\cdot V_{2}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B2%7D%28xy%29%5Ccdot+V_%7B2%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{2}(xy)\cdot V_{2}(y)"/>,</li>
<li class="enumerate" id="x1-19006x3"><img alt="U_{3}(x)\cdot V_{3}(xy)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B3%7D%28x%29%5Ccdot+V_%7B3%7D%28xy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{3}(x)\cdot V_{3}(xy)"/>.</li>
</ol>
<p style="text-align: justify;">The first type is just rectangles, what we have been discussing until now. The distinguishers in the last two classes can be visualized over <img alt="\mathbb {R}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BR%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {R}^{2}"/> as parallelograms with a 45-degree angle. The same extra properties we discussed for rectangles can be verified hold for them too.</p>
<p style="text-align: justify;">Recall that we want to show</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%3E%5Cfrac+%7B1%7D%7B%7CG%7C%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}"/></div>
<p>We’ll decompose the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th occurrence of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> via the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th decomposition listed above. We’ll write this decomposition as <img alt="f=g_{i}+h_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg_%7Bi%7D%2Bh_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g_{i}+h_{i}"/>. We apply this in a certain order to produce sums of products of three functions. The inputs to the functions don’t change, so to avoid clutter we do not write them, and it is understood that in each product of three functions the inputs are, in order <img alt="(x,y),(xg,y),(x,gy)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%2C%28xg%2Cy%29%2C%28x%2Cgy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y),(xg,y),(x,gy)"/>. The decomposition is:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+fff%5C%5C+%3D+%26+ffg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+fg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bh_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}"/></div>
<p style="text-align: justify;">We first show that the expectation of the first term is big. This takes the next two claims. Then we show that the expectations of the other terms are small.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19007r16"/> Claim 16. </span>For all <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/>, the expectations <img alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28xg%2Cy%29g_%7B3%7D%28x%2Cgy%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]"/> are the same up to an error of <img alt="2^{O(s)}/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}/|G|^{\Omega (1)}"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We just need to get error <img alt="1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{\Omega (1)}"/> for any product of three functions for the three decomposition types. We have:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bc_%7B1%7DU_%7B1%7D%28x%29V_%7B1%7D%28y%29%5Ccdot+c_%7B2%7DU_%7B2%7D%28xgy%29V_%7B2%7D%28y%29%5Ccdot+c_%7B3%7DU_%7B3%7D%28x%29V_%7B3%7D%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bz%7D%5B%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28z%29%5D%5Cpm+%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}"/></div>
<p style="text-align: justify;">This is similar to what we discussed in the overview, and is where we use mixing. Specifically, if <img alt="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]"/> or <img alt="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]"/> are at most <img alt="1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{c}"/> for a small enough constant <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> than we are done. Otherwise, conditioned on <img alt="(U_{1}\cdot U_{3})(x)=1" class="latex" src="https://s0.wp.com/latex.php?latex=%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(U_{1}\cdot U_{3})(x)=1"/>, the distribution on <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> is uniform over a set of density <img alt="1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{c}"/>, and the same holds for <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/>, and the result follows by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Recall that we start with a set of density <img alt="\ge 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge 1/\log ^{a}|G|"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19008r17"/> Claim 17. </span><img alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28x%2Cy%29g_%7B3%7D%28x%2Cy%29%5D%3E1%2F%5Clog+%5E%7B4a%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will relate the expectation over <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> to <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> using the Hölder inequality: For random variables <img alt="X_{1},X_{2},\ldots ,X_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=X_%7B1%7D%2CX_%7B2%7D%2C%5Cldots+%2CX_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_{1},X_{2},\ldots ,X_{k}"/>,</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5BX_%7B1%7D%5Cdots+X_%7Bk%7D%5D%5Cleq+%5Cprod+_%7Bi%3D1%7D%5E%7Bk%7D%5Cmathbb+%7BE%7D%5BX_%7Bi%7D%5E%7Bc_%7Bi%7D%7D%5D%5E%7B1%2Fc_%7Bi%7D%7D%5Ctext+%7B+such+that+%7D%5Csum+1%2Fc_%7Bi%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}"/></div>
<p style="text-align: justify;">To apply this inequality in our setting, write</p>
<div style="text-align: center;"><img alt="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%3D%28f%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%29%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}"/></div>
<p>By the Hölder inequality the expectation of the right-hand side is</p>
<div style="text-align: center;"><img alt="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}"/></div>
<p>The last three terms equal to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> because</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7Bg_%7Bi%7D%28x%2Cy%29%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}"/></div>
<p>where <img alt="\textit {Cell}(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextit+%7BCell%7D%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textit {Cell}(x,y)"/> is the set in the partition that contains <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/>. Putting the above together we obtain</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bf%5D%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}"/></div>
<p>Finally, because the functions are positive, we have that <img alt="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cleq+%5Cmathbb+%7BE%7D%5Bg_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}"/>. This concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">It remains to show the other terms are small. Let <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> be the error in the weak regularity lemma with respect to distinguishers with range <img alt="\{0,1\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\} "/>. Recall that this implies error <img alt="O(\epsilon )" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\epsilon )"/> with respect to distinguishers with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. We give the proof for one of the terms and then we say little about the other two.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19009r18"/> Claim 18. </span><img alt="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%7C%5Cleq+O%28%5Cepsilon+%29%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The proof involves changing names of variables and doing Cauchy-Schwarz to remove the terms with <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and bound the expectation above by <img alt="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]"/>, which is small by the regularity lemma.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Replace <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> with <img alt="gy^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=gy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="gy^{-1}"/> in the uniform distribution to get</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B4%7D%5Bf%28x%2Cy%29%5Cmathbb+%7BE%7D_%7Bg%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Bf%5E%7B2%7D%28x%2Cy%29%5D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29f%28xg%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%27%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}"/></div>
<p>where the first inequality is by Cauchy-Schwarz.</p>
<p style="text-align: justify;">Now replace <img alt="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+x%5E%7B-1%7Dg%2Cg%27%5Crightarrow+x%5E%7B-1%7Dg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g"/> and reason in the same way:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29f%28g%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bg%2Cg%27%2Cy%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29%5Ccdot+f%28g%27y%5E%7B-1%7D%2Cy%29%5Cmathbb+%7BE%7D_%7Bx%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29%5Ccdot+h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cx%27%2Cg%2Cg%27%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}"/></div>
<p style="text-align: justify;">Replace <img alt="g\rightarrow xg" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\rightarrow xg"/> to rewrite the expectation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dxg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}"/></div>
<p style="text-align: justify;">We want to view the last three terms as a distinguisher <img alt="U(x)\cdot V(xg)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28xg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(xg)"/>. First, note that <img alt="h_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{3}"/> has range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. This is because <img alt="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B3%7D%28x%2Cy%29%3Df%28x%2Cy%29-%5Cmathbb%7BE%7D+_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7Df%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')"/> and <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>, where recall that <img alt="Cell(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=Cell%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Cell(x,y)"/> is the set in the partition that contains <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/>. Fix <img alt="x',g'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%2Cg%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x',g'"/>. The last term in the expectation becomes a constant <img alt="c\in [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in [-1,1]"/>. The second term only depends on <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, and the third only on <img alt="xg" class="latex" src="https://s0.wp.com/latex.php?latex=xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="xg"/>. Hence for appropriate functions <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/> this expectation can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}"/></div>
<p>which concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">There are similar proofs to show the remaining terms are small. For <img alt="fh_{2}g_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=fh_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="fh_{2}g_{3}"/>, we can perform simple manipulations and then reduce to the above case. For <img alt="h_{1}g_{2}g_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B1%7Dg_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{1}g_{2}g_{3}"/>, we have a slightly easier proof than above.</p>
<h5 class="subsubsectionHead"><span class="titlemark">7.4.1 </span> <a id="x1-200007.4.1"/>Parameters</h5>
<p style="text-align: justify;">Suppose our set has density <img alt="\delta \ge 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\log ^{a}|G|"/>, and the error in the regularity lemma is <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/>. By the above results we can bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%5Cge+1%2F%5Clog+%5E%7B4a%7D%7CG%7C-2%5E%7BO%281%2F%5Cepsilon+%5E%7B2%7D%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D-%5Cepsilon+%5E%7B%5COmega+%281%29%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}"/></div>
<p>where the terms in the right-hand size come, left-to-right from Claim <a href="https://emanueleviola.wordpress.com/feed/#x1-19008r17">17<!--tex4ht:ref: claim:austin-g1 --></a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-19007r16">16<!--tex4ht:ref: claim:austin-same-for-every-g --></a>, and <a href="https://emanueleviola.wordpress.com/feed/#x1-19009r18">18<!--tex4ht:ref: claim:austin-h-error --></a>. Picking <img alt="\epsilon =1/\log ^{1/3}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F%5Clog+%5E%7B1%2F3%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon =1/\log ^{1/3}|G|"/> the proof is completed for sufficiently small <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>.</p>
<h3 class="likesectionHead"><a id="x1-210007.4.1"/>References</h3>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [AL00] <span class="bibsp">   </span></span><a id="XAmbainisL00"/>Andris Ambainis and Satyanarayana V. Lokam. Imroved upper bounds on the simultaneous messages complexity of the generalized addressing function. In Latin American Symposium on Theoretical Informatics (LATIN), pages 207–216, 2000.</p>
<p class="bibitem"><span class="biblabel"> [Amb96] <span class="bibsp">   </span></span><a id="XAmbainis96"/>Andris Ambainis. Upper bounds on multiparty communication complexity of shifts. In Symp. on Theoretical Aspects of Computer Science (STACS), pages 631–642, 1996.</p>
<p class="bibitem"><span class="biblabel"> [AMS99] <span class="bibsp">   </span></span><a id="XAMS99"/>Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the frequency moments. J. of Computer and System Sciences, 58(1, part 2):137–147, 1999.</p>
<p class="bibitem"><span class="biblabel"> [Aus16] <span class="bibsp">   </span></span><a id="XAustin2016"/>Tim Austin. Ajtai-Szemerédi theorems over quasirandom groups. In Recent trends in combinatorics, volume 159 of IMA Vol. Math. Appl., pages 453–484. Springer, [Cham], 2016.</p>
<p class="bibitem"><span class="biblabel"> [Bar89] <span class="bibsp">   </span></span><a id="XBarrington89"/>David A. Mix Barrington. Bounded-width polynomial-size branching programs recognize exactly those languages in NC<img alt="^1" class="latex" src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="^1"/>. J. of Computer and System Sciences, 38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel"> [BC92] <span class="bibsp">   </span></span><a id="XBen-OrC92"/>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant number of registers. SIAM J. on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel"> [BDPW10]<span class="bibsp">   </span></span><a id="XBeameDPW10"/>Paul Beame, Matei David, Toniann Pitassi, and Philipp Woelfel. Separating deterministic from randomized multiparty communication complexity. Theory of Computing, 6(1):201–225, 2010.</p>
<p class="bibitem"><span class="biblabel"> [BGKL03] <span class="bibsp">   </span></span><a id="XBGKL03"/>László Babai, Anna Gál, Peter G. Kimmel, and Satyanarayana V. Lokam. Communication complexity of simultaneous messages. SIAM J. on Computing, 33(1):137–166, 2003.</p>
<p class="bibitem"><span class="biblabel"> [BNP08] <span class="bibsp">   </span></span><a id="XBabaiNP08"/>László Babai, Nikolay Nikolov, and László Pyber. Product growth and mixing in finite groups. In ACM-SIAM Symp. on Discrete Algorithms (SODA), pages 248–257, 2008.</p>
<p class="bibitem"><span class="biblabel"> [CFL83] <span class="bibsp">   </span></span><a id="XCFL83"/>Ashok K. Chandra, Merrick L. Furst, and Richard J. Lipton. Multi-party protocols. In 15th ACM Symp. on the Theory of Computing (STOC), pages 94–99, 1983.</p>
<p class="bibitem"><span class="biblabel"> [CP10] <span class="bibsp">   </span></span><a id="XDBLP:journals/sigact/ChattopadhyayP10"/>Arkadev Chattopadhyay and Toniann Pitassi. The story of set disjointness. SIGACT News, 41(3):59–85, 2010.</p>
<p class="bibitem"><span class="biblabel"> [DHKP97] <span class="bibsp">   </span></span><a id="XDietzfelbingerHKP97"/>Martin Dietzfelbinger, Torben Hagerup, Jyrki Katajainen, and Martti Penttonen. A reliable randomized algorithm for the closest-pair problem. J. Algorithms, 25(1):19–51, 1997.</p>
<p class="bibitem"><span class="biblabel"> [FK96] <span class="bibsp">   </span></span><a id="XDBLP:conf/focs/FriezeK96"/>Alan M. Frieze and Ravi Kannan. The regularity lemma and approximation schemes for dense problems. In IEEE Symp. on Foundations of Computer Science (FOCS), pages 12–20, 1996.</p>
<p class="bibitem"><span class="biblabel"> [Gow08] <span class="bibsp">   </span></span><a id="XGowers08"/>W. T. Gowers. Quasirandom groups. Combinatorics, Probability &amp; Computing, 17(3):363–387, 2008.</p>
<p class="bibitem"><span class="biblabel"> [Gre05a] <span class="bibsp">   </span></span><a id="XGreen-supplement"/>Ben Green. An argument of Shkredov in the finite field setting, 2005. Available at people.maths.ox.ac.uk/greenbj/papers/corners.pdf.</p>
<p class="bibitem"><span class="biblabel"> [Gre05b] <span class="bibsp">   </span></span><a id="XGre04-finite"/>Ben Green. Finite field models in additive combinatorics. Surveys in Combinatorics, London Math. Soc. Lecture Notes 327, 1-27, 2005.</p>
<p class="bibitem"><span class="biblabel"> [GVa] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-journal"/>W. T. Gowers and Emanuele Viola. Interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GVb] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-2"/>W. T. Gowers and Emanuele Viola. The multiparty communication complexity of interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GV15] <span class="bibsp">   </span></span><a id="XGowersV-cc-int"/>W. T. Gowers and Emanuele Viola. The communication complexity of interleaved group products. In ACM Symp. on the Theory of Computing (STOC), 2015.</p>
<p class="bibitem"><span class="biblabel"> [IL95] <span class="bibsp">   </span></span><a id="XImmermanL95"/>Neil Immerman and Susan Landau. The complexity of iterated multiplication. Inf. Comput., 116(1):103–116, 1995.</p>
<p class="bibitem"><span class="biblabel"> [KMR66] <span class="bibsp">   </span></span><a id="XKrohnMR66"/>Kenneth Krohn, W. D. Maurer, and John Rhodes. Realizing complex Boolean functions with simple groups. Information and Control, 9:190–195, 1966.</p>
<p class="bibitem"><span class="biblabel"> [KN97] <span class="bibsp">   </span></span><a id="XKuN97"/>Eyal Kushilevitz and Noam Nisan. Communication complexity. Cambridge University Press, 1997.</p>
<p class="bibitem"><span class="biblabel"> [KS92] <span class="bibsp">   </span></span><a id="XKalyanasundaramS92"/>Bala Kalyanasundaram and Georg Schnitger. The probabilistic communication complexity of set intersection. SIAM J. Discrete Math., 5(4):545–557, 1992.</p>
<p class="bibitem"><span class="biblabel"> [LM07] <span class="bibsp">   </span></span><a id="XMR2289954"/>Michael T. Lacey and William McClain. On an argument of Shkredov on two-dimensional corners. Online J. Anal. Comb., (2):Art. 2, 21, 2007.</p>
<p class="bibitem"><span class="biblabel"> [LW54] <span class="bibsp">   </span></span><a id="XLangWeil54"/>Serge Lang and André Weil. Number of points of varieties in finite fields. American Journal of Mathematics, 76:819–827, 1954.</p>
<p class="bibitem"><span class="biblabel"> [Mil14] <span class="bibsp">   </span></span><a id="XMiles14"/>Eric Miles. Iterated group products and leakage resilience against <img alt="NC^1" class="latex" src="https://s0.wp.com/latex.php?latex=NC%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="NC^1"/>. In ACM Innovations in Theoretical Computer Science conf. (ITCS), 2014.</p>
<p class="bibitem"><span class="biblabel"> [MV13] <span class="bibsp">   </span></span><a id="XMilesV-leak"/>Eric Miles and Emanuele Viola. Shielding circuits with groups. In ACM Symp. on the Theory of Computing (STOC), 2013.</p>
<p class="bibitem"><span class="biblabel"> [PRS97] <span class="bibsp">   </span></span><a id="XPRS97"/>Pavel Pudlák, Vojtěch Rödl, and Jiří Sgall. Boolean circuits, tensor ranks, and communication complexity. SIAM J. on Computing, 26(3):605–633, 1997.</p>
<p class="bibitem"><span class="biblabel"> [Raz92] <span class="bibsp">   </span></span><a id="XRazborov92"/>Alexander A. Razborov. On the distributional complexity of disjointness. Theor. Comput. Sci., 106(2):385–390, 1992.</p>
<p class="bibitem"><span class="biblabel"> [Raz00] <span class="bibsp">   </span></span><a id="XRaz00"/>Ran Raz. The BNS-Chung criterion for multi-party communication complexity. Computational Complexity, 9(2):113–122, 2000.</p>
<p class="bibitem"><span class="biblabel"> [RY19] <span class="bibsp">   </span></span><a id="XRaoY2019"/>Anup Rao and Amir Yehudayoff. Communication complexity. 2019. <a href="https://homes.cs.washington.edu/&#xA0;anuprao/pubs/book.pdf" rel="nofollow">https://homes.cs.washington.edu/ anuprao/pubs/book.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Sha16] <span class="bibsp">   </span></span><a id="XShalev16"/>Aner Shalev. Mixing, communication complexity and conjectures of Gowers and Viola. Combinatorics, Probability and Computing, pages 1–13, 6 2016. arXiv:1601.00795.</p>
<p class="bibitem"><span class="biblabel"> [She14] <span class="bibsp">   </span></span><a id="XSherstov14-35years"/>Alexander A. Sherstov. Communication complexity theory: Thirty-five years of set disjointness. In Symp. on Math. Foundations of Computer Science (MFCS), pages 24–43, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Tao17] <span class="bibsp">   </span></span><a id="XTao2017-szemerediproof"/>Terence Tao. Szemerédiâs proof of Szemerédiâs theorem, 2017. <a href="https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf" rel="nofollow">https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vioa] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups"/>Emanuele Viola. Thoughts: Mixing in groups. <a href="https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/" rel="nofollow">https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Viob] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups-ii"/>Emanuele Viola. Thoughts: Mixing in groups ii. <a href="https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/" rel="nofollow">https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vio14] <span class="bibsp">   </span></span><a id="XViola-ccsum"/>Emanuele Viola. The communication complexity of addition. Combinatorica, pages 1–45, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Vio17] <span class="bibsp">   </span></span><a id="Xviola-special-topics17"/>Emanuele Viola. Special topics in complexity theory. Lecture notes of the class taught at Northeastern University. Available at <a href="http://www.ccs.neu.edu/home/viola/classes/spepf17.html" rel="nofollow">http://www.ccs.neu.edu/home/viola/classes/spepf17.html</a>, 2017.</p>
<p class="bibitem"><span class="biblabel"> [Yao79] <span class="bibsp">   </span></span><a id="XYao79"/>Andrew Chi-Chih Yao. Some complexity questions related to distributive computing. In 11th ACM Symp. on the Theory of Computing (STOC), pages 209–213, 1979.</p>
</div>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-10T17:00:32Z</updated>
    <published>2019-07-10T17:00:32Z</published>
    <category term="Uncategorized"/>
    <category term="lecture"/>
    <category term="lower bounds"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-07-15T12:21:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2019/07/10/trajectories-linear-nets/</id>
    <link href="http://offconvex.github.io/2019/07/10/trajectories-linear-nets/" rel="alternate" type="text/html"/>
    <title>Understanding implicit regularization in deep learning by analyzing trajectories of gradient descent</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sanjeev’s <a href="http://www.offconvex.org/2019/06/03/trajectories/">recent blog post</a> suggested that the conventional view of optimization is insufficient for understanding deep learning, as the value of the training objective does not reliably capture generalization.
He argued that instead, we need to consider the <em>trajectories</em> of optimization.
One of the illustrative examples given was our <a href="https://arxiv.org/abs/1905.13655">new paper with Sanjeev Arora and Yuping Luo</a>, which studies the use of deep linear neural networks for solving <a href="https://en.wikipedia.org/wiki/Matrix_completion"><em>matrix completion</em></a> more accurately than the classic convex programming approach. 
The current post provides more details on this result.</p>

<p>Recall that in matrix completion we are given some entries $\{ M_{i, j} : (i, j) \in \Omega \}$ of an unknown <em>ground truth</em> matrix $M$, and our goal is to recover the remaining entries.
This can be thought of as a supervised learning (regression) problem, where the training examples are the observed entries of $M$, the model is a matrix $W$ trained with the loss:
[
L(W) = \sum\nolimits_{(i, j) \in \Omega} (W_{i, j} - M_{i, j})^2 ~,
]
and generalization corresponds to how similar $W$ is to $M$ in the unobserved locations.
Obviously the problem is ill-posed if we assume nothing about $M$ $-$ the loss $L(W)$ is underdetermined, i.e. has multiple optima, and it would be impossible to tell (without access to unobserved entries) if one solution is better than another.
The standard assumption (which has many <a href="https://en.wikipedia.org/wiki/Matrix_completion#Applications">practical applications</a>) is that the ground truth matrix $M$ is low-rank, and thus the goal is to find, from among all global minima of the loss $L(W)$, one with minimal rank. 
The classic algorithm for achieving this is to find the matrix with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms"><em>nuclear norm</em></a>. 
This is a convex program, which <em>given enough observed entries</em> (and under mild technical assumptions $-$ “incoherence”) recovers the ground truth exactly (cf. <a href="https://statweb.stanford.edu/~candes/papers/MatrixCompletion.pdf">Candes and Recht</a>). 
We’re interested in the regime where the number of revealed entries is too small for the classic algorithm to succeed.
There it can be beaten by a simple deep learning approach, as described next.</p>

<h2 id="linear-neural-networks-lnn">Linear Neural Networks (LNN)</h2>

<p>A linear neural network (LNN) is a fully-connected neural network with linear activation (i.e. no non-linearity).
If $W_j$ is the weight matrix in layer $j$ of a depth $N$ network, the <em>end-to-end matrix</em> is given by $W = W_N W_{N-1} \cdots W_1$.
Our method for solving matrix completion involves minimizing the loss $L(W)$ by running gradient descent (GD) on this (over-)parameterization, with depth $N \geq 2$ and hidden dimensions that do not constrain rank.
This can be viewed as a deep learning problem with $\ell_2$ loss, and GD can be implemented through the chain rule as usual.
Note that the training objective does not include any regularization term controlling the individual layer matrices $\{ W_j \}_j$.</p>

<p>At first glance our algorithm seems naive, since parameterization by an LNN (that does not constrain rank) is equivalent to parameterization by a single matrix $W$, and obviously running GD on $L(W)$ directly with no regularization is not a good approach (nothing will be learned in the unobserved locations).
However, since matrix completion is an underdetermined problem (has multiple optima), the optimum reached by GD can vary depending on the chosen parameterization.
Our setup isolates the role of over-parameterization in implicitly biasing GD towards certain optima (that hopefully generalize well).</p>

<p>Note that in the special case of depth $N = 2$ our method reduces to a traditional approach for matrix completion,  named <em>matrix factorization</em>. 
By analogy, we refer to the case $N \geq 3$ as <em>deep matrix factorization</em>. 
The table below shows reconstruction errors (generalization) on a matrix completion task where the number of observed entries is too small for nuclear norm minimization to succeed.
As can be seen, it is outperformed by matrix factorization, which itself is outperformed by deep matrix factorization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-reconst-errs.png" style="width: 700px;"/>
<br/>
<b>Table 1:</b> Results for matrix completion with small number of observations.
</div>
<p><br/>
The main focus of our paper is on developing a theoretical understanding of this phenomenon.</p>

<h2 id="trajectory-analysis-implicit-regularization-towards-low-rank">Trajectory Analysis: Implicit Regularization Towards Low Rank</h2>

<p>We are interested in understanding what end-to-end matrix $W$ emerges when we run GD on an LNN to minimize a general convex loss $L(W)$, and in particular the matrix completion loss given above. 
Note that $L(W)$ is convex, but the objective obtained by over-parameterizing with an LNN is not.
We analyze the trajectories of $W$, and specifically the dynamics of its singular value decomposition.
Denote the singular values by $\{ \sigma_r \}_r$, and the corresponding left and right singular vectors by $\{ \mathbf{u}_r \}_r$ and $\{ \mathbf{v}_r \}_r$ respectively.</p>

<p>We start by considering GD applied to $L(W)$ directly (no over-parameterization).</p>

<blockquote>
  <p><strong>Known result:</strong>
Minimizing $L(W)$ directly by GD (with small learning rate $\eta$) leads the singular values of $W$ to evolve by:
[
\sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle ~.
\qquad (1)
]</p>
</blockquote>

<p>This statement implies that the movement of a singular value is proportional to the projection of the gradient onto the corresponding singular component.</p>

<p>Now suppose that we parameterize $W$ with an $N$-layer LNN, i.e. as $W = W_N W_{N-1} \cdots W_1$.
In previous work (described in <a href="http://www.offconvex.org/2018/03/02/acceleration-overparameterization/">Nadav’s earlier blog post</a>) we have shown that running GD on the LNN, with small learning rate $\eta$ and initialization close to the origin, leads the end-to-end matrix $W$ to evolve by:</p>



<p>In the new paper we rely on this result to prove the following:</p>

<blockquote>
  <p><strong>Theorem:</strong>
Minimizing $L(W)$ by running GD (with small learning rate $\eta$ and initialization close to the origin) on an $N$-layer LNN leads the singular values of $W$ to evolve by:
[ \sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle \cdot \color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}} ~.
]</p>
</blockquote>

<p>Comparing this to Equation $(1)$, we see that over-parameterizing the loss $L(W)$ with an $N$-layer LNN introduces the multiplicative factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$ to the evolution of singular values.
While the constant $N$ does not change relative dynamics (can be absorbed into the learning rate $\eta$), the terms $(\sigma_r(t))^{2 - 2 / N}$ do $-$ they enhance movement of large singular values, and on the hand attenuate that of small ones.
Moreover, the enhancement/attenuation becomes more significant as $N$ (network depth) grows.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-thm-dynamics.png" style="width: 900px;"/>
<br/>
<b>Figure 1:</b> Over-parameterizing with LNN modifies dynamics of singular values.
</div>
<p><br/></p>

<p>The enhancement/attenuation effect induced by an LNN (factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$) leads each singular value to progress very slowly after initialization, when close to zero, and then, upon reaching a certain threshold, move rapidly, with the transition from slow to rapid movement being sharper in case of a deeper network (larger $N$).
If the loss $L(W)$ is underdetermined (has multiple optima) these dynamics promote solutions that have a few large singular values and many small ones (that have yet to reach the phase transition between slow to rapid movement), with a gap that is more extreme the deeper the network is. 
This is an implicit regularization towards low rank, which intensifies with depth.
In the paper we support the intuition with empirical evaluations and theoretical illustrations, demonstrating how adding depth to an LNN can lead GD to produce solutions closer to low-rank.
For example, the following plots, corresponding to a task of matrix completion, show evolution of singular values throughout training of networks with varying depths $-$ as can be seen, adding layers indeed admits a final solution whose spectrum is closer to low-rank, thereby improving generalization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-dynamics.png" style="width: 900px;"/>
<br/>
<b>Figure 2:</b> Dynamics of singular values in training matrix factorizations (LNN).
</div>

<h2 id="do-the-trajectories-minimize-some-regularized-objective">Do the Trajectories Minimize Some Regularized Objective?</h2>

<p>In recent years, researchers have come to realize the importance of implicit regularization induced by the choice of optimization algorithm.
The strong gravitational pull of the conventional view on optimization (see <a href="http://www.offconvex.org/2019/06/03/trajectories/">Sanjeev’s post</a>) has led most papers on this line to try and capture the effect in the language of regularized objectives. 
For example, it is known that over linear models, i.e. depth $1$ networks, GD finds the solution with minimal Frobenius norm (cf. Section 5 in <a href="https://openreview.net/pdf?id=Sy8gdB9xx">Zhang et al.</a>), and a common hypothesis is that this persists over more elaborate neural networks, with Frobenius norm potentially replaced by some other norm (or quasi-norm) that depends on network architecture.
<a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a> explicitly conjectured:</p>

<blockquote>
  <p><strong>Conjecture (by <a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a>, informally stated):</strong>
GD (with small learning rate and near-zero initialization) training a matrix factorization finds a solution with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms">nuclear norm</a>.</p>
</blockquote>

<p>This conjecture essentially states that matrix factorization (i.e. $2$-layer LNN) trained by GD is equivalent to the famous method of nuclear norm minimization.
Gunasekar et al. motivated the conjecture with some empirical evidence, as well as mathematical evidence in the form of a proof for a (very) restricted setting.</p>

<p>Given the empirical observation by which adding depth to a matrix factorization can improve results in matrix completion, it would be natural to extend the conjecture of Gunasekar et al., and assert that the implicit regularization with depth $3$ or higher corresponds to minimizing some other norm (or quasi-norm) that approximates rank better than nuclear norm does.
For example, a natural candidate would be a <a href="https://en.wikipedia.org/wiki/Schatten_norm">Schatten-$p$ quasi-norm</a> with some $0 &lt; p &lt; 1$.</p>

<p>Our investigation began with this approach, but ultimately, we became skeptical of the entire “implicit regularization as norm minimization” line of reasoning, and in particular of the conjecture by Gunasekar et al.</p>

<blockquote>
  <p><strong>Theorem (mathematical evidence against the conjecture):</strong>
In the same restricted setting for which Gunasekar et al. proved their conjecture, nuclear norm is minimized by GD over matrix factorization not only with depth $2$, but with any depth $\geq 3$ as well.</p>
</blockquote>

<p>This theorem disqualifies Schatten quasi-norms as the implicit regularization in deep matrix factorizations, and instead suggests that all depths correspond to nuclear norm.
However, empirically we found a notable difference in performance between different depths, so the conceptual leap from a proof in the restricted setting to a general conjecture, as done by Gunasekar et al., seems questionable.</p>

<p>In the paper we conduct a systematic set of experiments to empirically evaluate the conjecture.
We find that in the regime where nuclear norm minimization is suboptimal (few observed entries), matrix factorizations consistently outperform it (see for example Table 1).
This holds in particular with depth $2$, in contrast to the conjecture’s prediction.
Together, our theory and experiments lead us to believe that it may not be possible to capture the implicit regularization in LNN with a single mathematical norm (or quasi-norm).</p>

<p>Full details behind our results on “implicit regularization as norm minimization” can be found in Section 2 of <a href="https://arxiv.org/abs/1905.13655">the paper</a>.
The trajectory analysis we discussed earlier appears in Section 3 there.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The <a href="http://www.offconvex.org/2019/06/03/trajectories/">conventional view of optimization</a> has been integral to the theory of machine learning. 
Our study suggests that the associated vocabulary may not suffice for understanding generalization in deep learning, and one should instead analyze trajectories of optimization, taking into account that speed of convergence does not necessarily correlate with generalization.
We hope this work will motivate development of a new vocabulary for analyzing deep learning.</p></div>
    </summary>
    <updated>2019-07-10T17:00:00Z</updated>
    <published>2019-07-10T17:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2019-07-14T23:52:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1382</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" rel="alternate" type="text/html"/>
    <title>Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part I</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>    I (n.b., Julien Mairal) have been interested in drawing links between neural networks and kernel methods for some time, and I am grateful to Sebastien for giving me the opportunity to say a few words about it on … <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p><a class="liimagelink" href="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/kernel_fig.jpg?ssl=1"><img alt="" class="alignnone wp-image-1393" height="368" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/kernel_fig.jpg?resize=646%2C368&amp;ssl=1" width="646"/></a></p>
<p> </p>
<p>I (<em>n.b., <a class="liinternal" href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a></em>) have been interested in drawing links between neural networks and kernel methods for some time, and I am grateful to Sebastien for giving me the opportunity to say a few words about it on his blog. My initial motivation was not to provide another “why deep learning works” theory, but simply to encode into kernel methods a few successful principles from convolutional neural networks (CNNs), such as the ability to model the local stationarity of natural images at multiple scales—we may call that modeling receptive fields—along with feature compositions and invariant representations. There was also something challenging in trying to reconcile end-to-end deep neural networks and non-parametric methods based on kernels that typically decouple data representation from the learning task.</p>
<p>The main goal of this blog post is then to discuss the construction of a particular multilayer kernel for images that encodes the previous principles, derive some invariance and stability properties for CNNs, and also present a simple mechanism to perform feature learning in reproducing kernel Hilbert spaces. In other words, we should not see any intrinsic contradiction between kernels and representation learning.</p>
<p><strong>Preliminaries on kernel methods</strong></p>
<p>Given data living in a set <img alt="\mathcal{X}" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/>, a positive definite kernel <img alt="K: \mathcal{X} \times \mathcal{X} \to \mathbb{R}" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f0d19a1401658006e20eb7aff7c20689_l3.png?resize=124%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="124"/> implicitly defines a Hilbert space <img alt="\mathcal{H}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/> of functions from <img alt="\mathcal{X}" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/> to <img alt="\mathbb{R}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/>, called reproducing kernel Hilbert space (RKHS), along with a mapping function <img alt="\varphi: \mathcal{X} \to \mathcal{H}" class="ql-img-inline-formula " height="16" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-075eb9a40ac7f19fc1d24932d430cf57_l3.png?resize=84%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="84"/>.</p>
<p>A predictive model <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/> in <img alt="\mathcal{H}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/> associates to every point <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> a label in <img alt="\mathbb{R}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/>, and admits a simple form <img alt="f(x) =\langle f, \varphi(x) \rangle_{\mathcal{H}}" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-af2242f529038b9f66bdd803a7fcf32d_l3.png?resize=138%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="138"/>. Then, Cauchy-Schwarz inequality gives us a first basic stability property</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \forall x, x'\in \mathcal{X},~~~~~ |f(x)-f(x')| \leq \|f\|_{\mathcal{H}} \| \varphi(x) - \varphi(x')\|_\mathcal{H}. \]" class="ql-img-displayed-equation " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ba1f97e9889116f67e3caf7d27f6dca2_l3.png?resize=418%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="418"/></p>
<p>This relation exhibits a discrepancy between neural networks and kernel methods. Whereas neural networks optimize the data representation for a specific task, the term on the right involves the product of two quantities where data representation and learning are decoupled:</p>
<p><img alt="\|\varphi(x)-\varphi(x')\|_\mathcal{H}" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9b7eefc0051c0b86a82ee0265f44a085_l3.png?resize=125%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="125"/> is a distance between two data representations <img alt="\varphi(x),\varphi(x')" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-41c6c60616e1acea2bdd02deee51011e_l3.png?resize=83%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="83"/>, which are independent of the learning process, and <img alt="\|f\|_\mathcal{H}" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c755a8a9349d0895075e9494d1b11fc1_l3.png?resize=38%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="38"/> is a norm on the model <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/> (typically optimized over data) that acts as a measure of complexity.</p>
<p>Thinking about neural networks in terms of kernel methods then requires defining the underlying representation <img alt="\varphi(x)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eb419c2adecf84ed9a2d9693bc58d101_l3.png?resize=35%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/>, which can only depend on the network architecture, and the model <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/>, which will be parametrized by (learned) network’s weights.</p>
<p><strong>Building a convolutional kernel for convolutional neural networks</strong></p>
<p>Following <a class="lipdf" href="http://jmlr.org/papers/volume20/18-190/18-190.pdf">Alberto Bietti’s paper</a>, we now consider the direct construction of a multilayer convolutional kernel for images. Given a two-dimensional image <img alt="x_0" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/>, the main idea is to build a sequence of “feature maps” <img alt="x_1,x_2,\ldots" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e504020251e8444e8047821206317fa_l3.png?resize=71%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="71"/> that are two-dimensional spatial maps carrying information about image neighborhoods (a.k.a receptive fields) at every location. As we proceed in this sequence, the goal is to model larger neighborhoods with more “invariance”.</p>
<p>Formally, an input image <img alt="x_0" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> is represented as a square-integrable function in <img alt="L^2(\Omega,\mathcal{H}_0)" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b1cdcac953d52ed35e77925a243c3df7_l3.png?resize=76%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="76"/>, where <img alt="\Omega" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> is a set of pixel coordinates, and <img alt="\mathcal{H}_0" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> is a Hilbert space. <img alt="\Omega" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> may be a discrete grid or a continuous domain such as <img alt="\mathbb{R}^2" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>, and <img alt="\mathcal{H}_0" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> may simply be <img alt="\mathbb{R}^3" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-97886402213f48c46e631e5331a34035_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/> for RGB images. Then, a feature map <img alt="x_k" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> in <img alt="L^2(\Omega,\mathcal{H}_k)" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-66fdb69a62e8ec8647eac89f54998a71_l3.png?resize=77%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="77"/> is obtained from a previous layer <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> as follows:</p>
<ul>
<li><em> modeling larger neighborhoods than in the previous layer:</em> we map neighborhoods (patches) from <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> to a new Hilbert space <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>. Concretely, we define a homogeneous dot-product kernel between patches <img alt="z, z'" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ce80943b7f55934d998e09542933b73e_l3.png?resize=30%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="30"/> from <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/>:
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ K_k(z,z') = \|z\| \|z'\| \kappa_k \left( \left\langle \frac{z}{\|z\|}, \frac{z'}{\|z'\|} \right\rangle \right), \]" class="ql-img-displayed-equation " height="43" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e98e6c584e7aa34a129d04fa46a6981c_l3.png?resize=304%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="304"/></p>
<p> where <img alt="\langle . , . \rangle" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b62527a227d32e3e2f43b8b9b2b31ad5_l3.png?resize=29%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="29"/> is an inner-product derived from <img alt="\mathcal{H}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec7eee8a3bac08b4c319cfce53408682_l3.png?resize=39%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="39"/>, and <img alt="\kappa_k" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> is a non-linear function that ensures positive definiteness, <em>e.g.</em>, <img alt="\kappa_k(\langle u,u'\rangle ) = e^{\alpha (\langle u,u'\rangle -1)} = e^{-\frac{\alpha}{2}\|u-u'\|^2}" class="ql-img-inline-formula " height="23" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-46c64b76ccc9f508d30fec2fb80e244d_l3.png?resize=289%2C23&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="289"/> for vectors <img alt="u, u'" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0b88ce07daf9a52ba8a46659cff355fd_l3.png?resize=32%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> with unit norm, see <a class="lipdf" href="http://jmlr.org/papers/volume20/18-190/18-190.pdf">this paper</a>. By doing so, we implicitly define a kernel mapping <img alt="\varphi_k" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-243ed60e88d807834cd7cb1e1fbe0658_l3.png?resize=19%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="19"/> that maps patches from <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> to a new Hilbert space <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>. This mechanism is illustrated in the picture at the beginning of the post, and produces a spatial map that carries these patch representations.</p></li>
<li><em>increasing invariance:</em> to gain invariance to small deformations, we smooth~<img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> with a linear filter, as shown in the picture at the beginning of the post, which may be interpreted as anti-aliasing (in terms of signal processing) or linear pooling (in terms of neural networks).</li>
</ul>
<p>Formally, the previous construction amounts to applying operators <img alt="P_k" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4726bbf70431cf284be54bbc6a04ad60_l3.png?resize=18%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> (patch extraction), <img alt="M_k" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78f07026bc8c5150a11bf9e00756b7a7_l3.png?resize=24%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="24"/> (kernel mapping), and <img alt="A_k" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-866de181a59a21d2ca2306a9adbd9bc1_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> (smoothing/pooling operator) to <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> such that the <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>-th layer representation can be written as</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \Phi_n(x_0)= x_n= A_n M_n P_n \ldots A_1 M_1 P_1 x_0~~~\text{in}~~~~L^2(\Omega,\mathcal{H}_n). \]" class="ql-img-displayed-equation " height="21" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e8c2d99cc679426d1af08e6d15510211_l3.png?resize=437%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="437"/></p>
<p>We may finally define a kernel for images as <img alt="\mathcal{K}_n(x_0,x_0')=\langle \Phi_n(x_0), \Phi_n(x_0') \rangle" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-16be084d5dd2ed3d7a18cdcf70c33fe2_l3.png?resize=231%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="231"/>, whose RKHS contains the functions <img alt="f_w(x_0) = \langle w , \Phi_n(x_0) \rangle" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-95aa9a4388dd5f5da6292875abe6596a_l3.png?resize=162%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="162"/> for <img alt="w" class="ql-img-inline-formula " height="8" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/> in <img alt="L^2(\Omega,\mathcal{H}_n)" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-502d385c60e5ecdb1a0f26ee770d30b1_l3.png?resize=77%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="77"/>. Note now that we have introduced a concept of image representation <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/>, which only depends on some network architecture (amounts of pooling, patch size), and predictive model <img alt="f_w" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-fb636251e88ba51d909c76c1110eed5e_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="19"/> parametrized by <img alt="w" class="ql-img-inline-formula " height="8" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/>.</p>
<p>From such a construction, we will now derive stability results for classical convolutional neural networks (CNNs) and then derive non-standard CNNs based on kernel approximations that we call convolutional kernel networks (CKNs).</p>
<p> </p>
<p>Next week, we will see how to perform feature (end-to-end) learning with the previous kernel representation, and also discuss other classical links between neural networks and kernel methods.</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-10T15:20:34Z</updated>
    <published>2019-07-10T15:20:34Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-07-14T23:52:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/092" rel="alternate" type="text/html"/>
    <title>TR19-092 |  Revisiting Alphabet Reduction in Dinur&amp;#39;s PCP | 

	Venkatesan Guruswami, 

	Jakub Opršal, 

	Sai Sandeep</title>
    <summary>Dinur's celebrated proof of the PCP theorem alternates two main steps in several iterations: gap amplification to increase the soundness gap by a large constant factor (at the expense of much larger alphabet size), and a composition step that brings back the alphabet size to an absolute constant (at the expense of a fixed constant factor loss in the soundness gap). We note that the gap amplification can produce a Label Cover CSP. This allows us to reduce the alphabet size via a direct long-code based reduction from Label Cover to a Boolean CSP. Our composition step thus bypasses the concept of Assignment Testers from Dinur's proof, and we believe it is more intuitive --- it is just a gadget reduction. The analysis also uses only elementary facts (Parseval's identity) about Fourier Transforms over the hypercube.</summary>
    <updated>2019-07-09T16:04:11Z</updated>
    <published>2019-07-09T16:04:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-15T12:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17523</id>
    <link href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/" rel="alternate" type="text/html"/>
    <title>Imre Bárány: Limit shape</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Limit shapes are fascinating objects in the interface between probability and geometry and between the discrete and the continuous. This post is kindly contributed by Imre Bárány. What is a limit shape? There are finitely many convex lattice polygons contained … <a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Limit shapes are fascinating objects in the interface between probability and geometry and between the discrete and the continuous. This post is kindly contributed by Imre Bárány.</em></p>
<h3><a href="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg"><img alt="" class="alignnone size-full wp-image-17560" src="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg?w=640"/></a></h3>
<h2>What is a limit shape?</h2>
<p>There are finitely many convex lattice polygons contained in the <img alt="{[0,n]^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B0%2Cn%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[0,n]^2}"/> square. Their number turns out to be</p>
<p><img alt="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cexp%5C%7B3%5Csqrt%5B3%5D%7B%5Czeta%283%29%2F%5Czeta%282%29%7Dn%5E%7B2%2F3%7D%281%2Bo%281%29%29%5C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)"/></p>
<p>This is a large number. How does a typical element of this large set look? Is there a<br/>
limit shape of these convex lattice polygons?</p>
<p>To answer this question it is convenient to consider the lattice <img alt="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%3D%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}"/> and define <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> as the family of all convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygons lying in the unit square <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. The polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> have a limit shape (as <img alt="{n\rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n\rightarrow \infty}"/>) if there is a convex set <img alt="{K\subset Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K\subset Q}"/> such that the overwhelming majority of the polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> are very close to <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/>. In other words, for every <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/> the number of polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> that are farther than <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/> from <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> (in Hausdorff distance, say) is a minute part of <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/>, that is, <img alt="{o(|\mathcal{F}^n|)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28%7C%5Cmathcal%7BF%7D%5En%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o(|\mathcal{F}^n|)}"/> as <img alt="{n \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \rightarrow \infty}"/>. To put it differently, the average of the characteristic functions <img alt="{\chi_P(.)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_P%28.%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_P(.)}"/> of <img alt="{P\in \mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P\in \mathcal{F}^n}"/> tends to a zero-one function:</p>
<p><img alt="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clim+%7B%5Crm+Ave%7D_%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D%5Cchi_P%28x%29%3D%5Cbegin%7Bcases%7D+1%26+%5Cmbox%7B+if+%7D+x+%5Cin+K%2C%5C%5C+0%26+%5Cmbox%7B+if+%7D+x+%5Cnotin+K.+%5Cend%7Bcases%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} "/></p>
<h2>The limit shape theorem</h2>
<h3/>
<p>The limit shape theorem says that such a <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> exists, its boundary consists of four parabola arcs each touching consecutive sides of <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/> at their midpoints, see the figure.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/limitshape.png"><img alt="" class="alignnone size-full wp-image-17536" src="https://gilkalai.files.wordpress.com/2019/07/limitshape.png?w=640"/></a></p>
<h3>Generating functions and saddle point methods</h3>
<p>The proof is based on the fact that a convex (lattice or non-lattice) polygon with vertices <img alt="v_1,\ldots,v_n" class="latex" src="https://s0.wp.com/latex.php?latex=v_1%2C%5Cldots%2Cv_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v_1,\ldots,v_n"/> (in this order on its boundary) is uniquely determined by the edge-vectors <img alt="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n" class="latex" src="https://s0.wp.com/latex.php?latex=v_2-v_1%2C%5Cldots%2Cv_n-v_%7Bn-1%7D%2C+v_1-v_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n"/>. Using this one can write down the generating function of the number of convex lattice paths from <img alt="(0,0)" class="latex" src="https://s0.wp.com/latex.php?latex=%280%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(0,0)"/> to <img alt="(a,b)\in \mathbb{Z}^2" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29%5Cin+%5Cmathbb%7BZ%7D%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)\in \mathbb{Z}^2"/> lying in the triangle whose vertices are <img alt="(0,0),(a,0)" class="latex" src="https://s0.wp.com/latex.php?latex=%280%2C0%29%2C%28a%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(0,0),(a,0)"/> and <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>. And this number can be estimated by saddle point methods (from complex variables). This is also how formula (1) for <img alt="|\mathcal{F}^n|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BF%7D%5En%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathcal{F}^n|"/> can be established.</p>
<h3>A beautiful geometric result</h3>
<p>On the geometry part one needs a beautiful (and almost elementary) result saying that, in a triangle <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> with vertices <img alt="1,2,3" class="latex" src="https://s0.wp.com/latex.php?latex=1%2C2%2C3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1,2,3"/> and with subtriangles <img alt="T_1" class="latex" src="https://s0.wp.com/latex.php?latex=T_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_1"/> and <img alt="T_2" class="latex" src="https://s0.wp.com/latex.php?latex=T_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_2"/> (see the figure)</p>
<p><img alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/triangle.png"><img alt="" class="alignnone size-full wp-image-17537" src="https://gilkalai.files.wordpress.com/2019/07/triangle.png?w=640"/></a></p>
<p>with equality iff the line segment 46 is touches the special parabola arc at point 5. The special parabola arc is the one that touches sides 12 and 13 of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> at points 2 and 3. I was very proud of inequality (2) but it turned out that it had been known for long (cf Blaschke: Vorlesungen Über Differentialgeometrie II, (1923) page 38).</p>
<p>In the proof one needs a slightly stronger version of (2). Assuming point 4 (resp. 6) divides segment 12 (and 13) in ratio <img alt="{1-a:a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-a%3Aa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1-a:a}"/>, (and <img alt="{b:1-b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%3A1-b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b:1-b}"/>), the stronger inequality says that</p>
<p><img alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cleft%281-%5Cfrac13+%28a-b%29%5E2%5Cright%29%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, "/></p>
<p>which was probably not known to Blaschke.</p>
<p>It is important to point out that <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is the unique convex subset of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> whose affine perimeter is the largest among all convex subsets of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. I’ll return to the affine perimeter later.</p>
<p>Yakov Sinai came up with a different, elegant, and more powerful proof using canonical ensembles from statistical physics. His method was developed further by Vershik and Zeitouni, by Bureaux and Enriquez, by Bogachev and Zarbaliev.</p>
<h2>Limit shapes for polygons in convex bodies</h2>
<p>More generally, one can consider a convex body (compact convex set with non-empty interior) <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in the plane and the family <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> of all convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygons contained in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, and ask whether a similar limit shape exists in this case. The answer is yes. The limit shape, <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, is the unique convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> whose affine perimeter is maximal among all convex subsets of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The affine perimeter is upper semicontinuous, implying the existence of convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with maximal affine perimeter. The proof of its uniqueness requires extra effort. In the case when <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is the unit square <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>, the limit shape <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is equal to <img alt="{Q_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_0}"/>. Note that for every convex body <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with <img alt="{Q_0\subset C \subset Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_0%5Csubset+C+%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_0\subset C \subset Q}"/>, <img alt="{C_0=Q_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%3DQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0=Q_0}"/>.</p>
<h2>Random points vs. lattice points</h2>
<p>What happens if, instead of the <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice points in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, we take a random sample <img alt="{X_n=\{x_1,\ldots,x_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%3D%5C%7Bx_1%2C%5Cldots%2Cx_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n=\{x_1,\ldots,x_n\}}"/> of points from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, chosen independently and uniformly? Let <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> be the set of all polygons whose vertices belong to <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/>. This is again a finite set and one can show that<br/>
<img alt="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E%7B-1%2F3%7D%5Clog+%5Cmathop%7B%5Cmathbb+E%7D%28+%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%3D3%5Ccdot2%5E%7B-2%2F3%7D%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, "/></p>
<p>where <img alt="{A^*(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)}"/> is equal to the affine perimeter, <img alt="{AP(C_0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28C_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(C_0)}"/>, of <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. This confirms the philosophy (or my intuition) that random points and lattice points in convex bodies behave similarly. Note that <img alt="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5Cmathcal%7BG%7D%28X_n%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}"/> is of order <img alt="{\exp\{c_1n^{1/3}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_1n%5E%7B1%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exp\{c_1n^{1/3}\}}"/> while <img alt="{|\mathcal{F}^n(C)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cmathcal%7BF%7D%5En%28C%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\mathcal{F}^n(C)|}"/> is of order <img alt="{\exp\{c_2n^{2/3}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_2n%5E%7B2%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exp\{c_2n^{2/3}\}}"/> which is fine as number of <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice points in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is approximately <img alt="{n^2 \textrm{Area} \; C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E2+%5Ctextrm%7BArea%7D+%5C%3B+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^2 \textrm{Area} \; C}"/>.</p>
<p>Even more interestingly, the limit shape of the polygons in <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> is <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, in the sense that, in expectation, the overwhelming majority of polygons in <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> is very close to <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. More precisely, for every <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/><br/>
<img alt="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn+%5Crightarrow+%5Cinfty%7D+%5Cfrac%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5C%7BP%5Cin+%5Cmathcal%7BG%7D%28X_n%29%3A%5Cdelta%28P%2CC_0%29%3E%5Cepsilon%5C%7D%7C%7D%7B%5Cmathop%7B%5Cmathbb+E%7D%28%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%7D%3D0%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, "/></p>
<p>where <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> stands for the Hausdorf distance.</p>
<p>The proof of the lattice case does not work here. The edge vectors determine the convex polygon, still, but the edge vectors can’t be used, there is no generating function, etc. Instead the proof is based on the following two theorems. For the first let <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> be a triangle with two specified vertices <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> say, and let <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> be a random independent sample of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> uniform points from <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/>. Then <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> is called a convex chain (from <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> to <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>) if the convex hull of <img alt="{\{a,b\}\bigcup X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Ba%2Cb%5C%7D%5Cbigcup+X_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{a,b\}\bigcup X_k}"/> is a convex polygon with exactly <img alt="{k+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k+2}"/> vertices. Then<br/>
<img alt="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%5BX_k+%5Cmbox%7B+is+a+convex+chain%7D%5D%3D%5Cfrac+%7B2%5Ek%7D%7Bk%21%28k%2B1%29%21%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, "/></p>
<p>a surprisingly precise result (due to Pavel Valtr).</p>
<p>For the second theorem let <img alt="{p(n,C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%28n%2CC%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(n,C)}"/> denote the probability that the random sample <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/> (independent and uniform again) lands in convex position, that is, their convex hull is a convex <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-gon. For <img alt="{n=4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=4}"/> this is Sylvester’s famous four point problem from 1864 (although he did not specify the underlying convex body <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>). Then<br/>
<img alt="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E2%5Csqrt%5Bn%5D%7Bp%28n%2CC%29%7D%3D%5Cfrac+%7Be%5E2%7D4%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, "/></p>
<p>with the same <img alt="{A^*(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)}"/> as before. The proof of this theorem uses the previous result of Valtr about convex chains in triangles and the properties of <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, the largest affine area convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The set <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> appears again: it is the limit shape of <img alt="{\textrm{conv}X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7Bconv%7DX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textrm{conv}X_n}"/> under the condition that <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/> landed in convex position.</p>
<p>The map <img alt="{C \rightarrow C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Crightarrow+C_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \rightarrow C_0}"/> is affinely equivariant and has interesting properties. <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> turns out to be the limit shape in some further cases as well. For instance, the maximal number of vertices of the polygons in <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> equals</p>
<p><img alt="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac+%7B3n%5E%7B2%2F3%7D%7D%7B%282%5Cpi%29%5E%7B2%2F3%7D%7DA%5E%2A%28C%29%281%2Bo%281%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), "/></p>
<p>as <img alt="{n \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \rightarrow \infty}"/>. This is of course the same as the maximal number of points in <img alt="{{\mathbb{Z}}_n\cap C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n\cap C}"/> that are in convex position. Although the convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygon <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> with maximal number of vertices is not necessary unique, they have a limit shape which is again <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. The same happens in <img alt="{\mathcal{G}_n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D_n%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}_n(C)}"/> as well. In this case, however, the expectation of the maximal number of vertices is equal to constant times <img alt="{A^*(C)n^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29n%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)n^{1/3}}"/> but the value of this (positive) constant is not known. The reason is the following. In the triangle <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> with specified vertices <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>, and random sample <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> we define <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> as the maximal number of points from <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> that form a convex chain in <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> from <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> to <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>. The random variable <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> is concentrated around its expectation, which is equal to some non-negative constant times <img alt="{k^{1/3}(1+o(1))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7B1%2F3%7D%281%2Bo%281%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{1/3}(1+o(1))}"/> as <img alt="{k \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k \rightarrow \infty}"/> but this constant is not known. Experiments suggest that it is equal to 3 but there is no proof in sight. Not surprisingly, the limit shape of these maximal convex chains is again the special parabola arc in <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/>. This question about the random variable <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> is similar to the longest increasing subsequence problem but much less is known about it.</p>
<h2>Open Problem: high dimensions</h2>
<p>What remains of the limit shape phenomenon in higher dimensions? Well, hardly anything has been proved. In the simplest case, let <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> denote the unit cube in 3-space, and let <img alt="{\mathcal{F}^n(Q)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28Q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(Q)}"/> denote the set of all convex <img alt="{\frac 1n {\mathbb{Z}}^3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac 1n {\mathbb{Z}}^3}"/>-lattice polygons contained in <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. It is known that <img alt="{\log |\mathcal{F}^n(Q)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+%7C%5Cmathcal%7BF%7D%5En%28Q%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log |\mathcal{F}^n(Q)|}"/> is between <img alt="{c_1n^{1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1n^{1/2}}"/> and <img alt="{c_2 n^{1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_2+n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_2 n^{1/2}}"/> with <img alt="{0&lt;c_1&lt;c_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3Cc_1%3Cc_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;c_1&lt;c_2}"/>, but nothing more precise. Probably there is a limit shape here as well, and it might be the convex subset of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> that has the largest affine surface area. The existence of such a set follows the same way as above but its uniqueness is not known.</p>
<h2>The affine perimeter</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/affper.png"><img alt="" class="alignnone size-full wp-image-17542" src="https://gilkalai.files.wordpress.com/2019/07/affper.png?w=640"/></a></p>
<p> </p>
<p>Finally a few words about the affine perimeter. Given a convex curve <img alt="{\Gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Gamma}"/> in the plane, choose points <img alt="{x_0,\ldots, x_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2C+x_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_0,\ldots, x_n}"/> on it, take the tangent lines at these points and form the triangles <img alt="{T_1,\ldots,T_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_1%2C%5Cldots%2CT_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_1,\ldots,T_n}"/> as in the figure. By definition, the affine perimeter <img alt="{AP(\Gamma)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(\Gamma)}"/> is the infimum of the sum <img alt="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}"/> as the subdivision <img alt="{x_0,\ldots,x_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_0,\ldots,x_n}"/> gets finer and finer. The affine perimeter of the unit circle is <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\pi}"/> which explains the constant <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> in front of <img alt="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}"/>. The exponent <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/3}"/> is the right choice here: for larger exponent the sum is zero, and for smaller it is infinity (for the circle for instance). Inequality (2) shows that infimum in the definition can be replaced by limit. The affine perimeter of a convex polygon is zero.</p>
<p>For a twice differentiable curve <img alt="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29+%3D+%5Cint_%7B%5CGamma%7D%5Ckappa%5E%7B1%2F3%7Dds%3D%5Cint_%7B%5CGamma%7Dr%5E%7B-1%2F3%7Dds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}"/> where <img alt="{\kappa}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ckappa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\kappa}"/> is the curvature and <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> the radius of curvature and <img alt="{ds}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ds}"/> means integration with arc length. The affine perimeter is an affine invariant or rather equivariant meaning that <img alt="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28S%28%5CGamma%29%29%3D%5Csqrt%5B3%5D%7B%7C%5Cdet+S%7C%7D+AP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}"/> for a non-degenerate affine transformation <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Quite often the affine perimeter (and the affine surface area) appears in connection with affine equivariant properties of the convex set <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. One example is best approximation by inscribed polygons <img alt="{P_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n}"/> on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vertices. When approximation is measured by <img alt="{\textrm{Area}\;(C\backslash P_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7BArea%7D%5C%3B%28C%5Cbackslash+P_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textrm{Area}\;(C\backslash P_n)}"/> then the best approximating polygon <img alt="{P_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n}"/> satisfies the estimate<br/>
<img alt="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ctextrm%7BArea%7D+%5C%3B+%28C%5Cbackslash+P_n%29%3D+%5Cfrac+1%7B4%5Csqrt+3%7D+%5Cfrac+%7BAP%28C%29%5E3%7D%7Bn%5E2%7D%281%2Bo%281%29%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)"/></p>
<p>The set <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, the convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with maximal affine perimeter has interesting properties. For instance its boundary contains no line segment, and if some piece of its boundary lies in the interior of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, then this piece is a parabola arc. It has positive curvature everywhere. It is of course affinely equivariant meaning that <img alt="{S(C_0)= S(C)_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%28C_0%29%3D+S%28C%29_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S(C_0)= S(C)_0}"/>. According to (3) <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> has the worst approximation properties among all convex subsets of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{C}"/>.  This might explain why it comes up as the limit shape so often. Actually, the high dimensional analogue of (3) suggests that the limit shape in higher dimensions is again connected to the maximal affine surface area subset of the underlying convex body.</p>
<p> </p>
<p>More reading: Imre Bárány, <a href="https://www.ams.org/journals/bull/2008-45-03/S0273-0979-08-01210-X/">Random points and lattice points in convex bodies</a>, Bull AMS (2008)</p></div>
    </content>
    <updated>2019-07-09T08:35:29Z</updated>
    <published>2019-07-09T08:35:29Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Geometry"/>
    <category term="Guest blogger"/>
    <category term="Probability"/>
    <category term="Imre Barany"/>
    <category term="limit shape"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-15T12:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8041836663315088806</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8041836663315088806/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8041836663315088806" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8041836663315088806" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html" rel="alternate" type="text/html"/>
    <title>Fortran is underated!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(Joint Post with David Marcus who was a classmate of mine at SUNY Stony Brook [now called Stony Brook University]. I was class of 1980, he was class of 1979. We were both math majors.)<br/>
<br/>
David has been reading <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a POINT</a> (I'm glad someone is reading it) and emailed me a comment on the following passage which was essentially <a href="https://blog.computationalcomplexity.org/2012/02/dusting-off-my-bookshelf-i-find-book-on.html">this post</a>. I paraphrase what I wrote:<br/>
<br/>
PASSAGE IN BOOK:<br/>
I dusted off my book shelves and found a book on Fortran. On the back it said:<br/>
<br/>
FORTRAN is one of the oldest high-level languages and remains the premier language for writing code for science and engineering applications. (NOTE- The back of the book uses Fortran but the spell checker I am using insists on FORTRAN. As a fan of capital letters, I don't mind going along.)<br/>
<br/>
When was the book written?<br/>
<br/>
The answer was surprising in that it was 2012 (the Chapter title was <i>Trick Question or Stupid Question</i>. This was a Trick Question.) I would have thought that FORTRAN was no longer the premier language by then. I also need to dust my bookshelves more often.<br/>
END OF PASSAGE IN BOOK<br/>
<br/>
David Marcus emailed me the following:<br/>
<br/>
DAVID'S EMAIL<br/>
Page 201. Fortran. One clue is that it said "Fortran" rather than"FORTRAN". Fortran 90 changed the name from all upper case. Whether it is the "premier language" depends on what you mean by "premier". It is probably the best language for scientific computing. I used it pretty much exclusively (by choice) in my previous job that I left in 2006. The handling of arrays is better than any other language I've used. Maybe there are some better languages that I'm not familiar with, but the huge number of high-quality scientific libraries available for Fortran makes it hard to beat. On the other hand, I never wrote a GUI app with it (Delphi is best for that).<br/>
END OF DAVID'S EMAIL<br/>
<br/>
In later emails we agreed that Fortran is not used that much (there are lists of most-used languages and neither Fortran nor FORTRAN is ever in the top 10).  But what intrigued me was the following contrast:<br/>
<br/>
1) David says that its the BEST language for Scientific Computing.  I will assume he is right.<br/>
<br/>
2) I doubt much NEW code is being written in it.  I will assume I am right.<br/>
<br/>
So---what's up with that? Some options<br/>
<br/>
OPTION 1) People SHOULD use Fortran but DON'T. If so, why is that?  Fortran is not taught in schools. People are used to what they already know.  Perhaps people who do pick up new things easily and want to use new things would rather use NEW things rather than NEW-TO-THEM-BUT-NOT-TO-THEIR-GRANDMOTHER things. Could be a coolness factor.  Do the advantages of Fortran outweight the disadvantages?  Is what they are using good enough?<br/>
<br/>
OPTION 2) The amount of Scientific computing software being written is small since we already have these great Fortran packages. So it may be a victim of its own success.<br/>
<br/>
CAVEAT: When I emailed David a first draft of the post he pointed out the following which has to do with the lists of most-used programming languages:<br/>
<br/>
DAVIDS EMAIL:<br/>
The problem with the lists you were looking at is that most people in the world are not scientists, so most software being written is not for scientists. Scientists and technical people are writing lots of new code.  If you look at a list of scientific languages, you will see Fortran, e.g., <a href="https://en.wikipedia.org/wiki/Scientific_programming_language">here</a> and <a href="https://en.wikipedia.org/wiki/Fortran#Science_and_engineering">here</a>.<br/>
<br/>
<br/>
There are several Fortran compilers available. One of the best was bought by Intel some time back and they still sell it. I doubt they would do that if no one was using it. Actually, I think Intel had a compiler, but bought the Compaq compiler (which used to be the Digital Equipment compiler) and merged the Compaq team with their team. Something like that. I was using the Compaq compiler around that time.<br/>
END OF DAVID's EMAIL<br/>
<br/>
One quote from the second pointer I find intriguing.  (Second use of the word <i>intriguing</i>. It was my word-of-the-day on my word-calendar).<br/>
<br/>
<i>... facilities for inter-operation with C were added to Fortran 2003 and enhanced by ISO/ICE technical specification 29113, which will be incorporated into Fortran 2018. </i><br/>
<br/>
I (Bill) don't know what some of that means; however, it does mean that Fortran is still active.<br/>
<br/>
<br/>
One fear: with its not being taught that much, will knowledge of it die out.  We be like Star Trek aliens:<br/>
<br/>
<i>The old ones built these machines, but then died and we can't fix them!<br/>
<br/>
<br/>
<br/>
</i></div>
    </content>
    <updated>2019-07-08T03:55:00Z</updated>
    <published>2019-07-08T03:55:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-15T11:44:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/091" rel="alternate" type="text/html"/>
    <title>TR19-091 |  A Sublinear-space and Polynomial-time Separator Algorithm for Planar Graphs | 

	Ryo Ashida, 

	Tatsuya Imai, 

	Kotaro Nakagawa, 

	A.  Pavan, 

	Vinodchandran Variyam, 

	Osamu Watanabe</title>
    <summary>In [12] (CCC 2013), the authors presented an algorithm for the reachability problem over directed planar graphs that runs in polynomial-time and uses $O(n^{1/2+\epsilon})$ space. A critical ingredient  of their algorithm is a polynomial-time, $\tldO(\sqrt{n})$-space algorithm to compute a separator of a planar graph. The conference version provided a sketch of the algorithm and many nontrivial details were left unexplained. In this work, we provide a detailed construction of their algorithm.</summary>
    <updated>2019-07-07T23:37:15Z</updated>
    <published>2019-07-07T23:37:15Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-15T12:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4233</id>
    <link href="https://www.scottaaronson.com/blog/?p=4233" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4233#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4233" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">John Wright joins UT Austin</title>
    <summary xml:lang="en-US">I’m delighted to announce that quantum computing theorist John Wright will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. John made an appearance on this blog a few months ago, when I wrote about the new breakthrough by him and Anand Natarajan: namely, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter"><img alt="" class="wp-image-4244" src="https://www.scottaaronson.com/blog/wp-content/uploads/2019/07/image-1.png"/></figure></div>



<p>I’m delighted to announce that quantum computing theorist <a href="http://www.mit.edu/~jswright/">John Wright</a> will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. </p>



<p>John made an appearance on this blog a few months ago, when I <a href="https://www.scottaaronson.com/blog/?p=4172">wrote about</a> the <a href="https://arxiv.org/abs/1904.05870">new breakthrough</a> by him and <a href="http://www.its.caltech.edu/~anataraj/">Anand Natarajan</a>: namely, that MIP* (multi-prover interactive proofs with entangled provers) contains NEEXP (nondeterministic double-exponential time).  Previously, MIP* had only been known to contain NEXP (nondeterministic <em>single</em> exponential time).  So, this is an exponential expansion in the power of entangled provers over what was previously known and believed, and the first proof that entanglement actually <em>increases</em> the power of multi-prover protocols, rather than decreasing it (as it could’ve done a priori).  Even more strikingly, there seems to be no natural stopping point: MIP* might soon swallow up arbitrary towers of exponentials or even the halting problem (!).  For more, see for example <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">this <em>Quanta</em> article</a>, or <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">this post by Thomas Vidick</a>, or <a href="http://www.henryyuen.net/post/alice-and-bob-visit/">this short story [sic] by Henry Yuen</a>.</p>



<p>John grew up in Texas, so he’s no stranger to BBQ brisket or scorching weather.  He did his undergrad in computer science at UT Austin—my colleagues remember him as a star—and then completed his PhD with Ryan O’Donnell at Carnegie Mellon, followed by a postdoc at MIT.  Besides the work on MIP*, John is also well-known for his <a href="https://arxiv.org/abs/1508.01907">2015 work with O’Donnell</a> pinning down the sample complexity of quantum state tomography.  Their important result, a version of which was independently obtained by <a href="https://arxiv.org/abs/1508.01797">Haah et al.</a>, says that if you want to learn an unknown d-dimensional quantum mixed state ρ to a reasonable precision, then ~d<sup>2</sup> copies of ρ are both necessary and sufficient.  This solved a problem that had personally interested me, and already plays a role in, e.g., my work on <a href="https://arxiv.org/abs/1711.01053">shadow tomography</a> and <a href="https://www.scottaaronson.com/papers/dpgentle.pdf">gentle measurements</a>.</p>



<p>Our little <a href="https://www.cs.utexas.edu/~qic/">quantum information center</a> at UT Austin is growing rapidly.  <a href="http://sites.utexas.edu/shyamshankar/">Shyam Shankar</a>, a superconducting qubits guy who previously worked in Michel Devoret’s group at Yale, will also be joining UT’s Electrical and Computer Engineering department this fall.  I’ll have two new postdocs—<a href="https://twitter.com/a_rocchetto?lang=en">Andrea Rocchetto</a> and <a href="http://www.cs.huji.ac.il/~yosiat/">Yosi Atia</a>—as well as new PhD students.  We’ll continue recruiting this coming year, with potential opportunities for students, postdocs, faculty, and research scientists across the CS, physics, and ECE departments as well as the Texas Advanced Computing Center (TACC).  I hope you’ll consider applying to join us.</p>



<p>With no evaluative judgment attached, I can honestly say that this is an unprecedented time for quantum computing as a field.  Where once faculty applicants struggled to make a case for quantum computing (physics departments: “but isn’t this really CS?” / CS departments: “isn’t it really physics?” / everyone: “couldn’t this whole QC thing, like, all blow over in a year?”), today departments are vying with each other and with industry players and startups to recruit talented people.  In such an environment, we’re fortunate to be doing as well as we are.  We hope to continue to expand.</p>



<p>Meanwhile, this was an <a href="https://www.nytimes.com/2019/01/24/technology/computer-science-courses-college.html">unprecedented year for CS hiring at UT Austin</a> more generally.  John Wright is one of at least four new faculty (probably more) who will be joining us.  It’s a good time to be in CS.</p>



<p>A huge welcome to John, and hook ’em Hadamards!</p>



<p>(And for US readers: have a great 4<sup>th</sup>!  Though how could any fireworks match the proof of the Sensitivity Conjecture?)</p></div>
    </content>
    <updated>2019-07-04T01:08:54Z</updated>
    <published>2019-07-04T01:08:54Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-14T19:20:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at National University of Singapore (apply by November 30, 2019)</title>
    <summary>Multiple post-doctoral research positions available in the project on “Provably Verified and Explainable Probabilistic Reasoning,” led by the Principle Investigator, Kuldeep S. Meel. The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods. Website: https://meelgroup.github.io/files/postdoc.html Email: meel+postdoc@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple post-doctoral research positions available in the project on “Provably Verified and Explainable Probabilistic Reasoning,” led by the Principle Investigator, Kuldeep S. Meel.</p>
<p>The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods.</p>
<p>Website: <a href="https://meelgroup.github.io/files/postdoc.html">https://meelgroup.github.io/files/postdoc.html</a><br/>
Email: meel+postdoc@comp.nus.edu.sg</p></div>
    </content>
    <updated>2019-07-03T19:39:18Z</updated>
    <published>2019-07-03T19:39:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-07-15T12:20:41Z</updated>
    </source>
  </entry>
</feed>
