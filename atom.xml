<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-05-08T05:21:46Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03584</id>
    <link href="http://arxiv.org/abs/2005.03584" rel="alternate" type="text/html"/>
    <title>Simulating Population Protocols in Sub-Constant Time per Interaction</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berenbrink:Petra.html">Petra Berenbrink</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hammer:David.html">David Hammer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaaser:Dominik.html">Dominik Kaaser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyer:Ulrich.html">Ulrich Meyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Penschuck:Manuel.html">Manuel Penschuck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tran:Hung.html">Hung Tran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03584">PDF</a><br/><b>Abstract: </b>We consider the problem of efficiently simulating population protocols. In
the population model, we are given a distributed system of $n$ agents modeled
as identical finite-state machines. In each time step, a pair of agents is
selected uniformly at random to interact. In an interaction, agents update
their states according to a common transition function. We empirically and
analytically analyze two classes of simulators for this model.
</p>
<p>First, we consider sequential simulators executing one interaction after the
other. Key to the performance of these simulators is the data structure storing
the agents' states. For our analysis, we consider plain arrays, binary search
trees, and a novel Dynamic Alias Table data structure.
</p>
<p>Secondly, we consider batch processing to efficiently update the states of
multiple independent agents in one step. For many protocols considered in
literature, our simulator requires amortized sub-constant time per interaction
and is fast in practice: given a fixed time budget, the implementation of our
batched simulator is able to simulate population protocols several orders of
magnitude larger compared to the sequential competitors, and can carry out
$2^{50}$ interactions among the same number of agents in less than 400s.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03552</id>
    <link href="http://arxiv.org/abs/2005.03552" rel="alternate" type="text/html"/>
    <title>Online Algorithms to Schedule a Proportionate Flexible Flow Shop of Batching Machines</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hertrich:Christoph.html">Christoph Hertrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei=szlig=:Christian.html">Christian Weiß</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ackermann:Heiner.html">Heiner Ackermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heydrich:Sandy.html">Sandy Heydrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krumke:Sven_O=.html">Sven O. Krumke</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03552">PDF</a><br/><b>Abstract: </b>This paper is the first to consider online algorithms to schedule a
proportionate flexible flow shop of batching machines (PFFB). The scheduling
model is motivated by manufacturing processes of individualized medicaments,
which are used in modern medicine to treat some serious illnesses. We provide
two different online algorithms, proving also lower bounds for the offline
problem to compute their competitive ratios. The first algorithm is an
easy-to-implement, general local scheduling heuristic. It is 2-competitive for
PFFBs with an arbitrary number of stages and for several natural scheduling
objectives. We also show that for total/average flow time, no deterministic
algorithm with better competitive ratio exists. For the special case with two
stages and the makespan or total completion time objective, we describe an
improved algorithm that achieves the best possible competitive ratio
$\varphi=\frac{1+\sqrt{5}}{2}$, the golden ratio. All our results also hold for
proportionate (non-flexible) flow shops of batching machines (PFB) for which
this is also the first paper to study online algorithms.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03497</id>
    <link href="http://arxiv.org/abs/2005.03497" rel="alternate" type="text/html"/>
    <title>Subquadratic-Time Algorithms for Normal Bases</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giesbrecht:Mark.html">Mark Giesbrecht</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jamshidpey:Armin.html">Armin Jamshidpey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schost:=Eacute=ric.html">Éric Schost</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03497">PDF</a><br/><b>Abstract: </b>For any finite Galois field extension $\mathsf{K}/\mathsf{F}$, with Galois
group $G = \mathrm{Gal}(\mathsf{K}/\mathsf{F})$, there exists an element
$\alpha \in \mathsf{K}$ whose orbit $G\cdot\alpha$ forms an $\mathsf{F}$-basis
of $\mathsf{K}$. Such an $\alpha$ is called a normal element and $G\cdot\alpha$
is a normal basis. We introduce a probabilistic algorithm for testing whether a
given $\alpha \in \mathsf{K}$ is normal, when $G$ is either a finite abelian or
a metacyclic group. The algorithm is based on the fact that deciding whether
$\alpha$ is normal can be reduced to deciding whether $\sum_{g \in G}
g(\alpha)g \in \mathsf{K}[G]$ is invertible; it requires a slightly
subquadratic number of operations. Once we know that $\alpha$ is normal, we
show how to perform conversions between the working basis of
$\mathsf{K}/\mathsf{F}$ and the normal basis with the same asymptotic cost.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03394</id>
    <link href="http://arxiv.org/abs/2005.03394" rel="alternate" type="text/html"/>
    <title>Scheduling with a processing time oracle</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dufoss=eacute=:Fanny.html">Fanny Dufossé</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=uuml=rr:Christoph.html">Christoph Dürr</a>, Noël Nadal, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Trystram:Denis.html">Denis Trystram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/V=aacute=squez:=Oacute=scar_C=.html">Óscar C. Vásquez</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03394">PDF</a><br/><b>Abstract: </b>In this paper we study a single machine scheduling problem on a set of
independent jobs whose execution time is not known, but guaranteed to be either
short or long, for two given processing times. At every time step, the
scheduler has the possibility either to test a job, by querying a processing
time oracle, which reveals its processing time, and occupies one time unit on
the schedule. Or the scheduler can execute a job, might it be previously tested
or not. The objective value is the total completion time over all jobs, and is
compared with the objective value of an optimal schedule, which does not need
to test. The resulting competitive ratio measures the price of hidden
processing time.
</p>
<p>Two models are studied in this paper. In the non-adaptive model, the
algorithm needs to decide before hand which jobs to test, and which jobs to
execute untested. However in the adaptive model, the algorithm can make these
decisions adaptively to the outcomes of the job tests. In both models we
provide optimal polynomial time two-phase algorithms, which consist of a first
phase where jobs are tested, and a second phase where jobs are executed
untested. Experiments give strong evidence that optimal algorithms have this
structure. Proving this property is left as an open problem.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03256</id>
    <link href="http://arxiv.org/abs/2005.03256" rel="alternate" type="text/html"/>
    <title>Critique of Boyu Sima's Proof that ${\rm P}\neq{\rm NP}$</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Brendon Pon <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03256">PDF</a><br/><b>Abstract: </b>We review and critique Boyu Sima's paper, "A solution of the P versus NP
problem based on specific property of clique function," (<a href="http://export.arxiv.org/abs/1911.00722">arXiv:1911.00722</a>)
which claims to prove that ${\rm P}\neq{\rm NP}$ by way of removing the gap
between the nonmonotone circuit complexity and the monotone circuit complexity
of the clique function. We first describe Sima's argument, and then we describe
where and why it fails. Finally, we present a simple example that clearly
demonstrates the failure.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03246</id>
    <link href="http://arxiv.org/abs/2005.03246" rel="alternate" type="text/html"/>
    <title>Fast multivariate empirical cumulative distribution function with connection to kernel density estimation</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langren=eacute=:Nicolas.html">Nicolas Langrené</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Warin:Xavier.html">Xavier Warin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03246">PDF</a><br/><b>Abstract: </b>This paper revisits the problem of computing empirical cumulative
distribution functions (ECDF) efficiently on large, multivariate datasets.
Computing an ECDF at one evaluation point requires $\mathcal{O}(N)$ operations
on a dataset composed of $N$ data points. Therefore, a direct evaluation of
ECDFs at $N$ evaluation points requires a quadratic $\mathcal{O}(N^2)$
operations, which is prohibitive for large-scale problems. Two fast and exact
methods are proposed and compared. The first one is based on fast summation in
lexicographical order, with a $\mathcal{O}(N{\log}N)$ complexity and requires
the evaluation points to lie on a regular grid. The second one is based on the
divide-and-conquer principle, with a $\mathcal{O}(N\log(N)^{(d-1){\vee}1})$
complexity and requires the evaluation points to coincide with the input
points. The two fast algorithms are described and detailed in the general
$d$-dimensional case, and numerical experiments validate their speed and
accuracy. Secondly, the paper establishes a direct connection between
cumulative distribution functions and kernel density estimation (KDE) for a
large class of kernels. This connection paves the way for fast exact algorithms
for multivariate kernel density estimation and kernel regression. Numerical
tests with the Laplacian kernel validate the speed and accuracy of the proposed
algorithms. A broad range of large-scale multivariate density estimation,
cumulative distribution estimation, survival function estimation and regression
problems can benefit from the proposed numerical methods.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03192</id>
    <link href="http://arxiv.org/abs/2005.03192" rel="alternate" type="text/html"/>
    <title>Trains, Games, and Complexity: 0/1/2-Player Motion Planning through Input/Output Gadgets</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Joshua Ani, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrickson:Dylan_H=.html">Dylan H. Hendrickson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lynch:Jayson.html">Jayson Lynch</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03192">PDF</a><br/><b>Abstract: </b>We analyze the computational complexity of motion planning through local
"input/output" gadgets with separate entrances and exits, and a subset of
allowed traversals from entrances to exits, each of which changes the state of
the gadget and thereby the allowed traversals. We study such gadgets in the 0-,
1-, and 2-player settings, in particular extending past
motion-planning-through-gadgets work to 0-player games for the first time, by
considering "branchless" connections between gadgets that route every gadget's
exit to a unique gadget's entrance. Our complexity results include containment
in L, NL, P, NP, and PSPACE; as well as hardness for NL, P, NP, and PSPACE. We
apply these results to show PSPACE-completeness for certain mechanics in
Factorio, [the Sequence], and a restricted version of Trainyard, improving
prior results. This work strengthens prior results on switching graphs and
reachability switching games.
</p></div>
    </summary>
    <updated>2020-05-08T01:22:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03185</id>
    <link href="http://arxiv.org/abs/2005.03185" rel="alternate" type="text/html"/>
    <title>Determinantal Point Processes in Randomized Numerical Linear Algebra</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Michał Dereziński, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahoney:Michael_W=.html">Michael W. Mahoney</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03185">PDF</a><br/><b>Abstract: </b>Randomized Numerical Linear Algebra (RandNLA) uses randomness to develop
improved algorithms for matrix problems that arise in scientific computing,
data science, machine learning, etc. Determinantal Point Processes (DPPs), a
seemingly unrelated topic in pure and applied mathematics, is a class of
stochastic point processes with probability distribution characterized by
sub-determinants of a kernel matrix. Recent work has uncovered deep and
fruitful connections between DPPs and RandNLA which lead to new guarantees and
improved algorithms that are of interest to both areas. We provide an overview
of this exciting new line of research, including brief introductions to RandNLA
and DPPs, as well as applications of DPPs to classical linear algebra tasks
such as least squares regression, low-rank approximation and the Nystr\"om
method. For example, random sampling with a DPP leads to new kinds of unbiased
estimators for least squares, enabling more refined statistical and inferential
understanding of these algorithms; a DPP is, in some sense, an optimal
randomized algorithm for the Nystr\"om method; and a RandNLA technique called
leverage score sampling can be derived as the marginal distribution of a DPP.
We also discuss recent algorithmic developments, illustrating that, while not
quite as efficient as standard RandNLA techniques, DPP-based algorithms are
only moderately more expensive.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03176</id>
    <link href="http://arxiv.org/abs/2005.03176" rel="alternate" type="text/html"/>
    <title>A Parameterized Perspective on Attacking and Defending Elections</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kishen N. Gowda, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misra:Neeldhara.html">Neeldhara Misra</a>, Vraj Patel <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03176">PDF</a><br/><b>Abstract: </b>We consider the problem of protecting and manipulating elections by
recounting and changing ballots, respectively. Our setting involves a
plurality-based election held across multiple districts, and the problem
formulations are based on the model proposed recently by~[Elkind et al, IJCAI
2019]. It turns out that both of the manipulation and protection problems are
NP-complete even in fairly simple settings. We study these problems from a
parameterized perspective with the goal of establishing a more detailed
complexity landscape. The parameters we consider include the number of voters,
and the budgets of the attacker and the defender. While we observe
fixed-parameter tractability when parameterizing by number of voters, our main
contribution is a demonstration of parameterized hardness when working with the
budgets of the attacker and the defender.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.03123</id>
    <link href="http://arxiv.org/abs/2005.03123" rel="alternate" type="text/html"/>
    <title>Rigid Matrices From Rectangular PCPs</title>
    <feedworld_mtime>1588896000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhangale:Amey.html">Amey Bhangale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harsha:Prahladh.html">Prahladh Harsha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paradise:Orr.html">Orr Paradise</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tal:Avishay.html">Avishay Tal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.03123">PDF</a><br/><b>Abstract: </b>We introduce a variant of PCPs, that we refer to as rectangular PCPs, wherein
proofs are thought of as square matrices, and the random coins used by the
verifier can be partitioned into two disjoint sets, one determining the row of
each query and the other determining the *column*.
</p>
<p>We construct PCPs that are efficient, short, smooth and (almost-)rectangular.
As a key application, we show that proofs for hard languages in NTIME$(2^n)$,
when viewed as matrices, are rigid infinitely often. This strengthens and
considerably simplifies a recent result of Alman and Chen [FOCS, 2019]
constructing explicit rigid matrices in FNP. Namely, we prove the following
theorem: - There is a constant $\delta \in (0,1)$ such that there is an
FNP-machine that, for infinitely many $N$, on input $1^N$ outputs $N \times N$
matrices with entries in $\mathbb{F}_2$ that are $\delta N^2$-far (in Hamming
distance) from matrices of rank at most $2^{\log N/\Omega(\log \log N)}$.
</p>
<p>Our construction of rectangular PCPs starts with an analysis of how
randomness yields queries in the Reed--Muller-based outer PCP of Ben-Sasson,
Goldreich, Harsha, Sudan and Vadhan [SICOMP, 2006; CCC, 2005]. We then show how
to preserve rectangularity under PCP composition and a smoothness-inducing
transformation. This warrants refined and stronger notions of rectangularity,
which we prove for the outer PCP and its transforms.
</p></div>
    </summary>
    <updated>2020-05-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-05-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19821</id>
    <link href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new hypercontractivity inequality of Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is a guest post kindly contributed by Noam Lifshitz. My short introduction: There is nothing like a new hypercontractivity inequality to cheer you up in difficult times and this post describes an amazing new hypercontractivity inequality.  The post describes … <a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is a guest post kindly contributed by Noam Lifshitz</em>.</p>
<p>My short introduction: There is nothing like a new hypercontractivity inequality to cheer you up in difficult times and this post describes an amazing new hypercontractivity inequality.  The post describes a recent hypercontractive inequality by Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer (KLLM) from their paper: <a href="https://arxiv.org/abs/1906.05568">Hypercontractivity for global functions and sharp thresholds</a>. (We reported on this development in <a href="https://gilkalai.wordpress.com/2018/10/30/exciting-beginning-of-the-year-activities-and-seminars/">this post</a>. By now, there are quite a few important applications.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/barrysimon.jpg"><img alt="" class="alignnone size-full wp-image-19825" src="https://gilkalai.files.wordpress.com/2020/04/barrysimon.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;">Barry Simon coined the term “hypercontractivity” in the 70s.  (We asked about it here and Nick Read was the first to answer.) A few months ago Barry told us about the early history of hypercontractivity inequalities, and, in particular, the very entertaining story on William Beckner’s Ph. D. qualifying exam.</span></p>
<p>And now to Noam Lifshitz’s guest post.</p>
<h2>Hypercontractivity on product spaces</h2>
<p>Analysis of Boolean functions (ABS) is a very rich subject. There are many works whose concern is generalising some of the results on analysis of Boolean functions to other (product) settings, such as functions on the multicube <img alt="{\left[m\right]^{n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5Bm%5Cright%5D%5E%7Bn%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left[m\right]^{n},}"/> where <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is very large. However, in some of these cases the fundemental tools of AOBF seem to be false for functions on the multicube <img alt="{f\colon\left[m\right]^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5Bm%5Cright%5D%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left[m\right]^{n}\rightarrow\mathbb{R}.}"/> However, in the recent work of Keevash, Long, Minzer, and I. We introduce the notion of global functions. These are functions that do not strongly depend on a small set of coordinates. We then show that most of the rich classical theory of AOBF can in fact be generalised to these global functions. Using our machinery we were able to strengthen an isoperimetric stability result of Bourgain, and to make progress on some Erdos-Ko-Rado type open problem.</p>
<p>We now discuss some background on the Fourier analysis on functions on the multicube <img alt="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}.}"/></p>
<h3>Derivatives and Laplacians</h3>
<p>There are two fundemental types of operators on Boolean functions <img alt="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}"/> The first ones are the discrete derivatives, defined by <img alt="{D_{i}[f]=\frac{f_{i\rightarrow1}-f_{i\rightarrow0}}{2},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD_%7Bi%7D%5Bf%5D%3D%5Cfrac%7Bf_%7Bi%5Crightarrow1%7D-f_%7Bi%5Crightarrow0%7D%7D%7B2%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D_{i}[f]=\frac{f_{i\rightarrow1}-f_{i\rightarrow0}}{2},}"/> where <img alt="{f_{i\rightarrow x}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bi%5Crightarrow+x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{i\rightarrow x}}"/> denotes the we plug in the value <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> for the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate. The other closely related ones are the laplacians defined by <img alt="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7Df%5Cleft%28x%5Cright%29%3A%3Df%5Cleft%28x%5Cright%29-%5Cmathbb%7BE%7Df%5Cleft%28%5Cmathbf%7By%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}"/> where <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is obtained from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> by resampling its <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate.</p>
<p>The laplacians and the derivatives are closely related. In fact, when we plug in <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate, we obtain <img alt="{L_{i}[f]_{i\rightarrow1}=D_{i}[f]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7D%5Bf%5D_%7Bi%5Crightarrow1%7D%3DD_%7Bi%7D%5Bf%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}[f]_{i\rightarrow1}=D_{i}[f]}"/>, and when we plug in <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> in it, we obtain <img alt="{L_{i}[f]_{i\rightarrow0}=-D_{i}[f].}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7D%5Bf%5D_%7Bi%5Crightarrow0%7D%3D-D_%7Bi%7D%5Bf%5D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}[f]_{i\rightarrow0}=-D_{i}[f].}"/></p>
<p>The 2-norm of the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th derivative is called the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th influence of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as it measures the impact of the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate on the value of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>. It’s usually denoted by <img alt="{\mathrm{Inf}_{i}[f]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BInf%7D_%7Bi%7D%5Bf%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{Inf}_{i}[f]}"/>.</p>
<h3>Generalisation to functions on the multicube</h3>
<p>For functions on the multicube we don’t have a very good notion of a discrete derivative, but it turns out that it will be enough to talk about the laplacians and their restrictions. The Laplacians are again defined via <img alt="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7Df%5Cleft%28x%5Cright%29%3A%3Df%5Cleft%28x%5Cright%29-%5Cmathbb%7BE%7Df%5Cleft%28%5Cmathbf%7By%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}"/> where <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is obtained from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> by resampling its <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate. It turns out that in the continuous cube it’s not enough to talk about Laplacians of coordinate, and we will also have to concern ourselves with Laplacians of sets. We define the generalised Laplacians of a set <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> by composing the laplacians corresponding to each coordinate in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> <img alt="{L_{\left\{ i_{1},i_{2},\ldots,i_{r}\right\} }\left[f\right]:=L_{i_{1}}\circ\cdots\circ L_{i_{r}}\left[f\right].}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Cleft%5C%7B+i_%7B1%7D%2Ci_%7B2%7D%2C%5Cldots%2Ci_%7Br%7D%5Cright%5C%7D+%7D%5Cleft%5Bf%5Cright%5D%3A%3DL_%7Bi_%7B1%7D%7D%5Ccirc%5Ccdots%5Ccirc+L_%7Bi_%7Br%7D%7D%5Cleft%5Bf%5Cright%5D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{\left\{ i_{1},i_{2},\ldots,i_{r}\right\} }\left[f\right]:=L_{i_{1}}\circ\cdots\circ L_{i_{r}}\left[f\right].}"/></p>
<p>We now need to convince ourselves that these laplacians have something to do with the impact of <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> on the outcome of <img alt="{f.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f.}"/> In fact, the following notions are equivalent</p>
<ol>
<li>For each <img alt="{x,y\in\left[m\right]^{S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%5Cin%5Cleft%5Bm%5Cright%5D%5E%7BS%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y\in\left[m\right]^{S}}"/>we have <img alt="{\|f_{S\rightarrow x}-f_{S\rightarrow y}\|_{2}&lt;\delta_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cf_%7BS%5Crightarrow+x%7D-f_%7BS%5Crightarrow+y%7D%5C%7C_%7B2%7D%3C%5Cdelta_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|f_{S\rightarrow x}-f_{S\rightarrow y}\|_{2}&lt;\delta_{1}}"/></li>
<li>For each <img alt="{x\in\left[m\right]^{S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5Cleft%5Bm%5Cright%5D%5E%7BS%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in\left[m\right]^{S}}"/> we have <img alt="{\|L_{S}[f]_{S\rightarrow x}\|_{2}&lt;\delta_{2},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%3C%5Cdelta_%7B2%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|L_{S}[f]_{S\rightarrow x}\|_{2}&lt;\delta_{2},}"/></li>
</ol>
<p>in the sense that if (1) holds then (2) holds with <img alt="{\delta_{2}=C^{\left|S\right|}\delta_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_%7B2%7D%3DC%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cdelta_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_{2}=C^{\left|S\right|}\delta_{1}}"/> and conversely if (2) holds, then (1) holds with <img alt="{\delta_{1}=C^{\left|S\right|}\delta_{2}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_%7B1%7D%3DC%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cdelta_%7B2%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_{1}=C^{\left|S\right|}\delta_{2}.}"/></p>
<p>The main theme of our work is that one can understand <strong>global</strong> function on the continuous cube, and these are functions that satisfy the above equivalent notions for all small sets <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>.</p>
<h3>Noise operator, hypercontractivity, and small set expansion</h3>
<p>For <img alt="{\rho\in\left(0,1\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cin%5Cleft%280%2C1%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\in\left(0,1\right),}"/> the noise operator is given by <img alt="{\mathrm{T}_{\rho}\left[f\right]\left(x\right)=\mathbb{E}f\left(\mathbf{y}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Cleft%5Bf%5Cright%5D%5Cleft%28x%5Cright%29%3D%5Cmathbb%7BE%7Df%5Cleft%28%5Cmathbf%7By%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}\left[f\right]\left(x\right)=\mathbb{E}f\left(\mathbf{y}\right)}"/> when <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is obtained from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> by independently setting each coordinate <img alt="{\mathbf{y}_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}_{i}}"/> to be <img alt="{\mathbf{x}_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7Bx%7D_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{x}_{i}}"/> with probability <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> and resampling it with uniformly out of <img alt="{\left\{ -1,1\right\} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ -1,1\right\} }"/> otherwise. The process which given <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> outputs <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is called the <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>-noisy process, and we write <img alt="{\mathbf{y}\sim N_{\rho}\left(x\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%5Csim+N_%7B%5Crho%7D%5Cleft%28x%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}\sim N_{\rho}\left(x\right).}"/></p>
<p>The Bonami hypercontractivity theorem, which was then generalised by Gross and Beckner states that the noise operator <img alt="{T_{\frac{1}{\sqrt{3}}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{\frac{1}{\sqrt{3}}}}"/> is a contraction from <img alt="{L^{4}\left(\left\{ 0,1\right\} ^{n}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5E%7B4%7D%5Cleft%28%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L^{4}\left(\left\{ 0,1\right\} ^{n}\right)}"/> to <img alt="{L^{2}\left(\left\{ 0,1\right\} ^{n}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5E%7B2%7D%5Cleft%28%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L^{2}\left(\left\{ 0,1\right\} ^{n}\right),}"/> i.e.</p>
<blockquote><p><img alt="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}f\|_{4}\le\|f\|_{2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7Df%5C%7C_%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}f\|_{4}\le\|f\|_{2} "/><br/>
for any function <img alt="{f.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f.}"/></p></blockquote>
<p>One consequence of the hypercontractivity theorem is the small set expansion theorem of KKL. It concerns fixed <img alt="{\rho\in\left(0,1\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cin%5Cleft%280%2C1%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\in\left(0,1\right)}"/> and a sequence of sets <img alt="{A_{n}\subseteq\{0,1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%5Csubseteq%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}\subseteq\{0,1\}^{n}}"/> with <img alt="{\left|A_{n}\right|=o\left(2^{n}\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%7CA_%7Bn%7D%5Cright%7C%3Do%5Cleft%282%5E%7Bn%7D%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left|A_{n}\right|=o\left(2^{n}\right).}"/> The small set expansion theorem states that if we choose <img alt="{\mathbf{x}\sim A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7Bx%7D%5Csim+A_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{x}\sim A_{n}}"/> uniformly and a noisy <img alt="{\mathbf{y}\sim N_{\rho}\left(\mathbf{x}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%5Csim+N_%7B%5Crho%7D%5Cleft%28%5Cmathbf%7Bx%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}\sim N_{\rho}\left(\mathbf{x}\right),}"/> then <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> will reside outside of <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> almost surely.</p>
<h3>The Generalisation to the multicube:</h3>
<p>The small set expansion theorem and the hypercontractivity theorem both fail for function on the multicube that are of a very local nature. For instance, let <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> be the set of all <img alt="{x\in\left\{ 1,\ldots,m\right\} ^{n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in\left\{ 1,\ldots,m\right\} ^{n},}"/> such that <img alt="{x_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{1}}"/> is <img alt="{m.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m.}"/> Then <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> is of size <img alt="{m^{n-1},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%5E%7Bn-1%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m^{n-1},}"/> which is <img alt="{o\left(m^{n}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%5Cleft%28m%5E%7Bn%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o\left(m^{n}\right)}"/> if we allow <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> to be a growing function of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. However, the <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>-noisy process from the set stays within the set with probability <img alt="{\rho.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho.}"/> For a similar reason the hypercontractivity theorem fails as is for functions on <img alt="{\left\{ 1,\ldots,m\right\} ^{n}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ 1,\ldots,m\right\} ^{n}.}"/> However we were able to generalise the hypercontractivity theorem by taking the globalness of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> into consideration.</p>
<p>Our main hypercontractive inequality is the following</p>
<p><strong>Theorem 1.</strong></p>
<blockquote><p><img alt="\displaystyle \|\mathrm{T}_{\frac{1}{100}}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{\mathbf{x}\sim\left\{ 1,\ldots,m\right\} ^{m}}\left(\|L_{S}\left[f\right]_{S\rightarrow\mathbf{x}}\|_{2}^{4}\right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B100%7D%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bx%7D%5Csim%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bm%7D%7D%5Cleft%28%5C%7CL_%7BS%7D%5Cleft%5Bf%5Cright%5D_%7BS%5Crightarrow%5Cmathbf%7Bx%7D%7D%5C%7C_%7B2%7D%5E%7B4%7D%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{1}{100}}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{\mathbf{x}\sim\left\{ 1,\ldots,m\right\} ^{m}}\left(\|L_{S}\left[f\right]_{S\rightarrow\mathbf{x}}\|_{2}^{4}\right). "/></p></blockquote>
<p>The terms <img alt="{\|L_{S}\left[f\right]_{S\rightarrow x}\|_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CL_%7BS%7D%5Cleft%5Bf%5Cright%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|L_{S}\left[f\right]_{S\rightarrow x}\|_{2}}"/> appearing on the right hand side are small whenever <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has a small dependency on <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and it turns out that you have the following corrolary of it, which looks a bit more similar to the hypercontractive intequality.</p>
<p> </p>
<p><strong>Corollary 2.</strong></p>
<p>Let <img alt="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}}"/>, and uppose that <img alt="{\|L_{S}[f]_{S\rightarrow x}\|_{2}\le4^{\left|S\right|}\|f\|_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5Cle4%5E%7B%5Cleft%7CS%5Cright%7C%7D%5C%7Cf%5C%7C_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|L_{S}[f]_{S\rightarrow x}\|_{2}\le4^{\left|S\right|}\|f\|_{2}}"/> for all sets <img alt="{S.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S.}"/></p>
<p>Then <img alt="{\mathrm{\|\mathrm{T}_{\frac{1}{1000}}f\|_{4}\le\|f\|_{2}.}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7B%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B1000%7D%7Df%5C%7C_%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D.%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{\|\mathrm{T}_{\frac{1}{1000}}f\|_{4}\le\|f\|_{2}.}}"/></p>
<p>Finally, one might ask wonder why this globalness notion appears only when we look at large values of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and not when <img alt="{m=2.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%3D2.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m=2.}"/> I think the corollary is a good explanation for that as <img alt="{\|f\|_{2}^{2}\ge\left(\frac{1}{2}\right)^{\left|S\right|}\|f_{S\rightarrow x}\|_{2}^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cf%5C%7C_%7B2%7D%5E%7B2%7D%5Cge%5Cleft%28%5Cfrac%7B1%7D%7B2%7D%5Cright%29%5E%7B%5Cleft%7CS%5Cright%7C%7D%5C%7Cf_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|f\|_{2}^{2}\ge\left(\frac{1}{2}\right)^{\left|S\right|}\|f_{S\rightarrow x}\|_{2}^{2}}"/> holds trivially for any Boolean function <img alt="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}"/></p></div>
    </content>
    <updated>2020-05-07T21:01:42Z</updated>
    <published>2020-05-07T21:01:42Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Guest post"/>
    <category term="Poetry"/>
    <category term="Probability"/>
    <category term="Barry Simon"/>
    <category term="Dor Minzer"/>
    <category term="Eoin Long"/>
    <category term="Noam Lifshitz"/>
    <category term="Peter Keevash"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-05-08T05:20:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7656443173792446291</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7656443173792446291/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/05/vidcast-on-conferences.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7656443173792446291" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7656443173792446291" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/05/vidcast-on-conferences.html" rel="alternate" type="text/html"/>
    <title>Vidcast on Conferences</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Bill and Lance have another socially-distanced <a href="https://youtu.be/VwvuTnE66xQ">vidcast</a>, this time with Lance telling the story of two conferences (<a href="http://ec20.sigecom.org/">ACM Economics and Computation</a> and the Game Theory Congress). As mentioned in the video the Game Theory Congress has been <a href="http://gametheorysociety.org/6th-world-congress-of-the-game-theory-society-in-budapest-july-13-17-2020/">postponed to next year</a>. Also mentioned in the video, for a limited time you can read Lance's <a href="https://goldenticket.fortnow.com/">book</a> on P v NP on <a href="https://muse.jhu.edu/book/36432">Project Muse</a>.<div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-05-07T14:28:00Z</updated>
    <published>2020-05-07T14:28:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-05-07T14:28:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02853</id>
    <link href="http://arxiv.org/abs/2005.02853" rel="alternate" type="text/html"/>
    <title>Sparktope: linear programs from algorithms</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Avis:David.html">David Avis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bremner:David.html">David Bremner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02853">PDF</a><br/><b>Abstract: </b>In a recent paper Avis, Bremner, Tiwary and Watanabe gave a method for
constructing linear programs (LPs) based on algorithms written in a simple
programming language called Sparks. If an algorithm produces the solution $x$
to a problem in polynomial time and space then the LP constructed is also of
polynomial size and its optimum solution contains $x$ as well as a complete
execution trace of the algorithm. Their method led us to the construction of a
compiler called Sparktope which we describe in this paper. This compiler allows
one to generate polynomial sized LPs for problems in P that have exponential
extension complexity, such as matching problems in non-bipartite graphs.
</p>
<p>In this paper we describe Sparktope, the language Sparks, and the assembler
instructions and LP constraints it produces. This is followed by two concrete
examples, the makespan problem and the problem of testing if a matching in a
graph is maximum, both of which are known to have exponential extension
complexity. Computational results are given. In discussing these examples we
make use of visualization techniques included in Sparktope that may be of
independent interest. The extremely large linear programs produced by the
compiler appear to be quite challenging to solve using currently available
software. Since the optimum LP solutions can be computed independently they may
be useful as benchmarks. Further enhancements of the compiler and its
application are also discussed.
</p></div>
    </summary>
    <updated>2020-05-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02819</id>
    <link href="http://arxiv.org/abs/2005.02819" rel="alternate" type="text/html"/>
    <title>Geoopt: Riemannian Optimization in PyTorch</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kochurov:Max.html">Max Kochurov</a>, Rasul Karimov, Sergei Kozlukov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02819">PDF</a><br/><b>Abstract: </b>Geoopt is a research-oriented modular open-source package for Riemannian
Optimization in PyTorch. The core of Geoopt is a standard Manifold interface
which allows for the generic implementation of optimization algorithms. Geoopt
supports basic Riemannian SGD as well as adaptive optimization algorithms.
Geoopt also provides several algorithms and arithmetic methods for supported
manifolds, which allow composing geometry-aware neural network layers that can
be integrated with existing models.
</p></div>
    </summary>
    <updated>2020-05-07T22:31:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02725</id>
    <link href="http://arxiv.org/abs/2005.02725" rel="alternate" type="text/html"/>
    <title>Incremental Multiple Longest Common Sub-Sequences</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Russo:Lu=iacute=s_M=_S=.html">Luís M. S. Russo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Francisco:Alexandre_P=.html">Alexandre P. Francisco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rocher:Tatiana.html">Tatiana Rocher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02725">PDF</a><br/><b>Abstract: </b>We consider the problem of updating the information about multiple longest
common sub-sequences. This kind of sub-sequences is used to highlight
information that is shared across several information sequences, therefore it
is extensively used namely in bioinformatics and computational genomics. In
this paper we propose a way to maintain this information when the underlying
sequences are subject to modifications, namely when letters are added and
removed from the extremes of the sequence. Experimentally our data structure
obtains significant improvements over the state of the art.
</p></div>
    </summary>
    <updated>2020-05-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02645</id>
    <link href="http://arxiv.org/abs/2005.02645" rel="alternate" type="text/html"/>
    <title>Search for developments of a box having multiple ways of folding by SAT solver</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Riona Tadaki, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amano:Kazuyuki.html">Kazuyuki Amano</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02645">PDF</a><br/><b>Abstract: </b>A polyomino is called a development if it can make a box by folding edges of
unit squares forming the polyomino. It is known that there are developments
that can fold into a box (or boxes) in multiple ways. In this work, we
conducted a computer search for finding such developments by using a SAT
solver. As a result, we found thousands of such developments including a
polyomino of area 52 that can fold into a box of size $1 \times 2 \times 8$ in
five different ways.
</p></div>
    </summary>
    <updated>2020-05-07T22:31:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02607</id>
    <link href="http://arxiv.org/abs/2005.02607" rel="alternate" type="text/html"/>
    <title>Towards quantum advantage for topological data analysis</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Casper Gyurik, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cade:Chris.html">Chris Cade</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dunjko:Vedran.html">Vedran Dunjko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02607">PDF</a><br/><b>Abstract: </b>A particularly promising line of quantum machine leaning (QML) algorithms
with the potential to exhibit exponential speedups over their classical
counterparts has recently been set back by a series of "dequantization"
results, that is, quantum-inspired classical algorithms which perform equally
well in essence. This raises the important question whether other QML
algorithms are susceptible to such dequantization, or whether it can be
formally argued that they are out of reach of classical computers. In this
paper, we study the quantum algorithm for topological data analysis by Lloyd,
Garnerone and Zanardi (LGZ). We provide evidence that certain crucial steps in
this algorithm solve problems that are classically intractable by closely
relating them to the one clean qubit model, a restricted model of quantum
computation whose power is strongly believed to lie beyond that of classical
computation. While our results do not imply that the topological data analysis
problem solved by the LGZ algorithm (i.e., Betti number estimation) is itself
DQC1-hard, our work does provide the first steps towards answering the question
of whether it is out of reach of classical computers. Additionally, we discuss
how to extend the applicability of this algorithm beyond its original aim of
estimating Betti numbers and demonstrate this by looking into quantum
algorithms for spectral entropy estimation. Finally, we briefly consider the
suitability of the LGZ algorithm for near-term implementations.
</p></div>
    </summary>
    <updated>2020-05-07T23:21:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02578</id>
    <link href="http://arxiv.org/abs/2005.02578" rel="alternate" type="text/html"/>
    <title>Differentiable Greedy Submodular Maximization with Guarantees and Gradient Estimators</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sakaue:Shinsaku.html">Shinsaku Sakaue</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02578">PDF</a><br/><b>Abstract: </b>We consider making outputs of the greedy algorithm for monotone submodular
function maximization differentiable w.r.t. parameters of objective functions.
Due to the non-continuous behavior of the algorithm, we must use some smoothing
methods. Our contribution is a theoretically guaranteed and widely applicable
smoothing framework based on randomization. We prove that our smoothed greedy
algorithm almost recovers original approximation guarantees in expectation for
the cases of cardinality and $\kappa$-extensible system constrains. We also
show that unbiased gradient estimators of any expected output-dependent
quantities can be efficiently obtained by sampling outputs. We confirm the
utility and effectiveness of our framework by applying it to sensitivity
analysis of the greedy algorithm and decision-focused learning of parameterized
submodular models.
</p></div>
    </summary>
    <updated>2020-05-07T22:30:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02537</id>
    <link href="http://arxiv.org/abs/2005.02537" rel="alternate" type="text/html"/>
    <title>Conditional Cuckoo Filters</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Ting:Daniel.html">Daniel Ting</a>, Rick Cole <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02537">PDF</a><br/><b>Abstract: </b>Bloom filters, cuckoo filters, and other approximate set membership sketches
have a wide range of applications. Oftentimes, expensive operations can be
skipped if an item is not in a data set. These filters provide an inexpensive,
memory efficient way to test if an item is in a set and avoid unnecessary
operations. Existing sketches only allow membership testing for single set.
However, in some applications such as join processing, the relevant set is not
fixed and is determined by a set of predicates.
</p>
<p>We propose the Conditional Cuckoo Filter, a simple modification of the cuckoo
filter that allows for set membership testing given predicates on a
pre-computed sketch. This filter also introduces a novel chaining technique
that enables cuckoo filters to handle insertion of duplicate keys. We evaluate
our methods on a join processing application and show that they significantly
reduce the number of tuples that a join must process.
</p></div>
    </summary>
    <updated>2020-05-07T22:30:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02530</id>
    <link href="http://arxiv.org/abs/2005.02530" rel="alternate" type="text/html"/>
    <title>Approximation Algorithms for Multi-Robot Patrol-Scheduling with Min-Max Latency</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Afshani:Peyman.html">Peyman Afshani</a>, Mark De Berg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchin:Kevin.html">Kevin Buchin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Jie.html">Jie Gao</a>, Maarten Loffler, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayyeri:Amir.html">Amir Nayyeri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raichel:Benjamin.html">Benjamin Raichel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sarkar:Rik.html">Rik Sarkar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Haotian.html">Haotian Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Hao=Tsung.html">Hao-Tsung Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02530">PDF</a><br/><b>Abstract: </b>We consider the problem of finding patrol schedules for $k$ robots to visit a
given set of $n$ sites in a metric space. Each robot has the same maximum speed
and the goal is to minimize the weighted maximum latency of any site, where the
latency of a site is defined as the maximum time duration between consecutive
visits of that site. The problem is NP-hard, as it has the traveling salesman
problem as a special case (when $k=1$ and all sites have the same weight). We
present a polynomial-time algorithm with an approximation factor of $O(k \log
\frac{w_{max}}{w_{min}})$ to the optimal solution, where $w_{max}$ and
$w_{min}$ are the maximum and minimum weight of the sites respectively.
Further, we consider the special case where the sites are in 1D. When all sites
have the same weight, we present a polynomial-time algorithm to solve the
problem exactly. When the sites may have different weights, we use dynamic
programming to generate an $8$-approximate solution, which also runs in
polynomial time.
</p></div>
    </summary>
    <updated>2020-05-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.02421</id>
    <link href="http://arxiv.org/abs/2005.02421" rel="alternate" type="text/html"/>
    <title>Spoofing Linear Cross-Entropy Benchmarking in Shallow Quantum Circuits</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barak:Boaz.html">Boaz Barak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chou:Chi=Ning.html">Chi-Ning Chou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Xun.html">Xun Gao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02421">PDF</a><br/><b>Abstract: </b>The linear cross-entropy benchmark (Linear XEB) has been used as a test for
procedures simulating quantum circuits. Given a quantum circuit $C$ with $n$
inputs and outputs and purported simulator whose output is distributed
according to a distribution $p$ over $\{0,1\}^n$, the linear XEB fidelity of
the simulator is $\mathcal{F}_{C}(p) = 2^n \mathbb{E}_{x \sim p} q_C(x) -1$
where $q_C(x)$ is the probability that $x$ is output from the distribution
$C|0^n\rangle$. A trivial simulator (e.g., the uniform distribution) satisfies
$\mathcal{F}_C(p)=0$, while Google's noisy quantum simulation of a 53 qubit
circuit $C$ achieved a fidelity value of $(2.24\pm0.21)\times10^{-3}$ (Arute
et. al., Nature'19).
</p>
<p>In this work we give a classical randomized algorithm that for a given
circuit $C$ of depth $d$ with Haar random 2-qubit gates achieves in expectation
a fidelity value of $\Omega(\tfrac{n}{L} \cdot 15^{-d})$ in running time
$\textsf{poly}(n,2^L)$. Here $L$ is the size of the \emph{light cone} of $C$:
the maximum number of input bits that each output bit depends on. In
particular, we obtain a polynomial-time algorithm that achieves large fidelity
of $\omega(1)$ for depth $O(\sqrt{\log n})$ two-dimensional circuits. To our
knowledge, this is the first such result for two dimensional circuits of
super-constant depth. Our results can be considered as an evidence that fooling
the linear XEB test might be easier than achieving a full simulation of the
quantum circuit.
</p></div>
    </summary>
    <updated>2020-05-07T23:20:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.01929</id>
    <link href="http://arxiv.org/abs/2005.01929" rel="alternate" type="text/html"/>
    <title>Edge-Weighted Online Bipartite Matching</title>
    <feedworld_mtime>1588809600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fahrbach:Matthew.html">Matthew Fahrbach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Zhiyi.html">Zhiyi Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Runzhou.html">Runzhou Tao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zadimoghaddam:Morteza.html">Morteza Zadimoghaddam</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01929">PDF</a><br/><b>Abstract: </b>Online bipartite matching and its variants are among the most fundamental
problems in the online algorithms literature. Karp, Vazirani, and Vazirani
(STOC 1990) introduced an elegant algorithm for the unweighted problem that
achieves an optimal competitive ratio of $1-1/e$. Later, Aggarwal et al. (SODA
2011) generalized their algorithm and analysis to the vertex-weighted case.
Little is known, however, about the most general edge-weighted problem aside
from the trivial $1/2$-competitive greedy algorithm. In this paper, we present
the first online algorithm that breaks the long-standing $1/2$ barrier and
achieves a competitive ratio of at least $0.5086$. In light of the hardness
result of Kapralov, Post, and Vondr\'ak (SODA 2013) that restricts beating a
$1/2$ competitive ratio for the more general problem of monotone submodular
welfare maximization, our result can be seen as strong evidence that
edge-weighted bipartite matching is strictly easier than submodular welfare
maximization in the online setting.
</p>
<p>The main ingredient in our online matching algorithm is a novel subroutine
called online correlated selection (OCS), which takes a sequence of pairs of
vertices as input and selects one vertex from each pair. Instead of using a
fresh random bit to choose a vertex from each pair, the OCS negatively
correlates decisions across different pairs and provides a quantitative measure
on the level of correlation. We believe our OCS technique is of independent
interest and will find further applications in other online optimization
problems.
</p></div>
    </summary>
    <updated>2020-05-07T22:29:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/075</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/075" rel="alternate" type="text/html"/>
    <title>TR20-075 |  Rigid Matrices From Rectangular PCPs | 

	Amey Bhangale, 

	Prahladh Harsha, 

	Orr Paradise, 

	Avishay Tal</title>
    <summary>We introduce a variant of PCPs, that we refer to as *rectangular* PCPs, wherein proofs are thought of as square matrices, and the random coins used by the verifier can be partitioned into two disjoint sets, one determining the *row* of each query and the other determining the *column*.

We construct PCPs that are *efficient*, *short*, *smooth* and (almost-)*rectangular*. As a key application, we show that proofs for hard languages in NTIME$(2^n)$, when viewed as matrices, are rigid infinitely often. This strengthens and considerably simplifies a recent result of Alman and Chen [FOCS, 2019] constructing explicit rigid matrices in FNP. Namely, we prove the following theorem:
- There is a constant $\delta \in (0,1)$ such that there is an FNP-machine that, for infinitely many $N$, on input $1^N$ outputs $N \times N$ matrices with entries in $\mathbb{F}_2$ that are $\delta N^2$-far (in Hamming distance) from matrices of rank at most $2^{\log  N/\Omega(\log \log N)}$.

Our construction of rectangular PCPs starts with an analysis of how randomness yields queries in the Reed--Muller-based outer PCP of Ben-Sasson, Goldreich, Harsha, Sudan and Vadhan [SICOMP, 2006; CCC, 2005]. We then show how to preserve rectangularity under PCP composition and a smoothness-inducing transformation. This warrants refined and stronger notions of rectangularity, which we prove for the outer PCP and its transforms.</summary>
    <updated>2020-05-06T19:28:27Z</updated>
    <published>2020-05-06T19:28:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/074</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/074" rel="alternate" type="text/html"/>
    <title>TR20-074 |  Depth-First Search in Directed Graphs, Revisited | 

	Eric Allender, 

	Archit Chauhan, 

	Samir Datta</title>
    <summary>We present an algorithm for constructing a depth-first search tree in planar digraphs; the algorithm can be implemented in the complexity class UL, which is contained in nondeterministic logspace NL, which in turn lies in NC^2. Prior to this (for more than a quarter-century), the fastest uniform deterministic parallel algorithm for this problem was O(log^10 n) (corresponding to the complexity class AC^10, which is contained in NC^11).

We also consider the problem of computing depth-first search trees in other classes of graphs, and obtain additional new upper bounds.</summary>
    <updated>2020-05-06T18:15:38Z</updated>
    <published>2020-05-06T18:15:38Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/073</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/073" rel="alternate" type="text/html"/>
    <title>TR20-073 |  Lower Bounds on OBDD Proofs with Several Orders | 

	Dmitry Itsykson, 

	Sam Buss, 

	Dmitry Sokolov, 

	Alexander Knop, 

	Artur Riazanov</title>
    <summary>This paper is motivated by seeking lower bounds on OBDD($\land$, weakening, reordering) refutations, namely OBDD refutations that allow weakening and arbitrary reorderings. We first work with 1-NBP($\land$) refutations based on read-once nondeterministic branching programs. These generalize OBDD($\land$, reordering) refutations. There are polynomial size 1-NBP($\land$) refutations of the pigeonhole principle, hence 1-NBP($\land$) is strictly stronger than OBDD($\land$, reordering). There are also formulas that have polynomial size tree-like resolution refutations but require exponential size 1-NBP($\land$) refutations. As a corollary, OBDD($\land$, reordering) does not simulate tree-like resolution, answering a previously open question.

The system 1-NBP($\land$, $\exists$) uses projection inferences instead of weakening. 1-NBP($\land$, $\exists_k$) is the system restricted to projection on at most $k$ distinct variables. We construct explicit constant degree graphs $G_n$ on $n$ vertices and an $\epsilon &gt; 0$, such that 1-NBP($\land$, $\exists_{\epsilon n}$) refutations of the Tseitin formula for $G_n$ require exponential size.

Second, we study the proof system OBDD($\land$, weakening, reordering$_\ell$) which allows $\ell$ different variable orders in a refutation. We prove an exponential lower bound on the complexity of tree-like OBDD($\land$, weakening, reordering$_\ell$) refutations for $\ell = \epsilon \log n$, where $n$ is the number of variables and $\epsilon &gt; 0$ is a constant. The lower bound is based on multiparty communication complexity.</summary>
    <updated>2020-05-05T18:13:59Z</updated>
    <published>2020-05-05T18:13:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5609460581142399437</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5609460581142399437/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5609460581142399437" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5609460581142399437" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html" rel="alternate" type="text/html"/>
    <title>Why is there no (d,n) grid for Hilbert's Tenth Problem?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
Hilbert's 10th problem, in modern language is:<br/>
<br/>
Find an algorithm that will, given a poly over Z in many variables, determine if it has a solution in Z.<br/>
<br/>
This problem was proven undecidable through the work of Davis, Putnam, Robinson and then<br/>
Matiyasevich supplied the last crucial part of the proof.<br/>
<br/>
Let H10(d,n) be the problem with degree d and n variables.<br/>
<br/>
I had assumed that somewhere on the web would be a grid where the dth row, nth col has<br/>
<br/>
U if  H10(d,n) is undecidable<br/>
<br/>
D if H10(d,n) is decidable<br/>
<br/>
? if the status of H10(d,n) was unknown.<br/>
<br/>
I found no grid. I then collected up all the results I could find <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/h10.pdf">here</a><br/>
<br/>
This lead to the (non-math) question: Why is there no grid out there? Here are my speculations.<br/>
<br/>
1) Logicians worked on proving particular (d,n) are undecidable. They sought solutions in N. By contrast number theorists worked on proving particular (d,n) decidable. They sought solutions in Z.. Hence a grid would need to reconcile these two related problems.<br/>
<br/>
<div>
<div>
2) Logicians and number theorists didn't talk to each other. Websites and books on Hilbert's Tenth problem do not mention any solvable cases of it.</div>
</div>
<div>
<br/></div>
<div>
<div>
3) There is a real dearth of positive results, so a grid would not be that interesting. Note that we do not even know if the following is decidable: given k in Z does there exists x,y,z in Z such that</div>
<div>
<br/></div>
<div>
x^3 +y^3+ z^3 = k. I blogged about that <a href="https://blog.computationalcomplexity.org/2019/04/x-3-y-3-z-3-33-has-solution-in-z-and.html">here</a></div>
</div>
<div>
<br/></div>
<div>
4) For an undecidable result for (d,n) if you make n small then all of the results make d very large.</div>
<div>
<br/></div>
<div>
For example</div>
<div>
<br/></div>
<div>
n=9, d= 1.6 x 10^{45}  is undecidable. The status of n=9, d=1.6 x 10^{45} -1 is unknown.</div>
<div>
<br/></div>
<div>
Hence the grid would be hard to draw.</div>
<div>
<br/></div>
<div>
Frankly I don't really want a grid. I really want a sense of what open problems might be solved. I think progress has gone in other directions- H10 over other domains. Oh well, I want to know about</div>
<div>
<br/></div>
<div>
n=9 and d=1.6 x 10^{45}-1. (parenthesis ambiguous but either way would be an advance.)</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
<br/></div></div>
    </content>
    <updated>2020-05-05T04:39:00Z</updated>
    <published>2020-05-05T04:39:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-05-07T14:28:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=48</id>
    <link href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/" rel="alternate" type="text/html"/>
    <title>Friday, May 15 — Amin Karbasi from Yale University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  Amin Karbasi from Yale University will speak about “User-Friendly Submodular Maximization”. Abstract: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they<a class="more-link" href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/">Continue reading <span class="screen-reader-text">"Friday, May 15 — Amin Karbasi from Yale University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Amin Karbasi </strong>from Yale University will speak about “<em>User-Friendly Submodular Maximization</em>”.</p>



<p class="has-text-align-left"><strong>Abstract</strong>: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they have been rediscovered in many fields such as information theory, operations research, statistical physics, economics, and machine learning. They also enjoy computational tractability as they can be minimized exactly or maximized approximately.</p>



<p>The goal of this talk is simple. We see how a little bit of randomness, a little bit of greediness, and the right combination can lead to pretty good methods for offline, streaming, and distributed solutions. I do not assume any background on submodularity and try to explain all the required details during the talk.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-05-05T01:30:02Z</updated>
    <published>2020-05-05T01:30:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-05-08T05:21:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/072</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/072" rel="alternate" type="text/html"/>
    <title>TR20-072 |  Locally testable codes via high-dimensional expanders | 

	Irit Dinur, 

	Prahladh Harsha, 

	Yotam Dikstein, 

	Noga Ron-Zewi</title>
    <summary>Locally testable codes (LTC) are error-correcting codes that have a local tester which can distinguish valid codewords from words that are far from all codewords, by probing a given word only at a very small (sublinear, typically constant) number of locations. Such codes form the combinatorial backbone of PCPs. A major open problem is whether there exist LTCs with positive rate, constant relative distance and testable with a constant number of queries. 

In this paper, we present a new approach towards constructing such LTCs using the machinery of high-dimensional expanders. 
To this end, we consider the Tanner representation of a code, which is specified by a graph and a base code. Informally, our result states that if this graph is part of an {\em agreement expander} then the local testability of the code follows from the local testability of the base code. Agreement expanders allow one to stitch together many mostly-consistent local functions into a single global function. High-dimensional expanders are known to yield agreement expanders with constant degree. 

This work unifies and generalizes the known results on testability of the Hadamard, Reed-Muller and lifted codes, all of which are proved via a single round of local self-correction: the corrected value at a vertex v depends on the values of all vertices that share a constraint with v. In the above codes this set includes all of the vertices. In contrast, in our setting the degree of a vertex might be a constant, so we cannot hope for one-round self-correction. We overcome this technical hurdle by performing iterative self correction with logarithmically many rounds and tightly controlling the error in each iteration using properties of the agreement expander.

Given this result, the missing ingredient towards constructing a constant-query LTC with positive rate and constant relative distance is an instantiation of a base code and a constant-degree agreement expander that interact well with each other.</summary>
    <updated>2020-05-05T00:09:11Z</updated>
    <published>2020-05-05T00:09:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/" rel="alternate" type="text/html"/>
    <title>postdoc position at University of Alberta (apply by December 31, 2020)</title>
    <summary>The Theory Group in the Dept. of Computing Science at U. of Alberta invites applications for TWO postdoc positions. The successful applicants are expected to work closely with Zachary Friggstad and Mohammad Salavatipour in the areas of: approx algorithms, hardness of approximation, combinatorial optimization. For details see https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf Email: mrs@ualberta.ca Website: http://www.cs.ualberta.ca Email: mrs@ualberta.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Theory Group in the Dept. of Computing Science at U. of Alberta invites applications for TWO postdoc positions. The successful applicants are expected to work closely with Zachary Friggstad and Mohammad Salavatipour in the areas of: approx algorithms, hardness of approximation, combinatorial optimization. For details see <a href="https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf">https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf</a><br/>
Email: mrs@ualberta.ca</p>
<p>Website: <a href="http://www.cs.ualberta.ca">http://www.cs.ualberta.ca</a><br/>
Email: mrs@ualberta.ca</p></div>
    </content>
    <updated>2020-05-04T18:43:57Z</updated>
    <published>2020-05-04T18:43:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-08T05:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/071</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/071" rel="alternate" type="text/html"/>
    <title>TR20-071 |  A Tight Lower Bound on Adaptively Secure Full-Information Coin Flip | 

	Iftach Haitner, 

	Yonatan Karidi-Heller</title>
    <summary>In a distributed coin-flipping protocol, Blum [ACM Transactions on Computer Systems '83],
the parties try to output a common (close to) uniform bit, even when some adversarially chosen parties try to bias the common output. In an adaptively secure full-information coin flip, Ben-Or and Linial [FOCS '85], the parties communicate over a broadcast channel and a computationally unbounded adversary can choose which parties to corrupt during the protocol execution. Ben-Or and Linial proved that the $n$-party majority protocol is resilient to $o(\sqrt{n})$ corruptions (ignoring log factors), and conjectured this is a tight upper bound for any $n$-party protocol (of any round complexity). Their conjecture was proved to be correct for single-turn (each party sends a single message) single-bit (a message is one bit) protocols, Lichtenstein, Linial, and Saks [Combinatorica '89], symmetric protocols Goldwasser, Kalai, and Park [ICALP '15], and recently for (arbitrary message length) single-turn protocols Tauman Kalai, Komargodski, and Raz [DISC '18]. Yet, the question for many-turn (even single-bit) protocols was left completely open.

In this work we close the above gap, proving that no $n$-party protocol (of any round complexity) is resilient to $O(\sqrt{n})$ (adaptive) corruptions.</summary>
    <updated>2020-05-04T14:14:22Z</updated>
    <published>2020-05-04T14:14:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/070</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/070" rel="alternate" type="text/html"/>
    <title>TR20-070 |  On the list recoverability of randomly punctured codes | 

	Ben Lund, 

	Aditya Potukuchi</title>
    <summary>We show that a random puncturing of a code with good distance is list recoverable beyond the Johnson bound.
In particular, this implies that there are Reed-Solomon codes that are list recoverable beyond the Johnson bound.
It was previously known that there are Reed-Solomon codes that do not have this property. 
As an immediate corollary to our main theorem, we obtain better degree bounds on unbalanced expanders that come from Reed-Solomon codes.</summary>
    <updated>2020-05-04T09:06:23Z</updated>
    <published>2020-05-04T09:06:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1297</id>
    <link href="https://ptreview.sublinear.info/?p=1297" rel="alternate" type="text/html"/>
    <title>News for April 2020</title>
    <summary>April is now behind us, and we hope you and your families are all staying safe and healthy. We saw six seven property papers appear online last month, so at least there is some reading ahead of us! A mixture of privacy, quantum, high-dimensional distributions, and juntas (juntæ?). A lot of distribution testing, overall. Connecting […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>April is now behind us, and we hope you and your families are all staying safe and healthy. We saw <s>six</s> seven property papers appear online last month, so at least there is some reading ahead of us! A mixture of privacy, quantum, high-dimensional distributions, and juntas (juntæ?). A lot of distribution testing, overall.</p>



<p><strong>Connecting Robust Shuffle Privacy and Pan-Privacy</strong>, by Victor Balcer, Albert Cheu, Matthew Joseph, and Jieming Mao (<a href="https://arxiv.org/abs/2004.09481">arXiv</a>). This paper considers a recent notion of differential privacy called<em> shuffle privacy</em>, where users have sensitive data, a central untrusted server wants to do something with that data (for instance, say… testing its distribution), and a trusted middle-man/entity shuffles the users’ messages u.a.r. to bring in a bit more anonymity. As it turns out, testing uniformity (or identity) of distributions in the shuffle privacy model is (i) much harder than without privacy constraints; (ii) much harder than with ‘usual’ (weaker) differential privacy (iii) much easier than with local privacy; (iv) related to the sample complexity under another privacy notion, <em>pan-privacy</em>. It’s a brand exciting new world out there!</p>



<p><em>(Note: for the reader interested in keeping track of identity/uniformity testing of probability distributions under various privacy models, I wrote a very short summary of the current results <a href="https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/private-goodness-of-fit.pdf">here</a>.)</em></p>



<p><strong>Entanglement is Necessary for Optimal Quantum Property Testing, </strong>by Sebastien Bubeck, Sitan Chen, and Jerry Li (<a href="https://arxiv.org/abs/2004.07869">arXiv</a>). The analogue of uniformity testing, in the quantum world, is testing whether a quantum state is equal (or far from) the maximally mixed state. It’s known that this task  has “quantum sample complexity” (number of measurements) \(\Theta(d/\varepsilon^2)\) (i.e., square root dependence on  the dimension of the state, \(d^2\)). But this requires <em>entangled</em> measurements, which may be tricky to get (or, in my case, understand): what happens if the measurements can be adaptive, but not entangled? In this work, the authors show that, under this weaker access model \(\Omega(d^{4/3}/\varepsilon^2)\) measurements are necessary: adaptivity alone won’t cut it. It may still help though: without either entanglement <em>nor</em> adaptivity, the authors also show a \(\Omega(d^{3/2}/\varepsilon^2)\) measurements lower bound.</p>



<p><strong>Testing Data Binnings</strong>, by Clément Canonne and Karl Wimmer (<a href="https://eccc.weizmann.ac.il/report/2020/062/">ECCC</a>). More identity testing! Not private and not quantum for this one, but… not <em>quite</em> identity testing either. To paraphrase the abstract: this paper introduces (and gives near matching bounds for)  the related question of <em>identity up to binning</em>, where the reference distribution \(q\) is over \(k \ll n\) elements: the question is then whether there exists a suitable binning of the domain \([n]\) into \(k\) intervals such that, <em>once binned</em>, \(p\) is equal to \(q\).” </p>



<p><strong>Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models</strong>, by Antonio Blanca, Zongchen Chen, Daniel Štefankovič, and Eric Vigoda (<a href="https://arxiv.org/abs/2004.10805">arXiv</a>). Back to identity testing of distributions, but for high-dimensional structured ones this one. Specifically, this paper focuses on the undirected graphical models known as <em>restricted Boltzmann machines, </em>and provides efficient algorithms for identity testing and conditional hardness lower bounds depending on the type of correlations allowed in the graphical models.</p>



<p><strong>Robust testing of low-dimensional functions</strong>, by Anindya De, Elchanan Mossel, and Joe Neeman (<a href="https://arxiv.org/abs/2004.11642">arXiv</a>). Junta testing is a classical, central problem in property testing, with motivations and applications in machine learning and complexity. The related (and equally well-motivated) question of junta testing of functions on \(\mathbb{R}^d\) (instead of the Boolean hypercube) was recently studied by the same authors; and the related (and, again, equally well-motivated) question of <em>tolerant</em> junta testing on the Boolean hypercube was also recently studied (among other works) by the same authors. Well, this paper does it all, and tackles the challenging (and, for a change, equally well-motivated!) question of <em>tolerant</em> testing of juntas  on \(\mathbb{R}^d\).</p>



<p><strong>Differentially Private Assouad, Fano, and Le Cam</strong>, by Jayadev Acharya, Ziteng Sun, and Huanyu Zhang (<a href="https://arxiv.org/abs/2004.06830">arXiv</a>). Back to probability distributions and privacy. This paper provides differentially private analogues of the classical eponymous statistical inference results (Assouad’s lemma, Fano’s inequality, and Le Cam’s method). In particular, it gives ready-to-use, blackbox tools to prove testing and learning lower bounds for distributions in the differentially private setting, and shows how to use them to easily derive, and rederive, several lower bounds.</p>



<p><strong>Edit: </strong>We missed one!</p>



<p><strong>Learning and Testing Junta Distributions with Subcube Conditioning</strong>, by Xi Chen, Rajesh Jayaram, Amit Levi, Erik Waingarten (<a href="https://arxiv.org/abs/2004.12496">arXiv</a>). This paper focuses on the <em>subcube conditioning</em> model of (high-dimensional) distribution testing, where the algorithm can fix some variables to values of its choosing and get samples conditioned on those variables. Extending and refining techniques from <a href="https://ptreview.sublinear.info/?p=1227">a previous work by a (sub+super)set of the authors</a>, the paper shows how to optimally learn and test <a href="http://proceedings.mlr.press/v49/aliakbarpour16.html">junta distributions</a> in this framework—with exponential savings with respect to the usual i.i.d. sampling model.</p></div>
    </content>
    <updated>2020-05-04T01:52:43Z</updated>
    <published>2020-05-04T01:52:43Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-05-07T22:38:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blog.simons.berkeley.edu/?p=164</id>
    <link href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/" rel="alternate" type="text/html"/>
    <title>Fine-grained hardness of lattice problems: Open questions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">1 Introduction 1.1 Lattices and lattice-based cryptography Lattices are classically-studied geometric objects that in the past few decades have found a multitude of applications in computer science. The most important application area is lattice-based cryptography, the design of cryptosystems whose … <a href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h1>1 Introduction</h1>
<h2>1.1 Lattices and lattice-based cryptography</h2>
<p>Lattices are classically-studied geometric objects that in the past few decades have found a multitude of applications in computer science. The most important application area is <em>lattice-based cryptography</em>, the design of cryptosystems whose security is based on the apparent intractability of computational problems on lattices, even for quantum computers. Indeed, lattice-based cryptography has revolutionized the field because of its apparent quantum resistance and its other attractive security, functionality, and efficiency properties.</p>
<p>Intuitively, a lattice is a regular ordering of points in some (typically high-dimensional) space. More precisely, a <em>lattice</em> \( {{\cal{L}}}\) of rank \( {n}\) is the set of all integer linear combinations of some linearly independent vectors \( {\mathbf{b}_1, \ldots, \mathbf{b}_n}\), which are called a <em>basis</em> of \( {{\cal{L}}}\). We will be primarily interested in analyzing the running times of lattice algorithms as functions of the lattice’s rank \( {n}\).</p>
<h2>1.2. Computational lattice problems</h2>
<p>The two most important computational problems on lattices are the Shortest Vector Problem (SVP) and the Closest Vector Problem (CVP). SVP asks, given a basis of a lattice \( {{\cal{L}}}\) as input, to find a shortest non-zero vector in \( {{\cal{L}}}\). CVP, which can be viewed as an inhomogeneous version of SVP, asks, given a basis of a lattice \( {{\cal{L}}}\) and a target point \( {\mathbf{t}}\) as input, to find a closest vector in \( {{\cal{L}}}\) to \( {\mathbf{t}}\).</p>
<p>Algorithms for solving SVP form the core of the best known attacks on lattice-based cryptography both in theory and in practice. Accordingly, it is critical to understand the precise complexity of SVP as well as possible. The best provably correct algorithms for both SVP and CVP run in \( {2^{n + o(n)}}\)-time [<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>, <a href="https://arxiv.org/abs/1504.01995">ADS15</a>, <a href="https://arxiv.org/abs/1709.01535">AS18a</a>]. The best heuristic algorithms for SVP run in \( {2^{cn + o(n)}}\)-time for \( {c = 0.292}\) classically [<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] and \( {c = 0.265}\) using quantum speedups [<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] (see also [<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>]), and most real-world lattice-based cryptosystems assume that these algorithms are close to optimal. Indeed, many of these cryptosystems assume what Bos et al. [<a href="https://eprint.iacr.org/2016/659">B+16</a>] call a “paranoid” worst-case estimate of \( {c = 0.2075}\) (based on the kissing number and assuming that sieving algorithms are optimal) as the fastest hypothetical running time for SVP algorithms when choosing parameters. (See also Albrecht et al. [<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>], which surveys the security assumptions made in a wide range of lattice-based cryptosystems.) Accordingly, the difference in being able to solve SVP in \( {2^{0.2075n}}\) versus \( {2^{n/20}}\) versus \( {2^{\sqrt{n}}}\) time may mean the difference between lattice-based cryptosystems being secure, insecure with current parameters, or effectively broken in practice.</p>
<p>There is a rank-preserving reduction from SVP to CVP [<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>], so any algorithm for CVP immediately gives an essentially equally fast algorithm for SVP. In other words, CVP is at least as hard as SVP (and probably a bit harder). Indeed, historically, almost all lower bounds for SVP are proven via reduction from CVP (and nearly all algorithmic progress on CVP uses ideas originally developed for SVP).</p>
<h2>1.3. Fine-grained hardness</h2>
<p>The field of fine-grained complexity works to give strong, quantitative lower bounds on computational problems assuming standard complexity-theoretic assumptions. Proving such a (conditional) lower bound for an \( {{\mathsf{NP}}}\)-hard problem generally works by (1) assuming a stronger hardness assumption than \( {{\mathsf{P}} \neq {\mathsf{NP}}}\) about the complexity of \( {k}\)-SAT (such as ETH or SETH, defined below), and (2) giving a highly efficient reduction from \( {k}\)-SAT to the problem. The most important hardness assumptions for giving lower bounds on \( {{\mathsf{NP}}}\)-hard problems are the Exponential Time Hypothesis (ETH) and the Strong Exponential Time Hypothesis (SETH) of Impagliazzo and Paturi [<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>]. ETH asserts that there is no \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT, and SETH asserts that for every \( {\epsilon &gt; 0}\) there exists \( {k \in {\mathbb Z}^+}\) such that there is no \( {2^{(1 – \epsilon)n}}\)-time algorithm for \( {k}\)-SAT, where \( {n}\) denotes the number of variables in the SAT instance.</p>
<p>Here by “highly efficient” reductions we mean linear ones, i.e., reductions that map a \( {3}\)-SAT or \( {k}\)-SAT formula on \( {n}\) variables to an SVP or CVP instance of rank \( {C n + o(n)}\) for some absolute constant \( {C &gt; 0}\). Indeed, by giving a reduction from \( {3}\)-SAT (respectively, \( {k}\)-SAT for any \( {k \in {\mathbb Z}^+}\)) instances on \( {n}\) variables to SVP or CVP instances of rank \( {C n + o(n)}\), we can conclude that there is no \( {2^{o(n)}}\)-time (resp., \( {2^{(1-\epsilon)n/C}}\)-time for any \( {\epsilon &gt; 0}\)) algorithm for the corresponding problem assuming ETH (resp., SETH). Note that the smaller the value of \( {C}\) for which one can show such a reduction, the stronger the conclusion. In particular, a reduction mapping \( {k}\)-SAT instances on \( {n}\) variables to SVP or CVP instances of rank \( {n + o(n)}\) would imply an essentially tight lower bound on the corresponding problem assuming SETH — as mentioned above, the best provably correct algorithms for both SVP and CVP run in time \( {2^{n + o(n)}}\).</p>
<h2>1.4. Fine-grained hardness of CVP (and SVP)</h2>
<p>It is relatively easy to show that CVP is “ETH-hard,” i.e., to show that a \( {2^{o(n)}}\)-time algorithm for CVP would imply a \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT instances with \( {n}\) variables. This would falsify ETH. (It’s a nice exercise to show that the Subset Sum problem on a set of size \( {n}\) reduces to CVP on a lattice of rank \( {n}\), which implies the result.)</p>
<p>With some work, Divesh Aggarwal and Noah extended this to SVP [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>]. In particular, we showed a reduction from CVP to SVP that only increases the rank of the lattice by some constant multiplicative factor. (Formally, the reduction only works with certain minor constraints on the CVP instance. The reduction originally relied on a geometric conjecture, which was open for decades. But, Serge Vlăduţ proved the conjecture [<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] shortly after we published!)</p>
<p>So, unless ETH is false, there is no \( {2^{o(n)}}\)-time algorithm for CVP or SVP. But, for cryptographic applications, even, say, a \( {2^{n/20}}\)-time algorithm would be completely devastating. If such an algorithm were found, cryptographic schemes that we currently think are secure against absurdly powerful attackers straight out of science fiction (say, one with a computer the size of the sun running until the heat death of the universe) would turn out to be easily broken (e.g., in seconds on our laptops).</p>
<p>In [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we <em>almost</em> showed that CVP is “SETH-hard,” i.e., that a \( {2^{(1-\epsilon)n}}\)-time algorithm for CVP would imply such an algorithm for \( {k}\)-SAT for <em>any</em> constant \( {k}\). This would falsify SETH. So, we <em>almost</em> showed that the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm is optimal. The “almost” is because our proof works with \( {\ell_p}\) norms, that is, we show hardness for the version of CVP in which the distance from the target to a lattice vector is defined in terms of the \( {\ell_p}\) norm,</p>
<p align="center">\( \displaystyle \|\mathbf{x}\|_p := (|x_1|^p + \cdots + |x_d|^p)^{1/p} \; . \)</p>
<p>We call the corresponding problem \( {{\mathrm{CVP}}_p}\). In fact, our proof works for all \( {\ell_p}\) norms <em>except</em> when \( {p}\) is an even integer. (To see why this might happen, notice \( {\|\mathbf{x}\|_p^p}\) is a polynomial in the \( {x_i}\) if and only if \( {p}\) is an even integer. In fact, there’s some sense in which “\( {\ell_2}\) is the easiest norm,” because for any \( {p}\), there is a linear map \( {A \in {\mathbb R}^{d \times m}}\) such that \( {m}\) is not too large and \( {\|\mathbf{x}\|_2 \approx \|A \mathbf{x}\|_p}\).) Of course, we are most interested in the case \( {p= 2}\) (the only case for which the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm works), which is an even integer! Indeed, for all \( {p \neq 2}\), the fastest known algorithm for CVP is still Ravi Kannan’s \( {n^{O(n)}}\)-time algorithm from 1987 [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>]. (For SVP and for constant-factor approximate CVP, \(2^{O(n)}\)-time algorithms are known [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>].)</p>
<p>In fact, we showed that for \( {p = 2}\), no “natural” reduction can rule out a \( {2^{3n/4}}\)-time algorithm for CVP under SETH. A “natural” reduction is one with a fixed bijection between witnesses. In particular, any “natural” reduction from \( {3}\)-SAT to CVP must reduce to a lattice with rank at least roughly \( {4n/3}\). So, new ideas will be needed to prove stronger hardness of CVP in the \( {\ell_2}\) norm.</p>
<h1>2. Open problems</h1>
<p>We now discuss some of the problems that we left open in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]. For simplicity, we ask for specific results (e.g., “prove that problem \( {A}\) is \( {T}\)-hard under hypothesis \( {B}\)“), but of course any similar results would be very interesting (e.g., “\( {A}\) is \( {T’}\)-hard under hypothesis \( {B’}\)“).</p>
<h2>2.1. Hardness in the \(\ell_2\) norm</h2>
<p>The most obvious question that we left open is, of course, to prove similar \( {2^n}\)-time hardness results for \( {{\mathrm{CVP}}_2}\) (and more generally for \( {{\mathrm{CVP}}_p}\) for even integers \( {p}\)).</p>
<blockquote>
<p><b>Open problem 1.</b> Show that there is no \( {2^{0.99 n}}\)-time algorithm for \( {{\mathrm{CVP}}_2}\) assuming SETH.</p>
</blockquote>
<p>Remember that we showed that any proof of such a strong result would have to use an “unnatural” reduction. So, a fundamentally different approach is needed. One potentially promising direction would be to find a Cook reduction, as our limitations only apply to Karp reductions.</p>
<p>Alternatively, one might try for a different result that gets around this “natural” reduction limitations. E.g., even the following much weaker result would be very interesting.</p>
<blockquote>
<p><b>Open problem 2.</b> Show an efficient reduction from \( {3}\)-SAT on \( {n}\) variables to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {\approx 10n}\).</p>
</blockquote>
<p>Such a reduction to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {Cn}\) for some large constant \( {C}\) is known by applying the Sparsification Lemma [<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] to \( {3}\)-SAT, but showing such a reduction for any reasonably small \( {C}\) or even any explicit \( {C}\) using a different proof technique would be interesting.</p>
<p>Also, our limitations only apply to reductions that map satisfying assignments to <em>exact</em> closest vectors. So, one might try to get around our limitation by working directly with approximate versions of \( {3}\)-SAT and \( {{\mathrm{CVP}}_2}\). (In [<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we show such reductions from Gap-\( {k}\)-SAT to constant-factor approximate \( {{\mathrm{CVP}}_p}\) for all \( {p \notin 2{\mathbb Z}}\) as well as all \( {k \leq p}\). We also show reductions from Gap-\( {k}\)-Parity that achieve relatively large approximation factors.)</p>
<blockquote>
<p><b>Open problem 3.</b> Show an efficient reduction from Gap-\( {3}\)-SAT on \( {n}\) variables to approximate \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {n}\).</p>
</blockquote>
<h2>2.2. Hardness in \(\ell_p\) norms</h2>
<p>Intuitively, one reason that we are able to prove such strong results for \( {\ell_p}\) norms for \( {p \neq 2}\) is because we can use lattices with large ambient dimension \( {d}\) but low rank \( {n}\). In other words, while our reductions produce lattices \( {{\cal{L}}}\) that live in some \( {n}\)-dimensional subspace of \( {\ell_p}\)-space, the ambient space itself has large dimension \( {d}\) relative to \( {n}\). Of course, any subspace of the \( {\ell_2}\) norm is an \( {\ell_2}\) subspace (i.e., every slice of a ball is a lower-dimensional ball), so in the \( {\ell_2}\) norm, one can assume without loss of generality that \( {d = n}\). In particular, if we were able to prove \( {2^n}\)-hardness for the \( {\ell_2}\) norm, then we would actually prove \( {2^d}\)-hardness for free. However, a potentially easier problem would be to improve the \( {2^n}\)-hardness of \( {{\mathrm{CVP}}_p}\) shown in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]  to \( {2^d}\)-hardness for some \( p \neq 2 \).</p>
<blockquote>
<p><b>Open problem 4.</b> Show that there is no \( {2^{0.99 d}}\)-time algorithm for \( {{\mathrm{CVP}}_p}\) (for some \( {p}\)) assuming SETH.</p>
</blockquote>
<p>More generally, it would be very interesting to settle the fine-grained complexity of \( {{\mathrm{CVP}}_p}\) for some \( {p \neq 2}\) (either in terms of rank \( {n} \) or dimension \( {d} \)). This could take the form either of showing improved algorithms (currently the fastest algorithms for \( {{\mathrm{CVP}}_p}\) for general \( {p}\) run in \( {n^{O(n)}}\)-time [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>], and \( {2^{O(n)}}\)-time for a constant approximation factor [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>]), or showing super-\( {2^n}\) hardness, or both.</p>
<blockquote>
<p><b>Open problem 5.</b> Show matching upper bounds and lower bounds (under SETH) for \( {{\mathrm{CVP}}_p}\) for some \( {p}\) (possibly with a constant approximation factor).</p>
</blockquote>
<p>The case where \( {p = \infty}\) is especially interesting. Indeed, because the kissing number in the \( {\ell_\infty}\) norm is \( {3^n-1}\), one might guess that the fastest algorithms for \( {{\mathrm{CVP}}_\infty}\) and \( {{\mathrm{SVP}}_\infty}\) actually run in time \( {3^{n + o(n)}}\) or perhaps \( {3^{d + o(d)}}\). (See [<a href="https://arxiv.org/pdf/1801.02358">AM18</a>], which essentially achieves this.) We therefore ask whether stronger lower bounds can be proven in this special case.</p>
<blockquote>
<p><b>Open problem 6.</b> Show that \( {{\mathrm{CVP}}_\infty}\) cannot be solved in time \( {3^{0.99n}}\) (under SETH).</p>
</blockquote>
<h2>2.3. Hardness closer to crypto</h2>
<p>The most relevant problem to cryptography is approximate \( {{\mathrm{SVP}}_2}\) with an approximation factor that is polynomial in the rank \( {n}\). Our fastest algorithms to solve this problem work via a reduction to exact (or near exact) \( {{\mathrm{SVP}}_2}\) with some lower rank \( {n’ = \Theta(n)}\), so that even for these polynomial approximation factors, our fastest algorithms run in time \( {2^{\Omega(n)}}\) (where the hidden constant depends on the polynomial; see <a href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/">Michael’s post</a> for more on this topic). And, hardness results for exact SVP rule out attacks on cryptography that use such reductions. We currently only know how to rule out \( {2^{o(n)}}\)-time algorithms for \( {{\mathrm{SVP}}_2}\) (under the Gap-ETH assumption). We ask whether we can do better. (In [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>], we proved the stronger result below for \( {\ell_p}\) norms for large enough \( {p \notin 2{\mathbb Z}}\).)</p>
<blockquote>
<p><b>Open problem 7.</b> Prove that there is no \( {2^{n/10}}\)-time algorithm for \( {{\mathrm{SVP}}_2}\) (under SETH).</p>
</blockquote>
<p>Of course, we would ideally like to directly rule out faster algorithms for approximate \( {{\mathrm{SVP}}_2}\) with the approximation factors that are most directly relevant to cryptography. There are serious complexity-theoretic barriers to overcome to get all the way there (e.g., \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) are known to be in \( {{\mathsf{NP}}} \cap {{\mathsf{coNP}}}\) for large enough polynomial approximation factors. But, we can still hope to get as close as possible, by proving stronger hardness results for approximate \( {{\mathrm{CVP}}_p}\) and approximate \( {{\mathrm{SVP}}_p}\). Indeed, a beautiful sequence of works showed hardness for approximation factors up to \( {n^{c/\log \log n}}\) (so “nearly polynomial) [<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>, <a href="https://arxiv.org/abs/1806.04087">HR12</a>], but these results are not fine grained.</p>
<p>The best <em>fine-grained</em> hardness of approximation results known rule out algorithms for small constant-factor approximations for \( {{\mathrm{CVP}}_p}\) with \( {p \notin 2{\mathbb Z}}\) in time \( {2^{0.99n}}\) for \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) for any \( {p}\) in time \( {2^{o(n)}}\). We ask whether we can do better.</p>
<blockquote>
<p><b>Open problem 8.</b> Prove that there is no \( {2^{0.99 n}}\)-time algorithm for \( {2}\)-approximate \( {{\mathrm{CVP}}_p}\) (under some form of Gap-SETH, see below).</p>
</blockquote>
<blockquote>
<p><b>Open problem 9.</b> Prove that there is no \( {2^{o(n)}}\)-time algorithm for \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for superconstant \( {\gamma = \omega(1)}\) (under Gap-ETH).</p>
</blockquote>
<h2>2.4. Gap-SETH?</h2>
<p>One issue that arose in our attempts to prove fine-grained hardness of approximation results is that we don’t even know the “right” complexity-theoretic assumption about approximate CSPs to use as a starting point. For fine-grained hardness of exact problems, ETH and SETH are very well established hypotheses, and they are in some sense “the weakest possible” assumptions of their form. E.g., it is easy to see that \( {k}\)-SAT is \( {2^{Cn}}\) hard if any \( {k}\)-CSP is. But, for hardness of approximation, the situation is less clear.</p>
<p>The analogue of ETH in the regime of hardness of approximation is the beautiful Gap-ETH assumption, which was defined independently by Irit Dinur [<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] and Pasin Manurangsi and Prasad Raghavendra [<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>]. This assumption says that there exists some constant approximation factor \( {\delta \neq 1}\) such that \( {\delta}\)-Gap-\( {3}\)-SAT cannot be solved in time \( {2^{o(n)}}\). (Formally, both Dinur and Manurangsi and Raghavendra say that there is no \( {2^{o(n)}}\)-time algorithm that distinguishes a satisfiable formula from a formula for which no assignment satisfies more than a \( {(1-\epsilon)}\) fraction of the clauses, but we ignore this requirement of perfect completeness here.) It is easy to see that this hypothesis is equivalent to a similar hypothesis about any \( {3}\)-CSP (or, indeed, any \( {k}\)-CSP for any constant\( {k}\)).</p>
<p>However, to prove hardness of approximation with the finest of grains, we need some “gap” analogue of SETH, i.e., we would like to assume that for large enough \( {k}\), some Gap-\( {k}\)-CSP is hard to approximate up to some constant factor \( {\delta \neq 1}\) in better than \( {2^{0.99n}}\)-time. (Formally, we should add an additional variable \( {\epsilon &gt; 0}\) and have such a hypothesis for every running time \( {2^{(1-\epsilon)n}}\), but we set \( {\epsilon = 0.01}\) here to keep things relatively simple.)</p>
<p>An issue arises here concerning the dependence of the approximation factor \( {\delta}\) on the arity \( {k}\). In particular, recall that \( {k}\)-SAT can be trivially approximated up to a factor of \( {1-2^{-k}}\) (since a random assignment satisfies a \( {1-2^{-k}}\) fraction of the clauses in expectation). So, if we define Gap-SETH in terms of Gap-\( {k}\)-SAT, then we must choose \( {\delta = \delta(k) \geq 1-2^{-k}}\) that converges to one as \(k\) increases. Manurangsi proposed such a version of Gap-SETH in his thesis [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>, Conjecture 12.1], specifically that for every large enough constant \( {k}\) there exists a constant \( {\delta = \delta(k) \neq 1}\) such that Gap-\( {k}\)-SAT cannot be approximated up to a factor of \( {\delta}\) in time \( {2^{0.99n}}\). (Again, we are leaving out an additional variable, \( {\epsilon}\).)</p>
<p>If we rely on this version of Gap-SETH, then our current techniques seem to get stuck at proving hardness of approximation for, say, \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for some non-explicit constant \( {\gamma_p &gt; 1}\) (and, if one works out the numbers, one can see immediately that \( {\gamma_p}\) must be really quite close to one). However, other Gap-\(k\)-CSPs are known to be (\(\mathsf{NP}\)-)hard to approximate up to much better approximation factors. E.g., for any \( {k}\), Gap-\(k\)-Parity is \( {{\mathsf{NP}}}\)-hard to approximate up to any constant approximation factor \( {1/2 &lt; \delta \leq 1}\) [<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>], and Gap-\( {k}\)-AND is \( {{\mathsf{NP}}}\)-hard to approximate for any constant approximation factor \( {\Omega(k/2^k) \leq \delta \leq 1}\) [<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>]. Indeed, Gap-\( {k}\)-AND is a quite natural problem to consider in this context since there is a fine-grained, approximation-factor preserving reduction from any Gap-\( {k}\)-CSP to Gap-\( {k}\)-AND. This generality motivates understanding the precise complexity of Gap-\( {k}\)-AND.</p>
<blockquote>
<p><b>Open problem 10.</b> What is the fine-grained complexity of the \( {\delta}\)-Gap-\( {k}\)-AND problem in terms of \( {n}\), \( {k}\), and \( {\delta}\)? In particular, if</p>
<p align="center">\( \displaystyle C_{k,\delta} := \inf \{ C &gt; 0 \ : \ \text{there is a $2^{C_{k,\delta}}$-time algorithm for algorithm for $\delta$-Gap-$k$-AND}\}\)</p>
<p>then what is the behavior of \( {C_{k,\delta}}\) as \( {k \rightarrow \infty}\) (for various functions \( {\delta = \delta(k)}\) of \( {k}\))?</p>
</blockquote>
<p>In particular, if one were to hypothesize sufficiently strong hardness of \( {\delta}\)-Gap-\( {k}\)-AND — i.e., to define an appropriate variant of Gap-SETH based on Gap-\( {k}\)-AND — then one might be able to use this hypothesis to prove very strong fine-grained hardness of approximation results. There is a fine-grained (but non-approximation preserving) reduction from Gap-\( {k}\)-AND to Gap-\( {k}\)-SAT, and so Manurangsi’s Gap-SETH is equivalent to the conjecture that there exists some non-explicit \( {\delta(k)}\) such that \( {\lim_{k \rightarrow \infty} C_{k,\delta} = 1}\).</p>


<ul><li>[<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>] Aggarwal, Bennett, Golovnev, Stephens-Davidowitz. Fine-grained hardness of CVP(P)— Everything that we can prove (and nothing else)</li><li>[<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>] Albrecht, Curtis, Deo, Davidson, Player, Postlethwaite, Virdia, Wunderer. Estimate all the {LWE, NTRU} schemes! <em>SCN</em>, 2019.</li><li>[<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>] Aggarwal, Dadush, Regev, Stephens-Davidowitz. Solving the Shortest Vector Problem in \(2^n\) time via discrete Gaussian sampling. <em>STOC</em>, 2015.</li><li>[<a href="https://arxiv.org/abs/1504.01995">ADS15</a>]  Aggarwal, Dadush, Stephens-Davidowitz. Solving the Closest Vector Problem in \(2^n\) time–The discrete Gaussian strikes again! <em>FOCS</em>, 2015.</li><li>[<a href="https://arxiv.org/pdf/1801.02358">AM18</a>] Aggarwal, Mukhopadhyay. Faster algorithms for SVP and CVP in the \(\ell_\infty\) norm. <em>ISAAC</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1709.01535">AS18a</a>] Aggarwal, Stephens-Davidowitz. Just take the average! An embarrassingly simple \(2^n\)-time algorithm for SVP (and CVP). <em>SOSA</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1712.00942">AS18b</a>] Aggarwal, Stephens-Davidowitz. (Gap/S)ETH hardness of SVP. <em>STOC</em>, 2018.</li><li>[<a href="https://eprint.iacr.org/2016/659">B+16</a>] Bos, Costello, Ducas, Mironov, Naehrig, Nikolaenko, Raghunathan, Stebila. Frodo: Take off the ring! Practical, Quantum-Secure Key Exchange from LWE. <em>CCS,</em> 2016.</li><li>[<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] Becker, Ducas, Gama, Laarhoven. New directions in nearest neighbor searching with applications to lattice sieving. <em>SODA</em>, 2016.</li><li>[<a href="https://arxiv.org/abs/1704.03928">BGS17</a>] Bennett, Golovnev, Stephens-Davidowitz. On the quantitative hardness of CVP. <em>FOCS</em>, 2017.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>] Chan. Approximation resistance from pairwise-independent subgroups. <em>J. ACM</em>, 2016.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] Dinur. Mildly exponential reduction from gap 3SAT to polynomial-gap label-cover.</li><li>[<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>] Dinur, Kindler, Raz, Safra. Approximating CVP to within almost-polynomial factors is NP-hard. <em>Combinatorica</em>, 2003.</li><li>[<a href="https://arxiv.org/abs/1011.5666">DPV11</a>] Dadush, Peikert, Vempala. Enumerative lattice algorithms in any norm via \(M\)-ellipsoid coverings. <em>FOCS</em>, 2011.</li><li>[<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>] Goldreich, Micciancio, Safra, Seifert. Approximating shortest lattice vectors is not harder than approximating closest lattice vectors. <em>IPL</em>, 1999.</li><li>[<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>] Håstad. Some optimal inapproximability results. <em>J. ACM</em>, 2001.</li><li>[<a href="https://arxiv.org/abs/1806.04087">HR12</a>] Haviv, Regev. Tensor-based hardness of the Shortest Vector Problem to within almost polynomial factors. <em>TOC</em>, 2012.</li><li>[<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>] Impagliazzo, Paturi. On the complexity of \(k\)-SAT. <em>JCSS</em>, 2001.</li><li>[<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] Impagliazzo, Paturi, Zane. Which problems have strongly exponential complexity? <em>JCSS</em>, 2001.</li><li>[<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] Laarhoven. Search problems in cryptography. Ph.D thesis, 2015.</li><li>[<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>] Kannan. Minkowski’s convex body theorem and Integer Programming. <em>MOR</em>, 1987.</li><li>[<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>] Kirshanova, Mårtensson, Postlethwaite, Roy Moulik. Quantum algorithms for the approximate \(k\)-list problem and their application to lattice sieving. <em>Asiacrypt</em>, 2019.</li><li>[<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>] Manurangsi. Approximation and Hardness: Beyond P and NP.</li><li>[<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>] Manurangsi, Raghavendra. A Birthday Repetition Theorem and Complexity of Approximating Dense CSPs. <em>ICALP</em>, 17.</li><li>[<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] Vlăduţ. Lattices with exponentially large kissing numbers. <em>Moscow J. of Combinatorics and Number Theory</em>, 2019<em>.</em></li></ul></div>
    </content>
    <updated>2020-05-04T01:07:28Z</updated>
    <published>2020-05-04T01:07:28Z</published>
    <category term="General"/>
    <author>
      <name>Huck Bennett</name>
    </author>
    <source>
      <id>https://blog.simons.berkeley.edu</id>
      <link href="https://blog.simons.berkeley.edu/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blog.simons.berkeley.edu" rel="alternate" type="text/html"/>
      <subtitle>What's New at the Simons Institute for the Theory of Computing.</subtitle>
      <title>Calvin Café: The Simons Institute Blog</title>
      <updated>2020-05-07T22:38:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/05/03/hanoi-vs-sierpinski</id>
    <link href="https://11011110.github.io/blog/2020/05/03/hanoi-vs-sierpinski.html" rel="alternate" type="text/html"/>
    <title>Hanoi vs Sierpiński</title>
    <summary>The Hanoi graphs and Sierpiński graphs both look like the Sierpiński triangle, and have a very similar recursive construction from triples of smaller graphs of the same type, but they are not quite the same graphs as each other. The Sierpiński graphs (left, below) are the graphs of the vertices and boundary edges of partially-constructed Sierpiński triangles; they can also be formed from three smaller Sierpiński graphs by identifying pairs of extreme vertices (the vertices of degree two at the three corners of the triangular layout). The Hanoi graphs (right, below) are the state spaces of the tower of Hanoi puzzle, in which rings of different size are moved one at a time between three pegs, only allowing moves that keep the rings sorted on each peg. They also have a construction from three smaller Hanoi graphs, but where the pairs of extreme vertices are connected by an edge rather than identified.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Hanoi graphs and Sierpiński graphs both look like the <a href="https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle">Sierpiński triangle</a>, and have a very similar recursive construction from triples of smaller graphs of the same type, but they are not quite the same graphs as each other. The Sierpiński graphs (left, below) are the graphs of the vertices and boundary edges of partially-constructed Sierpiński triangles; they can also be formed from three smaller Sierpiński graphs by identifying pairs of extreme vertices (the vertices of degree two at the three corners of the triangular layout). The <a href="https://en.wikipedia.org/wiki/Hanoi_graph">Hanoi graphs</a> (right, below) are the state spaces of the tower of Hanoi puzzle, in which rings of different size are moved one at a time between three pegs, only allowing moves that keep the rings sorted on each peg. They also have a construction from three smaller Hanoi graphs, but where the pairs of extreme vertices are connected by an edge rather than identified.</p>

<p style="text-align: center;"><img alt="Hanoi graphs and Sierpi&#x144;ski graphs" src="https://11011110.github.io/blog/assets/2020/hanoi-vs-sierpinski.svg"/></p>

<p>The difference between them comes out much more strongly when you generalize them to higher dimensions. The Sierpiński triangle generalizes to tetrahedra (a popular shape for kites) and higher-dimensional simplices; <a href="https://commons.wikimedia.org/wiki/File:Alexander_Graham_Bell_facing_his_wife,_Mabel_Hubbard_Gardiner_Bell,_who_is_standing_in_a_tetrahedral_kite,_Baddeck,_Nova_Scotia.tif">the photo below</a> shows <a href="https://en.wikipedia.org/wiki/Mabel_Gardiner_Hubbard">Mabel Bell</a> and <a href="https://en.wikipedia.org/wiki/Alexander_Graham_Bell">Alexander Graham Bell</a>, seemingly about to kiss, in a three-dimensional Sierpiński graph, the framework for a kite.</p>

<p style="text-align: center;"><img alt="Mabel Bell and Alexander Graham Bell kissing in a Sierpi&#x144;ski tetrahedron kite frame, from https://commons.wikimedia.org/wiki/File:Alexander_Graham_Bell_facing_his_wife,_Mabel_Hubbard_Gardiner_Bell,_who_is_standing_in_a_tetrahedral_kite,_Baddeck,_Nova_Scotia.tif" src="https://11011110.github.io/blog/assets/2020/bell-kite-kiss.jpg"/></p>

<p>Again, the -dimensional Sierpiński graph has a recursive construction from  smaller graphs of the same type, identified at extreme vertices (the vertices of degree  at the  corners of the layout). Because the number of vertices separating the subgraphs at each level of the recursion is so small, these graphs have bounded <a href="https://en.wikipedia.org/wiki/Treewidth">treewidth</a>, and a few years ago on the TCS stackexchange <a href="https://cstheory.stackexchange.com/q/36542">I calculated the treewidth of the Sierpiński triangle graphs explicitly as being four</a>. The same bound transfers easily enough to the three-peg Hanoi graphs.</p>

<p>The analogue of higher dimensions for the Hanoi graphs is to use more pegs. The Hanoi graph with  pegs and  rings has  states, more or less the same as the Sierpiński graph for -dimensional Sierpiński fractals with  levels of recursion. Here’s the one with two rings; each state is described by a pair of letters, using a capital letter for the peg holding the larger ring and a lowercase letter for the peg holding the smaller ring.</p>

<p style="text-align: center;"><img alt="Hanoi graph for two rings on four pegs" src="https://11011110.github.io/blog/assets/2020/Hanoi-4-2.svg"/></p>

<p>The recursive construction for these graphs combines  copies of a smaller graph of the same type: one copy for each position where the largest ring can be placed, and a smaller graph describing the placements of the smaller rings once the largest ring has been placed. These copies of the smaller graph are connected together by edges describing the movements of the largest ring. But I’ve only drawn an example for two rings because these graphs get messy and hard to draw very quickly. The reason is not the exponential number of total vertices, but the large number of connections from one recursive subgraph to another. Two recursive subgraphs are connected whenever the largest ring can move from its peg in one subgraph to its peg in the other, and this is allowed whenever these two pegs have no smaller rings on them. So in a Hanoi graph with  pegs,  rings, and  vertices, each pair of recursive subgraphs has  edges between them, one for each placement of the smaller rings on the  remaining pegs.</p>

<p>The recursive subdivision with  edges between subgraphs leads to a tree-decomposition with treewidth , and this naturally raises the question of whether this is tight or whether some other less-intuitive recursive decomposition has smaller cuts between its recursive subgraphs. This is the question studied in my newest preprint, “On the treewidth of Hanoi graphs” (<a href="https://arxiv.org/abs/2005.00179">arXiv:2005.00179</a>), with UCI student Daniel Frishberg and Oregon State student Will Maxwell, to appear at <a href="https://sites.google.com/view/fun2020/home">FUN 2020</a> (supposedly to be held in person in September in Italy after being rescheduled from June, but I’m not holding my breath). We don’t get a precise answer, but we succeed in proving bounds on the treewidth of the form <span style="white-space: nowrap;">.</span> This is nearly tight for fixed  and variable : we get the same exponential function of  as the upper bound, and are smaller than the upper bound by only a much lower-order polynomial factor. But the exact treewidth remains elusive.</p>

<p>To put it in a possibly more familiar form, when one of these graphs (for a fixed number of pegs and variable number of rings) has  vertices, it has separators of size , where . For the four-peg Hanoi graphs, this means separators of size , more or less the same as for planar graphs (although these graphs seem far from planar). But that nice exponent is just a coincidence caused by the fact that  is a power of . For other choices of , that doesn’t happen and we get a transcendental exponent . So these graphs don’t even act like -dimensional graphs, for which a reasonable separator exponent might be the rational number . And they certainly don’t act like the Sierpiński graphs, for which the exponent is zero.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104108481482094736">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-05-03T22:03:00Z</updated>
    <published>2020-05-03T22:03:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-05-04T05:19:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/069</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/069" rel="alternate" type="text/html"/>
    <title>TR20-069 |  Optimal Error Pseudodistributions for Read-Once Branching Programs | 

	Eshan Chattopadhyay, 

	Jyun-Jie Liao</title>
    <summary>In a seminal work, Nisan (Combinatorica'92) constructed a pseudorandom generator for length $n$ and width $w$ read-once branching programs  with seed length $O(\log n\cdot \log(nw)+\log n\cdot\log(1/\varepsilon))$ and  error $\varepsilon$. It remains a central question  to reduce the seed length to $O(\log (nw/\varepsilon))$, which would prove that $\mathbf{BPL}=\mathbf{L}$. However, there has been no improvement on Nisan's construction for the case $n=w$, which is most relevant to space-bounded derandomization.




Recently, in a beautiful work, Braverman, Cohen and Garg (STOC'18) introduced the notion of a \emph{pseudorandom pseudo-distribution} (PRPD) and gave an explicit construction of a PRPD with seed length $\tilde{O}(\log n\cdot \log(nw)+\log(1/\varepsilon))$. A PRPD is a relaxation of a pseudorandom generator, which suffices for derandomizing $\mathbf{BPL}$ and also implies a hitting set. Unfortunately, their construction is quite involved and complicated. Hoza and Zuckerman (FOCS'18) later constructed a much simpler hitting set generator with seed length $O(\log n\cdot \log(nw)+\log(1/\varepsilon))$, but their techniques are restricted to hitting sets.

In this work, we construct a PRPD with seed length 
$$O(\log n\cdot \log (nw)\cdot \log\log(nw)+\log(1/\varepsilon)).$$
This improves upon the construction in \cite{BCG18} by a $O(\log\log(1/\varepsilon))$ factor, and is optimal in the small error regime. In addition, we believe our construction and analysis to be   simpler than the work of Braverman, Cohen and Garg.</summary>
    <updated>2020-05-03T22:01:57Z</updated>
    <published>2020-05-03T22:01:57Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/068</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/068" rel="alternate" type="text/html"/>
    <title>TR20-068 |  One-Sided Error Testing of Monomials and Affine Subspaces | 

	Oded Goldreich, 

	Dana Ron</title>
    <summary>We consider the query complexity of three versions of the problem of testing monomials and affine (and linear) subspaces with one-sided error, and obtain the following results: 
\begin{itemize}
\item The general problem, in which the arity of the monomial (resp., co-dimension of the subspace) is not specified, has query complexity ${\widetilde{O}}(1/\epsilon)$, where $\epsilon$ denotes the proximity parameter. 
\item The bounded problem, in which the arity of the monomial (resp., co-dimension of the subspace) is upper bounded by a fixed parameter, has query complexity ${\widetilde{O}}(1/\epsilon)$.
\item The exact problem, in which the arity of the monomial (resp., co-dimension of the subspace) is required to equal a fixed parameter (e.g., equals~2), has query complexity ${\widetilde{\Omega}}(\log n)$, where $n$ denotes the length of the argument for the tested function.  
\end{itemize}
The running time of the testers in the positive results is linear in their query complexity.</summary>
    <updated>2020-05-03T20:04:44Z</updated>
    <published>2020-05-03T20:04:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4379</id>
    <link href="https://lucatrevisan.wordpress.com/2020/05/03/talagrands-generic-chaining/" rel="alternate" type="text/html"/>
    <title>Talagrand’s Generic Chaining</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Welcome to phase two of in theory, in which we again talk about math. I spent last Fall teaching two courses and getting settled, I mostly traveled in January and February, and I have spent the last two months on … <a href="https://lucatrevisan.wordpress.com/2020/05/03/talagrands-generic-chaining/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Welcome to phase two of <em>in theory</em>, in which we again talk about math. I spent last Fall teaching two courses and getting settled, I mostly traveled in January and February, and I have spent the last two months on my sofa catching up on TV series. Hence I will reach back to last Spring, when I learned about Talagrand’s machinery of generic chaining and majorizing measures from Nikhil Bansal, in the context of our work with Ola Svensson on <a href="https://arxiv.org/abs/1905.01495">graph and hypergraph sparsification</a>. Here I would like to record what I understood about the machinery, and in a follow-up post I plan to explain the application to hypergraph sparsification.</p>
<p>
<span id="more-4379"/></p>
<p>
</p><p><b>1. A Concrete Setting </b></p>
<p/><p>
Starting from a very concrete setting, suppose that we have a subset <img alt="{T \subseteq {\mathbb R}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T \subseteq {\mathbb R}^n}"/>, we pick a random Gaussian vector <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> from <img alt="{N({\bf 0}, I)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28%7B%5Cbf+0%7D%2C+I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N({\bf 0}, I)}"/>, and we are interested in the random variable</p>
<p>
<a name="eqg"/></p><a name="eqg">
<p align="center"><img alt="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+%5Crangle+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \ \ \ \ \ (1)"/></p>
</a><p><a name="eqg"/> In theoretical computer science, for example, a random variable like <a href="https://lucatrevisan.wordpress.com/feed/#eqg">(1)</a> comes up often in the study of rounding algorithms for semidefinite programming, but this is a problem of much broader interest. </p>
<p>
A first observation is that each <img alt="{\langle g,t \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+g%2Ct+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle g,t \rangle}"/> is Gaussian with mean zero and variance <img alt="{|| t||^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+t%7C%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|| t||^2}"/>. If <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is finite, we can use a union bound to estimate the tail of <img alt="{\sup_{t\in T} \langle t,g \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t%2Cg+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sup_{t\in T} \langle t,g \rangle}"/>, and we can compute the upper bound <a name="equb"/></p><a name="equb">
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \leq O\left(\sqrt{\log |T|} \cdot \sup_{t\in T} || t|| \right) \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+%5Crangle+%5Cleq+O%5Cleft%28%5Csqrt%7B%5Clog+%7CT%7C%7D+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%7C%7C+t%7C%7C+%5Cright%29+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \leq O\left(\sqrt{\log |T|} \cdot \sup_{t\in T} || t|| \right) \ \ \ \ \ (2)"/></p>
</a><p><a name="equb"/> The above bound can be tight, but it is poor if the points of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> are densely clustered, and it is useless if <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is infinite. </p>
<p>
It is useful to note that, if we fix, arbitrarily, an element <img alt="{t_0 \in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt_0+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t_0 \in T}"/>, then we have <a name="eqgtzero"/></p><a name="eqgtzero">
<p align="center"><img alt="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle = \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t - t_0 \rangle \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+%5Crangle+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+-+t_0+%5Crangle+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle = \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t - t_0 \rangle \ \ \ \ \ (3)"/></p>
</a><p><a name="eqgtzero"/> because <img alt="{\mathop{\mathbb E} \langle g, t_0 \rangle = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Clangle+g%2C+t_0+%5Crangle+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E} \langle g, t_0 \rangle = 0}"/>. The latter expression is nicer to work with because it makes it more explicit that what we are trying to compute is invariant under shifts of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, and only depends on pairwise distances of the elements of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, rather than their norm. </p>
<p>
In the cases in which <a href="https://lucatrevisan.wordpress.com/feed/#equb">(2)</a> gives a poor bound, a natural approach is to reason about an <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>-net <img alt="{T'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T'}"/> of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, that is, a subset <img alt="{T'\subseteq T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%27%5Csubseteq+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T'\subseteq T}"/> such that for every <img alt="{t\in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t\in T}"/> there is an element <img alt="{\pi(t) \in T'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28t%29+%5Cin+T%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi(t) \in T'}"/> such that <img alt="{||t - \pi(t) ||\leq \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%7Ct+-+%5Cpi%28t%29+%7C%7C%5Cleq+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{||t - \pi(t) ||\leq \epsilon}"/>. Then we can say that</p>
<p/><p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup_t \langle t - t_0, g \rangle = \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle + \langle \pi(t) -t_0, g \rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_t+%5Clangle+t+-+t_0%2C+g+%5Crangle+%3D+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t+-+%5Cpi%28t%29+%2C+g+%5Crangle+%2B+%5Clangle+%5Cpi%28t%29+-t_0%2C+g+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup_t \langle t - t_0, g \rangle = \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle + \langle \pi(t) -t_0, g \rangle "/></p>
<p align="center"><img alt="\displaystyle  \leq \left( \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle \right) + \left( \mathop{\mathbb E} \sup_{t\in T}\langle \pi(t) -t_0, g \rangle \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Cleft%28+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t+-+%5Cpi%28t%29+%2C+g+%5Crangle+%5Cright%29+%2B+%5Cleft%28+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D%5Clangle+%5Cpi%28t%29+-t_0%2C+g+%5Crangle+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \leq \left( \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle \right) + \left( \mathop{\mathbb E} \sup_{t\in T}\langle \pi(t) -t_0, g \rangle \right) "/></p>
<p align="center"><img alt="\displaystyle  \leq O( \sqrt{\log |T|} ) \cdot \sup_{t\in T} ||t-\pi(t) || + \left( \mathop{\mathbb E} \sup_{t'\in T'}\langle t' -t_0, g \rangle \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+O%28+%5Csqrt%7B%5Clog+%7CT%7C%7D+%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%7C%7Ct-%5Cpi%28t%29+%7C%7C+%2B+%5Cleft%28+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%27%5Cin+T%27%7D%5Clangle+t%27+-t_0%2C+g+%5Crangle+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \leq O( \sqrt{\log |T|} ) \cdot \sup_{t\in T} ||t-\pi(t) || + \left( \mathop{\mathbb E} \sup_{t'\in T'}\langle t' -t_0, g \rangle \right) "/></p>
<p align="center"><img alt="\displaystyle  \leq O\left( \sqrt{\log |T|} \cdot \epsilon + \sqrt {\log |T'|} \cdot \sup_{t'\in T'} || t' - t_0|| \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+O%5Cleft%28+%5Csqrt%7B%5Clog+%7CT%7C%7D+%5Ccdot+%5Cepsilon+%2B+%5Csqrt+%7B%5Clog+%7CT%27%7C%7D+%5Ccdot+%5Csup_%7Bt%27%5Cin+T%27%7D+%7C%7C+t%27+-+t_0%7C%7C+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \leq O\left( \sqrt{\log |T|} \cdot \epsilon + \sqrt {\log |T'|} \cdot \sup_{t'\in T'} || t' - t_0|| \right) "/></p>
<p>
which can be a much tighter bound. Notice that we used <a href="https://lucatrevisan.wordpress.com/feed/#equb">(2)</a> to bound </p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T'} \langle t' - t_0 , g\rangle \ , " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%27%7D+%5Clangle+t%27+-+t_0+%2C+g%5Crangle+%5C+%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T'} \langle t' - t_0 , g\rangle \ , "/></p>
<p> but it might actually be better to find an <img alt="{\epsilon'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon'}"/>-net <img alt="{T''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T''}"/> of <img alt="{T'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T'}"/>, and so on. In general, a tighter analysis would be to choose a sequence of nested sets <img alt="{T_0 \subseteq T_1 \subseteq \cdots \subseteq T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_0+%5Csubseteq+T_1+%5Csubseteq+%5Ccdots+%5Csubseteq+T_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_0 \subseteq T_1 \subseteq \cdots \subseteq T_k}"/>, where <img alt="{T_0 = \{ t_0 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_0+%3D+%5C%7B+t_0+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_0 = \{ t_0 \}}"/>, <img alt="{T_k = T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k+%3D+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k = T}"/>, and we have that <img alt="{T_{i-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bi-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{i-1}}"/> is an <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/>-net of <img alt="{T_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{i}}"/>, that is, for every element <img alt="{t_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t_{i}}"/> of <img alt="{T_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_i}"/> there is an element <img alt="{\pi_i (t_i) \in T_{i-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_i+%28t_i%29+%5Cin+T_%7Bi-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi_i (t_i) \in T_{i-1}}"/> such that <img alt="{|| t_i - \pi_i (t_i) || \leq \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+t_i+-+%5Cpi_i+%28t_i%29+%7C%7C+%5Cleq+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|| t_i - \pi_i (t_i) || \leq \epsilon_i}"/>. Then, by generalizing the above reasoning, we get </p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sum_{i=1}^k \sqrt{\log |T_i | } \cdot \sup_{t_i \in T_i} || t_i - \pi_i(t_i) || \leq O(1) \cdot \sum_{i=1}^n \epsilon_i \sqrt{\log |T_i | } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t-t_0%2Cg+%5Crangle+%5Cleq+O%281%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5Ek+%5Csqrt%7B%5Clog+%7CT_i+%7C+%7D+%5Ccdot+%5Csup_%7Bt_i+%5Cin+T_i%7D+%7C%7C+t_i+-+%5Cpi_i%28t_i%29+%7C%7C+%5Cleq+O%281%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5En+%5Cepsilon_i+%5Csqrt%7B%5Clog+%7CT_i+%7C+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sum_{i=1}^k \sqrt{\log |T_i | } \cdot \sup_{t_i \in T_i} || t_i - \pi_i(t_i) || \leq O(1) \cdot \sum_{i=1}^n \epsilon_i \sqrt{\log |T_i | } "/></p>
<p>
Finally, if the cardinality of the <img alt="{T_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_i}"/> grows sufficiently fast, namely, if we have <img alt="{|T_i| &gt; |T_{i-1}|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CT_i%7C+%3E+%7CT_%7Bi-1%7D%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|T_i| &gt; |T_{i-1}|^2}"/>, it is possible to refine the estimate to </p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{i=1}^k \sqrt{\log |T_i | } \cdot || t - \pi_i (t) || " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t-t_0%2Cg+%5Crangle+%5Cleq+O%281%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%5Csum_%7Bi%3D1%7D%5Ek+%5Csqrt%7B%5Clog+%7CT_i+%7C+%7D+%5Ccdot+%7C%7C+t+-+%5Cpi_i+%28t%29+%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{i=1}^k \sqrt{\log |T_i | } \cdot || t - \pi_i (t) || "/></p>
<p> where <img alt="{\pi_i(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_i%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi_i(t)}"/> is the closest element to <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> in <img alt="{T_{i-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bi-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{i-1}}"/>. This is done by avoiding to write the expectation of the sup of a sum as a sum of expectations of sups and then using <a href="https://lucatrevisan.wordpress.com/feed/#equb">(2)</a>, but by bounding the tail of the sup of the sum directly.</p>
<p>
At this point, we do not even need to assume that <img alt="{T_k= T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%3D+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k= T}"/>, that <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is finite, or that the sequence of sets is finite, and we have the following result.</p>
<blockquote><p><b>Theorem 1 (Talagrand’s generic chaining inequality)</b> <em> Let <img alt="{T \subseteq {\mathbb R}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T \subseteq {\mathbb R}^n}"/> be an arbitrary set, let <img alt="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_0+%5Csubseteq+T_1+%5Csubseteq+%5Ccdots+T_k+%5Csubseteq+%5Ccdots+%5Csubseteq+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}"/> be a countable sequence of finite subsets of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> such that <img alt="{|T_0| = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CT_0%7C+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|T_0| = 1}"/> and <img alt="{|T_k| \leq 2^{2^k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CT_k%7C+%5Cleq+2%5E%7B2%5Ek%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|T_k| \leq 2^{2^k}}"/>. Then </em></p><em>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t, g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} || t - \pi_k(t)|| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t%2C+g+%5Crangle+%5Cleq+O%281%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+2%5E%7Bk%2F2%7D+%7C%7C+t+-+%5Cpi_k%28t%29%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t, g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} || t - \pi_k(t)|| "/></p>
</em><p><em> where <img alt="{\pi_k(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_k%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi_k(t)}"/> is the element of <img alt="{T_{k-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bk-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{k-1}}"/> closest to <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. </em></p></blockquote>
<p/><p>
A short complete proof is in these <a href="https://tcsmath.wordpress.com/2010/06/15/the-generic-chaining/">notes by James Lee</a>.</p>
<p>
While the above Theorem has a very simple proof, the amazing thing, which is rather harder to prove, is that it is <em>tight</em>, in the sense that for every <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> there is a sequence of sets such that the bound of the above theorem has a matching lower bound, up to an absolute constant. This is why it is called <em>generic chaining</em>. <em>Chaining</em> because the projection <img alt="{\langle t-t_0,g\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+t-t_0%2Cg%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle t-t_0,g\rangle}"/> of <img alt="{t-t_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt-t_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t-t_0}"/> on <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is estimated based on the “chain” </p>
<p align="center"><img alt="\displaystyle  \sum_k \langle \pi_{k+1} (t) - \pi_k(t) , g \rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_k+%5Clangle+%5Cpi_%7Bk%2B1%7D+%28t%29+-+%5Cpi_k%28t%29+%2C+g+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_k \langle \pi_{k+1} (t) - \pi_k(t) , g \rangle"/></p>
<p> of projections of the intermediate steps of a path that goes from <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> to <img alt="{t_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t_0}"/> passing through the <img alt="{\pi_k(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_k%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi_k(t)}"/>. <em>Generic</em> because this upper bound technique works as well as any other possible upper bound, up to an absolute constant.</p>
<p>
</p><p><b>2. An Abstract Setting </b></p>
<p/><p>
Let now <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> be a completely arbitrary set, and suppose that we have a distribution <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/> over functions <img alt="{f: T \rightarrow {\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+T+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f: T \rightarrow {\mathbb R}}"/> and we want to upper bound </p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E}_{F \sim {\cal D}} \ \ \sup_{t\in T} \ F(t) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D_%7BF+%5Csim+%7B%5Ccal+D%7D%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D+%5C+F%28t%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E}_{F \sim {\cal D}} \ \ \sup_{t\in T} \ F(t) "/></p>
<p> That is, we have a random optimization problem with a fixed feasible set <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, and we want to know the typical value of the optimum. For example, <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> could be the set of cuts of a vertex set <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>, and <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/> describe a distribution of random graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> such that <img alt="{F(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t)}"/> is the number of edges cut in a random graph by the cut <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. Then the above problem is to estimate the average value of the max cut in the random graphs of the distribution. Or <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> could be the unit sphere <img alt="{\{ x \in {\mathbb R}^N : ||x|| = 1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+x+%5Cin+%7B%5Cmathbb+R%7D%5EN+%3A+%7C%7Cx%7C%7C+%3D+1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ x \in {\mathbb R}^N : ||x|| = 1 \}}"/> and <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/> describe a distribution of random Hermitian matrices such that <img alt="{F(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t)}"/> is the quadratic form of a random matrix evaluated at <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. In this case, the above problem is to estimate the average value of the largest eigenvalue of such a random matrix.</p>
<p>
We will call the collection of random variables <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> a <em>random process</em>, where <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is a random variable distributed according to <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/>.</p>
<p>
If every <img alt="{F(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t)}"/>, and every finite linear combination <img alt="{\sum_{i=1}^k \alpha_i F(t_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5Ek+%5Calpha_i+F%28t_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{i=1}^k \alpha_i F(t_i)}"/>, has a Gaussian distribution, then we say that <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> is a <em>Gaussian process</em>, and if, in addition, <img alt="{\mathop{\mathbb E} F(t) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+F%28t%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E} F(t) = 0}"/> for every <img alt="{t\in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t\in T}"/> then we say that it is a <em>centered Gaussian process</em>.</p>
<p>
If <img alt="{T\subseteq {\mathbb R}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T\subseteq {\mathbb R}^n}"/>, and we define <img alt="{F(t) = \langle t,g\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t%29+%3D+%5Clangle+t%2Cg%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t) = \langle t,g\rangle}"/> for a random standard Gaussian <img alt="{g\sim N({\bf 0},I)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2CI%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g\sim N({\bf 0},I)}"/>, then <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> is a centered Gaussian process and, in this case, upper bounding <img alt="{\mathop{\mathbb E} \sup F(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+F%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E} \sup F(t)}"/> is precisely the problem we studied before. </p>
<p>
If <img alt="{T\subseteq {\mathbb R}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T\subseteq {\mathbb R}^n}"/> and <img alt="{F(t) = \langle t,g \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t%29+%3D+%5Clangle+t%2Cg+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t) = \langle t,g \rangle}"/> for a random standard Gaussian <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/>, then, for every <img alt="{t_1,t_2 \in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt_1%2Ct_2+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t_1,t_2 \in T}"/>, we have</p>
<p/><p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \left(F(t_1) - F(t_2)\right)^2 = \mathop{\mathbb E}_{g \sim N({\bf 0},I)} \ \ \langle t_1-t_2,g \rangle^2 = ||t_1 - t_2 ||^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft%28F%28t_1%29+-+F%28t_2%29%5Cright%29%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bg+%5Csim+N%28%7B%5Cbf+0%7D%2CI%29%7D+%5C+%5C+%5Clangle+t_1-t_2%2Cg+%5Crangle%5E2+%3D+%7C%7Ct_1+-+t_2+%7C%7C%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \left(F(t_1) - F(t_2)\right)^2 = \mathop{\mathbb E}_{g \sim N({\bf 0},I)} \ \ \langle t_1-t_2,g \rangle^2 = ||t_1 - t_2 ||^2 "/></p>
<p> and, by analogy, if <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> is a centered Gaussian process, we will define the following distance function on <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>: </p>
<p align="center"><img alt="\displaystyle  d(t_1,t_2 ) := \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2))^2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28t_1%2Ct_2+%29+%3A%3D+%5Csqrt%7B+%5Cmathop%7B%5Cmathbb+E%7D+%28F%28t_1%29+-+F%28t_2%29%29%5E2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d(t_1,t_2 ) := \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2))^2} "/></p>
<p> If <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> is a centered Gaussian process then one can prove that the above distance function is a semi-metric on <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>.</p>
<p>
We will not need this fact, but if <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> is a centered Gaussian process and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is finite, then there is an embedding <img alt="{h: T \rightarrow {\mathbb R}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%3A+T+%5Crightarrow+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h: T \rightarrow {\mathbb R}^n}"/>, for some <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, such that the process can be equivalently defined as picking <img alt="{g\sim N({\bf 0} , I)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%5Csim+N%28%7B%5Cbf+0%7D+%2C+I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g\sim N({\bf 0} , I)}"/> and setting <img alt="{F(t) := \langle h(t), g \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t%29+%3A%3D+%5Clangle+h%28t%29%2C+g+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t) := \langle h(t), g \rangle}"/>, so that <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> is also an isometric embedding of the above distance function into <img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>.</p>
<p>
The arguments of the previous section apply to centered Gaussian processes without change, and so we have.</p>
<blockquote><p><b>Theorem 2</b> <em> Let <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> be an arbitrary set, and <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> be a centered Gaussian process. Let <img alt="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_0+%5Csubseteq+T_1+%5Csubseteq+%5Ccdots+T_k+%5Csubseteq+%5Ccdots+%5Csubseteq+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}"/> be a countable sequence of finite subsets of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> such that <img alt="{|T_0| = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CT_0%7C+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|T_0| = 1}"/> and <img alt="{|T_k| \leq 2^{2^k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CT_k%7C+%5Cleq+2%5E%7B2%5Ek%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|T_k| \leq 2^{2^k}}"/>. Then </em></p><em>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} F(t) \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} d (t , \pi_k(t)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+F%28t%29+%5Cleq+O%281%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+2%5E%7Bk%2F2%7D+d+%28t+%2C+%5Cpi_k%28t%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} F(t) \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} d (t , \pi_k(t)) "/></p>
</em><p><em> where <img alt="{d(\cdot,\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28%5Ccdot%2C%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(\cdot,\cdot)}"/> is the distance function <img alt="{d(t_1 , t_2) = \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2))^2 }}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28t_1+%2C+t_2%29+%3D+%5Csqrt%7B+%5Cmathop%7B%5Cmathbb+E%7D+%28F%28t_1%29+-+F%28t_2%29%29%5E2+%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(t_1 , t_2) = \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2))^2 }}"/>and <img alt="{\pi_k(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_k%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi_k(t)}"/> is the element of <img alt="{T_{k-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bk-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{k-1}}"/> closest to <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> according to <img alt="{d(\cdot,\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28%5Ccdot%2C%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(\cdot,\cdot)}"/>. </em></p></blockquote>
<p>
</p><p><b>3. Sub-Gaussian Random Processes </b></p>
<p/><p>
This theory does not seem to apply to problems such as bounding the max cut of a <img alt="{G_{n,p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG_%7Bn%2Cp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G_{n,p}}"/> unweighted graph, or bounding the largest eigenvalue of a random symmetric matrix with <img alt="{\pm 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pm 1}"/> entries, because such problems have a finite sample space and so cannot be modeled as Gaussian processes.</p>
<p>
Fortunately, there is a notion of a <em>sub-Gaussian</em> process, which applies to such problems and which reduces their analysis to the analysis of a related Gaussian process. </p>
<p>
First, recall that a centered real-valued random variable <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is <em>sub-Gaussian</em> if there is a centered Gaussian random variable whose tail dominates the tail of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, that is, if we have two constants <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> such that, for all <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>:</p>
<p/><p align="center"><img alt="\displaystyle  \Pr [ X \geq t ] \leq k \cdot e^{-t^2 /v } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPr+%5B+X+%5Cgeq+t+%5D+%5Cleq+k+%5Ccdot+e%5E%7B-t%5E2+%2Fv+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \Pr [ X \geq t ] \leq k \cdot e^{-t^2 /v } "/></p>
<p>
An equivalent condition is that there is a <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> such that</p>
<p/><p align="center"><img alt="\displaystyle  \mathop{\mathbb E} e^{X^2 / v} = O(1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7BX%5E2+%2F+v%7D+%3D+O%281%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} e^{X^2 / v} = O(1) "/></p>
<p>
In that case, we can define a norm, called the <img alt="{\Psi_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPsi_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Psi_2}"/> norm as</p>
<p/><p align="center"><img alt="\displaystyle  || X ||_{\Psi_2} := \inf \{ \sigma : \mathop{\mathbb E} e^{X^2 / \sigma^2} \leq 2 \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+X+%7C%7C_%7B%5CPsi_2%7D+%3A%3D+%5Cinf+%5C%7B+%5Csigma+%3A+%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7BX%5E2+%2F+%5Csigma%5E2%7D+%5Cleq+2+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  || X ||_{\Psi_2} := \inf \{ \sigma : \mathop{\mathbb E} e^{X^2 / \sigma^2} \leq 2 \} "/></p>
<p>
which is, roughly, the standard deviation of a centered Gaussian that dominates <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>.</p>
<blockquote><p><b>Example 1</b> <em> All bounded random variables are sub-Gaussian. </em></p></blockquote>
<p>
</p><blockquote><p><b>Example 2</b> <em> If </em></p><em>
<p align="center"><img alt="\displaystyle  X = \sum_i X_i " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%3D+%5Csum_i+X_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  X = \sum_i X_i "/></p>
</em><p><em> where the <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> are independent Rademacher random variables, that is, if each <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> is equally likely to be +1 or -1, then <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is sub-Gaussian with <img alt="{|| X||_{\Psi_2} = O(\sqrt n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+X%7C%7C_%7B%5CPsi_2%7D+%3D+O%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|| X||_{\Psi_2} = O(\sqrt n)}"/>, which is within a constant factor of its actual standard deviation. </em></p></blockquote>
<p>
</p><blockquote><p><b>Example 3</b> <em> If </em></p><em>
<p align="center"><img alt="\displaystyle  X = \sum_i X_i " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%3D+%5Csum_i+X_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  X = \sum_i X_i "/></p>
</em><p><em> where the <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> are independent and each <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> has probability <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> of being equal to <img alt="{1-p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1-p}"/> and probability <img alt="{1-p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1-p}"/> of being equal to <img alt="{-p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-p}"/> (that is, each <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> is a centered Bernoulli random variable), then <img alt="{|| X||_{\Psi_2} = \Omega \left( \sqrt {\frac {n} {\log 1/p } } \right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+X%7C%7C_%7B%5CPsi_2%7D+%3D+%5COmega+%5Cleft%28+%5Csqrt+%7B%5Cfrac+%7Bn%7D+%7B%5Clog+1%2Fp+%7D+%7D+%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|| X||_{\Psi_2} = \Omega \left( \sqrt {\frac {n} {\log 1/p } } \right)}"/>, which is much more than the standard deviation of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> when <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is small. </em></p></blockquote>
<p>
</p><blockquote><p><b>Example 4</b> <em> If </em></p><em>
<p align="center"><img alt="\displaystyle  X = \sum_i a_i X_i " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%3D+%5Csum_i+a_i+X_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  X = \sum_i a_i X_i "/></p>
</em><p><em> where the <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> are independent Rademacher random variables, and the <img alt="{a_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_i}"/> are arbitrary real scalars, then <img alt="{|| X ||_{\Psi_2} = O(\sqrt {\sum_i a_i^2 })}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+X+%7C%7C_%7B%5CPsi_2%7D+%3D+O%28%5Csqrt+%7B%5Csum_i+a_i%5E2+%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|| X ||_{\Psi_2} = O(\sqrt {\sum_i a_i^2 })}"/>, which is within a constant factor of the standard deviation that we would get by replacing each <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> with a standard Gaussian. </em></p></blockquote>
<p/><p>
Let now <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> be a centered random process. We will say that a Gaussian process <img alt="{\{ \hat F(t) \}_{t\in T} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+%5Chat+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ \hat F(t) \}_{t\in T} }"/> <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/>-dominates <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> if, for every <img alt="{t_1,t_2 \in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt_1%2Ct_2+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t_1,t_2 \in T}"/> we have</p>
<p/><p align="center"><img alt="\displaystyle  || F(t_1) - F(t_2) ||_{\Psi_2} \leq K \cdot \sqrt{\mathop{\mathbb E} \left (\hat F(t_1) - \hat F(t_2) \right)^2 }" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+F%28t_1%29+-+F%28t_2%29+%7C%7C_%7B%5CPsi_2%7D+%5Cleq+K+%5Ccdot+%5Csqrt%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft+%28%5Chat+F%28t_1%29+-+%5Chat+F%28t_2%29+%5Cright%29%5E2+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  || F(t_1) - F(t_2) ||_{\Psi_2} \leq K \cdot \sqrt{\mathop{\mathbb E} \left (\hat F(t_1) - \hat F(t_2) \right)^2 }"/></p>
<p>
That is, every random variable of the form <img alt="{F(t_1) - F(t_2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t_1%29+-+F%28t_2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t_1) - F(t_2)}"/> is sub-Gaussian, and its tail is dominated by the tail of the Gaussian distribution <img alt="{\hat F(t_1) - \hat F(t_2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%28t_1%29+-+%5Chat+F%28t_2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\hat F(t_1) - \hat F(t_2)}"/></p>
<blockquote><p><b>Theorem 3 (Talagrand’s comparison inequality)</b> <em> There is an absolute constant <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> such that if <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> is a centered random process that is <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/>-dominated by a centered Gaussian random process <img alt="{\{ \hat F(t) \}_{t\in T} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+%5Chat+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ \hat F(t) \}_{t\in T} }"/>, then </em></p><em>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \ F(t) \leq CK \mathop{\mathbb E} \sup_{t\in T} \hat F(t) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5C+F%28t%29+%5Cleq+CK+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Chat+F%28t%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \ F(t) \leq CK \mathop{\mathbb E} \sup_{t\in T} \hat F(t) "/></p>
<p> Furthermore, for every <img alt="{\ell \geq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell \geq 0}"/>, </p>
<p align="center"><img alt="\displaystyle  \Pr \left[ \sup_{t_1,t_2 \in T} F(t_1) - F(t_2) \geq CK \ \left( \ell \cdot diam(T) + \mathop{\mathbb E} \sup_{t\in T} \hat F(t) \right) \right] \leq 2 e^{-\ell^2} \ , " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPr+%5Cleft%5B+%5Csup_%7Bt_1%2Ct_2+%5Cin+T%7D+F%28t_1%29+-+F%28t_2%29+%5Cgeq+CK+%5C+%5Cleft%28+%5Cell+%5Ccdot+diam%28T%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Chat+F%28t%29+%5Cright%29+%5Cright%5D+%5Cleq+2+e%5E%7B-%5Cell%5E2%7D+%5C+%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \Pr \left[ \sup_{t_1,t_2 \in T} F(t_1) - F(t_2) \geq CK \ \left( \ell \cdot diam(T) + \mathop{\mathbb E} \sup_{t\in T} \hat F(t) \right) \right] \leq 2 e^{-\ell^2} \ , "/></p>
</em><p><em> where <img alt="{diam(T)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bdiam%28T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{diam(T)}"/> is the diameter of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> with respect to the distance function <img alt="{d(s,t) := \sqrt{\mathop{\mathbb E} \left (\hat F(s) - \hat F(t) \right)^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28s%2Ct%29+%3A%3D+%5Csqrt%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft+%28%5Chat+F%28s%29+-+%5Chat+F%28t%29+%5Cright%29%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(s,t) := \sqrt{\mathop{\mathbb E} \left (\hat F(s) - \hat F(t) \right)^2}}"/>. </em></p></blockquote>
<p/><p>
The way to apply this theory is the following. </p>
<p>
Suppose that we want estimate, on average or with high probability, the optimum of an optimization problem with feasible set <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> over the randomness of the choice of a random instance. We model this problem like a centered random process <img alt="{\{ F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ F(t) \}_{t\in T}}"/> in which <img alt="{F(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(t)}"/> is the difference between the cost of solution <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> in a random instance minus the average cost of <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>.</p>
<p>
Then we think about a related random experiment, in which the random choices involved in constructing our instance are replaced by Gaussian choices (for example, instead of a <img alt="{G_{n,1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG_%7Bn%2C1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G_{n,1/2}}"/> random graph we may think of a complete graph with Gaussian weights on the edges chosen with expectation 1/2 and constant variance) and we let <img alt="{\{ \hat F(t) \}_{t\in T}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+%5Chat+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ \hat F(t) \}_{t\in T}}"/> be the analogous process in this Gaussian model.</p>
<p>
If we can argue that <img alt="{\hat F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\hat F}"/> dominates <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/>, then it remains to estimate <img alt="{\mathop{\mathbb E} \sup \hat F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E} \sup \hat F}"/>, which we can do either by the generic chaining theorem or by other methods.</p>
<p>
</p><p><b>4. An Example </b></p>
<p/><p>
We will now use this machinery to show that the largest eigenvalue of a random symmetric <img alt="{n\times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n\times n}"/> matrix with Rademacher entries is <img alt="{O(\sqrt n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt n)}"/>. This is certainly not the simplest way of proving such a result, but it will give a sense of how these techniques can be applied.</p>
<p>
We let <img alt="{T = \{ x\in {\mathbb R}^n : ||x ||=1 \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5C%7B+x%5Cin+%7B%5Cmathbb+R%7D%5En+%3A+%7C%7Cx+%7C%7C%3D1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \{ x\in {\mathbb R}^n : ||x ||=1 \}}"/> be the unit sphere. </p>
<p>
Our Gaussian process will be to pick standard Gaussians <img alt="{g_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_{i,j}}"/>, for each <img alt="{1 \leq i \leq j \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+i+%5Cleq+j+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \leq i \leq j \leq n}"/>, define the matrix <img alt="{ \hat M_{i,j} = \hat M_{j,i} = g_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Chat+M_%7Bi%2Cj%7D+%3D+%5Chat+M_%7Bj%2Ci%7D+%3D+g_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ \hat M_{i,j} = \hat M_{j,i} = g_{i,j}}"/> and let</p>
<p/><p align="center"><img alt="\displaystyle  \hat F(x) = x^T \hat M x " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+F%28x%29+%3D+x%5ET+%5Chat+M+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \hat F(x) = x^T \hat M x "/></p>
<p> for every <img alt="{x\in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in T}"/>.</p>
<p>
Our “sub-Gaussian” random process is to pick Rademacher random variables <img alt="{r_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_{i,j}}"/>, for each <img alt="{1 \leq i \leq j \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+i+%5Cleq+j+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \leq i \leq j \leq n}"/>, define the matrix <img alt="{ M_{i,j} = M_{j,i} = r_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+M_%7Bi%2Cj%7D+%3D+M_%7Bj%2Ci%7D+%3D+r_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ M_{i,j} = M_{j,i} = r_{i,j}}"/> and let</p>
<p/><p align="center"><img alt="\displaystyle  F(x) = x^T M x " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28x%29+%3D+x%5ET+M+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F(x) = x^T M x "/></p>
<p> for every <img alt="{x\in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in T}"/>.</p>
<p>
We will argue that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is <img alt="{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(1)}"/>-dominated by <img alt="{\hat F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\hat F}"/> and that <img alt="{\mathop{\mathbb E} \sup \hat F = O(\sqrt n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+%5Chat+F+%3D+O%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E} \sup \hat F = O(\sqrt n)}"/>.</p>
<p>
For the first claim, we see that for every <img alt="{x,y \in T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y \in T}"/>, we can write <img alt="{F(x)-F(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28x%29-F%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(x)-F(y)}"/> as</p>
<p/><p align="center"><img alt="\displaystyle  F(x) - F(y) = \sum_{i,j} M_{i,j} (x_ix_j - y_iy_j) = 2 \sum_{i&lt;j} r_{i,j} (x_ix_j - y_iy_j) + \sum_i r_{i,i} (x_i^2 - y_i^2) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28x%29+-+F%28y%29+%3D+%5Csum_%7Bi%2Cj%7D+M_%7Bi%2Cj%7D+%28x_ix_j+-+y_iy_j%29+%3D+2+%5Csum_%7Bi%3Cj%7D+r_%7Bi%2Cj%7D+%28x_ix_j+-+y_iy_j%29+%2B+%5Csum_i+r_%7Bi%2Ci%7D+%28x_i%5E2+-+y_i%5E2%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F(x) - F(y) = \sum_{i,j} M_{i,j} (x_ix_j - y_iy_j) = 2 \sum_{i&lt;j} r_{i,j} (x_ix_j - y_iy_j) + \sum_i r_{i,i} (x_i^2 - y_i^2) "/></p>
<p>
So, as noted in one of our examples above, we can say that </p>
<p align="center"><img alt="\displaystyle  || F(x) - F(y) ||^2_{\Psi_2} \leq O \left( 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+F%28x%29+-+F%28y%29+%7C%7C%5E2_%7B%5CPsi_2%7D+%5Cleq+O+%5Cleft%28+4+%5Csum_%7Bi%3Cj%7D+%28x_ix_j+-+y_iy_j%29+%5E2+%2B+%5Csum_i+%28x_i%5E2+-+y_i%5E2%29%5E2+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  || F(x) - F(y) ||^2_{\Psi_2} \leq O \left( 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 \right) "/></p>
<p> and we see that </p>
<p align="center"><img alt="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} ( \hat F(x) - \hat F(y) )^2 = 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28d%28x%2Cy%29%29%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D+%28+%5Chat+F%28x%29+-+%5Chat+F%28y%29+%29%5E2+%3D+4+%5Csum_%7Bi%3Cj%7D+%28x_ix_j+-+y_iy_j%29+%5E2+%2B+%5Csum_i+%28x_i%5E2+-+y_i%5E2%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} ( \hat F(x) - \hat F(y) )^2 = 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 "/></p>
<p> so that, indeed, <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is <img alt="{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(1)}"/>-dominated by <img alt="{\hat F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\hat F}"/>.</p>
<p>
Now we need to apply generic chaining to <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/>. It is very helpful to note that the distance function defined on <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> by the Gaussian process is dominated by Euclidean distance between the vectors <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>, because</p>
<p/><p align="center"><img alt="\displaystyle  (d(x,y))^2 \leq 2 || xx^T - yy^T ||^2_F \leq 2 \cdot (||x|| + ||y||)^2 \cdot ||x-y||^2 = 8 ||x-y||^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28d%28x%2Cy%29%29%5E2+%5Cleq+2+%7C%7C+xx%5ET+-+yy%5ET+%7C%7C%5E2_F+%5Cleq+2+%5Ccdot+%28%7C%7Cx%7C%7C+%2B+%7C%7Cy%7C%7C%29%5E2+%5Ccdot+%7C%7Cx-y%7C%7C%5E2+%3D+8+%7C%7Cx-y%7C%7C%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (d(x,y))^2 \leq 2 || xx^T - yy^T ||^2_F \leq 2 \cdot (||x|| + ||y||)^2 \cdot ||x-y||^2 = 8 ||x-y||^2 "/></p>
<p> where we used the inequality </p>
<p align="center"><img alt="\displaystyle  || xx^T - yy^T ||_F \leq ( ||x || + ||y||) \cdot ||x-y|| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+xx%5ET+-+yy%5ET+%7C%7C_F+%5Cleq+%28+%7C%7Cx+%7C%7C+%2B+%7C%7Cy%7C%7C%29+%5Ccdot+%7C%7Cx-y%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  || xx^T - yy^T ||_F \leq ( ||x || + ||y||) \cdot ||x-y|| "/></p>
<p>
We can conclude that an <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>-net over the unit Euclidean sphere is also a <img alt="{\sqrt {8}\cdot \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+%7B8%7D%5Ccdot+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt {8}\cdot \epsilon}"/>-net for the metric space <img alt="{(T,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28T%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(T,d)}"/>. For the unit Euclidean sphere there is an <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>-net of size at most <img alt="{(3/\epsilon)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2F%5Cepsilon%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3/\epsilon)^n}"/>. To apply generic chaining, let <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> be an arbitrary subset of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of cardinality <img alt="{2^{2^k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2%5Ek%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{2^k}}"/> if <img alt="{2^k &lt; n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Ek+%3C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^k &lt; n}"/>, and an <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>-net with <img alt="{\epsilon = 3\cdot 2^{-2^k / n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+3%5Ccdot+2%5E%7B-2%5Ek+%2F+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon = 3\cdot 2^{-2^k / n}}"/> otherwise. Applying the generic chaining inequality,</p>
<p/><p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \sup \ \hat F \leq O(1) \cdot \sum_k 2^{k/2} \cdot \sqrt{8} \cdot \min \left\{ 2, 3\cdot 2^{-2^k / n} \right\} = O(\sqrt n) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+%5C+%5Chat+F+%5Cleq+O%281%29+%5Ccdot+%5Csum_k+2%5E%7Bk%2F2%7D+%5Ccdot+%5Csqrt%7B8%7D+%5Ccdot+%5Cmin+%5Cleft%5C%7B+2%2C+3%5Ccdot+2%5E%7B-2%5Ek+%2F+n%7D+%5Cright%5C%7D+%3D+O%28%5Csqrt+n%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathop{\mathbb E} \sup \ \hat F \leq O(1) \cdot \sum_k 2^{k/2} \cdot \sqrt{8} \cdot \min \left\{ 2, 3\cdot 2^{-2^k / n} \right\} = O(\sqrt n) "/></p>
<p/></div>
    </content>
    <updated>2020-05-03T17:19:38Z</updated>
    <published>2020-05-03T17:19:38Z</published>
    <category term="math"/>
    <category term="theory"/>
    <category term="generic chaining"/>
    <category term="Talagrand"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-05-08T05:20:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/067</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/067" rel="alternate" type="text/html"/>
    <title>TR20-067 |  Computational and proof complexity of partial string avoidability | 

	Dmitry Itsykson, 

	Alexander Okhotin, 

	Vsevolod Oparin</title>
    <summary>The partial string avoidability problem is stated as follows: given a finite set of strings with possible ``holes'' (wildcard symbols), determine whether there exists a two-sided infinite string containing no substrings from this set, assuming that a hole matches every symbol. The problem is known to be NP-hard and in PSPACE, and this paper establishes its PSPACE-completeness. Next, string avoidability over the binary alphabet is interpreted as a version of conjunctive normal form satisfiability problem (SAT), where each clause has infinitely many shifted variants. Non-satisfiability of these formulas can be proved using variants of classical propositional proof systems, augmented with derivation rules for shifting proof lines
(such as clauses, inequalities, polynomials, etc). First, it is proved that there is a particular formula that has a short refutation in Resolution with a shift rule, but requires classical proofs of exponential size At the same time, it is shown that exponential lower bounds for classical proof systems can be translated for their shifted versions. Finally, it is shown that superpolynomial lower bounds on the size of shifted proofs would separate NP from PSPACE; a connection to lower bounds on circuit complexity is also established.</summary>
    <updated>2020-05-03T11:07:00Z</updated>
    <published>2020-05-03T11:07:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/066</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/066" rel="alternate" type="text/html"/>
    <title>TR20-066 |  Quantum Implications of Huang&amp;#39;s Sensitivity Theorem | 

	Scott Aaronson, 

	Shalev Ben-David, 

	Robin Kothari, 

	Avishay Tal</title>
    <summary>Based on the recent breakthrough of Huang (2019), we show that for any total Boolean function $f$, the deterministic query complexity, $D(f)$, is at most quartic in the quantum query complexity, $Q(f)$: $D(f) = O(Q(f)^4)$. This matches the known separation (up to log factors) due to Ambainis, Balodis, Belovs, Lee, Santha, and Smotrovs (2017). We also use the result to resolve the quantum analogue of the Aanderaa-Karp-Rosenberg conjecture. We show that if $f$ is a nontrivial monotone graph property of an $n$-vertex graph specified by its adjacency matrix, then $Q(f) = \Omega(n)$, which is also optimal.</summary>
    <updated>2020-05-03T11:01:55Z</updated>
    <published>2020-05-03T11:01:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-08T05:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5494</id>
    <link href="https://adamsheffer.wordpress.com/2020/05/03/math-summer-programs/" rel="alternate" type="text/html"/>
    <title>Math Summer Programs</title>
    <summary>The virus is causing some math summer programs to cancel. Surprisingly, this led to something wonderful. Unusually strong undergrads are starting to run their own online summer math programs for high school students. 1. The MORPH program is run by the Harvard math club. It offers a variety of mathematical topics at different levels of […]</summary>
    <updated>2020-05-03T01:11:48Z</updated>
    <published>2020-05-03T01:11:48Z</published>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2020-05-08T05:21:15Z</updated>
    </source>
  </entry>
</feed>
