<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-08-31T23:45:52Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>https://differentialprivacy.org/icml2020/</id>
    <link href="https://differentialprivacy.org/icml2020/" rel="alternate" type="text/html"/>
    <title>Conference Digest - ICML 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://icml.cc/virtual/2020">ICML 2020</a> is one of the premiere venues in machine learning, and generally features a lot of great work in differentially private machine learning.
This year is no exception: the relevant papers are listed below to the best of our ability, including links to the full versions of papers, as well as the conference pages (which contain slides and 15 minute videos for each paper).
As always, please inform us if we overlooked any papers on differential privacy.</p>

<h2 id="papers">Papers</h2>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/1909.12732">Alleviating Privacy Attacks via Causal Learning</a> (<a href="https://icml.cc/virtual/2020/poster/6346">page</a>)<br/>
<a href="https://www.microsoft.com/en-us/research/people/shtople/">Shruti Tople</a>, <a href="http://www.amitsharma.in/">Amit Sharma</a>, <a href="https://www.microsoft.com/en-us/research/people/adityan/">Aditya Nori</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1805.10341">An end-to-end Differentially Private Latent Dirichlet Allocation Using a Spectral Algorithm</a> (<a href="https://icml.cc/virtual/2020/poster/6240">page</a>)<br/>
<a href="https://github.com/dpeng817">Chris DeCarolis</a>, <a href="https://twitter.com/exsidius">Mukul Ram</a>, <a href="https://www.cs.umd.edu/people/sesmaeil">Seyed Esmaeili</a>, <a href="https://sites.cs.ucsb.edu/~yuxiangw/">Yu-Xiang Wang</a>, <a href="http://furong-huang.com/">Furong Huang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1901.09697">Bayesian Differential Privacy for Machine Learning</a> (<a href="https://icml.cc/virtual/2020/poster/6547">page</a>)<br/>
<a href="https://scholar.google.com/citations?user=BCWx7iQAAAAJ">Aleksei Triastcyn</a>, <a href="https://people.epfl.ch/boi.faltings">Boi Faltings</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.03030">Certified Data Removal from Machine Learning Models</a> (<a href="https://icml.cc/virtual/2020/poster/5895">page</a>)<br/>
<a href="https://sites.google.com/view/chuanguo">Chuan Guo</a>, <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a>, <a href="https://awnihannun.com/">Awni Hannun</a>, <a href="https://lvdmaaten.github.io/">Laurens van der Maaten</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.00038">Context Aware Local Differential Privacy</a> (<a href="https://icml.cc/virtual/2020/poster/5775">page</a>)<br/>
<a href="https://people.ece.cornell.edu/acharya/">Jayadev Acharya</a>, <a href="https://research.google/people/105175/">Kallista Bonawitz</a>, <a href="https://kairouzp.github.io/">Peter Kairouz</a>, <a href="https://research.google/people/106777/">Daniel Ramage</a>, <a href="http://www.zitengsun.com/">Ziteng Sun</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1905.12813">Data-Dependent Differentially Private Parameter Learning for Directed Graphical Models</a> (<a href="https://icml.cc/virtual/2020/poster/6262">page</a>)<br/>
<a href="https://scholar.google.com/citations?user=lWWAZ4YAAAAJ">Amrita Roy Chowdhury</a>, <a href="http://pages.cs.wisc.edu/~thodrek/">Theodoros Rekatsinas</a>, <a href="http://pages.cs.wisc.edu/~jha/">Somesh Jha</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.09745">Differentially Private Set Union</a> (<a href="https://icml.cc/virtual/2020/poster/6541">page</a>)<br/>
<a href="https://www.microsoft.com/en-us/research/people/sigopi/">Sivakanth Gopi</a>, <a href="https://www.linkedin.com/in/pankajgulhane/">Pankaj Gulhane</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan Kulkarni</a>, <a href="https://heyyjudes.github.io/">Judy Hanwen Shen</a>, <a href="https://www.microsoft.com/en-us/research/people/milads/">Milad Shokouhi</a>, <a href="http://www.yekhanin.org/">Sergey Yekhanin</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.11651">Fair Learning with Private Demographic Data</a> (<a href="https://icml.cc/virtual/2020/poster/6499">page</a>)<br/>
<a href="https://husseinmozannar.github.io/">Hussein Mozannar</a>, <a href="https://sites.google.com/site/mesrob/home/">Mesrob Ohannessian</a>, <a href="https://ttic.uchicago.edu/~nati/">Nathan Srebro</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.15744">Fast and Private Submodular and $k$-Submodular Functions Maximization with Matroid Constraint</a> (<a href="https://icml.cc/virtual/2020/poster/6365">page</a>)<br/>
<a href="https://dblp.org/pid/166/1694.html">Akbar Rafiey</a>, <a href="http://research.nii.ac.jp/~yyoshida/">Yuichi Yoshida</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2006.00706">(Locally) Differentially Private Combinatorial Semi-Bandits</a> (<a href="https://icml.cc/virtual/2020/poster/6315">page</a>)<br/>
<a href="https://scholar.google.com/citations?user=sioumZAAAAAJ">Xiaoyu Chen</a>, <a href="https://scholar.google.com/citations?user=Bw-WdyUAAAAJ">Kai Zheng</a>, <a href="https://twitter.com/zixinjackzhou">Zixin Zhou</a>, <a href="https://scholar.google.com/citations?user=m8m9nD0AAAAJ">Yunchang Yang</a>, <a href="https://www.microsoft.com/en-us/research/people/weic/">Wei Chan</a>, <a href="http://www.liweiwang-pku.com/">Liwei Wang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.05453">New Oracle-Efficient Algorithms for Private Synthetic Data Release</a> (<a href="https://icml.cc/virtual/2020/poster/5814">page</a>)<br/>
<a href="https://sites.google.com/umn.edu/giuseppe-vietri/home">Giuseppe Vietri</a>, <a href="https://scholar.google.com/citations?user=dDVIyEQAAAAJ">Grace Tian</a>, <a href="https://cs-people.bu.edu/mbun/">Mark Bun</a>, <a href="http://www.thomas-steinke.net/">Thomas Steinke</a>, <a href="https://zstevenwu.com/">Zhiwei Steven Wu</a></p>
  </li>
  <li>
    <p><a href="https://proceedings.icml.cc/static/paper_files/icml/2020/1190-Paper.pdf">On Differentially Private Stochastic Convex Optimization with Heavy-tailed Data</a> (<a href="https://icml.cc/virtual/2020/poster/5948">page</a>)<br/>
<a href="http://www.acsu.buffalo.edu/~dwang45/">Di Wang</a>, <a href="https://scholar.google.com/citations?user=e3ZhEDEAAAAJ">Hanshen Xiao</a>, <a href="https://people.csail.mit.edu/devadas/">Srinivas Devadas</a>, <a href="https://cse.buffalo.edu/~jinhui/">Jinhui Xu</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.13830">Optimal Differential Privacy Composition for Exponential Mechanisms</a> (<a href="https://icml.cc/virtual/2020/poster/6687">page</a>)<br/>
<a href="https://www.math.upenn.edu/~jinshuo/">Jinshuo Dong</a>, <a href="https://dblp.org/pid/155/9794.html">David Durfee</a>, <a href="https://scholar.google.com/citations?user=jr7gGB4AAAAJ">Ryan Rogers</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.01783">Oracle Efficient Private Non-Convex Optimization</a> (<a href="https://icml.cc/virtual/2020/poster/5815">page</a>)<br/>
<a href="https://sethneel.com/">Seth Neel</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, <a href="https://sites.google.com/umn.edu/giuseppe-vietri/home">Giuseppe Vietri</a>, <a href="https://zstevenwu.com/">Zhiwei Steven Wu</a></p>
  </li>
  <li>
    <p><a href="https://proceedings.icml.cc/static/paper_files/icml/2020/2341-Paper.pdf">Private Counting from Anonymous Messages: Near-Optimal Accuracy with Vanishing Communication Overhead</a> (<a href="https://icml.cc/virtual/2020/poster/6134">page</a>)<br/>
<a href="https://sites.google.com/view/badihghazi/home">Badih Ghazi</a>, <a href="https://sites.google.com/site/ravik53/">Ravi Kumar</a>, <a href="https://pasin30055.github.io/">Pasin Manurangsi</a>, <a href="https://www.itu.dk/people/pagh/">Rasmus Pagh</a></p>
  </li>
  <li>
    <p><a href="https://proceedings.icml.cc/static/paper_files/icml/2020/6298-Paper.pdf">Private Outsourced Bayesian Optimization</a> (<a href="https://icml.cc/virtual/2020/poster/6783">page</a>)<br/>
<a href="https://scholar.google.com/citations?user=7_2XTQ8AAAAJ">Dmitrii Kharkovskii</a>, <a href="https://daizhongxiang.github.io/">Zhongxiang Dai</a>, <a href="https://www.comp.nus.edu.sg/~lowkh/research.html">Bryan Kian Hsiang Low</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2004.10941">Private Query Release Assisted by Public Data</a> (<a href="https://icml.cc/virtual/2020/poster/6329">page</a>)<br/>
<a href="https://sites.google.com/view/rbassily">Raef Bassily</a>, <a href="https://www.ccs.neu.edu/home/albertcheu/">Albert Cheu</a>, <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, <a href="http://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a>, <a href="https://zstevenwu.com/">Zhiwei Steven Wu</a></p>
  </li>
  <li>
    <p><a href="https://proceedings.icml.cc/static/paper_files/icml/2020/2453-Paper.pdf">Private Reinforcement Learning with PAC and Regret Guarantees</a> (<a href="https://icml.cc/virtual/2020/poster/6152">page</a>)<br/>
<a href="https://sites.google.com/umn.edu/giuseppe-vietri/home">Giuseppe Vietri</a>, <a href="https://borjaballe.github.io/">Borja Balle</a>, <a href="https://people.cs.umass.edu/~akshay/">Akshay Krishnamurthy</a>, <a href="https://zstevenwu.com/">Zhiwei Steven Wu</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1910.01327">Privately Detecting Changes in Unknown Distributions</a> (<a href="https://icml.cc/virtual/2020/poster/5854">page</a>)<br/>
<a href="https://sites.gatech.edu/rachel-cummings/">Rachel Cummings</a>, <a href="https://sites.google.com/view/skrehbiel/home">Sara Krehbiel</a>, <a href="https://scholar.google.com/citations?user=ayasb_wAAAAJ">Yuliia Lut</a>, <a href="https://wanrongz.github.io/">Wanrong Zhang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.09463">Privately Learning Markov Random Fields</a> (<a href="https://icml.cc/virtual/2020/poster/5776">page</a>)<br/>
<a href="https://huanyuzhang.github.io/">Huanyu Zhang</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan Kulkarni</a>, <a href="https://zstevenwu.com/">Zhiwei Steven Wu</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1903.09822">Scalable Differential Privacy with Certified Robustness in Adversarial Learning</a> (<a href="https://icml.cc/virtual/2020/poster/6401">page</a>)<br/>
<a href="https://sites.google.com/site/ihaiphan/">NhatHai Phan</a>, <a href="https://www.cise.ufl.edu/~mythai/">My T. Thai</a>, <a href="https://scholar.google.com/citations?user=OgXtPDIAAAAJ">Han Hu</a>, <a href="http://www.cs.kent.edu/~jin/">Ruoming Jin</a>, <a href="https://research.adobe.com/person/tong-sun/">Tong Sun</a>, <a href="https://ix.cs.uoregon.edu/~dou/">Dejing Dou</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2003.04493">Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth Expansion</a> (<a href="https://icml.cc/virtual/2020/poster/6734">page</a>)<br/>
<a href="https://enosair.github.io/">Qinqing Zheng</a>, <a href="https://www.math.upenn.edu/~jinshuo/">Jinshuo Dong</a>, <a href="https://www.med.upenn.edu/apps/faculty/index.php/g275/p8939931">Qi Long</a>, <a href="http://www-stat.wharton.upenn.edu/~suw/">Weijie J. Su</a></p>
  </li>
</ul></div>
    </summary>
    <updated>2020-08-31T18:00:00Z</updated>
    <published>2020-08-31T18:00:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-08-31T23:45:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17496</id>
    <link href="https://rjlipton.wordpress.com/2020/08/31/mea-culpa/" rel="alternate" type="text/html"/>
    <title>Mea Culpa</title>
    <summary>Plus more on the separating word problem Mea Culpa is not someone we introduced on the blog before. She does not come from the same world as Lofa Polir or Neil L. As in the French movie poster at right, the meaning is “my fault.” Today we apologize for some oversights and hasty omissions regarding […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Plus more on the separating word problem</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2020/08/31/mea-culpa/mea/" rel="attachment wp-att-17499"><img alt="" class="alignright wp-image-17499" height="147" src="https://rjlipton.files.wordpress.com/2020/08/mea.jpg?w=110&amp;h=147" width="110"/></a></p>
<p>
Mea Culpa is not someone we introduced on the blog before. She does not come from the same world as Lofa Polir or Neil L. As in the French <a href="https://en.wikipedia.org/wiki/Mea_Culpa_(film)">movie</a> poster at right, the meaning is “my fault.”</p>
<p/><p>
Today we apologize for some oversights and hasty omissions regarding the last <a href="https://rjlipton.wordpress.com/2020/08/29/20000-comments-and-more/">post</a>. Then we will explain Dick’s “laws with errors”.</p>
<p>
Let’s be clear. The paper we discussed in the last post claiming an order <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> upper bound is wrong. The best upper bound is still due to Zachary Chase and is order <img alt="{n^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{1/3}}"/>, with some log’s. </p>
<p>
At GLL we try to be fair and upbeat, especially with proof attempts. We know how hard it is to put yourself out there when you claim a new result. Whether for a famous open problem or not, it is always difficult. Mistakes are possible, miss understandings are possible. </p>
<p>
But perhaps this time we have gone too far, and for that we apologize. We just love the SWP, and want to reiterate the idea the post was supposed to be (only) about, an approach to SWP. </p>
<p>
There is also Nostra Culpa—“our fault,” Ken says too.  Not only is there a short <a href="https://www.imdb.com/title/tt8513100/">film</a> with that title, there is a 2013 one-singer <a href="https://www.youtube.com/watch?v=t2paj1mrCQI">opera</a> of that title with libretto drawn from a 2012 Twitter <a href="https://news.err.ee/106193/nostra-culpa-an-interview-with-the-writers-of-a-financial-opera">feud</a> between the economist Paul Krugman and the president of Estonia. At least our issue did not break out on Twitter. We were instead contacted privately by some friends who knew more about the erroneous paper highlighted in our post. We could have contacted them first—that was our omission.</p>
<p>
Again sorry for any confusion we created. Let’s turn to the approach we want to share about SWP.</p>
<p>
</p><p/><h2> Laws with Errors </h2><p/>
<p/><p>
I think there is hope that positive laws must be large, especially if we extend what it mean by a law. Consider a positive law 	</p>
<p align="center"><img alt="\displaystyle  U = V, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++U+%3D+V%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  U = V, "/></p>
<p>where <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> are words over the letters <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>. Recall we can tell if <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> are different provided there is a finite group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> so that for some <img alt="{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B}"/> in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> the value of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> are different. This can be computed by a FSA with at most order <img alt="{|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|G|}"/> states. So the smaller <img alt="{|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|G|}"/> is the better. </p>
<p>
The trouble is it does not seem to the case that strong enough lower bounds are known for positive laws. This suggest that we make it harder for a law to work. </p>
<p>
The idea is to use a FST, that is a finite state transducer. This is a finite state device that reads a symbol, updates its state, and outputs one or more symbols. If <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is the FST and <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> is a string, let <img alt="{T(U)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%28U%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T(U)}"/> be the result of applying <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>. For example, suppose that <img alt="{ABBBAB}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BABBBAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ABBBAB}"/> is an input <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/>. Let the transducer add a <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> after each <img alt="{AB}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AB}"/>. Thus <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> maps to: 	</p>
<p align="center"><img alt="\displaystyle  ABCBBABC. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++ABCBBABC.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  ABCBBABC. "/></p>
<p>	 Then the following is true: </p>
<blockquote><p><b>Lemma 1</b> <em> Let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> be group and let <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> be a transducer with <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> states. Then we can separate <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> from <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{V}"/> by a FSA with order <img alt="{|G| \cdot S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CG%7C+%5Ccdot+S%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{|G| \cdot S}"/> states provided 	</em></p><em>
<p align="center"><img alt="\displaystyle  T(U) = T(V) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++T%28U%29+%3D+T%28V%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  T(U) = T(V) "/></p>
</em><p><em>is not a law in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The key is to simulate <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> as we read the input, and at the same time update the group element. This can be done by a FSA with the product <img alt="{|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|G|}"/> and <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> states. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The hope is that having a law that is invariant for all FST, even only those with few states, is difficult. </p>
<blockquote><p><b> </b> <em> <b>A conjecture</b>: Positive laws that can handle all FST transducers with <img alt="{n^{\epsilon}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B%5Cepsilon%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n^{\epsilon}}"/> states must be large. </em>
</p></blockquote>
<p>That is are large enough to advance our best bounds on SWP. What do you think?</p>
<p/></font></font></div>
    </content>
    <updated>2020-08-31T13:41:04Z</updated>
    <published>2020-08-31T13:41:04Z</published>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="claims"/>
    <category term="mistake"/>
    <category term="open problem"/>
    <category term="separate words"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-31T23:44:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=99</id>
    <link href="https://nisheethvishnoi.wordpress.com/2020/08/31/algorithms-for-convex-optimization-book/" rel="alternate" type="text/html"/>
    <title>Algorithms for Convex Optimization Book</title>
    <summary>I am excited to announce that a pre-publication draft of my book Algorithms for Convex Optimization (to be published by Cambridge University Press) is now available for download here: Algorithms for Convex Optimization Book The goal of this book is to enable a reader to gain an in-depth understanding of algorithms for convex optimization. The emphasis is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am excited to announce that a pre-publication draft of my book <strong>Algorithms for Convex Optimization</strong> (to be published by Cambridge University Press) is now available for download here:</p>
<p><a href="https://convex-optimization.github.io/">Algorithms for Convex Optimization Book</a></p>
<p>The goal of this book is to enable a reader to gain an in-depth understanding of algorithms for convex optimization. The emphasis is to derive key algorithms for convex optimization from first principles and to establish precise running time bounds in terms of the input length.</p>
<p>The intended audience includes advanced undergraduate students, graduate students and researches from theoretical computer science, discrete optimization, and machine learning.</p>
<div class="page" title="Page 8">
<div class="layoutArea">
<div class="column">
<p>The book has four parts:</p>
</div>
</div>
</div>
<ol>
<li class="p1">Chapters 3,4, and 5: Introduction to convexity, models of computation and notions of efficiency in convex optimization, Lagrangian duality, Legendre-Fenchel duality, and KKT conditions.</li>
<li class="p1">Chapters 6,7, and 8: First-order methods such as gradient descent, mirror descent and the multiplicative weights update method, and accelerated gradient descent.</li>
<li class="p1">Chapters 9,10, and 11: Newton’s method, path-following interior point methods for linear programming, and self-concordant barrier functions.</li>
<li class="p1">Chapter 11 and 12: Cutting plane methods such as the ellipsoid method for linear and general convex programs.</li>
</ol>
<p class="p1">Chapter 1 summarizes the book via a brief history of the interplay between continuous and discrete optimization: how the search for fast algorithms for discrete problems is leading to improvements in algorithms for convex optimization.</p>
<p class="p1">Many chapters contain applications ranging from finding maximum flows, minimum cuts, and perfect matchings in graphs, to linear optimization over 0-1-polytopes, to submodular function minimization, to computing maximum entropy distributions over combinatorial polytopes.</p>
<p class="p1">The book is self-contained and starts with a review of calculus, linear algebra, geometry, dynamical systems, and graph theory in Chapter 2. Exercises posed in this book not only play an important role in checking one’s understanding, but sometimes important methods and concepts are introduced and developed entirely through them. Examples include the Frank-Wolfe method, coordinate descent, stochastic gradient descent, online convex optimization, the min-max theorem for zero-sum games, the Winnow algorithm for classification, the conjugate gradient method, primal-dual interior point method, and matrix scaling.</p>
<p>Feedback, corrections, and comments are welcome.</p></div>
    </content>
    <updated>2020-08-31T13:30:40Z</updated>
    <published>2020-08-31T13:30:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2020-08-31T23:45:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/31/postdoc-at-epfl-apply-by-september-13-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/31/postdoc-at-epfl-apply-by-september-13-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at EPFL (apply by September 13, 2020)</title>
    <summary>Applications are solicited for postdoctoral positions in all aspects of Theoretical Computer Science at EPFL. Each position will be for a period of up to two years and comes with a competitive salary and generous travel support. Website: https://theory.epfl.ch/postdoc.html Email: tcs-postdoc@groupes.epfl.ch</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are solicited for postdoctoral positions in all aspects of Theoretical Computer Science at EPFL. Each position will be for a period of up to two years and comes with a competitive salary and generous travel support.</p>
<p>Website: <a href="https://theory.epfl.ch/postdoc.html">https://theory.epfl.ch/postdoc.html</a><br/>
Email: tcs-postdoc@groupes.epfl.ch</p></div>
    </content>
    <updated>2020-08-31T08:29:08Z</updated>
    <published>2020-08-31T08:29:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-31T23:44:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.12776</id>
    <link href="http://arxiv.org/abs/2008.12776" rel="alternate" type="text/html"/>
    <title>Efficiently Solving MDPs with Stochastic Mirror Descent</title>
    <feedworld_mtime>1598832000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yujia.html">Yujia Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.12776">PDF</a><br/><b>Abstract: </b>We present a unified framework based on primal-dual stochastic mirror descent
for approximately solving infinite-horizon Markov decision processes (MDPs)
given a generative model. When applied to an average-reward MDP with $A_{tot}$
total state-action pairs and mixing time bound $t_{mix}$ our method computes an
$\epsilon$-optimal policy with an expected $\widetilde{O}(t_{mix}^2 A_{tot}
\epsilon^{-2})$ samples from the state-transition matrix, removing the
ergodicity dependence of prior art. When applied to a $\gamma$-discounted MDP
with $A_{tot}$ total state-action pairs our method computes an
$\epsilon$-optimal policy with an expected $\widetilde{O}((1-\gamma)^{-4}
A_{tot} \epsilon^{-2})$ samples, matching the previous state-of-the-art up to a
$(1-\gamma)^{-1}$ factor. Both methods are model-free, update state values and
policies simultaneously, and run in time linear in the number of samples taken.
We achieve these results through a more general stochastic mirror descent
framework for solving bilinear saddle-point problems with simplex and box
domains and we demonstrate the flexibility of this framework by providing
further applications to constrained MDPs.
</p></div>
    </summary>
    <updated>2020-08-31T23:42:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.12727</id>
    <link href="http://arxiv.org/abs/2008.12727" rel="alternate" type="text/html"/>
    <title>Recoverable Robust Representatives Selection Problems with Discrete Budgeted Uncertainty</title>
    <feedworld_mtime>1598832000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goerigk:Marc.html">Marc Goerigk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lendl:Stefan.html">Stefan Lendl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wulf:Lasse.html">Lasse Wulf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.12727">PDF</a><br/><b>Abstract: </b>Recoverable robust optimization is a multi-stage approach, where it is
possible to adjust a first-stage solution after the uncertain cost scenario is
revealed. We analyze this approach for a class of selection problems. The aim
is to choose a fixed number of items from several disjoint sets, such that the
worst-case costs after taking a recovery action are as small as possible. The
uncertainty is modeled as a discrete budgeted set, where the adversary can
increase the costs of a fixed number of items. While special cases of this
problem have been studied before, its complexity has remained open. In this
work we make several contributions towards closing this gap. We show that the
problem is NP-hard and identify a special case that remains solvable in
polynomial time. We provide a compact mixed-integer programming formulation and
two additional extended formulations. Finally, computational results are
provided that compare the efficiency of different exact solution approaches.
</p></div>
    </summary>
    <updated>2020-08-31T23:20:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-08-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.12626</id>
    <link href="http://arxiv.org/abs/2008.12626" rel="alternate" type="text/html"/>
    <title>Algorithmic Persuasion with Evidence</title>
    <feedworld_mtime>1598832000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoefer:Martin.html">Martin Hoefer</a>, Pasin Manirangsi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Psomas:Alexandros.html">Alexandros Psomas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.12626">PDF</a><br/><b>Abstract: </b>We consider a game of persuasion with evidence between a sender and a
receiver. The sender has private information. By presenting evidence on the
information, the sender wishes to persuade the receiver to take a single action
(e.g., hire a job candidate, or convict a defendant). The sender's utility
depends solely on whether or not the receiver takes the action. The receiver's
utility depends on both the action as well as the sender's private information.
We study three natural variations. First, we consider sequential equilibria of
the game without commitment power. Second, we consider a persuasion variant,
where the sender commits to a signaling scheme and then the receiver, after
seeing the evidence, takes the action or not. Third, we study a delegation
variant, where the receiver first commits to taking the action if being
presented certain evidence, and then the sender presents evidence to maximize
the probability the action is taken. We study these variants through the
computational lens, and give hardness results, optimal approximation
algorithms, as well as polynomial-time algorithms for special cases. Among our
results is an approximation algorithm that rounds a semidefinite program that
might be of independent interest, since, to the best of our knowledge, it is
the first such approximation algorithm for a natural problem in algorithmic
economics.
</p></div>
    </summary>
    <updated>2020-08-31T23:41:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.12567</id>
    <link href="http://arxiv.org/abs/2008.12567" rel="alternate" type="text/html"/>
    <title>A Topological Similarity Measure between Multi-Field Data using Multi-Resolution Reeb Spaces</title>
    <feedworld_mtime>1598832000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Tripti.html">Tripti Agarwal</a>, Yashwanth Ramamurthi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chattopadhyay:Amit.html">Amit Chattopadhyay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.12567">PDF</a><br/><b>Abstract: </b>Searching topological similarity between a pair of shapes or data is an
important problem in data analysis and visualization. The problem of computing
similarity measures using scalar topology has been studied extensively and
proven useful in shape and data matching. Even though multi-field (or
multivariate) topology-based techniques reveal richer topological features,
research on computing similarity measures using multi-field topology is still
in its infancy. In the current paper, we propose a novel similarity measure
between two piecewise-linear multi-fields based on their multi-resolution Reeb
spaces - a newly developed data-structure that captures the topology of a
multi-field. Overall, our method consists of two steps: (i) building a
multi-resolution Reeb space corresponding to each of the multi-fields and (ii)
proposing a similarity measure for a list of matching pairs (of nodes),
obtained by comparing the multi-resolution Reeb spaces. We demonstrate an
application of the proposed similarity measure by detecting the nuclear
scission point in a time-varying multi-field data from computational physics.
</p></div>
    </summary>
    <updated>2020-08-31T23:43:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.12516</id>
    <link href="http://arxiv.org/abs/2008.12516" rel="alternate" type="text/html"/>
    <title>Work-Efficient Parallel Algorithms for Predicate Detection</title>
    <feedworld_mtime>1598832000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Rohan Garg <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.12516">PDF</a><br/><b>Abstract: </b>Recently, the predicate detection problem was shown to be in the parallel
complexity class NC. In this paper, we give some more work efficient parallel
algorithms to solve the predicate detection problem on a distributed
computation with $n$ processes and at most $m$ states per process. The previous
best known parallel predicate detection algorithm, ParallelCut, had work
complexity $O(m^3n^3\log mn)$. We give two algorithms, a deterministic
algorithm with work complexity $O(m^2n^2)$ and a randomized algorithm with work
complexity $\tilde{O}(m^2n^2)$. Furthermore, our algorithms have a space
complexity of $O(mn^2)$ whereas ParallelCut had a space complexity of
$O(m^2n^2)$.
</p></div>
    </summary>
    <updated>2020-08-31T23:42:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.12388</id>
    <link href="http://arxiv.org/abs/2008.12388" rel="alternate" type="text/html"/>
    <title>Differentially Private Clustering via Maximum Coverage</title>
    <feedworld_mtime>1598832000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jones:Matthew.html">Matthew Jones</a>, Huy Lê Nguyen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Thy.html">Thy Nguyen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.12388">PDF</a><br/><b>Abstract: </b>This paper studies the problem of clustering in metric spaces while
preserving the privacy of individual data. Specifically, we examine
differentially private variants of the k-medians and Euclidean k-means
problems. We present polynomial algorithms with constant multiplicative error
and lower additive error than the previous state-of-the-art for each problem.
Additionally, our algorithms use a clustering algorithm without differential
privacy as a black-box. This allows practitioners to control the trade-off
between runtime and approximation factor by choosing a suitable clustering
algorithm to use.
</p></div>
    </summary>
    <updated>2020-08-31T23:42:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.12386</id>
    <link href="http://arxiv.org/abs/2008.12386" rel="alternate" type="text/html"/>
    <title>Polynomial-time trace reconstruction in the smoothed complexity model</title>
    <feedworld_mtime>1598832000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xi.html">Xi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/De:Anindya.html">Anindya De</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Chin_Ho.html">Chin Ho Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Servedio:Rocco_A=.html">Rocco A. Servedio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinha:Sandip.html">Sandip Sinha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.12386">PDF</a><br/><b>Abstract: </b>In the \emph{trace reconstruction problem}, an unknown source string $x \in
\{0,1\}^n$ is sent through a probabilistic \emph{deletion channel} which
independently deletes each bit with probability $\delta$ and concatenates the
surviving bits, yielding a \emph{trace} of $x$. The problem is to reconstruct
$x$ given independent traces. This problem has received much attention in
recent years both in the worst-case setting where $x$ may be an arbitrary
string in $\{0,1\}^n$ \cite{DOS17,NazarovPeres17,HHP18,HL18,Chase19} and in the
average-case setting where $x$ is drawn uniformly at random from $\{0,1\}^n$
\cite{PeresZhai17,HPP18,HL18,Chase19}.
</p>
<p>This paper studies trace reconstruction in the \emph{smoothed analysis}
setting, in which a ``worst-case'' string $x^{\worst}$ is chosen arbitrarily
from $\{0,1\}^n$, and then a perturbed version $\bx$ of $x^{\worst}$ is formed
by independently replacing each coordinate by a uniform random bit with
probability $\sigma$. The problem is to reconstruct $\bx$ given independent
traces from it.
</p>
<p>Our main result is an algorithm which, for any constant perturbation rate
$0&lt;\sigma &lt; 1$ and any constant deletion rate $0 &lt; \delta &lt; 1$, uses $\poly(n)$
running time and traces and succeeds with high probability in reconstructing
the string $\bx$. This stands in contrast with the worst-case version of the
problem, for which $\text{exp}(O(n^{1/3}))$ is the best known time and sample
complexity \cite{DOS17,NazarovPeres17}.
</p>
<p>Our approach is based on reconstructing $\bx$ from the multiset of its short
subwords and is quite different from previous algorithms for either the
worst-case or average-case versions of the problem. The heart of our work is a
new $\poly(n)$-time procedure for reconstructing the multiset of all $O(\log
n)$-length subwords of any source string $x\in \{0,1\}^n$ given access to
traces of $x$.
</p></div>
    </summary>
    <updated>2020-08-31T23:20:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4942</id>
    <link href="https://www.scottaaronson.com/blog/?p=4942" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4942#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4942" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My new motto</title>
    <summary xml:lang="en-US">The Right could only kill me and everyone I know.The Left is scarier; it could convince me that it was my fault! (In case you missed it on the blog’s revised header, right below “Quantum computers aren’t just nondeterministic Turing machines” and “Hold the November US election by mail.” I added an exclamation point at […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>The Right could only kill me and everyone I know.<br/>The Left is scarier; it could convince me that it was my fault</strong>!</p>



<p>(In case you missed it on the blog’s revised header, right below “Quantum computers aren’t just nondeterministic Turing machines” and “Hold the November US election by mail.”  I added an exclamation point at the end to suggest a <em>slightly</em> comic delivery.)</p></div>
    </content>
    <updated>2020-08-30T23:21:02Z</updated>
    <published>2020-08-30T23:21:02Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Embarrassing Myself"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Self-Referential"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-08-31T11:24:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/08/30/linkage</id>
    <link href="https://11011110.github.io/blog/2020/08/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>The evolution of mathematical word processing (\(\mathbb{M}\)). “Developments in computing over the last 30 years have not done as much as one might have thought to make writing mathematics easier.”</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://sinews.siam.org/Details-Page/the-evolution-of-mathematical-word-processing">The evolution of mathematical word processing</a> (<a href="https://mathstodon.xyz/@11011110/104701998974894412">\(\mathbb{M}\)</a>). “Developments in computing over the last 30 years have not done as much as one might have thought to make writing mathematics easier.”</p>
  </li>
  <li>
    <p><a href="https://prideout.net/blog/svg_wireframes/">3D Wireframes in SVG, via Python</a> (<a href="https://mathstodon.xyz/@11011110/104707509485635530">\(\mathbb{M}\)</a>, <a href="https://github.com/prideout/svg3d">code repository</a>). Once you generate the model, it does the rest. Its depth-ordering heuristics aren’t perfect (and will fail when the depth order is cyclic), but generally work pretty well. For example, here’s <a href="https://en.wikipedia.org/wiki/Jessen%27s_icosahedron">Jessen’s icosahedron</a> in a simple partially-transparent style without fancy shading (<a href="https://11011110.github.io/blog/assets/2020/jessen.py">Python code</a>). To get it to look right I had to edit the resulting svg and manually reorder the faces.</p>

    <p style="text-align: center;"><img alt="Jessen's icosahedron" src="https://11011110.github.io/blog/assets/2020/jessen.svg"/></p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/news/2020/08/17/ip-grab-youngstown-state">Intellectual property grab at Youngstown State</a> (<a href="https://mathstodon.xyz/@11011110/104714502717608284">\(\mathbb{M}\)</a>). In negotiations with the faculty union, the university wants to replace the tradition of faculty holding copyright to research articles, textbooks, syllabi and lectures, etc by instead taking ownership of “all nonpatentable faculty work” as work-for-hire. They claim that they aren’t changing their policies and are merely doing this “to be consistent with the law” but this comes across as unlikely and disingenuous.</p>
  </li>
  <li>
    <p><a href="https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/15700/Lost%20Mathematics.pdf?fterence=1">Lectures on lost mathematics</a> (<a href="https://mathstodon.xyz/@11011110/104718951109084030">\(\mathbb{M}\)</a>). In this 79-page pdf from 1975, Branko Grünbaum discusses mathematical questions studied by non-mathematicians but snubbed by pure mathematicians, including which polygons tile, the girth of infinitely-repeating cubic spatial graphs, the classification of vertex-transitive polyhedral manifolds in space, generalization of Kempe universality to surfaces, flexible polyhedra, and tensegrity.</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2348/">A recent xkcd on river crossing puzzles</a> particularly amused me (<a href="https://mathstodon.xyz/@11011110/104726172352360084">\(\mathbb{M}\)</a>).</p>

    <p style="text-align: center;"><img alt="xkcd comic &quot;Boat Puzzle&quot;, https://xkcd.com/2348/" src="https://11011110.github.io/blog/assets/2020/xkcd-2348.png" width="80%"/></p>

    <p>It’s too bad xkcd uses an -NC clause in its CC license; if it didn’t, we could use it or its first frame to replace <a href="https://en.wikipedia.org/wiki/River_crossing_puzzle">the Wikipedia article’s illustration</a>, which is undergoing a long slow <a href="https://commons.wikimedia.org/wiki/Commons:Deletion_requests/File:Vovk_koza_kapusta.png">deletion discussion because copied from a 1954 Soviet book</a>. If you know something useful about the copyright status of 1954 Soviet books, please add your knowledge to that discussion.</p>
  </li>
  <li>
    <p><a href="https://www.flyingcoloursmaths.co.uk/eye-to-eye/">Eye to eye</a> (<a href="https://mathstodon.xyz/@11011110/104731872882549290">\(\mathbb{M}\)</a>). Let \(C\) and \(C'\) be circles with centers outside the other circle, and draw tangent rays from each center to the other circle. These rays cut their circles in chords of equal length. But I wonder: when only one circle has its center outside the other, its chord is still well defined, but the same length can’t be a chord of the other circle because it exceeds the diameter. But it should still have a geometric meaning with respect to the other circle: what is it?</p>
  </li>
  <li>
    <p><a href="https://petapixel.com/2020/08/20/lightroom-app-update-wipes-users-photos-and-presets-adobe-says-they-are-not-recoverable/">Lightroom App update irrecoverably loses users’ photos</a> (<a href="https://mathstodon.xyz/@11011110/104742916488291004">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24229864">via</a>). My choice to continue using an oldish powerbook with dubiously-reliable keyboard, to avoid giving up my paid-for non-subscription Adobe apps which won’t run on newer Macs, has an unexpected benefit: my files haven’t been auto-deleted. Also, let this be a reminder to do your backups, and make sure that they include a local non-cloud backup of your files.</p>
  </li>
  <li>
    <p><a href="https://github.andrewt.net/mines/">Minesweeper where forced guesses are always safe, but unforced guesses always explode</a> (<a href="https://mastodon.technology/@andrewt/104701318997810776">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://www.reddit.com/r/Scotland/comments/ig9jia/ive_discovered_that_almost_every_single_article/">“The Scots language version of Wikipedia is legendarily bad” — turns out because it was mostly written by an American teenager</a> (<a href="https://mathstodon.xyz/@11011110/104751072546716749">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/188374/The-problem-is-that-this-person-cannot-speak-Scots">via</a>). See <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2020-08-30/News_and_notes">the <em>Signpost</em> article</a> for an update.</p>
  </li>
  <li>
    <p>Today’s mini-episode of “not the Reuleaux triangle” (<a href="https://mathstodon.xyz/@11011110/104757581337870450">\(\mathbb{M}\)</a>): the logo of Polish football club Ruch Chorzów, which a supporter tried to add to the Wikipedia article. Unlike many non-Reuleaux round triangles, it appears to use circular arcs, but not centered at the corners and with non-equilateral corners. The arc across the bottom is longer than the two sides, and it is wider than it is tall. Image from <a href="http://kubamalicki.com/portfolio_page/ruch-chorzow-100-years-anniversary/">an article on a recent redesign of the official logo</a>.</p>

    <p style="text-align: center;"><img alt="Geometric analysis of the Ruch Chorz&#xF3;w logo showing that it is not a Reuleaux triangle" src="https://11011110.github.io/blog/assets/2020/ruch-logo.png" width="80%"/></p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@jsiehler/104763100825420197">J. Siehler asks for unsolved problems in mathematics whose statements are understandable by elementary school students, other than in number theory </a>. Examples given so far include <a href="https://en.wikipedia.org/wiki/Inscribed_square_problem">square pegs</a>, <a href="https://en.wikipedia.org/wiki/Bellman%27s_lost_in_a_forest_problem">lost in a forest</a>, <a href="https://en.wikipedia.org/wiki/Moving_sofa_problem">sofa-moving</a>, <a href="https://en.wikipedia.org/wiki/Moser%27s_worm_problem">Moser’s worm</a>, <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)#Existence_and_uniqueness">Dürer’s nets</a>, the <a href="https://en.wikipedia.org/wiki/Tur%C3%A1n%27s_brick_factory_problem">brick factory</a>, and <a href="https://en.wikipedia.org/wiki/Lonely_runner_conjecture">lonely runners</a>.</p>
  </li>
  <li>
    <p><a href="https://www.rayawolfsun.com/2015/02/06/the-romance-of-al-asturlabiya/">Concerning “Mariam” Al-Asturlabiya</a> (<a href="https://mathstodon.xyz/@11011110/104771298687510642">\(\mathbb{M}\)</a>). A warning about how romanticizing past figures (in this case <a href="https://en.wikipedia.org/wiki/Mariam_al-Asturlabi">the only woman astrolabist known from the medieval Islamic world</a>) can result in creating biographical details for them out of thin air.</p>
  </li>
  <li>
    <p><a href="https://prideout.net/knotgl/">Interactive 3d knot table</a> (<a href="https://mathstodon.xyz/@11011110/104779316951663485">\(\mathbb{M}\)</a>). One of many interesting visualizations on “<a href="https://prideout.net/">the little grasshopper</a>”, by Philip Rideout (author of the svg3d Python library linked above).</p>
  </li>
  <li>
    <p><a href="https://gd2020.cs.ubc.ca/program-no-links/">The Graph Drawing 2020 program is online</a> (<a href="https://mathstodon.xyz/@11011110/104781215682863021">\(\mathbb{M}\)</a>). It is September 16-18, from 8AM to noon Pacific daylight time (the time in Vancouver, where the conference was originally to be held). The format has talk videos available pre-conference, with sessions consisting of 1-minute reminders of each talk and 5 minutes of live questions per talk. Jeff Erickson and Sheelagh Carpendale will give live invited talks. It’s free but requires registration, with deadline September 10.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-08-30T17:47:00Z</updated>
    <published>2020-08-30T17:47:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-31T01:37:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17466</id>
    <link href="https://rjlipton.wordpress.com/2020/08/29/20000-comments-and-more/" rel="alternate" type="text/html"/>
    <title>20,000 Comments and More</title>
    <summary>With more about the Separating Words Problem I.I.T. Madras page Anoop S K M is a PhD student in the theory group of I.I.T. Madras in Chennai, India. His comment two weeks ago Monday was the 20,000th reader comment (including trackbacks) on this blog. Today we thank Anoop and all our readers and say more […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>With more about the Separating Words Problem</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/08/anoopskm-1.jpg"><img alt="" class="alignright size-thumbnail wp-image-17474" height="150" src="https://rjlipton.files.wordpress.com/2020/08/anoopskm-1.jpg?w=128&amp;h=150" width="128"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">I.I.T. Madras <a href="http://www.cse.iitm.ac.in/~theory/memberdetails.php?memberid=512">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Anoop S K M is a PhD student in the theory group of I.I.T. Madras in Chennai, India. His <a href="https://rjlipton.wordpress.com/2020/08/03/cleverer-automata-exist/#comment-111947">comment</a> two weeks ago Monday was the <font color="green"><b>20,000</b></font>th reader comment (including trackbacks) on this blog.</p>
<p>
Today we thank Anoop and all our readers and say more about the subject of his comment.</p>
<p>
Anoop’s advisor is Jayalal Sarma, who has a further connection to me (Ken). Sarma has <a href="https://arxiv.org/abs/1002.1496">co-authored</a> <a href="https://link.springer.com/article/10.1007/s00224-013-9519-3">three</a> <a href="https://arxiv.org/abs/0912.2565">papers</a> with my PhD graduate Maurice Jansen, whose work we have <a href="https://rjlipton.wordpress.com/2011/04/20/could-euler-have-solved-this/">also</a> featured <a href="https://rjlipton.wordpress.com/2011/04/28/succinct-constant-depth-arithmetic-circuits-are-weak/">here</a>. </p>
<p>
The comment was Anoop’s first and thus far only one on the blog. In passing we note that after one’s first comment is moderated through, subsequent ones appear freely and immediately. Thus one can say that Anoop had only a 0.005% chance of hitting the milestone. </p>
<p>
Dick and I would also like to give a warm shout out to someone else who in another sense had almost a 56% chance of hitting it: Jon Awbrey, who writes the blog <a href="https://inquiryintoinquiry.com/">Inquiry Into Inquiry</a> and also <a href="https://ncatlab.org/nlab/show/Jon+Awbrey">contributes</a> to the <a href="https://ncatlab.org/nlab/show/About">nLab</a> Project.</p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/08/jon_awbrey.jpg"><img alt="" class="alignright size-thumbnail wp-image-17470" src="https://rjlipton.files.wordpress.com/2020/08/jon_awbrey.jpg?w=128&amp;h=150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2"><a href="https://www.researchgate.net/profile/Jon_Awbrey">src</a><br/>
</font>
</td>
</tr>
</tbody></table>
<p>As we were twenty-seven comments into our third myriad at the time of drafting this post, we note that most of his 15-of-27 comments are trackback citations of our previous <a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/">post</a> on proof complexity, but he wrote <a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/#comment-112175">two</a> long <a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/#comment-112189">comments</a> as well. We have not had time to act on them; for my part, chess cheating has found ways to mutate into new kinds of cases even as I see hope for stemming the main online outbreak of it. But comments can also be resources for others, especially students who may be emboldened to take a swing at progress from where we’ve left off.</p>
<p>
</p><p/><h2> Anoop’s Comment and SWP Ideas </h2><p/>
<p/><p>
Anoop’s comment was in our recent <a href="https://rjlipton.wordpress.com/2020/08/03/cleverer-automata-exist/">post</a> on the Separating Word Problem (SWP). He asked about a technical <a href="http://invenio.nusl.cz/record/251413/files/content.csg.pdf">report</a> by Jiří Wiedermann claiming a clean best-possible <img alt="{O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\log n)}"/> bound on the SWP over alphabet <img alt="{\{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}}"/>. </p>
<p>
Wiedermann’s idea is simple to state—maybe too simple: Consider finite state automata (FSAs) <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> whose <img alt="{2m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2m}"/> states form two <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>-cycle “tracks”: </p>
<p align="center"><img alt="\displaystyle  q_0 \rightarrow q_1 \rightarrow \cdots \rightarrow q_{m-1} \rightarrow q_0; \qquad q'_0 \rightarrow q'_1 \rightarrow \cdots \rightarrow q'_{m-1} \rightarrow q'_0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q_0+%5Crightarrow+q_1+%5Crightarrow+%5Ccdots+%5Crightarrow+q_%7Bm-1%7D+%5Crightarrow+q_0%3B+%5Cqquad+q%27_0+%5Crightarrow+q%27_1+%5Crightarrow+%5Ccdots+%5Crightarrow+q%27_%7Bm-1%7D+%5Crightarrow+q%27_0+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q_0 \rightarrow q_1 \rightarrow \cdots \rightarrow q_{m-1} \rightarrow q_0; \qquad q'_0 \rightarrow q'_1 \rightarrow \cdots \rightarrow q'_{m-1} \rightarrow q'_0 "/></p>
<p>Each edge goes to the next state on the same track on both <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> <em>unless</em> we place a “crossover” so that the edges switch tracks on <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The primed track has accepting states. It does not matter whether the start state is <img alt="{q_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_0}"/> or <img alt="{q'_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%27_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q'_0}"/>, but it is the same for any pair of strings <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> of length <img alt="{n \gg m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgg+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \gg m}"/> that we wish to distinguish.</p>
<p>
Let <img alt="{S \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \subseteq [n]}"/> be the set of places where <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> differ. Now suppose we have <img alt="{b \in [m]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%5Cin+%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b \in [m]}"/> such that the intersection of <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> with the residue class <img alt="{R_{m,b} = \{am + b : a \in \mathbb{N}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR_%7Bm%2Cb%7D+%3D+%5C%7Bam+%2B+b+%3A+a+%5Cin+%5Cmathbb%7BN%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R_{m,b} = \{am + b : a \in \mathbb{N}\}}"/> is odd. Make <img alt="{A = A_{m,b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%3D+A_%7Bm%2Cb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A = A_{m,b}}"/> by placing one “crossover” at point <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> on the tracks; that is, make the transitions for <img alt="{q_b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_b}"/> and <img alt="{q'_b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%27_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q'_b}"/> be </p>
<p align="center"><img alt="\displaystyle  (q_b,0,q_{b+1}),~(q_b,1,q'_{b+1}),~(q'_b,0,q'_{b+1}),~(q'_b,1,q_{b+1}), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28q_b%2C0%2Cq_%7Bb%2B1%7D%29%2C%7E%28q_b%2C1%2Cq%27_%7Bb%2B1%7D%29%2C%7E%28q%27_b%2C0%2Cq%27_%7Bb%2B1%7D%29%2C%7E%28q%27_b%2C1%2Cq_%7Bb%2B1%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (q_b,0,q_{b+1}),~(q_b,1,q'_{b+1}),~(q'_b,0,q'_{b+1}),~(q'_b,1,q_{b+1}), "/></p>
<p>where the addition is modulo <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>. Then whenever a place where <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> differ enters the crossover, the strings flip their status of being on the same track or different tracks. Since this happens an odd number of times, <img alt="{A_{m,b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bm%2Cb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{m,b}}"/> accepts <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and rejects <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> or vice-versa.</p>
<p>
If for every <img alt="{S \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \subseteq [n]}"/> we could find such <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> with <img alt="{m = O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+O%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = O(\log n)}"/> then SWP would fall with the best possible logarithmic size, nullifying anything like Zachary Chase’s improvement from <img alt="{m = \tilde{O}(n^{2/5})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+%5Ctilde%7BO%7D%28n%5E%7B2%2F5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = \tilde{O}(n^{2/5})}"/> to <img alt="{m = \tilde{O}(n^{1/3})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = \tilde{O}(n^{1/3})}"/>. The “<img alt="{m = O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+O%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = O(\log n)}"/>” is not hiding any <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> factors with a tilde—it is just a bare <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> factor. The report claims this complete resolution, but it makes and then unmakes a point in a way we don’t follow. The point is that the idea of focusing on subsets <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> is not only independent of particular strings <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> but also independent of the lengths <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> of the string, except insofar as the maximum index in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> constrains the smallest <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> that works. But then the report states a theorem that invests <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> itself with significance that contradicts said point, so it just appears wrong.</p>
<p>
The report anyway does not appear either on Wiedermann’s publications page or his DBLP page. Its conclusion references a 2015 <a href="https://rjlipton.wordpress.com/2015/09/03/open-problems-that-might-be-easy/">post</a> on this blog in which SWP was included, but we had not heard of this until Anoop’s comment. So it goes in our mistake file. We have been grappling all week with the subject of claims and mistakes on a much larger scale with complicated papers and techniques. In the old days, ideas and errors would be threshed out in-person at conferences and workshops and only the finished product would be visible to those outside the loop. Now we not only have Internet connectivity but also the pandemic has curtailed the “in-person” aspect. Thus we are not averse to promoting the threshing and wonder how best to extract the useful novelty from new attempts that likely have errors.</p>
<p>
The <img alt="{A_{m,b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bm%2Cb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{m,b}}"/> construction is neat but has a weakness that can be framed as motivation for Dick’s idea in the rest of this post.  Adding more crossovers for a fixed <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> does not help separate any more strings: If <img alt="{S \cap R_{m,b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Ccap+R_%7Bm%2Cb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \cap R_{m,b}}"/> and <img alt="{S \cap R_{m,c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Ccap+R_%7Bm%2Cc%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \cap R_{m,c}}"/> both have even cardinality then adding <em>two</em> crossovers at <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> and <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> has no effect.  Intuitively speaking, all crossovers behave merely as the same non-unit element of the two-element group.  In particular, they commute with each other.  The idea moving forward is, can we get more interesting behavior from <em>non</em>-commutative groups that still yield small automata <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> separating given pairs of strings? </p>
<p>
</p><p/><h2> Laws on Finite Groups </h2><p/>
<p/><p>
Let’s start to explain a connection of SWP with finite groups. A <b>law</b> for a group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is 	</p>
<p align="center"><img alt="\displaystyle  U = V, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++U+%3D+V%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  U = V, "/></p>
<p>where <img alt="{U,V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%2CV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U,V}"/> are words over <img alt="{\{ A,B \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+A%2CB+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{ A,B \}}"/>. We will think of <img alt="{U,V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%2CV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U,V}"/> as embeddings within the group of the binary strings <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> we want to separate. The law says that <img alt="{U=V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%3DV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U=V}"/> for all substitutions of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> as elements in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Thus 	</p>
<p align="center"><img alt="\displaystyle  AB = BA " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++AB+%3D+BA+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  AB = BA "/></p>
<p>is a law that holds in abelian groups. Every finite group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> satisfies the law 	</p>
<p align="center"><img alt="\displaystyle  A^{n} = 1, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A%5E%7Bn%7D+%3D+1%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A^{n} = 1, "/></p>
<p>where <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is the size of the group. </p>
<p>
There has been quite a bit of research on laws for groups. </p>
<ul>
<li>
Some are on the complexity of checking if they hold. It is a famous result that with randomness one can check to see if <img alt="{AB=BA}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAB%3DBA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AB=BA}"/> with few tests. <p/>
</li><li>
Some are on the structure of laws. <p/>
</li><li>
Most relevant to SWP is the interest in the smallest size law that holds for all groups of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> or less elements. The size of a law is the maximum of the length of the words <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>.
</li></ul>
<p>
</p><p/><h2> Laws and SWP </h2><p/>
<p/><p>
Suppose that we wish to construct a FSA that can tell <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> from <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/>. We assume that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> and <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> are distinct <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> long strings over <img alt="{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B}"/>. Pick a finite group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. The key is two observations: </p>
<ol>
<li>
If <img alt="{\alpha = \beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3D+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha = \beta}"/> is <b>not</b> a law over <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>, then we can set <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> to elements in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> so that 	<p/>
<p align="center"><img alt="\displaystyle  \alpha \neq \beta. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha+%5Cneq+%5Cbeta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha \neq \beta. "/></p>
</li><li>
There is a FSA that can compute the values of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> and <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> as elements in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> with order <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> states.
</li></ol>
<p>This then proves that we can separate the words <img alt="{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B}"/> with order the size of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> states. </p>
<p>
<i>Warning</i> It is important that the FSA operates on <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> and <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> independently. Moreover, the FSA must run the same computation on these strings—the output must be different. </p>
<p>
I liked this approach since I hoped there would be useful results on laws in groups. There is quite a bit known. It would have been neat if there was a paper that proved: No law of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> holds in all finite groups of size at most <img alt="{n^{1/4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B1%2F4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{1/4}}"/>. Alas this is not true. Well not exactly. Our laws are of the form 	</p>
<p align="center"><img alt="\displaystyle  U = V. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++U+%3D+V.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  U = V. "/></p>
<p>Since there are no inverses allowed in <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> these are called <i>positive laws</i>. If we drop that restriction, then short laws do exist. There are laws of size <img alt="{O(n^{2/3})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B2%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^{2/3})}"/> that hold for all groups of order <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. But I believe it is still open whether positive laws can be small.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/08/f2_cayley_graph.png"><img alt="" class="aligncenter size-full wp-image-17454" src="https://rjlipton.files.wordpress.com/2020/08/f2_cayley_graph.png?w=600"/></a></p>
<p/><h2> Positive Laws </h2><p/>
<p/><p>
I (Dick) started to search the web about laws in groups. I quickly found a <a href="https://arxiv.org/pdf/1609.03199.pdf">paper</a> by Andrei Bulatov, Olga Karpova, Arseny Shur, Konstantin Startsev on exactly this approach, titled “Lower Bounds on Words Separation: Are There Short Identities in Transformation Semigroups?” They study the problem, prove some results, and do some computer searches. They say: </p>
<blockquote><p><b> </b> <em> It is known that the shortest positive identity in the symmetric group on <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{3}"/> objects <img alt="{S_{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_%7B3%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S_{3}}"/> is <img alt="{x^{2}y^{2} = y^{2}x^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7B2%7Dy%5E%7B2%7D+%3D+y%5E%7B2%7Dx%5E%7B2%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x^{2}y^{2} = y^{2}x^{2}}"/>. The shortest such identity in <img alt="{S_{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_%7B4%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S_{4}}"/> has length <img alt="{11}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B11%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{11}"/>: 	</em></p><em>
<p align="center"><img alt="\displaystyle  x^{6}y^{2}xy^{2} = y^{2}xy^{2}x^{6}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7B6%7Dy%5E%7B2%7Dxy%5E%7B2%7D+%3D+y%5E%7B2%7Dxy%5E%7B2%7Dx%5E%7B6%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  x^{6}y^{2}xy^{2} = y^{2}xy^{2}x^{6}. "/></p>
</em><p><em/>
</p></blockquote>
<p>They also note that:</p>
<blockquote><p><b> </b> <em> The problem is to find upper bounds on the function <img alt="{Sep}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BSep%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Sep}"/>. This problem is inverse to finding the asymptotics of the length of the shortest identity in full transformation semigroups <img alt="{T_{k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bk%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T_{k}}"/>. </em>
</p></blockquote>
<p/><p>
I believe the last part of their statement is true, but perhaps misleading. I would argue that laws are related to SWP with a twist. The hope is that this twist is enough to make progress. Let me explain. </p>
<p>
</p><p/><h2> Laws with Errors </h2><p/>
<p/><p>
I think there is hope that positive laws must be large, if we extend what it mean by a law. Suppose that we have a law 	</p>
<p align="center"><img alt="\displaystyle  U_{1} \cdots U_{n} = V_{1} \cdots V_{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++U_%7B1%7D+%5Ccdots+U_%7Bn%7D+%3D+V_%7B1%7D+%5Ccdots+V_%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  U_{1} \cdots U_{n} = V_{1} \cdots V_{n}. "/></p>
<p>Where <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> are as before words over <img alt="{\{A,B\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BA%2CB%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{A,B\}}"/>. Assume that for all small groups this is always true when we set <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> to elements. </p>
<p>
We note however we can have the FSA do more than just substitutions. We could have it modify the <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>. We can have the FSA make some changes to <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>: Of course the FSA must do the same to <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> and <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>, and it must keep the number of states down. </p>
<p>
This means that the law <img alt="{U=V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%3DV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U=V}"/> must be robust to modifications that can be done with few states. As examples, the FSA could: </p>
<ol>
<li>
The FSA could map <img alt="{A^{2} \rightarrow A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%7B2%7D+%5Crightarrow+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^{2} \rightarrow A}"/> and leave all others the same. <p/>
</li><li>
The FSA could map <img alt="{ABBBA}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BABBBA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ABBBA}"/> to <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> when ever it sees this. <p/>
</li><li>
The FSA could delete the even letters. Thus <p/>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}   A^{6}B^{2}AB^{2} &amp;=&amp; B^{2}AB^{2}A^{6} \\  AAAAAA BB A BB &amp;=&amp; BB A BB AAAAAA \\  A~ A~ A~ B~ A ~ B &amp;=&amp; B~ A~ B ~ A~ A~ A \\  AAABA &amp;=&amp; BABAAA. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%09A%5E%7B6%7DB%5E%7B2%7DAB%5E%7B2%7D+%26%3D%26+B%5E%7B2%7DAB%5E%7B2%7DA%5E%7B6%7D+%5C%5C+%09AAAAAA+BB+A+BB+%26%3D%26+BB+A+BB+AAAAAA+%5C%5C+%09A%7E+A%7E+A%7E+B%7E+A+%7E+B+%26%3D%26+B%7E+A%7E+B+%7E+A%7E+A%7E+A+%5C%5C+%09AAABA+%26%3D%26+BABAAA.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}   A^{6}B^{2}AB^{2} &amp;=&amp; B^{2}AB^{2}A^{6} \\  AAAAAA BB A BB &amp;=&amp; BB A BB AAAAAA \\  A~ A~ A~ B~ A ~ B &amp;=&amp; B~ A~ B ~ A~ A~ A \\  AAABA &amp;=&amp; BABAAA. \end{array} "/></p>
</li></ol>
<p>Note the FSA could even add new letters. Thus it could 	</p>
<p align="center"><img alt="\displaystyle  AB \rightarrow ACB, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++AB+%5Crightarrow+ACB%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  AB \rightarrow ACB, "/></p>
<p>where <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is a new letter. Thus 	</p>
<p align="center"><img alt="\displaystyle  AAAAAA BB A BB = BB A BB AAAAAA " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++AAAAAA+BB+A+BB+%3D+BB+A+BB+AAAAAA+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  AAAAAA BB A BB = BB A BB AAAAAA "/></p>
<p>becomes 	</p>
<p align="center"><img alt="\displaystyle  AAAAAA CBB A CBB = BB A C BB AAAAAA. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++AAAAAA+CBB+A+CBB+%3D+BB+A+C+BB+AAAAAA.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  AAAAAA CBB A CBB = BB A C BB AAAAAA. "/></p>
<p>And so on. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can we get better lower bounds on positive laws if we require them to be resilient to such modifications? Ones that can be done by a small state FSA. What do you think?</p>
<p>
Again we thank Anoop and all our readers for stimulating comments.</p>
<p/><p><br/>
[changed wording in section 2 and improved transition to the rest]</p></font></font></div>
    </content>
    <updated>2020-08-29T21:54:23Z</updated>
    <published>2020-08-29T21:54:23Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Anoop SKM"/>
    <category term="blog milestone"/>
    <category term="comments"/>
    <category term="finite automata"/>
    <category term="groups"/>
    <category term="readers"/>
    <category term="separating words problem"/>
    <category term="SWP"/>
    <category term="thanks"/>
    <category term="upper bounds"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-31T23:44:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/28/full-time-position-at-universidad-catolica-de-chile-apply-by-october-7-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/28/full-time-position-at-universidad-catolica-de-chile-apply-by-october-7-2020/" rel="alternate" type="text/html"/>
    <title>Full-time Position at Universidad Católica de Chile (apply by October 7, 2020)</title>
    <summary>Universidad Católica de Chile (UC) is offering one or more full-time positions at the assistant (tenure-track) or associate level. We invite applications from highly qualified candidates in Data Science, Machine Learning, Optimization, Statistics and Stochastics, although other areas from Computational Science and Engineering, Optimization and Applied Mathematics will also be considered. Website: http://imc.uc.cl/index.php/noticias/183-open-position-at-the-institute-for-mathematical-and-computational-engineering-uc Email: vacancysearch.imc@uc.cl</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Universidad Católica de Chile (UC) is offering one or more full-time positions at the assistant (tenure-track) or associate level. We invite applications from highly qualified candidates in Data Science, Machine Learning, Optimization, Statistics and Stochastics, although other areas from Computational Science and Engineering, Optimization and Applied Mathematics will also be considered.</p>
<p>Website: <a href="http://imc.uc.cl/index.php/noticias/183-open-position-at-the-institute-for-mathematical-and-computational-engineering-uc">http://imc.uc.cl/index.php/noticias/183-open-position-at-the-institute-for-mathematical-and-computational-engineering-uc</a><br/>
Email: vacancysearch.imc@uc.cl</p></div>
    </content>
    <updated>2020-08-28T18:02:24Z</updated>
    <published>2020-08-28T18:02:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-31T23:44:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-08-28-what-is-a-cryptographic-hash-function/</id>
    <link href="https://decentralizedthoughts.github.io/2020-08-28-what-is-a-cryptographic-hash-function/" rel="alternate" type="text/html"/>
    <title>What is a Cryptographic Hash Function?</title>
    <summary>If you ever tried to understand Bitcoin, you’ve probably banged your head against the wall trying to understand what is a cryptographic hash function? The goal of this post is to: Give you a very simple mental model for how hash functions work, called the random oracle model Give you...</summary>
    <updated>2020-08-28T17:05:00Z</updated>
    <published>2020-08-28T17:05:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-08-31T23:45:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blog.simons.berkeley.edu/?p=276</id>
    <link href="https://blog.simons.berkeley.edu/2020/08/lattice-blog-reduction-part-iii-self-dual-bkz/" rel="alternate" type="text/html"/>
    <title>Lattice Blog Reduction – Part III: Self-Dual BKZ</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the third and last entry in a series of posts about lattice block reduction. See here and here for the first and second part, resp. In this post I will assume you have read the other parts. In … <a href="https://blog.simons.berkeley.edu/2020/08/lattice-blog-reduction-part-iii-self-dual-bkz/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is the third and last entry in a series of posts about lattice block reduction. See <a class="uri" href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/">here</a> and <a class="uri" href="https://blog.simons.berkeley.edu/2020/05/lattice-blog-reduction-part-ii-slide-reduction/">here</a> for the first and second part, resp. In this post I will assume you have read the other parts.</p>
<p>In the first two parts we looked at BKZ and Slide reduction, the former being the oldest and most useful in practice, while the latter achieves the best provable bounds and has the cleaner analysis. While BKZ is a natural generalization of LLL, we have seen that the analysis of LLL does not generalize well to BKZ. One can view Slide reduction as a different generalization of LLL with the goal of also naturally generalizing its analysis. As we mentioned in the first part, there is another analysis technique based on dynamical systems, introduced in [HPS11]. Unfortunately, as applied to BKZ, there are some cumbersome technicalities and the resulting bounds on the output quality are not as tight as we would like them to be (i.e. as for Slide reduction). One can view the algorithm we are considering today – SDBKZ [MW16] – as a generalization of LLL that lends itself much easier to this dynamical systems analysis: it is simpler, cleaner and yields better results. Since part of the goal of today’s post is to demonstrate this very useful analysis technique, SDBKZ is a natural candidate.</p>
<h1 id="sec:sdbkz">SDBKZ</h1>
<p>Recall the two tools we’ve been relying on in the first two algorithms, SVP and DSVP reduction of projected subblocks:</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-block-image"><figure class="alignleft size-large"><img alt="" class="wp-image-156" src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/04/svp.png"/>Effect of a call to the DSVP oracle. GSO log norms of the input in black, of the output in blue. Note that the sum of the GSO log norms is a constant, so increasing the length of the last vector, decreases the (average of the) remaining vectors.</figure></div>
</div></div>



<div class="wp-block-image"><figure class="alignleft size-large"><img alt="" class="wp-image-262" src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/05/dsvp.png"/>Effect of a call to the DSVP oracle. GSO log norms  of the input in black, of the output in blue. Note that the sum of the GSO log norms is a constant, so increasing the length of the last vector, decreases the (average of the) remaining vectors.</figure></div>



<p>We will use both of them again today. Like BKZ, a tour of SDBKZ starts by calling the SVP oracle on successive blocks of our basis. However, when we reach the end of the basis, we will not decrease the size of the window, since this is actually quite inconvenient for the analysis. Instead, we will keep the size of the window constant but switch to DSVP reduction, i.e. at the end of the BKZ tour we DSVP reduce the last block. This will locally maximize the last GSO vector in the basis, just as the first SVP call locally minimized the first vector of the basis. Then we will move the window successively backwards, mirroring a BKZ tour, but using DSVP reduction, until we reach the beginning of the basis again. At this point, we switch back to SVP reduction and move the window forward, etc. So SDBKZ runs in forward and backward tours.</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-283" src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/08/sdbkz-1024x825.png"/>SDBKZ in one picture: apply the SVP oracle to the projected blocks from start to finish and when you reach the end, apply the DSVP oracle to from finish to start. Repeat.</figure>



<p>A nice observation here is that the backward tour can be viewed equivalently as: 1) compute the reversed dual basis (i.e. the dual basis with reversed columns), 2) run a forward tour, 3) compute the primal basis again. The first of these two steps is self-inverse: computing the reversed dual basis of the reversed dual basis yields the original primal basis. This means step 3) is actually the same as step 1). So in effect, one can view SDBKZ as simply repeating the following two steps: 1) run a forward tour, 2) compute the reversed dual basis. So it doesn’t matter if we use the primal or the dual basis as input, the operations of the algorithm are the same. This is why it is called <em>Self-Dual</em> BKZ.</p>
<p>There is one caveat with this algorithm: it is not clear, when one should terminate. In BKZ and Slide reduction one can formulate clear criteria, when the algorithm makes no more progress anymore. In SDBKZ this is not the case, but the analysis will show that we can bound the number of required tours ahead of time.</p>
<h4 id="the-analysis">The Analysis</h4>
<p>We will start by analyzing the effect of a forward tour. Let <span class="math inline">\({\mathbf{B}}\)</span> be our input basis. The first call to the SVP oracle in a forward tour replaces <span class="math inline">\({\mathbf{b}}_1\)</span> with the shortest vector in <span class="math inline">\({\mathbf{B}}_{[1,k]}\)</span>. This means that the new basis <span class="math inline">\({\mathbf{B}}’\)</span> satifies <span class="math inline">\(\| {\mathbf{b}}_1′ \| \leq \sqrt{\gamma_k} (\prod_{i=1}^k \|{\mathbf{b}}_i^* \|)^{1/k}\)</span> by Minkowski’s bound. Equivalently, this can be written as <span class="math display">\[\log \| {\mathbf{b}}_1′ \|
  \leq \log \sqrt{\gamma_k} + \frac1k (\sum_{i=1}^k \log \|{\mathbf{b}}_i^* \|).\]</span> So if we consider the <span class="math inline">\(\log \|{\mathbf{b}}_i^*\|\)</span> as variables, it seems like linear algebra could be useful here. So far, so good. The second step is more tricky though. We know that the next basis <span class="math inline">\({\mathbf{B}}”\)</span>, i.e. after the call to the SVP oracle on <span class="math inline">\({\mathbf{B}}’_{[2,k+1]}\)</span>, satisfies <span class="math inline">\({\mathbf{b}}_1” = {\mathbf{b}}_1’\)</span> and <span class="math inline">\(\| ({\mathbf{b}}_2”)^* \| \leq \sqrt{\gamma_k} (\prod_{i=2}^{k+1} \|({\mathbf{b}}’_i)^* \|)^{1/k}\)</span>. Unfortunately, we have no control over <span class="math inline">\(\|({\mathbf{b}}’_i)^* \|\)</span> for <span class="math inline">\(i \in {2,\dots,k} \)</span>, since we do not know how the SVP oracle in the first call changed these vector. However, we do know that the lattice <span class="math inline">\({\mathbf{B}}_{[1,k+1]}\)</span> did not change in that call. So we can write <span class="math display">\[\prod_{i=2}^{k+1} \|({\mathbf{b}}’_i)^* \| = \frac{\prod_{i=1}^{k+1} \|{\mathbf{b}}_i^* \|}{\| {\mathbf{b}}’_1 \|}\]</span> and thus we obtain <span class="math display">\[\log \| ({\mathbf{b}}_2′)^* \|
  \leq \log \sqrt{\gamma_k} + \frac1k (\sum_{i=1}^{k+1} \log \|{\mathbf{b}}_i^* \| – \log \|{\mathbf{b}}’_1 \|).\]</span> Again, this looks fairly “linear algebraicy”, so it could be useful. But there is another issue now: in order to get an inequality purely in the input basis <span class="math inline">\({\mathbf{B}}\)</span>, we would like to use our inequality for <span class="math inline">\(\log \|{\mathbf{b}}_1′ \|\)</span> in the one for <span class="math inline">\(\log \| ({\mathbf{b}}_2′)^* \|\)</span>. But the coefficient of <span class="math inline">\(\log \|{\mathbf{b}}_1′ \|\)</span> is negative, so we would need a lower bound for <span class="math inline">\(\log \|{\mathbf{b}}_1′ \|\)</span>. Furthermore, we would like to use upper bounds for our variables later, since the analysis of a tour will result in upper bounds and we would like to apply it iteratively. For this, negative coefficients are a problem. So, we need one more modification: we will use a change of variable to fix this. Instead of considering the variables <span class="math inline">\(\log \| {\mathbf{b}}_i^* \|\)</span>, we let the input variables to our forward tour be <span class="math inline">\(x_i = \sum_{j &lt; k+i} \log \|{\mathbf{b}}^*_i \|\)</span> and the output variables <span class="math inline">\(y_i = \sum_{j \leq i} \log \|({\mathbf{b}}’_i)^* \|\)</span> for <span class="math inline">\(i \in [1,\dots,n-k]\)</span>. Clearly, we can now write our upper bound on <span class="math inline">\(\log \|({\mathbf{b}}’_1)^*\|\)</span> as <span class="math display">\[y_1 \leq \log \sqrt{\gamma_k} + \frac{x_1}{k}.\]</span> More generally, we have <span class="math display">\[\|({\mathbf{b}}’_i)^* \| \leq \sqrt{\gamma_k} \left(\frac{\prod_{j=1}^{i+k-1} \|{\mathbf{b}}_j^* \|}{\prod_{j=1}^{i-1} \|({\mathbf{b}}’_j)^* \|} \right)^{\frac1k}\]</span> which means for our variables <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> that <span class="math display">\[y_i = y_{i-1} + \log \| ({\mathbf{b}}’_i)^* \|
  \leq y_{i-1} + \log \sqrt{\gamma_k} + \frac{x_i – y_{i-1}}{k}
  = (1-\frac1k) y_{i-1} + \frac1k x_i + \log \sqrt{\gamma_k}.\]</span></p>
<p>Note that we can write each <span class="math inline">\(y_i\)</span> in terms of <span class="math inline">\(x_i\)</span> and the previous <span class="math inline">\(y_i\)</span> with only positive coefficients. So now we can apply induction to write each <span class="math inline">\(y_i\)</span> only in terms of the <span class="math inline">\(x_i\)</span>’s, which shows that <span class="math display">\[y_i = \frac1k \sum_{j=1}^i \omega^{i-j} x_j + (1-\omega)^i k \alpha\]</span> where we simplified notation a little by defining <span class="math inline">\(\alpha = \log \sqrt{\gamma_k}\)</span> and <span class="math inline">\(\omega = 1-\frac1k\)</span>. By collecting the <span class="math inline">\(x_i\)</span>’s and <span class="math inline">\(y_i\)</span>’s in a vector each, we have the vectorial inequality <span class="math display">\[{\mathbf{y}} \leq {\mathbf{A}} {\mathbf{x}} + {\mathbf{b}}\]</span> where <span class="math display">\[{\mathbf{b}} = \alpha k \left[
\begin{array}{c}
1 – \omega \\ 
\vdots \\
1 – \omega^{n-k} 
\end{array}\right]
\qquad\qquad
{\mathbf{A}} = \frac1k 
\left[
\begin{array}{cccc}
  1 &amp; &amp; &amp; \\
  \omega &amp; 1 &amp; &amp; \\
   \vdots &amp; \ddots &amp; \ddots &amp; \\
   \omega^{n-k-1} &amp; \cdots &amp; \omega &amp; 1
\end{array}
\right].\]</span></p>
<p>Now recall that after a forward tour, SDBKZ computes the reversed dual basis. Given the close relationship between the primal and the dual basis and their GSO, one can show that simply reversing the vector <span class="math inline">\({\mathbf{y}}\)</span> will yield the right variables <span class="math inline">\({\mathbf{x}}’_i\)</span> to start the next “forward tour” (which is actually a backward tour, but on the dual). I.e. after reversing <span class="math inline">\({\mathbf{y}}\)</span>, the variables represent the logarithm of the corresponding subdeterminants of the dual basis. (For this we assume for convenience and w.l.o.g. that the lattice has determinant 1; otherwise, there would be a scaling factor involved in this transformation.)</p>
<p>In summary, the effect on the vector <span class="math inline">\({\mathbf{x}}\)</span> of executing once the two steps, 1) forward tour and 2) computing the reversed dual basis, can be described as <span class="math display">\[{\mathbf{x}}’ \leq {\mathbf{R}} {\mathbf{A}} {\mathbf{x}} + {\mathbf{R}} {\mathbf{b}}\]</span> where <span class="math inline">\({\mathbf{R}}\)</span> is the reversed identity matrix (i.e. the identity matrix with reversed columns). Iterating the two steps simply means we will be iterating the vectorial inequality above. So analyzing the affine dynamical system <span class="math display">\[{\mathbf{x}} \mapsto {\mathbf{R}} {\mathbf{A}} {\mathbf{x}} + {\mathbf{R}} {\mathbf{b}}\]</span> will allow us to deduce information about the basis after a certain number of iterations.</p>
<h4 id="small-digression-affine-dynamical-systems">Small Digression: Affine Dynamical Systems</h4>
<p>Consider some dynamical system <span class="math inline">\({\mathbf{x}} \mapsto {\mathbf{A}} {\mathbf{x}} + {\mathbf{b}} \)</span> and assume it has exactly one fixed point, i.e. <span class="math inline">\({\mathbf{x}}^*\)</span> such that <span class="math inline">\({\mathbf{A}} {\mathbf{x}}^* + {\mathbf{b}} = {\mathbf{x}}^* \)</span>. We can write any input <span class="math inline">\({\mathbf{x}}’\)</span> as <span class="math inline">\({\mathbf{x}}’ = {\mathbf{x}}^* + {\mathbf{e}}\)</span> for some “error vector” <span class="math inline">\({\mathbf{e}}\)</span>. When applying the system to it, we get <span class="math inline">\({\mathbf{x}}’ \mapsto {\mathbf{A}} {\mathbf{x}}’ + {\mathbf{b}} = {\mathbf{x}}^* + {\mathbf{A}} {\mathbf{e}}\)</span>. So the error vector <span class="math inline">\({\mathbf{e}}\)</span> is mapped to <span class="math inline">\({\mathbf{A}} {\mathbf{e}}\)</span>. Applying this <span class="math inline">\(t\)</span> times maps <span class="math inline">\({\mathbf{e}}\)</span> to <span class="math inline">\({\mathbf{A}}^t {\mathbf{e}}\)</span>, which means after <span class="math inline">\(t\)</span> iterations the error vector has norm <span class="math inline">\(\|{\mathbf{A}}^t {\mathbf{e}} \|_{p} \leq \|{\mathbf{A}}^t \|_{p} \| {\mathbf{e}} \|_{p} \)</span> (where <span class="math inline">\(\| \cdot \|_{p}\)</span> is the matrix norm induced by the vector <span class="math inline">\(p\)</span>-norm). If we can show that <span class="math inline">\(\|{\mathbf{A}} \|_p \leq 1 – \epsilon\)</span>, then <span class="math inline">\(\|{\mathbf{A}}^t \|_p \leq \|A \|^t \leq (1-\epsilon)^t \leq e^{-\epsilon t}\)</span>, so the error vector will decay exponentially in <span class="math inline">\(t\)</span> with base <span class="math inline">\(e^{-\epsilon}\)</span> and the algorithm converges to the fixed point <span class="math inline">\({\mathbf{x}}^*\)</span>.</p>
<p>Back to our concrete system above. As we just saw, we can analyze its output quality by computing its fixed point and its running time by computing <span class="math inline">\(\|{\mathbf{R}} {\mathbf{A}} \|_p\)</span> for some induced matrix <span class="math inline">\(p\)</span>-norm. Since this has been a lenghty post already, I hope you’ll trust me that our system above has a fixed point <span class="math inline">\({\mathbf{x}}^*\)</span>, which can be written out explicitely in closed form. As a teaser, its first coordinate is <span class="math display">\[x^*_1 = \frac{(n-k)k}{k-1} \alpha.\]</span> This means that if the algorithm converges, it will converge to a basis such that <span class="math inline">\(\sum_{j \leq k}\log \| {\mathbf{b}}_j^*\| \leq \frac{(n-k)k}{k-1} \log \sqrt{\gamma_k}\)</span>. Applying Minkowski’s Theorem to the first block <span class="math inline">\({\mathbf{B}}_{[1,k]}\)</span> now shows that the shortest vector in this block satisfies <span class="math inline">\(\lambda_1({\mathbf{B}}_{[1,k]}) \leq \sqrt{\gamma_k}^{\frac{n-1}{k-1}}\)</span>. Note that the next forward tour will find a vector of such length. Recall that we assumed that our lattice has determinant 1, so this is exactly the Hermite factor achieved by Slide reduction, but for arbitrary block size (we do not need to assume that <span class="math inline">\(k\)</span> divides <span class="math inline">\(n\)</span>) and better than what we can achieve for BKZ (even using the same technique). Moreover, the fixed point actually gives us more information: the other coordinates (that I have ommited here) allow us control over all but <span class="math inline">\(k\)</span> GSO vectors and by terminating the algorithm at different positions, it allows us to choose which vectors we want control over.</p>
<p>It remains to show that the algorithm actually converges and figure out how fast. It is fairly straight-forward to show that <span class="math display">\[\|{\mathbf{R}} {\mathbf{A}}\|_{\infty} = \|{\mathbf{A}}\|_{\infty} = 1 – \omega^{n-k} \approx e^{-\frac{n-k}{k}}.\]</span> (Consider the last row of <span class="math inline">\({\mathbf{A}}\)</span>.) This is always smaller than 1, so the algorithm does indeed converge. For <span class="math inline">\(k = \Omega(n)\)</span> this is bounded far enough from 1 such that the system will converge to the fixed point up to an arbitrary constant in a number of SVP calls that is polynomial in <span class="math inline">\(n\)</span>. Using another change of variable [N16] or considering the relative error instead of the absolute error [MW15], one can show that this also holds for smaller <span class="math inline">\(k\)</span>.</p>
<p>As mentioned before, this type of analysis was introduced in [HPS11] and has inspired new ideas even in the heuristic analysis of BKZ. In particular, one can predict the behavior of BKZ by simply running such a dynamical system on typical inputs (and making some heuristic assumptions). This idea has been and is being used extensively in cryptanalysis and in optimizing parameters of state-of-the-art algorithms.</p>
<p>Finally, a few last words on SDBKZ: we have seen that it achieves a good Hermite factor, but what can we say about the approximation factor? I actually do not know if the algorithm achieves a good approximation factor and also do not see a good way to analyze it. However, there is a reduction [L86] from achieving approximation factor <span class="math inline">\(\alpha\)</span> to achieving Hermite factor <span class="math inline">\(\sqrt{\alpha}\)</span>. So SDBKZ can be used to achieve approximation factor <span class="math inline">\(\gamma_k^{\frac{n-1}{k-1}}\)</span>. This is a little unsatisfactory in two ways: 1) the reduction results in a different algorithm, and 2) the bound is a little worse than the factor achieved by slide reduction, which is <span class="math inline">\(\gamma_k^{\frac{n-k}{k-1}}\)</span>. On a positive note, a recent work [ALNS20] has shown that, due to the strong bound on the Hermite factor, SDBKZ can be used to generalize Slide reduction to arbitrary block size <span class="math inline">\(k\)</span> in a way to achieve the approximation factor <span class="math inline">\(\gamma_k^{\frac{n-k}{k-1}}\)</span>. Another recent work [ABFKSW20] exploited the fact that SDBKZ allows to heuristically predict large parts of the basis to achieve better bounds on the running time of the SVP oracle.</p>
<ul>
<li><p>Lov<span>á</span>sz. An Algorithmic Theory of Numbers, Graphs and Convexity. 1986</p></li>
<li><p>Hanrot, Pujol, Stehlé. Analyzing blockwise lattice algorithms using dynamical systems. CRYPTO 2011</p></li>
<li><p>Micciancio, Walter. Practical, predictable lattice basis reduction – Full Version. <a class="uri" href="http://eprint.iacr.org/2015/1123">http://eprint.iacr.org/2015/1123</a></p></li>
<li><p>Micciancio, Walter. Practical, predictable lattice basis reduction. EUROCRYPT 2016</p></li>
<li><p>Neumaier. Bounding basis reduction properties. Designs, Codes and Cryptography 2016</p></li>
<li><p>Aggarwal, Li, Nguyen, Stephens-Davidowitz. Slide Reduction, Revisited—Filling the Gaps in SVP Approximation. CRYPTO 2020</p></li>
<li><p>Albrecht, Bai, Fouque, Kirchner, Stehlé, Wen. Faster Enumeration-based Lattice Reduction: Root Hermite Factor <span class="math inline">\(k^{(1/(2k))}\)</span> in Time <span class="math inline">\(k^{(k/8 + o(k))}\)</span>. CRYPTO 2020</p></li>
</ul></div>
    </content>
    <updated>2020-08-28T11:56:55Z</updated>
    <published>2020-08-28T11:56:55Z</published>
    <category term="General"/>
    <author>
      <name>Michael Walter</name>
    </author>
    <source>
      <id>https://blog.simons.berkeley.edu</id>
      <link href="https://blog.simons.berkeley.edu/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blog.simons.berkeley.edu" rel="alternate" type="text/html"/>
      <subtitle>What's New at the Simons Institute for the Theory of Computing.</subtitle>
      <title>Calvin Café: The Simons Institute Blog</title>
      <updated>2020-08-31T23:45:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/26/postdoc-at-uc-berkeley-apply-by-september-10-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/26/postdoc-at-uc-berkeley-apply-by-september-10-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at UC Berkeley (apply by September 10, 2020)</title>
    <summary>Please send a cover letter, CV, and research statement to the email below. In CV please list at least 3 references. In cover letter please identify faculty of interest. Also, have references submit letters to the e-mail below, with your name in the subject line. Multiple opportunities available; earliest deadline requires nomination by September 10th. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Please send a cover letter, CV, and research statement to the email below. In CV please list at least 3 references. In cover letter please identify faculty of interest. Also, have references submit letters to the e-mail below, with your name in the subject line. Multiple opportunities available; earliest deadline requires nomination by<br/>
September 10th.</p>
<p>Website: <a href="http://theory.cs.berkeley.edu/postdoc.html">http://theory.cs.berkeley.edu/postdoc.html</a><br/>
Email: tcs-postdoc-inquiries@lists.eecs.berkeley.edu</p></div>
    </content>
    <updated>2020-08-26T04:54:53Z</updated>
    <published>2020-08-26T04:54:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-31T23:44:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=790</id>
    <link href="https://emanueleviola.wordpress.com/2020/08/25/my-monitor-setup/" rel="alternate" type="text/html"/>
    <title>My monitor setup</title>
    <summary>In the not-distant future there will be a single monitor that gets you the best of both worlds. For the contemporaneous, I maintain that the above is the best monitor setup available to us in 2020. I use the tiny E-ink monitor as much as possible, including now, for my blitz matches on chess.com, and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><img alt="" class="wp-image-792" src="https://emanueleviola.files.wordpress.com/2020/08/webcam-toy-photo7.jpg?w=800"/></figure>

<p>In the not-distant future there will be a single monitor that gets you the best of both worlds. For the contemporaneous, I maintain that the above is the best monitor setup available to us in 2020. I use the tiny E-ink monitor as much as possible, including now, for my blitz matches on chess.com, and of course for writing and sometimes reviewing papers. But as I mentioned earlier unfortunately for certain bureaucratic tasks that not all of us can skip altogether you just need a bigger monitor with color. So I push a button on the hdmi switch, and the image blasts open on the 30-inch screen, <em>m’illumino d’immenso</em>, and suddenly the mouse feels like the interface from <em>Minority Reports</em>.</p></div>
    </content>
    <updated>2020-08-25T19:35:48Z</updated>
    <published>2020-08-25T19:35:48Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="tech"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-08-31T23:44:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/colt2020/</id>
    <link href="https://differentialprivacy.org/colt2020/" rel="alternate" type="text/html"/>
    <title>Conference Digest - COLT 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.learningtheory.org/colt2020/">COLT 2020</a> was held online in July, and featured nine papers on differential privacy, as well as a keynote talk by Salil Vadhan.
While differential privacy has always had a home in the COLT community, it seems like this year was truly exceptional in terms of the number of results.
We link all the content below, including pointers to the papers, videos on Youtube, and the page on the conference website. 
Please let us know if we missed any papers on differential privacy, either in the comments below or by email.</p>

<h2 id="keynote">Keynote</h2>
<ul>
  <li><a href="http://www.learningtheory.org/colt2020/virtual/speaker_1.html">The Theory and Practice of Differential Privacy</a> (<a href="https://www.youtube.com/watch?v=4bpFDpT1t7I">video</a>)<br/>
<a href="https://salil.seas.harvard.edu/">Salil Vadhan</a></li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/1907.08743">Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit</a> (<a href="https://www.youtube.com/watch?v=dgGdARyU6oY">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_96.html">page</a>)<br/>
<a href="https://people.ece.cornell.edu/acharya/">Jayadev Acharya</a>, <a href="http://www.cs.columbia.edu/~ccanonne/">Clément L. Canonne</a>, <a href="https://web.stanford.edu/~yjhan/">Yanjun Han</a>, <a href="http://www.zitengsun.com/">Ziteng Sun</a>, <a href="https://ece.iisc.ac.in/~htyagi/">Himanshu Tyagi</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2003.04509">Closure Properties for Private Classification and Online Prediction</a> (<a href="https://www.youtube.com/watch?v=U9hqJH6sEyY">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_320.html">page</a>)<br/>
<a href="https://web.math.princeton.edu/~nalon/">Noga Alon</a>, <a href="https://www.cs.bgu.ac.il/~beimel/">Amos Beimel</a>, <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.01452">Pan-Private Uniformity Testing</a> (<a href="https://www.youtube.com/watch?v=yMXAjEGDXdI">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_141.html">page</a>)<br/>
<a href="http://amin.kareemx.com/">Kareem Amin</a>, <a href="https://www.majos.net/">Matthew Joseph</a>, <a href="https://sites.google.com/view/jieming-mao">Jieming Mao</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.01100">Efficient, Noise-Tolerant, and Private Learning via Boosting</a> (<a href="https://www.youtube.com/watch?v=xCh7oZKcINs">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_304.html">page</a>)<br/>
<a href="https://cs-people.bu.edu/mbun/">Mark Bun</a>, <a href="https://marco.ntime.org/">Marco L. Carmosino</a>, <a href="http://cseweb.ucsd.edu/~jlsorrel/">Jessica Sorrell</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.10541">PAC Learning with Stable and Private Predictions</a> (<a href="https://www.youtube.com/watch?v=jZlgmBUQ4nU">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_37.html">page</a>)<br/>
<a href="https://yuvaldagan.wordpress.com/">Yuval Dagan</a>, <a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.09465">Locally Private Hypothesis Selection</a> (<a href="https://www.youtube.com/watch?v=MGeBYQ7lJYw">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_5.html">page</a>)<br/>
<a href="https://www.microsoft.com/en-us/research/people/sigopi/">Sivakanth Gopi</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan D. Kulkarni</a>, <a href="http://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a>, <a href="https://zstevenwu.com/">Zhiwei Steven Wu</a>, <a href="https://huanyuzhang.github.io/">Huanyu Zhang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.09464">Private Mean Estimation of Heavy-Tailed Distributions</a> (<a href="https://www.youtube.com/watch?v=6NVuAZqxrSE">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_6.html">page</a>)<br/>
<a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="http://www.ccs.neu.edu/home/vikrantsinghal/">Vikrant Singhal</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.10137">Privately Learning Thresholds: Closing the Exponential Gap</a> (<a href="https://www.youtube.com/watch?v=uGTfJsJAkh0">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_219.html">page</a>)<br/>
<a href="http://www.cs.tau.ac.il/~haimk/">Haim Kaplan</a>, <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a>, <a href="https://www.tau.ac.il/~mansour/">Yishay Mansour</a>, <a href="http://www.wisdom.weizmann.ac.il/~naor/">Moni Naor</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2001.09122">Reasoning About Generalization via Conditional Mutual Information</a> (<a href="https://www.youtube.com/watch?v=c5fzeqiTwWk">video</a>, <a href="https://www.learningtheory.org/colt2020/virtual/papers/paper_98.html">page</a>)<br/>
<a href="http://www.thomas-steinke.net/">Thomas Steinke</a>, <a href="http://www.ccs.neu.edu/home/lydiazak/">Lydia Zakynthinou</a></p>
  </li>
</ul></div>
    </summary>
    <updated>2020-08-25T14:00:00Z</updated>
    <published>2020-08-25T14:00:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-08-31T23:45:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/25/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/25/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-30-2020/" rel="alternate" type="text/html"/>
    <title>Assistant Professor (tenure-track) and Professor positions in Computer Science at Institute of Science and Technology Austria (apply by October 30, 2020)</title>
    <summary>The Institute of Science and Technology Austria (IST Austria) invites applications for several open positions in all areas of computer science. IST Austria values diversity and is committed to equal opportunity. We strive for increasing the number of women, particularly in fields where they are underrepresented, and therefore we strongly encourage female researchers to apply. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Institute of Science and Technology Austria (IST Austria) invites applications for several open positions in all areas of computer science.</p>
<p>IST Austria values diversity and is committed to equal opportunity. We strive for increasing the number of women, particularly in fields where they are underrepresented, and therefore we strongly encourage female researchers to apply.</p>
<p>Website: <a href="https://ist.ac.at/en/jobs/faculty/">https://ist.ac.at/en/jobs/faculty/</a><br/>
Email: faculty.recruiting@ist.ac.at</p></div>
    </content>
    <updated>2020-08-25T13:23:45Z</updated>
    <published>2020-08-25T13:23:45Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-31T23:44:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7790</id>
    <link href="https://windowsontheory.org/2020/08/24/highlights-of-algorithms-halg-free-aug-31-sep-2/" rel="alternate" type="text/html"/>
    <title>Highlights of Algorithms (HALG) -free – Aug 31- Sep 2</title>
    <summary>[Guest post by Yossi Azar] The 5th Highlights of Algorithms conference (HALG 2020) will take place Aug 31- Sep 2, 2020. http://highlightsofalgorithms.org/ The Highlights of Algorithms conference is a forum for presenting the highlights of recent developments in algorithms and for discussing potential further advances in this area. The conference will provide a broad picture […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post by Yossi Azar]</em></p>



<p>The 5th <strong>Highlights of Algorithms conference (HALG 2020)</strong> will take place Aug 31- Sep 2, 2020. <a href="http://highlightsofalgorithms.org/" rel="noreferrer noopener" target="_blank">http://highlightsofalgorithms.org/</a></p>



<p>The Highlights of Algorithms conference is a forum for presenting the highlights of recent developments in algorithms and for discussing potential further advances in this area. The conference will provide a broad picture of the latest research in algorithms through a series of invited talks, as well as short talks. <br/>Invited talks includes top algorithmic surveys and papers from FOCS/STOC/SODA/COLT/PODC/SPAA/ITCS/PODS (2019-20)</p>



<p><br/>PROGRAM<br/>The conference will take place online on Mon, Aug 31-Wed, Sep 2 from 12:00 noon until 19:30 CEST (Europe time) <a href="http://highlightsofalgorithms.org/programme" rel="noreferrer noopener" target="_blank">http://highlightsofalgorithms.org/programme</a></p>



<p>The short contributed talk are on Sep 1-2, 9:45-11:30 CEST <a href="http://highlightsofalgorithms.org/shorttalks" rel="noreferrer noopener" target="_blank">http://highlightsofalgorithms.org/shorttalks</a></p>



<p>REGISTRATION<br/>Registration is free but mandatory<br/>Please register on our webpage: <a href="https://highlightsofalgorithms2020.ethz.ch/registration" rel="noreferrer noopener" target="_blank">https://highlightsofalgorithms2020.ethz.ch/registration</a></p></div>
    </content>
    <updated>2020-08-24T19:17:23Z</updated>
    <published>2020-08-24T19:17:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-08-31T23:44:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/</id>
    <link href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/" rel="alternate" type="text/html"/>
    <title>IDEAL Special Quarter (Theory of Deep Learning)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 21 – December 12, 2020 Online (https://www.ideal.northwestern.edu/special-quarters/fall-2020/) https://www.ideal.northwestern.edu/special-quarters/fall-2020/registration There will be a Special Quarter on Theory of Deep Learning this Fall as a part of IDEAL – The Institute for Data, Econometrics, Algorithms, and Learning, runs jointly with TTIC and the University of Chicago. The Special Quarter will be entirely online, and take place … <a class="more-link" href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/">Continue reading <span class="screen-reader-text">IDEAL Special Quarter (Theory of Deep Learning)</span></a></div>
    </summary>
    <updated>2020-08-24T16:02:27Z</updated>
    <published>2020-08-24T16:02:27Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-08-31T23:45:11Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1663724076500583508</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1663724076500583508/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/08/sharp-p-and-issue-of-natural-problems.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1663724076500583508" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1663724076500583508" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/08/sharp-p-and-issue-of-natural-problems.html" rel="alternate" type="text/html"/>
    <title>Sharp P and the issue of `natural problems'</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> #P was defined by Valiant as a way to pin down that the PERMANENT of a matrix is hard to compute.</p><p>The definition I give is equivalent to the one Valiant gave.</p><p>g is in #P if there exists p a poly and B in P such that</p><p>g(x) = | { y : |y| = p(|x|) and (x,y) \in B } |</p><p>A function f is #P-complete if g is in #P and for all g in #P,  f is poly-Turing reducible to g.</p><p>#SAT is the function that, given a formula, returns the number of satisfying assignments. It is #P-complete by looking at the proof the Cook-Levin Theorem. The reduction of f to #SAT only makes one query to #SAT. A common way to show that #A is #P-complete is to show that SAT \le A with a reduction that preserves the number of solutions. </p><p>Valiant proved that PERM was #P-complete (his reduction only used 1 call to PERM).</p><p>There are problems in P whose #-version is #-P complete: Matching and DNF-SAT are two of them.</p><p>Notice that I defined #SAT directly, not in terms of a poly p and a set B as above. Here is why: if you use poly p and set B one can do obnoxious things like: </p><p>SAT = { phi : exists yz 2n-bits long such that phi(y)=T and z is prime }</p><p>The # version of this definition is not really what I want (though I am sure its #P-complete).</p><p>Valiant (see <a href="https://www.math.cmu.edu/~af1p/Teaching/MCC17/Papers/enumerate.pdf">here</a> and <a href="http://www.math.cmu.edu/~af1p/Teaching/MCC17/Papers/permanent.pdf">here</a>) and Simon (see <a href="https://link.springer.com/content/pdf/10.1007%2F3-540-08342-1_37.pdf">here</a>) showed that  for many known NPC-problems A, #A is #P-complete. They meant NATURAL problems. Is it true for all natural NP-complete problems?</p><p>Unfortunately the statement `All NATURAL NPC problems give rise to #P-complete functions' is hard (impossible?) to state rigorously and hence hard (impossible?) to prove. </p><p>1) Is there a natural A in NP such that #A is NOT #P-complete (under assumptions)?</p><p>2) Are there any theorems that show a large set of NPC problems have #P counterparts? Or are we doomed to, when we want to show some #A is #P-complete, come up with a new proof?</p><p>3) Can one PROVE there are NPC problems A such that #A is NOT #P-complete? (under assumptions).</p></div>
    </content>
    <updated>2020-08-24T01:40:00Z</updated>
    <published>2020-08-24T01:40:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-31T08:25:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron</id>
    <link href="https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron.html" rel="alternate" type="text/html"/>
    <title>Bricard’s jumping octahedron</title>
    <summary>The Schönhardt polyhedron is a non-convex octahedron that can be formed from a convex regular octahedron by twisting two opposite faces, stretching and deforming the other faces as you twist. It’s well known for not having any interior diagonals, and for being impossible to subdivide into tetrahedra without introducing new vertices. But long before Erich Schönhardt described it in 1928 in connection with these properties, Raoul Bricard was investigating flexible octahedra, in connection with Cauchy’s theorem on the rigidity of polyhedra. The Schönhardt polyhedron forms an interesting example of flexibility, as I learned from a 1975 collection of lecture notes by Branko Grünbaum on “Lost Mathematics”). I’m not entirely sure that it was known to Bricard (it’s not clear from Bricard’s paper and Grünbaum doesn’t really say so) but it wouldn’t surprise me if it was.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="https://en.wikipedia.org/wiki/Sch%C3%B6nhardt_polyhedron">Schönhardt polyhedron</a> is a non-convex octahedron that can be formed from a convex regular octahedron by twisting two opposite faces, stretching and deforming the other faces as you twist. It’s well known for not having any interior diagonals, and for being impossible to subdivide into tetrahedra without introducing new vertices. But long before Erich Schönhardt described it in 1928 in connection with these properties, Raoul Bricard was investigating <a href="https://en.wikipedia.org/wiki/Bricard_octahedron">flexible octahedra</a>, in connection with <a href="https://en.wikipedia.org/wiki/Cauchy%27s_theorem_(geometry)">Cauchy’s theorem on the rigidity of polyhedra</a>. The Schönhardt polyhedron forms an interesting example of flexibility, as I learned from a 1975 collection of lecture notes by Branko Grünbaum on “<a href="https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/15700/Lost%20Mathematics.pdf?fterence=1">Lost Mathematics</a>”). I’m not entirely sure that it was known to Bricard (it’s not clear from Bricard’s paper and Grünbaum doesn’t really say so) but it wouldn’t surprise me if it was.</p>

<p>Cauchy’s theorem states that the shape of every convex polyhedron is uniquely determined by the shapes and connectivity of its faces. There can be no other convex polyhedron that has faces of the same shape, connected in the same way. But in some cases (like the regular icosahedron) you can dent some of the faces in to make a different, non-convex polyhedron with the same face shapes and connectivity. So Cauchy’s theorem doesn’t immediately extend to non-convex polyhedra. In fact, certain non-convex “<a href="https://en.wikipedia.org/wiki/Flexible_polyhedron">flexible polyhedra</a>” can deform continuously into an infinite range of shapes, without changing the shape or connectivity of their faces. Bricard’s octahedra are self-crossing examples and later investigators found examples without self-crossings.</p>

<p>But Grünbaum describes a different, non-self-crossing non-convex octahedron, the “jumping octahedron”. Rather than having a continuous range of rigid shapes, it has exactly two shapes, both of which have faces of the same shapes and connectivity. Unlike the example of the regular icosahedron and dented icosahedron, the two shapes have dihedral angles that are convex and concave in the same places. If you make this polyhedron out of perfectly rigid faces, with hinged connections at their edges, it could only be in one or the other of its two shapes: you wouldn’t be able to get it to the other shape without taking it apart and rebuilding it. But if you make it out of a material that’s stiff enough to hold its shape but flexible enough to deform a little, you can make a model that jumps or snaps from one shape to the other when you twist it. If you deform it a little out of shape, it will snap back to the nearest of its two valid shapes. Here’s one I made very roughly from some light cardstock and transparent tape, in its two shapes, one with only slightly-concave long diagonals down its sides and the other much more twisted and folded up:</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img alt="Jumping octahedron" src="http://www.ics.uci.edu/~eppstein/pix/jumping-octahedron/1-m.jpg" style="border-style: solid; border-color: black;" width="315"/></td>
<td style="padding: 10px;"><img alt="Jumping octahedron" src="http://www.ics.uci.edu/~eppstein/pix/jumping-octahedron/2-m.jpg" style="border-style: solid; border-color: black;" width="315"/></td>
</tr></tbody></table></div>

<p>My model makes an interesting squelchy sound when I twist it from the more upright shape to the more twisted one, because these two shapes have different volumes and the air has to get out through the cracks between the faces. If I had perfectly sealed all these cracks, the pressure change would prevent it from changing shape. This change in volume is a big contrast from the Bricard octahedra and other continuously-flexible polyhedra, which must maintain constant volume as they flex.</p>

<p>The net I folded it from looks like this:</p>

<p style="text-align: center;"><img alt="Net for jumping octahedron" src="https://11011110.github.io/blog/assets/2020/jumping-octahedron-net.svg"/></p>

<p>It’s in two parts in order to make the seams of my model be symmetric, but also that way it fits better onto a single sheet of paper or card. It consists of two equilateral-triangle faces (the faces at the top and bottom of the model shown above) and six identical obtuse triangles on the sides. In my net and model, these triangles are isosceles, but that’s not important. The important part is that, if one of these triangles is projected onto the line between it and the equilateral triangle, its projected length is slightly more than the length of the connecting edge (because it’s an obtuse triangle) but not too long: longer by a factor strictly between one and</p>

\[\frac{1}{2}+\frac{1}{\sqrt{3}}\approx 1.07735.\]

<p>If you make the projection too short (with a right or acute side triangle shape) then it will not have two different shapes that maintain the same faces and convex-concave relation at each dihedral. If you make the projection too long, then you won’t be able to put it together at all while keeping all the faces flat. An explanation for some of this behavior can be seen from the diagram below, which shows the bottom equilateral triangle and one of the obtuse side triangles of the polyhedron, flattened out into a single plane, from a top view.</p>

<p style="text-align: center;"><img alt="Overhead view of two faces of the jumping octahedron" src="https://11011110.github.io/blog/assets/2020/jumping-octahedron-overhead.svg"/></p>

<p>If you fold these two triangles on their connecting edge, keeping the bottom equilateral triangle fixed but lifting the obtuse triangle into space, then the outer vertex of the obtuse triangle will rotate through a semicircle, but the plane of this semicircle is perpendicular to the plane of view of the diagram, so in top view it just looks like a line, the red line in the diagram. The edge along which the two triangles are attached is the axis of rotation, so it’s perpendicular to the semicircle of rotation and to the projected red line. If you fold all three edges of the bottom equilateral triangle at equal angles, then by symmetry the tips of the three folded obtuse triangles will form another equilateral triangle, and the size of this equilateral triangle will depend on the fold angle. If the vertices of this second equilateral triangle project to points on the yellow circle (the circumcircle of the bottom equilateral triangle) then this triangle will have exactly the correct size to attach the top face. This is only possible when the vertex of the obtuse triangle in the drawing is folded to a point that projects to of the two crossings of the red line and the yellow circle. The two fold angles for which this happens give the two shapes of the jumping octahedron.</p>

<p>The constraint that the side triangles be obtuse is what is needed to make the two crossing points of the red line and the circle be in the same arc of the circle relative to the vertices of the bottom equilateral triangle. The constraint that their projected length should be only a little bit longer than the side length of the equilateral triangle is what is needed to make the red line cross the circle at all. So these two constraints are necessary to make the jumping octahedron work. There’s one more necessary constraint: the height of the obtuse triangle above the edge connecting it to the equilateral triangle has to be large enough to reach both of the crossing points of the red line. When I started to make the model I was worried about a different geometric constraint: maybe the twisted state of the model is so twisted that its inner folded parts cross each other near the center of the model? But that can’t happen. If it did happen, the projected view of the model would have the side triangles folded into a position where they cover the center of the yellow circle. But that would mean that the top triangle’s vertices are too far around the yellow circle, past the point where the farthest point of the red line can cross.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104737012685827990">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-08-22T17:46:00Z</updated>
    <published>2020-08-22T17:46:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-31T01:37:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20013</id>
    <link href="https://gilkalai.wordpress.com/2020/08/22/quantum-matters/" rel="alternate" type="text/html"/>
    <title>Quantum Matters</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A comparison between the Google estimator U for the fidelity and two improved estimators that we studied  MLE (maximum likelihood estimator) and V (a variant of U). (More figures at the end of the post.) Here are some links on … <a href="https://gilkalai.wordpress.com/2020/08/22/quantum-matters/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2020/08/fig_2.jpeg"><img alt="" class="alignnone size-full wp-image-20101" height="472" src="https://gilkalai.files.wordpress.com/2020/08/fig_2.jpeg?w=640&amp;h=472" width="640"/></a></p>
<p><span style="color: #ff0000;">A comparison between the Google estimator U for the fidelity and two improved estimators that we studied  MLE (maximum likelihood estimator) and V (a variant of U). (More figures at the end of the post.)</span></p>
<p>Here are some links on quantum matters. I hope to return to them in more detail in some future posts.</p>
<h2>1. A <a href="https://gilkalai.files.wordpress.com/2019/11/stat-quantum2.pdf">paper</a> with Yosi Rinott and Tomer Shoham on the Statistics of Google’s experiment</h2>
<p>Yosef Rinott, Tomer Shoham and Gil Kalai:  <a href="https://gilkalai.files.wordpress.com/2019/11/stat-quantum2.pdf">Statistical aspects of the quantum supremacy demonstration</a>, (<a href="https://arxiv.org/abs/2008.05177">arXive</a>)</p>
<p><strong>Abstract:</strong></p>
<blockquote><p><span style="color: #0000ff;"><em>The notable claim of quantum supremacy presented by Google’s team in 2019 consists of demonstrating the ability of a quantum circuit to generate, albeit with considerable noise, bitstrings from a distribution that is considered hard to simulate on classical computers. Verifying that the generated data is indeed from the claimed distribution and assessing the circuit’s noise level and its fidelity is a purely statistical undertaking.</em></span></p>
<p><span style="color: #0000ff;"><em>The objective of this paper is to explain the relations between quantum computing and some of the statistical aspects involved in demonstrating quantum supremacy in terms that are accessible to statisticians, computer scientists, and mathematicians.</em></span></p>
<p><span style="color: #0000ff;"><em>Starting with the statistical analysis in Google’s demonstration, which we explain, we study various estimators of the fidelity, and different approaches to testing the distributions generated by the quantum computer. We propose different noise models, and discuss their implications. A preliminary study of the Google data, focusing mostly on circuits of 12 and 14 qubits is discussed throughout the paper.</em></span></p></blockquote>
<p>I am greatly enjoying working with Yosi and Tomer, and I hope to devote a special post to the very interesting statistics of the Google supremacy experiment.</p>
<h2/>
<h2>2. My paper <a href="https://gilkalai.files.wordpress.com/2020/08/laws-blog2.pdf">The Argument against Quantum Computers, the Quantum Laws of Nature, and Google’s Supremacy Claims</a></h2>
<p>Here is how the paper concludes</p>
<blockquote><p><span style="color: #0000ff;"><em>Over the past four decades, the very idea of quantum computation has led to many advances in several areas of physics, engineering, computer science, and mathematics. I expect that the most important application will eventually be the understanding of the impossibility of quantum error-correction and quantum computation. Overall, the debate over quantum computing is a fascinating one, and I can see a clear silver lining: major advances in human ability to simulate quantum physics and quantum chemistry are expected to emerge if quantum computational supremacy can be demonstrated and quantum computers can be built, but also if quantum computational supremacy cannot be demonstrated and quantum computers cannot be built.</em></span></p>
<p><span style="color: #0000ff;"><em>Some of the insights and methods characteristic of the area of quantum computation might be useful for classical computation of realistic quantum systems – which is, apparently, what nature does.</em></span></p></blockquote>
<p> </p>
<p>The link above is the most recent version that will be updated; Here is the <a href="https://arxiv.org/abs/2008.05188">arXive version</a>. A discussion on <a href="https://news.ycombinator.com/item?id=23291071">Hacker News</a>.</p>
<h2/>
<h2>3. My Dec 2019 surprise lecture and the panel discussion</h2>
<p>My Dec  19 2019 (B.C.) surprise lecture at the mathematics of quantum computing school and the afternoon panel on the same day. It turned out that the lecture was videotaped. The slides can be seen in <a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/">this post</a>. Remarkably, social distancing was pioneered by the session chair toward the end of the lecture (while not justified in that case).</p>
<p/>
<p>Here once again again is <a href="https://youtu.be/_Yb7uIGBynU">the link for the panel discussion on quantum supremacy</a> of the same day (<a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/">reviewed here</a>) . Here is a quote of mine from the panel.</p>
<blockquote><p><em><span style="color: #0000ff;">Of course, it is important to think what are the implications of quantum supremacy, is it useful? what does it say on the extended Church-Turing thesis? on prospects for quantum error-correction and universal quantum computers? etc. but I think that in the next few years one thing that we need to also concentrate on is the following question: Is the Google experiment correct? Is this a correct scientific verification of quantum supremacy?</span></em></p></blockquote>
<h2/>
<h2>4. My July 15 USTLC lecture</h2>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/4slides.png"><img alt="" class="alignnone size-full wp-image-20091" height="364" src="https://gilkalai.files.wordpress.com/2020/08/4slides.png?w=640&amp;h=364" width="640"/></a></p>
<p><span style="color: #ff0000;">Four slides from my USTLC zoom lecture</span><span style="color: #ff0000;">. (Click to enlarge.)<br/>
</span></p>
<p>Here is the <a href="https://idc-il.zoom.us/rec/share/4v58MpbZ-CBJG7OO1E3SYYN-P426aaa82ndLr_cMyEgOuIwdOStnnIw18Xsg0dUr?fbclid=IwAR31ShatGHJ1bWpVCdBPUoWhG3VjqmhfD1kQBFVLGzmvtNlWNMW-T58_0dw">videotaped Zoom presentation</a> and <a href="https://gilkalai.files.wordpress.com/2019/11/july1.pptx">here are the slides</a>.</p>
<h2/>
<h2>5. A small taste of quantum poetry for the skeptics. (A full post is coming.)</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/dslide16.png"><img alt="" class="alignnone size-large wp-image-19013" height="362" src="https://gilkalai.files.wordpress.com/2019/12/dslide16.png?w=640&amp;h=362" width="640"/></a></p>
<p><span style="color: #ff0000;">Poems by Peter Shor and Renan Gross (click to enlarge)</span></p>
<p>Peter Shor <a href="https://twitter.com/PeterShor1/status/1199299777743204354">pioneered</a> quantum poetry for the skeptics over Twitter. There were many very nice contributions all over social media by <a href="https://gilkalai.files.wordpress.com/2019/12/dslide16.png">Renan Gross</a>, John Dowling, Vidit Nanda, ⟨dl|yonge|mallo⟩, Alfred Marcel Bruckstein, Kenneth Regan, and others. <strong>Keep the quantum poems coming!</strong> Of course, the poems should be taken with humor. Here is a small taste.</p>
<h3><span style="color: #993366;">My short response to Peter’s poem</span></h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>Understanding nature and ourselves is a worthy dream</em></span><br/>
<span style="color: #0000ff;"><em>Requiring no interaction with the supreme</em></span></h3>
</blockquote>
<h3><span style="color: #993366;">Limericks</span></h3>
<h3>Jon Dowling</h3>
<p><span id="more-20013"/></p>
<blockquote><p><em>A quantum computer from Google,</em><br/>
<em>Turned the Church-Turing thesis to strudel.</em><br/>
<em>And yet there remain,</em><br/>
<em>Many doubting this claim,</em><br/>
<em>And we lash all of them with wet noodles.</em></p></blockquote>
<h3>Avi Wigderson</h3>
<blockquote><p><em>“There once was a quantum computer</em><br/>
<em>Whose pet was a five-legged hamster …”</em><br/>
<em>So Peter and Gil</em><br/>
<em>Their grandchildren will</em><br/>
<em>Tell “…happy they lived ever after”</em></p></blockquote>
<p>Avi suggests a kids’ chorus saying “yeah, right” or “sure, sure”, after each line</p>
<h3><span style="color: #993366;">Six-word stories</span></h3>
<h3>Ehud Friedgut</h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>For sale: <span class="il">quantum</span> computer. Never used.</em></span></h3>
</blockquote>
<h3>Another 6-word story (mine) with a rhyme (of some sort)</h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>Michelson and Morley weren’t </em></span><em><strong><span style="color: #0000ff;">G</span><span style="color: #ff0000;">o</span><span style="color: #ffcc00;">o</span><span style="color: #0000ff;">g</span><span style="color: #339966;">l</span><span style="color: #ff0000;">e</span></strong></em><span style="color: #0000ff;"><em> employees.</em></span></h3>
</blockquote>
<h2/>
<h2>6. More figures from my paper with Yosi and Tomer.</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/plot_3.jpeg"><img alt="" class="alignnone size-full wp-image-20102" height="350" src="https://gilkalai.files.wordpress.com/2020/08/plot_3.jpeg?w=640&amp;h=350" width="640"/></a></p>
<p><span style="color: #ff0000;">Various estimators for the fidelity for the Google data compared to simulations. </span></p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/fig_8.jpeg"><img alt="" class="alignnone size-full wp-image-20103" height="519" src="https://gilkalai.files.wordpress.com/2020/08/fig_8.jpeg?w=640&amp;h=519" width="640"/></a></p>
<p><span style="color: #ff0000;">The model expected values compared to the empirical distribution. On the left for the real data and on the right for simulated data.  As it turned out the Google noise model does not fit for the sample data. (Our readout model provides only a small improvement.)  </span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/hists.jpeg"><img alt="" class="alignnone size-full wp-image-20104" height="249" src="https://gilkalai.files.wordpress.com/2020/08/hists.jpeg?w=640&amp;h=249" width="640"/></a></p>
<p><span style="color: #ff0000;">The size biased distribution fits the model very well.</span></p></div>
    </content>
    <updated>2020-08-22T17:02:49Z</updated>
    <published>2020-08-22T17:02:49Z</published>
    <category term="Quantum"/>
    <category term="Statistics"/>
    <category term="Tomer Shoham"/>
    <category term="Yosi Rinott"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-08-31T23:44:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/127</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/127" rel="alternate" type="text/html"/>
    <title>TR20-127 |  $k$-Forrelation Optimally Separates Quantum and Classical Query Complexity | 

	Nikhil Bansal, 

	Makrand Sinha</title>
    <summary>Aaronson and Ambainis (SICOMP '18) showed that any partial function on $N$ bits that can be computed with an advantage $\delta$ over a random guess by making $q$ quantum queries, can also be computed classically with an advantage $\delta/2$ by a randomized decision tree making ${O}_q(N^{1-\frac{1}{2q}}\delta^{-2})$ queries. Moreover, they conjectured the $k$-Forrelation problem --- a partial function that can be computed with $q = \lceil k/2 \rceil$ quantum queries --- to be a suitable candidate for exhibiting such an extremal separation. 
    
     We prove their conjecture by showing a tight lower bound of $\widetilde{\Omega}_k(N^{1-1/k})$ for the randomized query complexity of $k$-Forrelation, where the advantage $\delta = 1/\mathrm{polylog}^k(N)$ and $\widetilde{\Omega}_k$ hides $\mathrm{polylog}^k(N)$ factors. Our proof relies on classical Gaussian tools, in particular, Gaussian interpolation and Gaussian integration by parts, and in fact, shows a more general statement, that to prove lower bounds for $k$-Forrelation against a family of functions, it suffices to bound the $\ell_1$-weight of the Fourier coefficients at levels $k, 2k, 3k, \ldots, (k-1)k$ for functions in the family.</summary>
    <updated>2020-08-21T19:02:19Z</updated>
    <published>2020-08-21T19:02:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-31T23:43:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/08/21/phd-or-postdoc-at-goethe-university-frankfurt-apply-by-august-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/08/21/phd-or-postdoc-at-goethe-university-frankfurt-apply-by-august-31-2020/" rel="alternate" type="text/html"/>
    <title>PhD or Postdoc at Goethe University Frankfurt (apply by August 31, 2020)</title>
    <summary>The research group by Holger Dell at Goethe University Frankfurt is inviting applications for a three-year PhD or Postdoc position, starting at the earliest possible date. Potential topics include the algorithmic theory of network science, algebraic graph algorithms, fine-grained and parameterized complexity, “classical” complexity theory, as well as adjacent areas. Website: https://www.t.cs.uni-frankfurt.de/positions/ Email: recruiting2020@holgerdell.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The research group by Holger Dell at Goethe University Frankfurt is inviting applications for a three-year PhD or Postdoc position, starting at the earliest possible date. Potential topics include the algorithmic theory of network science, algebraic graph algorithms, fine-grained and parameterized complexity, “classical” complexity theory, as well as adjacent areas.</p>
<p>Website: <a href="https://www.t.cs.uni-frankfurt.de/positions/">https://www.t.cs.uni-frankfurt.de/positions/</a><br/>
Email: recruiting2020@holgerdell.com</p></div>
    </content>
    <updated>2020-08-21T14:41:55Z</updated>
    <published>2020-08-21T14:41:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-31T23:44:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17421</id>
    <link href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/" rel="alternate" type="text/html"/>
    <title>Logical Complexity of Proofs</title>
    <summary>If you cannot find proofs, talk about them. Robert Reckhow with his advsior Stephen Cook famously started the formal study of the complexity of proofs with their 1979 paper. They were interested in the length of the shortest proofs of propositional statements. Georg Kreisel and others may have looked at proof length earlier, but one […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>If you cannot find proofs, talk about them.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/rr/" rel="attachment wp-att-17427"><img alt="" class="alignright size-medium wp-image-17427" height="119" src="https://rjlipton.files.wordpress.com/2020/08/rr.png?w=300&amp;h=119" width="300"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Robert Reckhow with his advsior Stephen Cook famously started the formal study of the complexity of proofs with their 1979 <a href="https://www.cs.toronto.edu/~sacook/homepage/cook_reckhow.pdf">paper</a>. They were interested in the length of the shortest <a href="https://en.wikipedia.org/wiki/Proof_complexity">proofs</a> of propositional statements. Georg Kreisel and others may have looked at proof length earlier, but one of the key insights of Reckhow and Cook is that low level propositional logic is important.</p>
<p>
Today I thought we might look at the complexity of proofs.<br/>
<span id="more-17421"/></p>
<p>
Cook and Reckhow were motivated by issues like: How hard is it to prove that a graph has no clique of a certain size? Or how hard to prove that some program halts on all inputs of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>? All of these questions ask about the length of proofs in a precise sense. Proofs have been around forever, back to Euclid at least, but Cook and Reckhow were the first to formally study the lengths of proofs. </p>
<p>
They were not directly interested in actual proofs. The kind you can find in the <a href="https://arxiv.org/archive/math">arXiv</a> or in a math journal, or at a conference—online or not. The kind that are in their paper.<br/>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/paper-5/" rel="attachment wp-att-17432"><img alt="" class="aligncenter size-medium wp-image-17432" height="60" src="https://rjlipton.files.wordpress.com/2020/08/paper.png?w=300&amp;h=60" width="300"/></a></p>
<p>We are talking today about these types of proofs. Not proofs that graphs have cliques. But proofs that a no planar graph can have a <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/> clique. </p>
<p><a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/unknown-144/" rel="attachment wp-att-17430"><img alt="" class="aligncenter size-full wp-image-17430" src="https://rjlipton.files.wordpress.com/2020/08/unknown.png?w=600"/></a></p>
<p>
</p><p/><h2> Proofs </h2><p/>
<p/><p>
Proofs are what we strive to find ever day. They the coin that measures progress in a mathematical field like complexity theory. We do sometimes work out examples, sometimes do computations to confirm conjectures on small examples, sometimes consider analogies to other proofs. But mostly we want to understand proofs. We want to create new ones and understand others proofs. </p>
<p>
Years ago when studying the graph isomorphism problem, I did some extensive computations for the random case. That is for the case of isomorphism for a random dense graphs against a worst case other graph. The computations helped me improve my result. It did not yield a proof, of course, but helped me realize that a certain lemma could be improved from a bound <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> to <img alt="{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(1)}"/>. My results were dominated by <a href="https://www.researchgate.net/profile/Stanley_Selkow/publication/220618511_Random_Graph_Isomorphism/links/00463537d337e6a35d000000/Random-Graph-Isomorphism.pdf">paper</a> of Laszlo Babai, Paul Erdös, and Stanley Selkow. Oh well. </p>
<p>
</p><p/><h2> Proofs Complexity </h2><p/>
<p/><p>
There are several measures of complexity for proofs. One is the length. Long proofs are difficult to find, difficult to write up, difficult to read, and difficult to check. Another less obvious measure is the logical structure of a proof. What does this mean?</p>
<p>
Our idea is that a proof can be modeled by a formula from propositional logic. The <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> is what we are trying to prove and the letters <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and so on are for statements we already know.  </p>
<li>
<img alt="{(A \rightarrow P)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A \rightarrow P)}"/>  This is a direct proof. <p/>
</li><li>
<img alt="{(\neg P \rightarrow \neg A)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cneg+P+%5Crightarrow+%5Cneg+A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\neg P \rightarrow \neg A)}"/>  This is a proof by contradiction. <p/>
</li><li>
<img alt="{( A \vee \neg A \rightarrow P)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28+A+%5Cvee+%5Cneg+A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{( A \vee \neg A \rightarrow P)}"/>  This is proof that uses a statement <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> that may be true or false. <p/>
<p>
The last is a slight cheat, we use <img alt="{A \vee \neg A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cvee+%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \vee \neg A}"/> to stand for a kind of axiom. A perfect example is from number theory. Let <img alt="{\pi(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi(X)}"/> be the number of primes less than <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and the function <img alt="{li(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{li(x)}"/> the <a href="https://en.wikipedia.org/w/index.php?title=Logarithmic_integral_function&amp;action=edit&amp;section=1">logarithmic function</a>. 	</p>
<p align="center"><img alt="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%3D+%5Cint_0%5Ex+%5Cfrac%7Bdt%7D%7B%5Cln+t%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. "/></p>
<p>The prime number <a href="https://en.wikipedia.org/wiki/Prime_number_theorem">theorem</a> says that 	</p>
<p align="center"><img alt="\displaystyle  \pi(x) = li(x) + E(x), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+%3D+li%28x%29+%2B+E%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) = li(x) + E(x), "/></p>
<p>an error term. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/graph/" rel="attachment wp-att-17425"><img alt="" class="aligncenter size-medium wp-image-17425" height="171" src="https://rjlipton.files.wordpress.com/2020/08/graph.png?w=300&amp;h=171" width="300"/></a>
</td>
</tr>
<tr>
</tr>
</tbody></table>
<p>
It was noted that <img alt="{li(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{li(x)}"/> is larger than <img alt="{\pi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi(x)}"/> for known values. The obvious question was that could 	</p>
<p align="center"><img alt="\displaystyle  li(x) \ge \pi(x), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%5Cge+%5Cpi%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  li(x) \ge \pi(x), "/></p>
<p>be always true? If so this would be an interesting inequality. In 1914 John Littlewood famously <a href="https://www.google.com/books/edition/_/2SUrpE8NK6sC?hl=en&amp;gbpv=1&amp;pg=PA33&amp;dq=John+Littlewood+pi+nd+li">proved</a> that this was not true: </p>
<blockquote><p><b>Theorem 1</b> <em> If the Riemann Hypothesis is true: 	</em></p><em>
<p align="center"><img alt="\displaystyle  \pi(x) - li(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) - li(x) "/></p>
<p>is infinitely often positive and negative. If the Riemann Hypothesis is false: 	</p>
<p align="center"><img alt="\displaystyle  \pi(x) - li(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) - li(x) "/></p>
</em><p><em>is infinitely often positive and negative. </em>
</p></blockquote>
<p/><p>
Thus he proved that 	</p>
<p align="center"><img alt="\displaystyle  \pi(x) - li(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \pi(x) - li(x) "/></p>
<p>is infinitely often positive and negative whether the the Riemann is true or not. </p>
<p>
</p><p/><h2> Proofs in Trouble </h2><p/>
<p/><p>
A sign of a proof in danger is, in my opinion, is not just the length. A better measure I think is the logical flow of proof. I know of no actual proof that uses this structure: 	</p>
<p align="center"><img alt="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28A+%5Crightarrow+B%29+%5Crightarrow+%28%28A+%5Cvee+C%29+%5Crightarrow+%28B+%5Cvee+C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) "/></p>
<p>Do you? Even if your proof is only a few lines or even pages, if the high level flow was the above tautology I would be worried. </p>
<p>
Another example is <img alt="{P \rightarrow P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%5Crightarrow+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P \rightarrow P}"/>. This of course is a circular proof. It seems hard to believe we would actually do this, but it has happen. The key is that no one says: I will assume the theorem to prove it. The flaw is disguised better than that.</p>
<p>
I cannot formally define this measure. Perhaps it is known, but I do think that it would be an additional measure. For actual proofs, ones we use every day, perhaps it would be valuable. I know I have looked at an attempted proof of X and noticed the logical flow in this sense was too complex. So complex that it was wrong. The author of the potential proof was me. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is this measure, the logical flow of a proof, of any interest? </p>
<p/></li></font></font></div>
    </content>
    <updated>2020-08-19T13:00:52Z</updated>
    <published>2020-08-19T13:00:52Z</published>
    <category term="Oldies"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="complexity proof"/>
    <category term="Logic"/>
    <category term="logical flow"/>
    <category term="proof length"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-31T23:44:18Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-41257542542066199</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/41257542542066199/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=41257542542066199" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/41257542542066199" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/41257542542066199" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2020/08/moment-multicalibration-for-uncertainty.html" rel="alternate" type="text/html"/>
    <title>Moment Multicalibration for Uncertainty Estimation</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This blog post is about<a href="https://arxiv.org/abs/2008.08037" target="_blank"> a new paper</a> that I'm excited about, which is joint work with <a href="https://www.cis.upenn.edu/~chrjung/" target="_blank">Chris Jung</a>,<a href="https://economics.sas.upenn.edu/people/changhwa-lee" target="_blank"> Changhwa Lee</a>, <a href="https://sites.google.com/view/malleshpai/">Mallesh Pai</a>, and <a href="https://sites.google.com/site/quaerereverum9/">Ricky Vohra</a>. <div><br/></div><div>Suppose you are diagnosed with hypertension, and your doctor recommends that you take a certain drug to lower your blood pressure. The latest research, she tells you, finds that the drug lowers diastolic blood pressure by an average of 10 mm Hg. You remember your statistics class from college, and so you ask about confidence intervals. She looks up the paper, and tells you that it reports a 95% confidence interval of [5, 15]. How should you interpret this? </div><div><br/></div><div>What you might naively hope is that [5, 15] represents a <i>conditional prediction interval</i>. If you have some set of observable features $x$, and a label $y$ (in this case corresponding to your decrease in diastolic blood pressure after taking the drug), a 95% conditional prediction interval would promise that:</div><div>$$\Pr_y [y \in [5, 15] | x] \geq 0.95$$</div><div><br/></div><div>In other words, a conditional prediction interval would promise that given all of your observed features, <i>over the unrealized/unmeasured randomness of the world</i>, there is a 95% chance that your diastolic blood pressure will decrease by between 5 and 15 points. </div><div><br/></div><div>But if you think about it, coming up with a conditional prediction interval is essentially impossible in a rich feature space. If $x$ contains lots of information about you, then probably there was nobody in the original study population that exactly matched your set of features $x$, and so we have no information at all about the conditional distribution on $y$ given $x$ --- i.e. no samples at all from the distribution over which our coverage probability supposedly holds! So how can you expect any sort of promise at all? There are two typical ways around this difficulty. </div><div><br/></div><div>The first is to make heroic assumptions about the data generation process. For example, if we assume that the world looks like an ordinary least squares model, and that there is a linear relationship between $y$ and $x$, then we can form a confidence region around the parameters of the model, and from that derive prediction intervals. But these prediction intervals are not valid if the model fails to hold, which it inevitably will. </div><div><br/></div><div>The second is to give up on conditional prediction intervals, and instead give <i>marginal prediction intervals</i>. This is what the <a href="https://arxiv.org/abs/0706.3188" target="_blank">conformal prediction</a> literature aims to do. A marginal prediction interval looks quite similar to a conditional prediction interval (at least syntactically), and promises:</div><div>$$\Pr_{(x,y)} [y \in [5, 15] ] \geq 0.95$$</div><div><br/></div><div>Rather than conditioning on your features $x$, a marginal prediction interval averages over all people, and promises that 95% of people who take the drug have their diastolic blood pressure lowered by between 5 and 15 points. But the semantics of this promise are quite different than that of a conditional prediction interval. Because the average is now taken over a large, heterogeneous population, very little is promised to <i>you</i>. For example, it might be that for patients in your demographic group (e.g. middle aged women with Sephardic Jewish ancestry and a family history of diabetes) that the drug is actually expected to raise blood pressure rather than lower it. Because this subgroup represents less than 5% of the population, it is entirely consistent with the marginal prediction interval being correct. Of course, if you are lucky, then perhaps someone has conducted a study of people from this demographic group and has computed marginal prediction intervals over it! But what if there are multiple different groups that you are a member of, over which the results seem to conflict? For example, you might also have a low BMI value and have unusually good cholesterol readings --- features of a group for which the drug works unusually well. Which uncertainty estimate should you trust, if you are a member of both groups? </div><div><br/></div><div>These concerns actually arise already when we think about the semantics of mean estimations ("the expected drop in blood pressure amongst patients who take this drug is 10 mm Hg"). Ideally, if you were a patient with features $x$, then 10 would be an estimate of $\mathbb{E}[y | x]$. But just as with uncertainty estimation, in a large feature space, we typically have no information about the distribution on $y$ conditional on $x$ (because we have never met anyone exactly like <i>you</i> before), and so instead what we have is just an estimate of $\mathbb{E}[y]$ --- i.e. averaging over people. If you have a method of making predictions $f(x)$ as a function of features $x$, then a standard performance metric is <i>calibration</i> --- which informally asks that for every prediction $p$, amongst all people for whom we predicted $f(x) = p$, the average of the realized labels $y$ should be $p$. Again, estimates of this form promise little to individuals, because they are averages over a large and heterogeneous population.   </div><div><br/></div><div>Several years ago, <a href="https://arxiv.org/abs/1711.08513" target="_blank">Hebert-Johnson et al.</a> proposed a nice way to interpolate between the (impossible) ideal of offering conditional mean predictions  $f(x) = \mathbb{E}[y | x]$, and the weak guarantee of merely offering calibrated predictions $f$. Roughly speaking, they proposed to specify a very large collection of potentially intersecting groups $G$ (representing e.g. demographic groups like Sephardic Jewish women with a family history of diabetes, and hypertensive patients with low cholesterol and BMI values, etc) and to ask that a trained predictor be <i>simultaniously</i> calibrated on each sufficiently large group in $G$. They showed how to accomplish this using a polynomially sized sample from the underlying distribution, with polynomial running time overhead, on top of the cost of solving learning problems over $G$. </div><div><br/></div><div>In our paper, we --- roughly speaking --- show how to accomplish the same thing, but for variances and other higher moments, in addition to just means. And our "multicalibrated moment estimates" can be used to construct prediction intervals in exactly the same way that real moments of the conditional label distribution could be used. If you used the real (unknown) label distribution moments, you would have gotten conditional prediction intervals. If you use our multi-calibrated moments, you get marginal prediction intervals that are simultaneously valid as averaged over each of the groups in $G$. So, for example, our hypertensive patient above could interpret her prediction interval --- if it was constructed from multicalibrated moment estimates computed from her features --- as an average over each of the demographic groups that she is a member of (so long as they are contained within $G$), and all of those interpretations would be simultaneously valid. </div><div><br/></div><div>I'll leave the details to the paper --- including what exactly we mean by "moment multicalibration". I'll just note that a major difficulty is that variances and higher moments --- unlike expectations --- do not combine linearly, so it is no longer sensible to ask that "amongst all people for whom we predicted variance v, the true variance should be v" --- because even the true conditional label variances do not satisfy this property. But it <i>is </i>sensible to ask that a pair of mean and moment predictions be calibrated in this way: "amongst all people for whom we predicted mean $\mu$ and variance v, the true mean should be $\mu$ and the true variance should be $v$." This is what we call "mean-conditioned moment calibration", and it is satisfied by the true distributional moments. </div><div><br/></div><div>The paper is here: <a href="https://arxiv.org/abs/2008.08037">Moment Multicalibration for Uncertainty Estimation</a>.</div><div><br/></div></div>
    </content>
    <updated>2020-08-19T11:47:00Z</updated>
    <published>2020-08-19T11:47:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2020-08-31T08:27:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/126</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/126" rel="alternate" type="text/html"/>
    <title>TR20-126 |  Indistinguishability Obfuscation from Well-Founded Assumptions | 

	Aayush  Jain, 

	Huijia Lin, 

	Amit Sahai</title>
    <summary>In this work, we show how to construct indistinguishability obfuscation from subexponential hardness of four well-founded assumptions. We prove:

Let $\tau \in (0,\infty), \delta \in (0,1), \epsilon \in (0,1)$ be arbitrary constants. Assume sub-exponential security of the following assumptions, where $\lambda$ is a security parameter, and the parameters $\ell,k,n$ below are large enough polynomials in $\lambda$:

- The SXDH assumption on asymmetric bilinear groups of a prime order $p = O(2^\lambda)$,

- The LWE assumption over $\mathbb{Z}_{p}$ with subexponential modulus-to-noise ratio $2^{k^\epsilon}$, where $k$ is the dimension of the LWE secret,

- The LPN assumption over $\mathbb{Z}_p$ with polynomially many LPN samples and error rate $1/\ell^\delta$, where $\ell$ is the dimension of the LPN secret,

- The existence of a Boolean PRG in $\mathsf{NC}^0$ with stretch $n^{1+\tau}$,
 
Then, (subexponentially secure) indistinguishability obfuscation for all polynomial-size circuits exists.</summary>
    <updated>2020-08-19T11:37:19Z</updated>
    <published>2020-08-19T11:37:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-31T23:43:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/125</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/125" rel="alternate" type="text/html"/>
    <title>TR20-125 |  Efficient reconstruction of depth three circuits with top fan-in two | 

	Gaurav  Sinha</title>
    <summary>In this paper we develop efficient randomized algorithms to solve the black-box reconstruction problem for polynomials(over finite fields) computable by depth three arithmetic circuits with alternating addition/multiplication gates, such that top(output) gate is an addition gate with in-degree $2$. Such circuits naturally compute polynomials of the form $G\times(T_1 + T_2)$, where $G,T_1,T_2$ are product of affine forms computed at the first(addition) layer in the circuit, and polynomials $T_1,T_2$ have no common factors. Rank of such a circuit is defined to be the dimension of vector space spanned by all affine factors of $T_1$ and $T_2$. For any polynomial $f$ computable by such a circuit, $rank(f)$ is defined to be the minimum rank of any such circuit computing it. Our work develops randomized algorithms, which take as input a black-box computing polynomial $f$, with coefficients in a finite field $\mathbb{F}$, exhibiting such a circuit. Here are the results. 

$[$Low rank$]:$ When $5\leq r = rank(f) = O(\log^3 d)$, it runs in time $(nd^{\log^3d}\log |\mathbb{F}|)^{O(1)}$ and outputs a depth three circuit computing $f$ (with high probability), with top addition gate having in-degree $\leq d^{rank(f)}$.

$[$High rank$]:$ When $rank(f) = \Omega(\log^3 d)$, it runs in time $(nd\log |\mathbb{F}|)^{O(1)}$, and with high probability outputs a depth three circuit computing $f$, with top addition gate having in-degree $2$.

Prior to our work, black-box reconstruction for this circuit class was addressed in [Shp07, KS09, Sin16b]. Reconstruction algorithm in [Shp07] runs in time quasi-polynomial in $n,d,|\mathbb{F}|$ and that in [KS09] is quasi-polynomial in $d,|\mathbb{F}|$. Algorithm in [Sin16b] works only for polynomials over characteristic zero fields. Thus ours is the first blackbox reconstruction algorithm for this class of circuits that runs in time polynomial in $\log |\mathbb{F}|$. This problem has been mentioned as an open problem in [GKL12] (STOC 2012). In the high rank case, our algorithm runs in $(nd\log|\mathbb{F}|)^{O(1)}$ time, thereby significantly improving the existing algorithms in [Shp07, KS09].</summary>
    <updated>2020-08-17T19:11:47Z</updated>
    <published>2020-08-17T19:11:47Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-31T23:43:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/124</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/124" rel="alternate" type="text/html"/>
    <title>TR20-124 |  A Strong XOR Lemma for Randomized Query Complexity | 

	Joshua Brody, 

	JaeTak Kim, 

	Peem Lerdputtipongporn, 

	Hariharan Srinivasulu</title>
    <summary>We give a strong direct sum theorem for computing $XOR \circ g$.  Specifically, we show that the randomized query complexity of computing the XOR of $k$ instances of $g$ satisfies $\bar{R}_\varepsilon(XOR \circ g)=\Theta(\bar{R}_{\varepsilon/k}(g))$.  This matches the naive success amplification bound and answers a question of Blais and Brody.

As a consequence of our strong direct sum theorem, we give a total function $g$ for which $R(XOR \circ g) = \Theta(k\log(k)R(g))$, answering an open question from Ben-David et al.</summary>
    <updated>2020-08-17T13:19:41Z</updated>
    <published>2020-08-17T13:19:41Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-31T23:43:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/123</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/123" rel="alternate" type="text/html"/>
    <title>TR20-123 |  An Optimal Tester for k-Linear | 

	Nader Bshouty</title>
    <summary>A Boolean function $f:\{0,1\}^n\to \{0,1\}$ is $k$-linear if it returns the sum (over the binary field $F_2$) of $k$ coordinates of the input. In this paper, we study property testing of the classes $k$-Linear, the class of all $k$-linear functions, and $k$-Linear$^*$, the class $\cup_{j=0}^kj$-Linear.
We give a non-adaptive distribution-free two-sided $\epsilon$-tester for $k$-Linear that makes
$$O\left(k\log k+\frac{1}{\epsilon}\right)$$ queries.
This matches the lower bound known from the literature.

We then give a non-adaptive distribution-free one-sided $\epsilon$-tester for $k$-Linear$^*$ that makes the same number of queries and show that any non-adaptive uniform-distribution one-sided $\epsilon$-tester for $k$-Linear must make at least $ \tilde\Omega(k)\log n+\Omega(1/\epsilon)$ queries. The latter bound, almost matches the upper bound $O(k\log n+1/\epsilon)$ known from the literature. We then show that any adaptive uniform-distribution one-sided $\epsilon$-tester for $k$-Linear must make at least $\tilde\Omega(\sqrt{k})\log n+\Omega(1/\epsilon)$ queries.</summary>
    <updated>2020-08-17T13:17:37Z</updated>
    <published>2020-08-17T13:17:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-31T23:43:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6748297921609096715</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6748297921609096715/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/what-if-history-of-science-factoring.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6748297921609096715" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6748297921609096715" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/what-if-history-of-science-factoring.html" rel="alternate" type="text/html"/>
    <title>Mathematics is not commutative</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In my poll of P vs NP and other issues, one of the questions was<br/>
<br/>
<br/>
                             <i>Is factoring in P?</i><br/>
<i><br/></i>
One of the most interesting answers was<br/>
<br/>
<br/>
                            <i> I don't really see why it shouldn't be. - Peter Shor</i><br/>
<i><br/></i>
Recall that Peter Shor proved Factoring is in Quantum-P which lead to intense interest in Quantum Computing.<br/>
<br/>
1) What if factoring was in P and this was shown before Shor's algorithm? Would Shor or someone else have ever proven factoring in quantum P? Would there be as much intense interest in quantum computing as there is now? Perhaps by physicists more than CS people?<br/>
<br/>
2) What if factoring was in P and this was shown before RSA? Where would crypto be now? Zip drives with a googleplex random (or nearly random) bits and more 1-time pads? More lattice based crypto? Or RSA but with larger numbers? This may depend on how good the factoring algorithm is.<br/>
<br/>
3) More generally, how much does the order of events matter for science?<br/>
<br/>
a) If the Banach-Tarski paradox was discovered early on, would we have just tossed out the Axiom of Choice before so much more was build on it? Darling thinks we should toss out AC NOW because of Banach-Tarski.<br/>
<br/>
b) In the model of set theory L you can do ALL of math except some parts of set theory and maybe a few other things (note quite: Harvey Friedman has found some combinatorial statements that need large cardinals to prove). Had L been discovered earlier then could we all now be working in L (except a few people who look at other models, but they are not in the mainstream)? We might know more about L and less about forcing. We would KNOW that AC and CH are true. Or we would think we know.<br/>
<br/>
c) If  Engineers were the first ones to look at SAT and reductions, might they have been content to know that  if SAT \le A then A is probably hard? No need for the Cook-Levin Theorem! And then when someone proved Cook-Levin would the Engineers not really cares since they already knew SAT was hard?<br/>
<br/>d) I can imagine Ramsey's Theorem being discovered much later for some application, or perhaps never being discovered at all.<div><br/></div><div>e) VDW's theorem has so few application, I can imagine it never being discovered. </div><div><br/></div><div>4) There are cases where if A was discovered before B then B has an easy proof, whereas if B was discovered before A, then B has a hard proof. I'll give one example:</div><div><br/></div><div>Given HALT is undecidable, Godel's theorem is easy.</div><div><br/></div><div>Assume HALT is undecidable. </div><div><br/></div><div>Let STAT(e) be the statement M_e(0) does not  halt.</div><div><br/></div><div>There is some e such that M_e(0) does not halt  but ZFC cannot prove this.</div><div><br/></div><div>PROOF: Assume, By Way of Contradiction that for all e such that M_e(0) does not halt,</div><div>ZFC could prove this. Then HALT is DECIDABLE:</div><div><br/>Given e, run M_e(0) and at the same time enumerate all proofs in ZFC. It is guaranteed that</div><div>you will either find M_e(0) halts or a proof that M_e(0) does not halt. Hence you will,</div><div>in finite time, know if M_e(0) halts OR NOT.</div><div><br/></div><div>END OF PROOF</div><div><br/></div><div>Is the sequence of events where HALT is proven undecidable  before Godel's theorem plausible.</div><div>I  think so</div><div><br/></div><div>I INVITE my readers to give there own examples of when Math is not commutative- meaning that</div><div>the order of events matters.</div><div>
<br/></div></div>
    </content>
    <updated>2020-08-17T12:35:00Z</updated>
    <published>2020-08-17T12:35:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-31T08:25:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/122</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/122" rel="alternate" type="text/html"/>
    <title>TR20-122 |  Size Bounds on Low Depth Circuits for Promise Majority | 

	Joshua Cook</title>
    <summary>We give two results on the size of AC0 circuits computing promise majority. $\epsilon$-promise majority is majority promised that either at most an $\epsilon$ fraction of the input bits are 1, or at most $\epsilon$ are 0.

First, we show super quadratic lower bounds on both monotone and general depth 3 circuits for promise majority.

For any $\epsilon \in (0, 1/2)$, monotone depth 3 AC0 circuits for $\epsilon$-promise majority have size 
$\tilde{\Omega}\left(\epsilon^3 n^{2 + \frac{\ln(1 - \epsilon)}{\ln(\epsilon)}}\right)$
         
For any $\epsilon \in (0, 1/2)$, general depth 3 AC0 circuits for $\epsilon$-promise majority have size
$\tilde{\Omega}\left(\epsilon^3 n^{2 + \frac{\ln(1 - \epsilon^2)}{2\ln(\epsilon)}}\right)$

These are the first nontrivial size lower bounds on depth 3 promise majority circuits for $\epsilon &lt; 0.45$.
        
Second, we give both uniform and non-uniform sub-quadratic size constant depth circuits for promise majority.

For integer $k \geq 1$, constant $\epsilon \in (0, 1/2)$, there exists monotone non uniform AC0 circuits of depth $2 + 2 \cdot k$ computing $\epsilon$-promise majority with size
$\tilde{O}\left(n^{\frac{1}{1 - 2^{-k}}}\right)$

For integer $k \geq 1$, constant $\epsilon \in (0, 1/2)$, there exists monotone uniform AC0 circuit of depth $2 + 2 \cdot k$ computing $\epsilon$-promise majority with size
$n^{\frac{1}{1 - \left(\frac{2}{3}\right)^k} + o(1)}$

These circuits are based on incremental improvements to existing depth 3 circuits for promise majority given by Ajtai and Viola combined with a divide and conquer strategy.</summary>
    <updated>2020-08-16T14:37:01Z</updated>
    <published>2020-08-16T14:37:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-31T23:43:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/121</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/121" rel="alternate" type="text/html"/>
    <title>TR20-121 |  Fractional Pseudorandom Generators from the $k$th Fourier Level | 

	Eshan Chattopadhyay, 

	Jason Gaitonde, 

	Abhishek Shetty</title>
    <summary>In recent work by Chattopadhyay et al.[CHHL19,CHLT19], the authors exhibit a simple and flexible construction of pseudorandom generators for classes of Boolean functions that satisfy $L_1$ Fourier bounds. [CHHL19] show that if a class satisfies such tail bounds at all levels, this implies a PRG whose seed length depends on the quality of these bounds through their innovative random walk framework that composes together fractional PRGs that polarize quickly to the Boolean hypercube. On the other hand, [CHLT19] show that, by derandomizing the analysis of [RT19], just level-two Fourier bounds suffice to construct a pseudorandom generator using their framework; as this is a much weaker assumption on the class, [CHLT19] naturally obtain exponentially worse dependence on the error in the seed length compared to [CHHL19]. Moreover, this derandomization relies on simulating nearly independent Gaussians for the fractional pseudorandom generator, which necessitates the  polynomial dependence on $1/\epsilon$ in each fractional step.
    
    In this work, we attempt to bridge the gap between these two results. Namely, we partially answer an open question by [CHLT19] that nearly interpolates between them. In particular, we show that if one has bounds up to the level-$k$ $L_1$ Fourier mass of a closely related class of functions, where $k&gt;2$, one can obtain improved seed length, the degree to which is determined by how high $k$ can be taken. Our analysis shows that for error $\epsilon=1/\text{poly}(n)$, one needs control at just level $O(\log n)$ to recover the seed length of [CHHL19], without assumptions on the entire tail. We avoid this by providing a simple, alternate analysis of their fractional PRG that instead relies on Taylor's theorem and $p$-biased Fourier analysis to avoid assumptions on the weights of the higher-order terms. This further allows us to show that this framework can handle the class of low-degree polynomials over $\mathbb{F}_2$, with slightly worse dependence than the current state-of-the-art, which was not previously known. We hope that this alternate analysis will be fruitful in improving the understanding of this new and powerful framework.</summary>
    <updated>2020-08-16T14:35:43Z</updated>
    <published>2020-08-16T14:35:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-31T23:43:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/privacy-composition/</id>
    <link href="https://differentialprivacy.org/privacy-composition/" rel="alternate" type="text/html"/>
    <title>Why Privacy Needs Composition</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We’re back!  In our last <a href="https://differentialprivacy.org/\average-case-dp">post</a> we discussed some of the subtle pitfalls of formulating the assumptions underlying average-case relaxations of differential privacy.  This time we’re going to look at the composition property of differential privacy—that is, the fact that running two independent differentially private algorithms on your data and combining their outputs is still differentially private. This is a key property of differential privacy and is actually closely related to the worst-case nature of differential privacy.</p>

<p>Composition is really the crucial property that has made differential privacy successful. Data analysis doesn’t happen in a vacuum, and the greatest threat to privacy comes from combining multiple pieces of information. These pieces of information can come from a single source that releases detailed statistics, or they could come from separate sources. So it’s critical to understand how the composition of multiple pieces of information can affect privacy.</p>

<p>In this post we’ll give some examples to illustrate why we need composition, and why composition is challenging for average-case relaxations of differential privacy.  Composition is what allows you to design sophisticated differentially private algorithms out of simple building blocks, and it’s what allows one organization to release differentially private statistics without having to understand the entire ecosystem of related information that has been or will be released.  As we’ll see, the challenges of composing average-case privacy guarantees are also very closely related to the subtleties that arise in thinking about the adversary’s beliefs.</p>

<h3 id="differencing-attacks">Differencing Attacks</h3>

<p>Let’s start with a simple example of composition that was alluded to in our last post.</p>

<p>You’ve just started a new job and signed up for the health insurance provided by your employer. Thus, your employer is able to obtain aggregated data from the insurance provider. In particular, your employer can ask “How many of our employees have submitted claims for condition X?”  However, your employer should not be able to find out whether or not <em>you</em> have condition X. 
For concreteness, condition X could be a mental health condition, drug addiction, being pregnant, terminal cancer, or an expensive chronic illness. Each of these could result in some kind of employment discrimination.</p>

<p>The employer may find out that 417 employees have condition X.  That’s OK; on its own, this number reveals very little about whether or not <em>you</em> have condition X, as long as your employer is uncertain about how many employees <em>other than you</em> have condition X.  We can formalize this as some kind of average-case or Bayesian privacy guarantee. Thus the health-insurance company is comfortable releasing this number exactly.  But, yesterday, before you started your job, it also seemed reasonable to allow your employer to ask the exact same question, and yesterday the answer was 416. Thus your employer concludes that you have condition X.</p>

<p>In this example, we see how two pieces of information—the count before you started and the count after you started—each of which seems innocuous on its own can be combined to reveal private information. This is a simple example of a <em>differencing attack</em> and composition is important in part because it prevents these attacks.</p>

<p>This example involves only two pieces of information. However, an attack could combine many pieces of information. For example, the counts could be broken down by sex, race/ethnicity, age, location, and tobacco use.<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1">1</a></sup> Additional data may also be obtained from other sources, such as public records, social media, voluntary disclosures, healthcare providers, financial records, employment records, or even illicit sources. The possibilities for attacks grow rapidly as more information is made available. And an employer is only one example of a potential privacy adversary.</p>

<p>The point of this example is that it’s easy to argue that one piece of information is harmless to privacy by making plausible-looking assumptions about the adversary. But this intuition rapidly breaks down once you consider the bigger picture where there are many pieces of information that can complete the puzzle. That’s why we need rigorous methods for understanding privacy and its composition.</p>

<h3 id="quantifying-composition">Quantifying Composition</h3>

<p>How does differential privacy prevent a differencing attack like the one we just discussed? The simplest way is to add a little bit of random noise to each answer. On the first day, instead of releasing the exact count 416, we could release a noisy count, say, 420. Then on the second day, instead of releasing the true count 417, we release another noisy count, say, 415. More precisely, it is common to add noise to counts drawn from a Laplace or Gaussian distribution.  These figures are still close enough to the true values to be useful, but the difference of 1 is now obscured by the noise, so your privacy is protected.</p>

<p>Since the noise is unknown to <em>any</em> potential adversary, it introduces uncertainty that protects the contribution that an individual makes to the count. Taking the difference of two independent noisy counts results in something that is still noisy. However, we must be careful to quantify this privacy guarantee, particularly when it comes to composition.</p>

<p>So, how much noise do we need to add? Let’s go back to the example and suppose the insurance company provides noisy answers where the noise has mean zero and some fixed variance. Your employer could simply ask the same question again and again and each time receive a different noisy answer. Averaging these noisy answers will effectively reduce the variance of the added noise and allow the true answer to be discerned. That leaves us back where we started.</p>

<p>The moral of this revised example is that the scale of the noise must increase if we allow more access to the data, so more questions means more noise in each answer.<sup id="fnref:2"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:2">2</a></sup> 
Asking the same question again and again may seem silly. There are easy ways to defend against this and some similar attacks. (E.g., by returning the same answer each time instead of generating fresh noise.) But, unfortunately, the underlying phenomenon cannot be circumvented. One of the seminal works that led to differential privacy <a href="https://dl.acm.org/doi/10.1145/773153.773173" title="Irit Dinur, Kobbi Nissim. Revealing Information While Preserving Privacy. PODS 2003"><strong>[DN03]</strong></a> showed that there is an inherent tradeoff between the number of questions to be answered and the amount of noise that needs to be added to protect privacy. The general attack is simple: Instead of asking the same query again and again, the attacker asks “random” queries.<sup id="fnref:3"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:3">3</a></sup> This attack only requires basic linear algebra and, importantly, has been demonstrated on real systems <a href="https://arxiv.org/abs/1810.05692" title="Aloni Cohen, Kobbi Nissim. Linear Program Reconstruction in Practice. 2018."><strong>[CN18]</strong></a>.</p>

<h3 id="adaptive-composition">Adaptive Composition</h3>

<p>There are actually two kinds of composition to consider. There is <strong>non-adaptive composition</strong>, where the questions to be asked are pre-specified and thus independent of the data, and there is <strong>adaptive composition</strong>, where the questions may themselves depend on the results of prior access to the data. Adaptive composition arises in an interactive system where queries are submitted one-by-one and each answer is returned before the next query is submitted. So far, we have really only considered non-adaptive composition.</p>

<p>Any interactive system must take adaptive composition into account.  A natural algorithm which asks adaptive questions is gradient descent for minimizing a function that is determined by private data (e.g., for logistic regression on medical records). At each step, the algorithm asks for a gradient of the function, which depends on the private data, at the current point. Then the point is updated according to the reported gradient and the process repeats. Since the updated point depends on the previous answer, the next gradient computation is adaptive.</p>

<p>The good news is that differential privacy can handle adaptive composition just fine.  However, to handle adaptive composition, it’s really important that you have a worst-case privacy definition like differential privacy. As we will see below, average-case variants of differential privacy cannot handle adaptive composition. Intuitively, the problem is that whatever distributional assumption you might make about the data or query a priori is unlikely to hold when you condition on past interactions with the same data or related data.</p>

<p>Here’s a technical example that shows the difficulty of adaptive composition. Our data \(x \in \{-1,+1\}^n\) is a vector of \(n\) bits, one bit per person.<sup id="fnref:4"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:4">4</a></sup>  Because we’re considering average-case differential privacy, we’ll model this vector as uniformly random.  Consider the following slightly odd algorithm \(M_2(x,v)\)—it takes a vector \(v \in \{-1,+1\}^n\) from the user, and, if the correlation \(\langle x, v \rangle / n\) between \(v\) and \(x\) is smaller than \(\varepsilon/2\), the query returns \(\emptyset\), but, if the correlation between \(v\) and \(x\) is larger than \(\varepsilon/2\), the query returns the dataset \(x\).  In isolation this algorithm satisfies an average-case version of differential privacy, because if \(n\) is large enough and \(x\) is uniformly random, then it’s very unlikely that the user can guess a vector \(v\) that causes this algorithm to output anything other than \(\emptyset\).  This algorithm may seem contrived; it is a simple stand-in for any algorithm that behaves very well most of the time, but fails completely on some rare inputs.</p>

<p>Now, consider another, more familiar differentially private algorithm called randomized response <a href="https://www.jstor.org/stable/2283137?seq=1" title="Stanley Warner. Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias. Journal of the American Statistical Association 1965."><strong>[W65]</strong></a>.  For those not familiar, this algorithm \(M_1(x)\) outputs a vector \(y \in \{-1,+1\}^n\), where \(y_i\) is slightly more likely to be \(x_i\) than \(-x_i\).  Specifically, we set \(y_i = x_i\) with probability \((1+\varepsilon)/2\) and \(y_i = - x_i\) otherwise. This satisfies \(\log(\frac{1+\varepsilon}{1-\varepsilon})\)-differential privacy or, roughly, \(2\varepsilon\)-differential privacy. The upshot is that we obtain a vector \(y\) where the correlation between \(x\) and \(y\) is about \(\varepsilon\), i.e. \(\langle x , y \rangle / n \approx \varepsilon\).</p>

<p>OK, so \(M_1\) and \(M_2\) both satisfy strong average-case versions of differential privacy when the data is uniform, but what about their composition?  Well, the bad news is that running \(y = M_1(x)\) followed by \(M_2(x,y)\) is going to return the dataset \(x\) with probability approaching 100%!  That’s because \(y\) was designed precisely to be a vector with correlation about \(\varepsilon\) with \(x\), and this is exactly the key that gets \(M_2\) to unlock the dataset.</p>

<p>What went wrong here is that, even if \(x\) really is uniformly random, it’s very far from it when conditioned on the output \(y=M_1(x)\). To analyze \(M_2(x,y)\) we must look at the distribution of \(x\) conditioned on \(y\). This distribution is going to be messy and may as well be a worst-case distribution, which means we must leave the realm of average-case privacy.</p>

<h3 id="conclusion">Conclusion</h3>
<p>Composition guarantees that, as long as each part of your system is differentially private, then the overall system is too. It would be difficult to build sophisticated systems without this property. And it’s what allows one organization to release differentially private statistics without having to worry about what other information might be out there. In short, composition is what allows differential privacy to deal with the complexities of the real world.</p>

<p>It is unlikely that differential privacy would have taken off as a field of research without this composition property. Any proposal for an alternative approach to privacy-preserving data analysis should first be evaluated in terms of how it handles composition.</p>

<p>This post only scratches the surface. In particular, we haven’t talked about the quantitative aspects of composition; that’s where the fun really begins. We will leave you with some pointers to further reading on the topic:</p>

<ul>
  <li><a href="http://www.annualreviews.org/eprint/E84vbD3Yzw4ff7YPAjnv/full/10.1146/annurev-statistics-060116-054123" title="Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman. Exposed! A Survey of Attacks on Private Data. Annual Review of Statistics and its Applications 2017."><strong>[DSSU17]</strong></a> This is a survey of attacks which explains quantitatively the relationship between noise, number of questions, and privacy risks.</li>
  <li><a href="https://arxiv.org/abs/1311.0776" title="Peter Kairouz, Sewoong Oh, Pramod Viswanath. The Composition Theorem for Differential Privacy. ICML 2015."><strong>[KOV15]</strong></a> <a href="https://arxiv.org/abs/1507.03113" title="Jack Murtagh, Salil Vadhan. The Complexity of Computing the Optimal Composition of Differential Privacy. TCC 2016"><strong>[MV15]</strong></a> <a href="https://arxiv.org/abs/1603.01887" title="Cynthia Dwork, Guy Rothbum. Concentrated Differential Privacy. 2016."><strong>[DR16]</strong></a> <a href="https://arxiv.org/abs/1605.02065" title="Mark Bun, Thomas Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. TCC 2016."><strong>[BS16]</strong></a> <a href="https://arxiv.org/abs/1702.07476" title="Ilya Mironov. Renyi Differential Privacy. CSF 2017."><strong>[M17]</strong></a> <a href="https://arxiv.org/abs/1905.02383" title="Jinshuo Dong, Aaron Roth, Weijie Su. Gaussian Differential Privacy. Journal of the Royal Statistical Society: Series B. 2020"><strong>[DRS19]</strong></a> On the positive side, these papers analyze how differential privacy composes, yielding sharp quantitative bounds.</li>
</ul>

<hr/>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>A good rule of thumb is that, if the number of released values is much larger than the number of people, then a privacy attack is probably possible. This is analogous to the rule from algebra that, if the number of constraints (released values) is greater than the number of unknown variables (people’s data), then the unknowns can be worked out. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:2">
      <p>Exactly quantifying how much noise is needed as the number of questions grows leads to the concept of a “privacy budget.” That is, we must precisely quantify how differential privacy degrades under composition. This is a very deep topic and is something we hope to discuss in future posts. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:2">↩</a></p>
    </li>
    <li id="fn:3">
      <p>The queries do not need to be random <strong><a href="https://iacr.org/archive/crypto2008/51570469/51570469.pdf" title="Cynthia Dwork, Sergey Yekhanin. New Efficient Attacks on Statistical Disclosure Control Mechanisms. CRYPTO 2008">[DY08]</a></strong>. The queries simply need to be “sufficiently distinct”, which can be formulated precisely as being nearly orthogonal vectors. Random, or even pseudorandom queries (e.g., hash functions), will almost certainly satisfy this property. In general, it is fairly likely that a set of queries will have this property and allow a reconstruction attack; that is, it is hard to <em>avoid</em> this phenomenon. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:3">↩</a></p>
    </li>
    <li id="fn:4">
      <p>This representation of the dataset as a vector of bits \(x \in \{-1,+1\}^n \) is an abstraction. The entries in the dataset would actually be something like a set of pairs \( ( u_i, x_i ) \) for \(i = 1, \cdots, n \), where \(u_i\) is various information that identifies the individual concerned (name, address, race, date of birth, etc.). <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:4">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2020-08-16T14:00:00Z</updated>
    <published>2020-08-16T14:00:00Z</published>
    <author>
      <name>Jonathan Ullman</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-08-31T23:45:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/08/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/08/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Two sites on toroidal polyhedra: Bonnie Stewarts Hohlkörper and Alex Doskey’s virtual reality models of Stewart’s polyhedra (\(\mathbb{M}\)). Found while researching a new WP article on Stewart’s book Adventures Among the Toroids. The first link is in German but readable through Google translate and has lots of pretty pictures. The second needs VR software to be usable.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p>Two sites on toroidal polyhedra: <a href="https://www.spektrum.de/alias/raeumliche-geometrie/bonnie-stewarts-hohlkoerper/681891">Bonnie Stewarts Hohlkörper</a> and <a href="http://polyhedra.doskey.com/Stewart00.html">Alex Doskey’s virtual reality models of Stewart’s polyhedra</a> (<a href="https://mathstodon.xyz/@11011110/104618649607830730">\(\mathbb{M}\)</a>). Found while researching a new WP article on Stewart’s book <em><a href="https://en.wikipedia.org/wiki/Adventures_Among_the_Toroids">Adventures Among the Toroids</a></em>. The first link is in German but readable through Google translate and has lots of pretty pictures. The second needs VR software to be usable.</p>
  </li>
  <li>
    <p><a href="https://www.robertdickau.com/mapfolding.html">The map folding problem, illustrated by Robert Dickau</a> (<a href="https://mathstodon.xyz/@11011110/104630030819531499">\(\mathbb{M}\)</a>). See <a href="https://www.robertdickau.com/default.html#math">Dickau’s home page</a> for many more mathematical illustrations, mostly of combinatorial enumeration problems and fractals.</p>
  </li>
  <li>
    <p>For some reason I wanted the name of a surface of revolution of a circular arc less than \(\pi\) around its chord (<a href="https://mathstodon.xyz/@11011110/104635297508909080">\(\mathbb{M}\)</a>). <a href="https://en.wikipedia.org/wiki/Lemon_(geometry)">Wikipedia said “lemon”</a> but sourced to MathWorld so I thought maybe MathWorld had made it up. Not so. Better sources say the same. And the surface for the complementary arc is an “apple”. It looks like a North American football but <a href="http://modellsammlung.uni-goettingen.de/index.php?lang=en&amp;r=5&amp;sr=17&amp;m=182">a “football” is a different surface of revolution, of constant positive Gaussian curvature</a>.</p>
  </li>
  <li>
    <p><a href="https://link.springer.com/journal/454/64/2">Special issue of <em>Discrete &amp; Computational Geometry</em> in memory of Branko Grünbaum</a> (<a href="https://mathstodon.xyz/@11011110/104643955543481823">\(\mathbb{M}\)</a>). I think many of the research papers in it are interesting but I want to draw particular attention to <a href="https://link.springer.com/article/10.1007/s00454-020-00214-y">the preface by Gil Kalai, Bojan Mohar, and Isabella Novik</a>, which provides a nice brief survey both of Grünbaum’s many contributions to discrete geometry and of the lines of active research they have led to.</p>
  </li>
  <li>
    <p><a href="http://gallery.bridgesmathart.org/exhibitions/2020-Bridges-Conference">2020 Bridges Conference Mathematical Art Gallery</a> (<a href="https://mathstodon.xyz/@11011110/104646771923669610">\(\mathbb{M}\)</a>). Many are great but a couple of my favorites are <a href="http://gallery.bridgesmathart.org/exhibitions/2020-bridges-conference/conan-chadbourne">Conan Chadbourne’s grid partition enumeration</a> and <a href="http://gallery.bridgesmathart.org/exhibitions/2020-bridges-conference/mdlevin_publicmsncom">Martin Levin’s ten-tetrahedron tensegrity</a>. I didn’t participate but apparently the Bridges conference itself was held virtually a few days ago; see <a href="https://2020.bridgesmathart.org/">the conference site</a> for more including papers and videos.</p>
  </li>
  <li>
    <p><a href="https://felixboiii.github.io/paper-plotter/">Paper plotter</a> (<a href="https://mathstodon.xyz/@11011110/104655233453519187">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24091297">via</a>): tool to make 3d paper cut-and-assemble models of the graphs of bivariate functions.</p>
  </li>
  <li>
    <p>Kowhaiwhai (<a href="https://mathstodon.xyz/@11011110/104663925881930344">\(\mathbb{M}\)</a>).  are repeating decorative patterns used in New Zealand on Maori buildings. <a href="https://natlib.govt.nz/photos?text=kowhaiwhai&amp;commit=Search">The National Library of NZ has a number of good examples</a>, including the <a href="https://natlib.govt.nz/records/23146518">sketches of patterns by Tamati Ngakoho (top) and of a traditional Arawa pattern (bottom)</a> shown below. There’s also <a href="http://www.maori.org.nz/whakairo/default.php?pid=sp55&amp;parent=52">a brief guide to their interpretation online</a>. I can’t find much analysis of their structure, though, beyond pointing to frieze groups for their symmetries. The part that interests me more is their fractal-like swooping structure, reminiscent of (and in some cases directly modeled on) fern fronds.</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="Godber, Albert Percy, 1875-1949. Godber, Albert Percy, 1876-1949. Drawings of Maori rafter patterns or kowhaiwhai. 16. 22W. MA22; 17. 21W. MA21; and, 18. 25W. MA25. Puhoro. [1939-1947]. Ref: E-302-q-1-016/018. Alexander Turnbull Library, Wellington, New Zealand. From https://natlib.govt.nz/records/23146518" src="https://11011110.github.io/blog/assets/2020/Kowhaiwhai.jpg"/></p>

<ul>
  <li>
    <p><a href="https://www.wired.com/story/why-wikipedia-decided-to-stop-calling-fox-a-reliable-source/">Why Wikipedia decided to stop calling Fox a reliable source</a> (<a href="https://mathstodon.xyz/@11011110/104666160845673755">\(\mathbb{M}\)</a>). Note however that Fox has not actually been deemed unreliable, in general. <a href="https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources/Noticeboard/Archive_303#RfC:_Fox_News">The discussion had a no-consensus close</a>.</p>
  </li>
  <li>
    <p><a href="https://sinews.siam.org/Details-Page/untangling-random-polygons-and-other-things">Untangling random polygons</a> (<a href="https://mathstodon.xyz/@11011110/104677553383067578">\(\mathbb{M}\)</a>): repeatedly rescaling midpoint polygons always leads to an ellipse.</p>
  </li>
  <li>
    <p><a href="https://www.atlasobscura.com/articles/kek-lapis-sarawak">The mesmerizing geometry of Malaysia’s most complex cakes:
Bold colors and designs set kek lapis Sarawak apart</a> (<a href="https://mathstodon.xyz/@11011110/104680812259935603">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24116775">via</a>). As seen on The Great British Bake Off. These cakes have many parallel layers in bright colors, cut and rearranged to form complex designs. Mostly they involve 45 and 90-degree angles but at least one of the examples uses hexagonal symmetry instead.</p>
  </li>
  <li>
    <p>My Google Scholar profile has mildly broken down (<a href="https://mathstodon.xyz/@11011110/104683176033821672">\(\mathbb{M}\)</a>). When I go there, it offers me two new profiles to link as my coauthors: Man-Kwun Chiu and Matí Korman. They are indeed coauthors, from my new CCCG papers. But when I click to accept them as listed coauthors, it tells me I have too many coauthors, refuses to add them, and returns to offering me new profiles to link. I can see no way out of this other than to not accept my coauthors, which would be wrong. Google, fix this limitation!</p>
  </li>
  <li>
    <p>A use for old CDs: <a href="https://momath.org/home/math-monday-those-circles-are-great/">cut them up and glue the pieces together to make visualizations of great circle arrangements on the sphere</a> (<a href="https://mathstodon.xyz/@11011110/104690896919723051">\(\mathbb{M}\)</a>). The mathematical question posed by this is: for which numbers of great circles is it possible to make an arrangement in which all the arcs between pairs of neighbors have equal lengths?</p>
  </li>
  <li>
    <p><a href="https://thonyc.wordpress.com/">The Renaissance Mathematicus</a> (<a href="https://mathstodon.xyz/@pkra/104694183591138626">\(\mathbb{M}\)</a>), an interesting blogger on the history of science. See also the <a href="https://thonyc.wordpress.com/2020/08/15/keep-the-renaissance-mathematicus-online/">crowdfunding drive to replace their old creaky iMac</a>, from which I found this.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-08-15T17:02:00Z</updated>
    <published>2020-08-15T17:02:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-31T01:37:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20069</id>
    <link href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 9: Alexey Pokrovskiy proved that Rota’s Basis Conjecture holds asymptotically</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Pokrovskiy’s startling morning  rainbow Rota’s Basis Conjecture holds asymptotically, by Alexey Pokrovskiy Abstract: Rota’s Basis Conjecture is a well known problem from matroid theory, that states that for any collection of n bases in a rank n matroid, it is … <a href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2><a href="https://gilkalai.files.wordpress.com/2020/08/alexeypokrovskiy.jpg"><img alt="" class="alignnone size-medium wp-image-20075" height="300" src="https://gilkalai.files.wordpress.com/2020/08/alexeypokrovskiy.jpg?w=209&amp;h=300" width="209"/></a></h2>
<h2>Pokrovskiy’s startling morning  <strong><span style="color: #ff0000;">r</span><span style="color: #0000ff;">ai</span><span style="color: #ff6600;">n</span><span style="color: #ff9900;">b</span><span style="color: #ff00ff;">o</span><span style="color: #800080;">w</span></strong></h2>
<p><a href="https://arxiv.org/abs/2008.06045">Rota’s Basis Conjecture holds asymptotically</a>, by Alexey <span style="color: #000000;">Pokrovskiy</span></p>
<p><strong>Abstract:</strong> Rota’s Basis Conjecture is a well known problem from matroid theory, that states that for any collection of n bases in a rank n matroid, it is possible to decompose all the elements into n disjoint rainbow bases. Here an asymptotic version of this is proved. We show that it is possible to find <em>n − o(n)</em> disjoint rainbow independent sets of size <em>n − o(n)</em>.</p>
<p>A <strong><span style="color: #ff0000;">r</span><span style="color: #0000ff;">ai</span><span style="color: #ff6600;">n</span><span style="color: #ff9900;">b</span><span style="color: #ff00ff;">o</span><span style="color: #800080;">w </span></strong><span style="color: #800080;"><span style="color: #000000;">basis is a basis with one element from each collection.</span></span></p>
<p>(I thank Nati Linial for telling me about it.)</p>
<p>Another way to formulate Rota’s basis conjecture (for representable matroids) is that if <em>B</em><sub>1</sub>, <em>B</em><sub>2</sub>, …, <em>B<sub>n</sub></em> are <em>n</em> bases of an <em>n</em>-dimensional vector space <em>V</em> (not necessarily distinct or disjoint), then there exists an <em>n</em> × <em>n</em> grid of vectors (<em>v<sub>ij</sub></em>) such that</p>
<p>1. the <em>n</em> vectors in row <em>i</em> are the members of the <em>i</em>th basis <em>B<sub>i</sub></em> (in some order), and</p>
<p>2. in each column of the matrix, the <em>n</em> vectors in that column form a basis of <em>V</em>.</p>
<p>If all the bases are the standard basis then this reduces to the existence of <a href="https://en.wikipedia.org/wiki/Latin_square">Latin squares</a>.</p>
<p><strong>Unrelated trivia question:</strong>  AGC-GTC-TGC-GTC-TGC-GAC-GATC-? what comes next in the sequence?</p>
<p>We mentioned Rota’s basis conjecture in various earlier posts.  A classic paper on the subject is the <a href="https://gilkalai.files.wordpress.com/2017/02/huang-rota.pdf">1989 paper by Rosa Huang and Gian Carlo-Rota</a>. Three and a half years ago Timothy Chow lunched a polymath project (Polymath 12) to solve it. (Here is my<a href="https://gilkalai.wordpress.com/2017/02/26/timothy-chow-launched-polymath12-on-rota-basis-conjecture-and-other-news/"> post on the project with various variants of the conjecture</a>, the <a href="https://polymathprojects.org/2017/02/23/rotas-basis-conjecture-polymath-12/">first post on the polymath blog</a>, and the <a href="https://asone.ai/polymath/index.php?title=Rota%27s_conjecture">wiki</a>). See <a href="https://gilkalai.wordpress.com/2014/08/08/jim-geelen-bert-gerards-and-geo%ef%ac%80-whittle-solved-rotas-conjecture-on-matroids/">this post</a> for several famous conjectures by Rota, and this post about the related <a href="https://gilkalai.wordpress.com/2017/03/15/test-your-intuition-about-the-alon-tarsi-conjecture/">Alon-Tarsi conjecture</a>.</p></div>
    </content>
    <updated>2020-08-14T10:09:36Z</updated>
    <published>2020-08-14T10:09:36Z</published>
    <category term="Combinatorics"/>
    <category term="Updates"/>
    <category term="Alexey Pokrovskiy"/>
    <category term="Gian Carlo Rota"/>
    <category term="Rosa Huang"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-08-31T23:44:11Z</updated>
    </source>
  </entry>
</feed>
