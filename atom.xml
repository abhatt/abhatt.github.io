<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-08-03T02:22:17Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00491</id>
    <link href="http://arxiv.org/abs/1908.00491" rel="alternate" type="text/html"/>
    <title>On Cycle Transversals and Their Connected Variants in the Absence of a Small Linear Forest</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dabrowski:Konrad_K=.html">Konrad K. Dabrowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feghali:Carl.html">Carl Feghali</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Johnson:Matthew.html">Matthew Johnson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paesani:Giacomo.html">Giacomo Paesani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paulusma:Dani=euml=l.html">Daniël Paulusma</a>, Paweł Rzążewski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00491">PDF</a><br/><b>Abstract: </b>A graph is $H$-free if it contains no induced subgraph isomorphic to $H$. We
prove new complexity results for the two classical cycle transversal problems
Feedback Vertex Set and Odd Cycle Transversal by showing that they can be
solved in polynomial time on $(sP_1+P_3)$-free graphs for every integer $s\geq
1$. We show the same result for the variants Connected Feedback Vertex Set and
Connected Odd Cycle Transversal. We also prove that the latter two problems are
polynomial-time solvable on cographs; this was already known for Feedback
Vertex Set and Odd Cycle Transversal. We complement these results by proving
that Odd Cycle Transversal and Connected Odd Cycle Transversal are NP-complete
on $(P_2+P_5,P_6)$-free graphs.
</p></div>
    </summary>
    <updated>2019-08-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00351</id>
    <link href="http://arxiv.org/abs/1908.00351" rel="alternate" type="text/html"/>
    <title>Sparse Regression via Range Counting</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cardinal:Jean.html">Jean Cardinal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ooms:Aur=eacute=lien.html">Aurélien Ooms</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00351">PDF</a><br/><b>Abstract: </b>The sparse regression problem, also known as best subset selection problem,
can be cast as follows: Given a real $d \times n$ matrix $A$, a vector $y$ in
$\mathbb{R}^d$, and an integer $2 \leq k \leq d$, find an affine combination of
at most $k$ columns of $A$ that is closest to $y$. We describe a $O(n^{k-1}
\log^{d-k+2} n)$-time randomized $(1+\varepsilon)$-approximation algorithm for
this problem with $d$ and $\varepsilon$ constant. This is the first algorithm
for this problem running in time $o(n^k)$. Its running time is similar to the
query time of a data structure recently proposed by Har-Peled, Indyk, and
Mahabadi (ICALP'18), while not requiring any preprocessing. Up to
polylogarithmic factors, it matches a conditional lower bound relying on a
conjecture about affine degeneracy testing. In the special case where $k = d =
O(1)$, we also provide a simple $O(n^{d-1+\epsilon})$-time deterministic exact
algorithm. Finally, we show how to adapt the approximation algorithm for the
sparse linear regression and sparse convex regression problems with the same
running time, up to polylogarithmic factors.
</p></div>
    </summary>
    <updated>2019-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00241</id>
    <link href="http://arxiv.org/abs/1908.00241" rel="alternate" type="text/html"/>
    <title>The Tropical Division Problem and the Minkowski Factorization of Generalized Permutahedra</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Crowell:Robert_Alexander.html">Robert Alexander Crowell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00241">PDF</a><br/><b>Abstract: </b>Given two tropical polynomials $f, g$ on $\mathbb{R}^n$, we provide a
characterization for the existence of a factorization $f= h \odot g$ and the
construction of $h$. As a ramification of this result we obtain a parallel
result for the Minkowski factorization of polytopes. Using our construction we
show that for any given polytopal fan there is a polytope factorization basis,
i.e. a finite set of polytopes with respect to which any polytope whose normal
fan is refined by the original fan can be uniquely written as a signed
Minkowski sum. We explicitly study the factorization of polymatroids and their
generalizations, Coxeter matroid polytopes, and give a hyperplane description
of the cone of deformations for this class of polytopes.
</p></div>
    </summary>
    <updated>2019-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00236</id>
    <link href="http://arxiv.org/abs/1908.00236" rel="alternate" type="text/html"/>
    <title>Distributed Data Summarization in Well-Connected Networks</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Su:Hsin=Hao.html">Hsin-Hao Su</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vu:Hoa_T=.html">Hoa T. Vu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00236">PDF</a><br/><b>Abstract: </b>We study distributed algorithms for some fundamental problems in data
summarization. Given a communication graph $G$ of $n$ nodes each of which may
hold a value initially, we focus on computing $\sum_{i=1}^N g(f_i)$, where
$f_i$ is the number of occurrences of value $i$ and $g$ is some fixed function.
This includes important statistics such as the number of distinct elements,
frequency moments, and the empirical entropy of the data.
</p>
<p>In the CONGEST model, a simple adaptation from streaming lower bounds shows
that it requires $\tilde{\Omega}(D+ n)$ rounds, where $D$ is the diameter of
the graph, to compute some of these statistics exactly. However, these lower
bounds do not hold for graphs that are well-connected. We give an algorithm
that computes $\sum_{i=1}^{N} g(f_i)$ exactly in $\tau_G \cdot 2^{O(\sqrt{\log
n})}$ rounds where $\tau_G$ is the mixing time of $G$. This also has
applications in computing the top $k$ most frequent elements.
</p>
<p>We demonstrate that there is a high similarity between the GOSSIP model and
the CONGEST model in well-connected graphs. In particular, we show that each
round of the GOSSIP model can be simulated almost-perfectly in
$\tilde{O}(\tau_G $ rounds of the CONGEST model. To this end, we develop a new
algorithm for the GOSSIP model that $1\pm \epsilon$ approximates the $p$-th
frequency moment $F_p = \sum_{i=1}^N f_i^p$ in $\tilde{O}(\epsilon^{-2}
n^{1-k/p})$ rounds, for $p &gt;2$, when the number of distinct elements $F_0$ is
at most $O\left(n^{1/(k-1)}\right)$. This result can be translated back to the
CONGEST model with a factor $\tilde{O}(\tau_G)$ blow-up in the number of
rounds.
</p></div>
    </summary>
    <updated>2019-08-03T00:04:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00221</id>
    <link href="http://arxiv.org/abs/1908.00221" rel="alternate" type="text/html"/>
    <title>Automatic pre-grasps generation for unknown 3D objects</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>IA Sainul, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deb:Sankha.html">Sankha Deb</a>, AK Deb <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00221">PDF</a><br/><b>Abstract: </b>In this paper, the problem of automating the pre-grasps generation for novel
3d objects has been discussed. The objects represented as cloud of 3D points
are split into parts and organized in a tree structure, where parts are
approximated by simple box primitives. Applying grasping only on the individual
object parts may miss a good grasp which involves a combination of parts. The
problem has been addressed by traversing the decomposition tree and checking
each node of the tree for possible pre-grasps against a set of conditions.
Further, a face mask has been introduced to encode the free and blocked faces
of the box primitives. Pre-grasps are generated only for the free faces.
Finally, the proposed method implemented on a set twenty-four household objects
and toys, where a grasp planner based on object slicing method has been used to
compute the contact-level grasp plan.
</p></div>
    </summary>
    <updated>2019-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00204</id>
    <link href="http://arxiv.org/abs/1908.00204" rel="alternate" type="text/html"/>
    <title>GLU3.0: Fast GPU-based Parallel Sparse LU Factorization for Circuit Simulation</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Shaoyi.html">Shaoyi Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Sheldon_X==D=.html">Sheldon X.-D. Tan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00204">PDF</a><br/><b>Abstract: </b>In this article, we propose a new GPU-based sparse LU factorization method,
called GLU3.0, solves the aforementioned problems. First, it introduces a much
more efficient double-U dependency detection algorithm to make the detection
much simpler. Second, we observe that the potential parallelism is different as
the matrix factorization goes on. We then develop three different modes of GPU
kernel to adapt to different stages to accommodate the computing task changes
in the factorization. As a result, the new GLU can dynamically allocate GPU
blocks and wraps based on the number of columns in a level to better balance
the computing demands and resources during the LU factorization process.
Experimental results on circuit matrices from University of Florida Sparse
Matrix Collection (UFL) show that the GLU3.0 can deliver 2-3 orders of
magnitude speedup over GLU2.0 for the data dependency detection. Furthermore,
GLU3.0 achieve 13.0X (arithmetic mean) and 6.7X (geometric mean) speedup over
GLU2.0 and 7.1X (arithmetic mean) and 4.8X (geometric mean) over the recently
proposed enhanced GLU2.0 sparse LU solver on the same set of circuit matrices.
</p></div>
    </summary>
    <updated>2019-08-03T00:05:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00159</id>
    <link href="http://arxiv.org/abs/1908.00159" rel="alternate" type="text/html"/>
    <title>A True $O(n \log{n}) $ Algorithm for the All-k-Nearest-Neighbors Problem</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Hengzhao Ma, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jianzhong.html">Jianzhong Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00159">PDF</a><br/><b>Abstract: </b>In this paper we examined an algorithm for the All-k-Nearest-Neighbor problem
proposed in 1980s, which was claimed to have an $O(n\log{n})$ upper bound on
the running time. We find the algorithm actually exceeds the so claimed upper
bound, and prove that it has an $\Omega(n^2)$ lower bound on the time
complexity. Besides, we propose a new algorithm that truly achieves the
$O(n\log{n})$ bound. Detailed and rigorous theoretical proofs are provided to
show the proposed algorithm runs exactly in $$O(n\log{n})$$ time.
</p></div>
    </summary>
    <updated>2019-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00113</id>
    <link href="http://arxiv.org/abs/1908.00113" rel="alternate" type="text/html"/>
    <title>A Structural Average of Labeled Merge Trees for Uncertainty Visualization</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yan:Lin.html">Lin Yan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yusu.html">Yusu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munch:Elizabeth.html">Elizabeth Munch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gasparovic:Ellen.html">Ellen Gasparovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Bei.html">Bei Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00113">PDF</a><br/><b>Abstract: </b>Physical phenomena in science and engineering are frequently modeled using
scalar fields. In scalar field topology, graph-based topological descriptors
such as merge trees, contour trees, and Reeb graphs are commonly used to
characterize topological changes in the (sub)level sets of scalar fields. One
of the biggest challenges and opportunities to advance topology-based
visualization is to understand and incorporate uncertainty into such
topological descriptors to effectively reason about their underlying data. In
this paper, we study a structural average of a set of labeled merge trees and
use it to encode uncertainty in data. Specifically, we compute a 1-center tree
that minimizes its maximum distance to any other tree in the set under a
well-defined metric called the interleaving distance. We provide heuristic
strategies that compute structural averages of merge trees whose labels do not
fully agree. We further provide an interactive visualization system that
resembles a numerical calculator that takes as input a set of merge trees and
outputs a tree as their structural average. We also highlight structural
similarities between the input and the average and incorporate uncertainty
information for visual exploration. We develop a novel measure of uncertainty,
referred to as consistency, via a metric-space view of the input trees.
Finally, we demonstrate an application of our framework through merge trees
that arise from ensembles of scalar fields. Our work is the first to employ
interleaving distances and consistency to study a global, mathematically
rigorous, structural average of merge trees in the context of uncertainty
visualization.
</p></div>
    </summary>
    <updated>2019-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00089</id>
    <link href="http://arxiv.org/abs/1908.00089" rel="alternate" type="text/html"/>
    <title>A Model of Random Industrial SAT</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barak=Pelleg:Dina.html">Dina Barak-Pelleg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berend:Daniel.html">Daniel Berend</a>, J. C. Saunders <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00089">PDF</a><br/><b>Abstract: </b>One of the most studied models of SAT is random SAT. In this model, instances
are composed from clauses chosen uniformly randomly and independently of each
other. This model may be unsatisfactory in that it fails to describe various
features of SAT instances, arising in real-world applications. Various
modifications have been suggested to define models of industrial SAT. Here, we
focus on community-structured SAT. Namely, the set of variables consists of a
number of disjoint communities, and clauses tend to consist of variables from
the same community. Thus, we suggest a model of random community-structured
SAT. There has been a lot of work on the satisfiability threshold of random
$k$-SAT, starting with the calculation of the threshold of $2$-SAT, up to the
recent result that the threshold exists for sufficiently large $k$. In this
paper, we endeavor to study the satisfiability threshold for random industrial
SAT. Our main result is that the threshold of random community-structured SAT
tends to be smaller than its counterpart for random SAT. Moreover, under some
conditions, this threshold even vanishes.
</p></div>
    </summary>
    <updated>2019-08-03T00:04:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00063</id>
    <link href="http://arxiv.org/abs/1908.00063" rel="alternate" type="text/html"/>
    <title>Intrinsic Interleaving Distance for Merge Trees</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gasparovic:Ellen.html">Ellen Gasparovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munch:Elizabeth.html">Elizabeth Munch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oudot:Steve.html">Steve Oudot</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Turner:Katharine.html">Katharine Turner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Bei.html">Bei Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yusu.html">Yusu Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00063">PDF</a><br/><b>Abstract: </b>Merge trees are a type of graph-based topological summary that tracks the
evolution of connected components in the sublevel sets of scalar functions.
They enjoy widespread applications in data analysis and scientific
visualization. In this paper, we consider the problem of comparing two merge
trees via the notion of interleaving distance in the metric space setting. We
investigate various theoretical properties of such a metric. In particular, we
show that the interleaving distance is intrinsic on the space of labeled merge
trees and provide an algorithm to construct metric 1-centers for collections of
labeled merge trees. We further prove that the intrinsic property of the
interleaving distance also holds for the space of unlabeled merge trees. Our
results are a first step toward performing statistics on graph-based
topological summaries.
</p></div>
    </summary>
    <updated>2019-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.13558</id>
    <link href="http://arxiv.org/abs/1907.13558" rel="alternate" type="text/html"/>
    <title>Level-Planar Drawings with Few Slopes</title>
    <feedworld_mtime>1564790400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Br=uuml=ckner:Guido.html">Guido Brückner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krisam:Nadine_Davina.html">Nadine Davina Krisam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mchedlidze:Tamara.html">Tamara Mchedlidze</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.13558">PDF</a><br/><b>Abstract: </b>We introduce and study level-planar straight-line drawings with a fixed
number $\lambda$ of slopes. For proper level graphs, we give an $O(n \log^2 n /
\log \log n)$-time algorithm that either finds such a drawing or determines
that no such drawing exists. Moreover, we consider the partial drawing
extension problem, where we seek to extend an immutable drawing of a subgraph
to a drawing of the whole graph, and the simultaneous drawing problem, which
asks about the existence of drawings of two graphs whose restrictions to their
shared subgraph coincide. We present $O(n^{4/3} \log n)$-time and $O({\lambda}
n^{10/3} \log n)$-time algorithms for these respective problems on proper
level-planar graphs. We complement these positive results by showing that
testing whether non-proper level graphs admit level-planar drawings with
$\lambda$ slopes is $\textsf{NP}$-hard even in restricted cases.
</p></div>
    </summary>
    <updated>2019-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16133</id>
    <link href="https://rjlipton.wordpress.com/2019/08/02/the-electoral-college-is-it-good/" rel="alternate" type="text/html"/>
    <title>The Electoral College: Is It Good?</title>
    <summary>A old unpublished result, some new published results [ Playbill ] Alexander Hamilton was a framer of the U.S. Constitution. He wrote the bulk of the Federalist Papers (FP) defending the Constitution. Today he is best known for the playbill—the musical on his life—and the bill, the US ten dollar bill. Today I thought we […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A old unpublished result, some new published results</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/08/02/the-electoral-college-is-it-good/96902-11/" rel="attachment wp-att-16136"><img alt="" class="alignright size-medium wp-image-16136" height="300" src="https://rjlipton.files.wordpress.com/2019/08/96902-11.jpg?w=194&amp;h=300" width="194"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Playbill ]</font></td>
</tr>
</tbody>
</table>
<p>
Alexander Hamilton was a framer of the U.S. Constitution. He wrote the bulk of the <a href="https://en.wikipedia.org/wiki/The_Federalist_Papers">Federalist Papers</a> (FP) defending the Constitution. Today he is best known for the playbill—the <a href="https://en.wikipedia.org/wiki/Hamilton_(musical)">musical</a> on his life—and the bill, the US ten dollar bill.</p>
<p>
Today I thought we would discuss the U.S. electoral college (EC).</p>
<p>
We are in the midst of the run-up to next year’s President election. An on-going discussion is the issue of the EC. Should it be modified? Should it be replaced? Is it a good idea? </p>
<p>
So let’s recall how the EC works. Then we will look at it from a theory viewpoint. </p>
<p>
</p><p/><h2> The College </h2><p/>
<p/><p>
The electoral college is how every four years we elect the President of the United States. It is not a direct popular vote. The Constitution created it as a compromise between a direct popular vote and a vote by the members of Congress. Back then, the framers of the Constitution, including Hamilton, did not trust the electorate. Hence, the rationale for the EC.</p>
<p>
Today the EC consists of 538 electors. Voters in each state pick electors, who then vote in EC for the President. Thus by high math, 270 electors are required to win. A state gets one electoral vote for each member in the House of Representatives plus two. The latter rule ensures that no state gets too few votes. It is some times called the “two-plus rule”.</p>
<p>
The arguments for the EC are distilled in FP <a href="https://en.wikipedia.org/wiki/Federalist_No._68">No. 68</a>. Although the collaboration/authorship status of numerous FP remains unclear, Hamilton’s claim in his last testament to sole authorship of FP 68 is not seriously disputed. <a href="https://en.wikipedia.org/wiki/Federalist_No._68">Quoting</a> Wikipedia:</p>
<blockquote><p><b> </b> <em> Entitled “The Mode of Electing the President”, No. 68 describes a perspective on the process of selecting the Chief Executive of the United States. In writing this essay, the author sought to convince the people of New York of the merits of the proposed Constitution. Number 68 is the second in a series of 11 essays discussing the powers and limitations of the Executive branch and the only one to describe the method of selecting the president. </em>
</p></blockquote>
<p/><p>
Opponents today argue against the EC. They point out that it allows one to win without getting the most votes. This has happened in two of the last five elections, in 2000 and 2016. The EC rewards uneven allocations of campaigning to the few “swing-states”. It also gives voters in less populated states more voting power. A vote from Wyoming has over three times the influence on the EC tally as a vote from California. The battle over FP 68 has even been <a href="https://securingdemocracy.gmfus.org/hamilton-68">internationalized</a>.</p>
<p>
</p><p/><h2> My College </h2><p/>
<p/><p>
Years ago. Decades ago. Eons ago. When I was in college, I almost flunked a required one-credit course in my senior year. The course was on issues of the election that year of the President. No it did not involve Hamilton. </p>
<p>
The grade of the course was based on a term paper. Mine, which got a <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/>, was based on an argument for the EC. Thankfully, the grade was just enough to get me a pass in the course, and allow me to graduate. I did not take the course seriously—my attendance was spotty, at best.</p>
<p>
My idea was that there was an argument for the EC based on a connection with the ability to manage elections. My central thesis was: </p>
<blockquote><p><b> </b> <em> <i>The ability to accurately predict the outcome of a Presidential election is inherently undesirable</i>. </em>
</p></blockquote>
<p/><p>
Let’s agree that we will call this the <i>Prediction Assumption</i> (PA). Predicting the outcome of elections may not be a good idea. If predictions could be accurate, then one could argue that this would allow candidates to manipulate the election. I think you could make the case that this could be a problem. Candidates would be able to manage their opinions to optimize their chances of winning the election. </p>
<p>
In any event I then proved a result that showed that given PA, one could argue that the EC was better than a popular election. Note, the usual math arguments against the EC are based on the power of individual voters. See <a href="https://www.siam.org/Portals/0/Publications/SIURO/Vol12/S01616.pdf?ver=2019-02-12-215230-620">here</a> and <a href="https://blogs.scientificamerican.com/guest-blog/the-funky-math-of-the-electoral-college/">here</a> for some of their insights.</p>
<p>
</p><p/><h2> My College Paper </h2><p/>
<p/><p>
The central point of my paper was informally this:</p>
<blockquote><p><b>Theorem:</b> <em> Prediction of an election using EC is more difficult than one using the popular vote. </em>
</p></blockquote>
<p/><p>
A simple example should help. Imagine an election with three states: Northeast, West, and South. Let them each have one electoral vote. Clearly <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> are needed to win. Suppose the states are arranged like this:</p>
<ul>
<li>
Northeast: Almost all for A; <p/>
</li><li>
West: Almost all for B; <p/>
</li><li>
South: Close between A and B.
</li></ul>
<p>
Then prediction requires the polling to be able to tell the outcome of the South vote. The point is:</p>
<blockquote><p><b> </b> <em> The smaller the number of voters in the ensemble being predicted, the more uncertain the prediction. </em>
</p></blockquote>
<p/><p>
Ken argues that simply having a multiplicity of component elections—one in each state plus DC—also increases the uncertainty. This may happen technically just because the result is a kind of average over unequal-sized averages. </p>
<p>
</p><p/><h2> Their Papers </h2><p/>
<p/><p>
Modern results in Boolean function theory actually have studied the noise sensitivity of the EC. They have studied how errors in voting can flip an election. Look at Gil Kalai’s 2010 <a href="http://www.ma.huji.ac.il/~kalai/CHAOS.pdf">paper</a>, “Noise Sensitivity And Chaos In Social Choice Theory.” He shows that majority is more stable in the presence of noise than the EC. Look at Ryan O’Donnell’s <a href="https://www.cs.cmu.edu/~odonnell/papers/analysis-survey.pdf">paper</a>, “Some Topics in Analysis of Boolean Functions.” He shows a related point that errors in EC—in a simple model—can increase the chance that errors flip the election factor of about <img alt="{5.7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5.7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5.7}"/>.</p>
<p>
Neither paper strikes me as studying whether predictions are easier with the simple majority rule than with the EC.<br/>
I believe that their new results can be used to prove the same type of theorems on prediction. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Did I deserve a better grade than a <img alt="{\cal D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal D}"/>? Or should I have flunked? Should I have published something?</p>
<p>
For comparison, the college term paper which eventually became the <a href="https://en.wikipedia.org/wiki/Twenty-seventh_Amendment_to_the_United_States_Constitution">27th Amendment</a> to the Constitution received a better grade: <img alt="{\cal C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal C}"/>. Oh well.</p>
<p/></font></font></div>
    </content>
    <updated>2019-08-02T14:32:54Z</updated>
    <published>2019-08-02T14:32:54Z</published>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="election"/>
    <category term="electoral college"/>
    <category term="old result"/>
    <category term="predictions"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-03T02:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00432</id>
    <link href="http://arxiv.org/abs/1908.00432" rel="alternate" type="text/html"/>
    <title>Online Payment Network Design</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Avarikioti:Georgia.html">Georgia Avarikioti</a>, Kenan Besic, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yuyi.html">Yuyi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wattenhofer:Roger.html">Roger Wattenhofer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00432">PDF</a><br/><b>Abstract: </b>Payment channels allow transactions between participants of the blockchain to
be executed securely off-chain, and thus provide a promising solution for the
scalability problem of popular blockchains. We study the online network design
problem for payment channels, assuming a central coordinator. We focus on a
single channel, where the coordinator desires to maximize the number of
accepted transactions under given capital constraints. Despite the simplicity
of the problem, we present a flurry of impossibility results, both for
deterministic and randomized algorithms against adaptive as well as oblivious
adversaries.
</p></div>
    </summary>
    <updated>2019-08-02T23:51:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00352</id>
    <link href="http://arxiv.org/abs/1908.00352" rel="alternate" type="text/html"/>
    <title>An SPQR-Tree-Like Embedding Representation for Upward Planarity</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Br=uuml=ckner:Guido.html">Guido Brückner</a>, Markus Himmel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rutter:Ignaz.html">Ignaz Rutter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00352">PDF</a><br/><b>Abstract: </b>The SPQR-tree is a data structure that compactly represents all planar
embeddings of a biconnected planar graph. It plays a key role in constrained
planarity testing. We develop a similar data structure, called the UP-tree,
that compactly represents all upward planar embeddings of a biconnected
single-source directed graph. We demonstrate the usefulness of the UP-tree by
solving the upward planar embedding extension problem for biconnected
single-source directed graphs.
</p></div>
    </summary>
    <updated>2019-08-02T23:47:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00265</id>
    <link href="http://arxiv.org/abs/1908.00265" rel="alternate" type="text/html"/>
    <title>New Techniques for Graph Edit Distance Computation</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blumenthal:David_B=.html">David B. Blumenthal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00265">PDF</a><br/><b>Abstract: </b>Due to their capacity to encode rich structural information, labeled graphs
are often used for modeling various kinds of objects such as images, molecules,
and chemical compounds. If pattern recognition problems such as clustering and
classification are to be solved on these domains, a (dis-)similarity measure
for labeled graphs has to be defined. A widely used measure is the graph edit
distance (GED), which, intuitively, is defined as the minimum amount of
distortion that has to be applied to a source graph in order to transform it
into a target graph. The main advantage of GED is its flexibility and
sensitivity to small differences between the input graphs. Its main drawback is
that it is hard to compute.
</p>
<p>In this thesis, new results and techniques for several aspects of computing
GED are presented. Firstly, theoretical aspects are discussed: competing
definitions of GED are harmonized, the problem of computing GED is
characterized in terms of complexity, and several reductions from GED to the
quadratic assignment problem (QAP) are presented. Secondly, solvers for the
linear sum assignment problem with error-correction (LSAPE) are discussed.
LSAPE is a generalization of the well-known linear sum assignment problem
(LSAP), and has to be solved as a subproblem by many GED algorithms. In
particular, a new solver is presented that efficiently reduces LSAPE to LSAP.
Thirdly, exact algorithms for computing GED are presented in a systematic way,
and improvements of existing algorithms as well as a new mixed integer
programming (MIP) based approach are introduced. Fourthly, a detailed overview
of heuristic algorithms that approximate GED via upper and lower bounds is
provided, and eight new heuristics are described. Finally, a new easily
extensible C++ library for exactly or approximately computing GED is presented.
</p></div>
    </summary>
    <updated>2019-08-02T23:49:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00227</id>
    <link href="http://arxiv.org/abs/1908.00227" rel="alternate" type="text/html"/>
    <title>An Improved Approximation Algorithm for TSP in the Half Integral Case</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karlin:Anna.html">Anna Karlin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klein:Nathan.html">Nathan Klein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gharan:Shayan_Oveis.html">Shayan Oveis Gharan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00227">PDF</a><br/><b>Abstract: </b>We design a $1.49993$-approximation algorithm for the metric traveling
salesperson problem (TSP) for instances in which an optimal solution to the
subtour linear programming relaxation is half-integral. These instances
received significant attention over the last decade due to a conjecture of
Schalekamp, Williamson and van Zuylen stating that half-integral LP solutions
have the largest integrality gap over all fractional solutions. So, if the
conjecture of Schalekamp et al. holds true, our result shows that the
integrality gap of the subtour polytope is bounded away from $3/2$.
</p></div>
    </summary>
    <updated>2019-08-02T23:59:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00161</id>
    <link href="http://arxiv.org/abs/1908.00161" rel="alternate" type="text/html"/>
    <title>The Constrained Round Robin Algorithm for Fair and Efficient Allocation</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aziz:Haris.html">Haris Aziz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Xin.html">Xin Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mattei:Nicholas.html">Nicholas Mattei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Segal=Halevi:Erel.html">Erel Segal-Halevi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00161">PDF</a><br/><b>Abstract: </b>We consider a multi-agent resource allocation setting that models the
assignment of papers to reviewers. A recurring issue in allocation problems is
the compatibility of welfare/efficiency and fairness. Given an oracle to find a
welfare-achieving allocation, we embed such an oracle into a flexible algorithm
called the Constrained Round Robin (CRR) algorithm, that achieves the required
welfare level. Our algorithm also allows the system designer to lower the
welfare requirements in order to achieve a higher degree of fairness. If the
welfare requirement is lowered enough, a strengthening of envy-freeness up to
one item is guaranteed. Hence, our algorithm can be viewed as a computationally
efficient way to interpolate between welfare and approximate envy-freeness in
allocation problems.
</p></div>
    </summary>
    <updated>2019-08-02T23:49:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00142</id>
    <link href="http://arxiv.org/abs/1908.00142" rel="alternate" type="text/html"/>
    <title>An L0-Norm Constrained Non-Negative Matrix Factorization Algorithm for the Simultaneous Disaggregation of Fixed and Shiftable Loads</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zarabie:Ahmad_Khaled.html">Ahmad Khaled Zarabie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Sanjoy.html">Sanjoy Das</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00142">PDF</a><br/><b>Abstract: </b>Energy disaggregation refers to the decomposition of energy use time series
data into its constituent loads. This paper decomposes daily use data of a
household unit into fixed loads and one or more classes of shiftable loads. The
latter is characterized by ON OFF duty cycles. A novel algorithm based on
nonnegative matrix factorization NMF for energy disaggregation is proposed,
where fixed loads are represented in terms of real-valued basis vectors,
whereas shiftable loads are divided into binary signals. This binary
decomposition approach directly applies L0 norm constraints on individual
shiftable loads. The new approach obviates the need for more computationally
intensive methods e.g. spectral decomposition or mean field annealing that have
been used in earlier research for these constraints. A probabilistic framework
for the proposed approach has been addressed. The proposed approach s
effectiveness has been demonstrated with real consumer energy data.
</p></div>
    </summary>
    <updated>2019-08-02T23:57:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00140</id>
    <link href="http://arxiv.org/abs/1908.00140" rel="alternate" type="text/html"/>
    <title>Sublinear Subwindow Search</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reuter:Max.html">Max Reuter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bercea:Gheorghe=Teodor.html">Gheorghe-Teodor Bercea</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00140">PDF</a><br/><b>Abstract: </b>We propose an efficient approximation algorithm for subwindow search that
runs in sublinear time and memory. Applied to object localization, this
algorithm significantly reduces running time and memory usage while maintaining
competitive accuracy scores compared to the state-of-the-art. The algorithm's
accuracy also scales with both the size and the spatial coherence
(nearby-element similarity) of the matrix. It is thus well-suited for real-time
applications and against many matrices in general.
</p></div>
    </summary>
    <updated>2019-08-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.00041</id>
    <link href="http://arxiv.org/abs/1908.00041" rel="alternate" type="text/html"/>
    <title>FaVeST: Fast Vector Spherical Harmonic Transforms</title>
    <feedworld_mtime>1564704000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Quoc T. Le Gia, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ming.html">Ming Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yu_Guang.html">Yu Guang Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.00041">PDF</a><br/><b>Abstract: </b>Vector spherical harmonics on $\mathbb{S}^{2}\subset \mathbb{R}^3$ have wide
applications in geophysics, quantum mechanics and astrophysics. In the
representation of a tangent field, one needs to evaluate the expansion and the
Fourier coefficients of vector spherical harmonics. In this paper, we develop
fast algorithms (FaVeST) for vector spherical harmonic transforms for these
evaluations. The forward FaVeST which evaluates the Fourier coefficients has
computational steps proportional to $N\log \sqrt{N}$ for $N$ number of
evaluation points. The adjoint FaVeST which evaluates a linear combination of
vector spherical harmonics with degree up to $\sqrt{M}$ for $M$ evaluation
points is proportional to $M\log\sqrt{M}$. Numerical examples illustrate the
accuracy and efficiency of FaVeST.
</p></div>
    </summary>
    <updated>2019-08-02T23:25:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/08/01/the-mathematics-of-quantum-computation-iiashuji-israel/</id>
    <link href="https://cstheory-events.org/2019/08/01/the-mathematics-of-quantum-computation-iiashuji-israel/" rel="alternate" type="text/html"/>
    <title>The Mathematics of Quantum Computation (IIAS@HUJI, Israel)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">December 15-19, 2019 IIAS @ Hebrew University of Jerusalem, Israel http://ias.huji.ac.il/SchoolCSE4 Registration deadline: August 23, 2019 The school will introduce TCS and math students and faculty, who are interested in the theoretical aspects of quantum computation, to the beautiful and fascinating mathematical and computational open questions in the area, starting from scratch. No prior knowledge … <a class="more-link" href="https://cstheory-events.org/2019/08/01/the-mathematics-of-quantum-computation-iiashuji-israel/">Continue reading <span class="screen-reader-text">The Mathematics of Quantum Computation (IIAS@HUJI, Israel)</span></a></div>
    </summary>
    <updated>2019-08-01T08:19:47Z</updated>
    <published>2019-08-01T08:19:47Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-08-03T02:21:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/31/linkage</id>
    <link href="https://11011110.github.io/blog/2019/07/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A little out of order because it made more sense that way:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A little out of order because it made more sense that way:</p>

<ul>
  <li>
    <p><a href="https://mathstodon.xyz/@jeffgerickson/102453558801250536">A triangulated polygon, from <em>Les Amusemens Mathématiques</em> by André-Joseph Mancoucke, 1749</a>. Jeff Erickson delves once again into the history of mathematics, to find what might be the first statement of the theorem that every simple polygon has a triangulation.</p>
  </li>
  <li>
    <p><a href="https://daringfireball.net/linked/2019/06/13/dropbox-sucks">The new Dropbox sucks</a> (<a href="https://mathstodon.xyz/@11011110/102459317265416759"/>). At least, it does if all you want is low-fuss synchronization of files between your computers. If you want cloud backup, a <a href="https://twitter.com/sandofsky/status/1138686582859239425">resource-intensive</a> desktop app, or easy collaboration between multiple users, it might still be ok for you.</p>

    <p>After getting annoyed with Dropbox’s mission creep and bloat, I’ve started trying <a href="https://syncthing.net/">syncthing</a> as a replacement (<a href="https://mathstodon.xyz/@11011110/102500777811510032"/>, <a href="https://news.ycombinator.com/item?id=20466469">via</a>). It seems like a pretty good replacement, without the bells and whistles that I don’t want or need.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2019/07/manmade-patterns-and-uncanny-shadows-photographed-from-above-by-jp-and-mike-andrews/">Abstract aerial photography by JP and Mike Andrews</a> (<a href="https://mathstodon.xyz/@11011110/102463616656875898"/>).</p>
  </li>
  <li>
    <p><a href="https://sympa.inria.fr/sympa/arc/compgeom-announce/2019-07/msg00006.html">Godfried Toussaint has died</a> (<a href="https://mathstodon.xyz/@11011110/102469388912273069"/>). Godfried “<a href="https://en.wikipedia.org/wiki/Godfried_Toussaint">is considered to be the father of computational geometry in Canada</a>”. This comes as a bit of a shock to me as he seemed healthy enough when I saw him last spring in Barbados. For more, see <a href="https://godfriedtoussaint.blogspot.com/">his memorial web site</a>.</p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/How-Should-Professors-Cite/246675">How should academics cite their transgender colleagues’ work produced under past identities?</a> (<a href="https://mathstodon.xyz/@11011110/102478166860077268"/>).    This article has more questions than answers but the advice at the end (when in doubt, ask them what they prefer) seems like a good idea.</p>
  </li>
  <li>
    <p><em><a href="https://archive.org/details/LesElementsDeLArtArabeBourgoin/page/n1">Les Éléments de l’Art Arabe</a></em> (<a href="https://mathstodon.xyz/@11011110/102482369062908993"/>, <a href="https://www.metafilter.com/181967/geometry-and-ornament-in-Islamic-architecture">via</a>). Lots of plates of pretty geometric girih patterns, from an 1879 book by Jules Bourgoin.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1016/j.respol.2018.04.013">A walk on the wild side: Predatory journals and information asymmetries in scientific evaluations</a> (<a href="https://mathstodon.xyz/@11011110/102489353679943016"/>, <a href="https://ideas.repec.org/a/eee/respol/v48y2019i2p462-477.html">non-paywalled version</a>, <a href="https://www.openaccessrepository.it/record/23448">talk slides</a>). A study of which Italian researchers use predatory journals, why, and how prevalent they are. One conclusion surprised me: 40% of Scopus-listed journals show symptoms of being predatory. See also <a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Academic_Journals/Journals_cited_by_Wikipedia/Questionable1">a list of dubious journals aimed at helping Wikipedia editors identify bad sources</a>.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/">Limit shapes and affine perimeters</a> (<a href="https://mathstodon.xyz/@11011110/102495315622469118"/>), guest post on Gil Kalai’s blog by Imre Bárány. The affine perimeter of a convex curve is an affine-equivariant number in units of length, zero for polygons and larger for smooth curves. And the limit shape of a convex set is what you get by taking a uniformly random convex subset of a grid within the set, in the limit as the grid becomes very fine; it turns out to be the max-affine-perimeter curve contained in the set.</p>
  </li>
  <li>
    <p><a href="https://blog.bonnieeisenman.com/projects/clojure-puzzles/">Voronoi diagrams + irregular line segment replacement curves + Clojure + SVG + laser cutter = jigsaw puzzles</a> (<a href="https://mathstodon.xyz/@11011110/102506299092731515"/>, <a href="https://news.ycombinator.com/item?id=20531861">via</a>).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.11808">Non-concentration of the chromatic number of a random graph</a> (<a href="https://mathstodon.xyz/@11011110/102512091234238124"/>, <a href="ttps://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/">via</a>).
<a href="https://doi.org/10.1007/BF02579208">Shamir &amp; Spencer ‘87</a> and <a href="https://doi.org/10.1007/10.1007/BF01215914">Alon &amp; Krivelevich ‘97</a> proved that random graphs  with  have almost surely only two possible chromatic numbers. But now Annika Heckel has shown that dense random graphs have a significantly wider spread in colors.</p>
  </li>
  <li>
    <p><a href="https://medium.com/open-glam/the-great-wave-what-hokusais-masterpiece-tells-us-about-museums-copyright-and-online-da0f25bd4ed2">The Great Wave: what Hokusai’s masterpiece tells us about museums, copyright and online collections today</a> (<a href="https://mathstodon.xyz/@11011110/102516638326312168"/>, <a href="https://www.metafilter.com/182234/The-Great-Save">via</a>). An interesting comparison of different museum policies on re-use of images of their artworks, and availability of high-resolution images, when the art itself is old enough to be out of copyright but photos of the art might still be copyrighted depending on different national laws. The Library of Congress and Rijksmuseum get high marks.</p>
  </li>
  <li>
    <p><a href="http://www.mathamaze.co.uk/artwork/">Helena Verrill’s mathematical/geometric art</a> (<a href="https://mathstodon.xyz/@11011110/102534506175667851"/>), mostly involving arrangements of circles.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1907.13086">Atomic embeddability, clustered planarity, and thickenability</a> (<a href="https://mathstodon.xyz/@11011110/102537368093048271"/>). Rado Fulek and Csaba Tóth announce a polynomial time algorithm for <a href="https://en.wikipedia.org/wiki/Clustered_planarity">clustered planarity</a> (given a graph and a hierarchical clustering of its vertices, draw the graph planarly with clusters as simple closed curves and no unnecessary cluster-edge crossings). If this holds up, it’s big: the problem has been open since 1995 and a lot of people have worked on it with only modest progress until now.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-07-31T23:16:00Z</updated>
    <published>2019-07-31T23:16:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-01T06:42:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17714</id>
    <link href="https://gilkalai.wordpress.com/2019/08/01/an-interview-with-noga-alon/" rel="alternate" type="text/html"/>
    <title>An interview with Noga Alon</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Update: and here is a great interview of Noga in English and the interviewer is Narkis Alon, Noga’s youngest daughter and Amalya Duek. I was very happy to interview my academic doctoral  twin and long-time friend Noga Alon.  The interview … <a href="https://gilkalai.wordpress.com/2019/08/01/an-interview-with-noga-alon/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Update</strong>: and here is a <a href="http://www.careeryoga.life/440ebcdf?fbclid=IwAR2BWeyMdhTg2fbdHp5U-D9gCy2oqLZBk2ljRBMhjtyAEtSgqBCt7kMlSFk">great interview</a> of Noga in English and the interviewer is Narkis Alon, Noga’s youngest daughter and Amalya Duek.</p>
<p>I was very happy to interview my academic doctoral  twin and long-time friend Noga Alon.  <a href="https://youtu.be/9PhckP9eJhg">The interview</a> is an initiative of the Israel Academy of Sciences and Humanities. (This is my second interview of this kind. See <a href="https://gilkalai.wordpress.com/2018/06/15/an-interview-with-yisrael-robert-aumann/">here</a> for an interview with Yisrael Aumann.) The interview is in Hebrew.</p>
<p/>
<p>For our English speaking readers here is a recent <a href="https://youtu.be/rwiEiGqgetU">Numberphile video</a> with Noga.</p>
<p>We agreed in advance that most of the interview would be about mathematics, and  most of the time  we courageously (and perhaps somewhat recklessly)  tried to explain to a large audience  (starting from scratch) some of Noga’s research directions and results. We hope that people will enjoy the beauty of it even with the missing details and background.</p>
<h3>Noga’s parents, family and childhood</h3>
<p>In the first part of the  interview  Noga talked about his family, his parents, Dror and Hemda, his great uncle <a href="https://en.wikipedia.org/wiki/Yigal_Allon">Yigal Alon</a>, his early childhood, and his early interest in mathematics. Noga liked to solve mathematical riddles from a young age. One reason Noga was drawn to mathematics is that unlike other topics, in mathematics there are absolute truths, and a mathematical proof (when such exists)  is perhaps the only way you can settle a debate. Noga gave an amusing example from his youth regarding the Eurovision song context. Then he mentioned the <a href="https://www.reali.org.il/en/%d7%9e%d7%90%d7%94-%d7%a9%d7%a0%d7%95%d7%aa-%d7%a8%d7%99%d7%90%d7%9c%d7%99/">Hebrew Reali school in Haifa</a>, a mathematics teacher there, Yaakov Kaplan,  newly immigrated from the former Soviet Union, who greatly influenced Noga. Noga also talked about his participation in the Israeli Mathematical Olympiad where the two of us first met 45 years ago.  Next, the two of us met during our military service, and in parallel to his service, Noga finished his M. Sc. and Ph. D with Micha A. Perles, who was also my supervisor.</p>
<h3>An hour of mathematics</h3>
<p>The mathematical part of the video starts with Noga’s  overview of combinatorics. Then we moved to specific topics.</p>
<p>(22:40- 33:30) Noga’s negative solution to Shannon’s conjecture about the capacity of two graphs (and a little about Claude Shannon and information theory)</p>
<p>(33:30- 40:25) The combinatorial nullstellensatz and the polynomial method and a little about the game SET</p>
<p>(40:25 – 46:50) The probabilistic method and a little on the history of probability and about Paul Erdos.</p>
<p>(46:50-  54:50)  Streaming algorithms, a topic introduced by Noga Alon, Yossi Matias, and Mario Szegedy, and more generally, about positive and negative results in computer science, and their practical applications.</p>
<p>(54:50 – 59:25)    Expander graphs and “spectroscopy of graphs”</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga1.png"><img alt="" class="alignnone size-large wp-image-17717" height="326" src="https://gilkalai.files.wordpress.com/2019/07/noga1.png?w=640&amp;h=326" width="640"/></a></p>
<p>59:25  -1:05:40 Ramsey theory</p>
<p>1:05:40-1:12:20 Factoring integers with quantum computers and with classical methods</p>
<p>1:12:00-1:20:00 Combinatorics, economics and game theory:  Noga’s theorem that large committees require a large budget!</p>
<h3>Going back from mathematics to life itself</h3>
<p>After a full hour of mathematics, we returned to life itself. Memories from our years as postdocs at MIT, and our 1993 conference in Jerusalem. Noga talked a little about women in science and in society, about his three daughters, about  the possibility that science, like sport,  can bridge different groups and different peoples, and about politics and prospects for better relations with our Arab neighbors and Iran (Noga is somewhat optimistic and so am I),  prospects about getting old (we are hopeful about it), and advice to young researchers. Noga’s message at the end was that there are many paths to mathematical research and he encouraged young people that like mathematics to follow and enjoy them.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey1.png"><img alt="" class="alignnone size-medium wp-image-17740" height="266" src="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey1.png?w=300&amp;h=266" width="300"/>  </a><a href="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey2.png"><img alt="" class="alignnone size-medium wp-image-17737" height="275" src="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey2.png?w=300&amp;h=275" width="300"/></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey3.png"><img alt="" class="alignnone size-medium wp-image-17738" height="204" src="https://gilkalai.files.wordpress.com/2019/07/alon-ramsey3.png?w=300&amp;h=204" width="300"/></a></p>
<p><span style="color: #ff0000;">Ramsey theory and a conjecture by Erdos and Sos</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/alon-prob-1.png"><img alt="" class="alignnone size-large wp-image-17743" height="272" src="https://gilkalai.files.wordpress.com/2019/07/alon-prob-1.png?w=640&amp;h=272" width="640"/></a></p>
<p><span style="color: #ff0000;">Probability theory and the probabilistic method</span></p>
<p><span id="more-17714"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga3.png"><img alt="" class="alignnone size-medium wp-image-17718" height="195" src="https://gilkalai.files.wordpress.com/2019/07/noga3.png?w=300&amp;h=195" width="300"/>  </a><a href="https://gilkalai.files.wordpress.com/2019/07/noga2.png"><img alt="" class="alignnone size-medium wp-image-17720" height="148" src="https://gilkalai.files.wordpress.com/2019/07/noga2.png?w=300&amp;h=148" width="300"/></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga4.png"><img alt="" class="alignnone size-large wp-image-17722" height="311" src="https://gilkalai.files.wordpress.com/2019/07/noga4.png?w=640&amp;h=311" width="640"/></a></p>
<p><span style="color: #ff0000;">Pictures from our late twenties and a conversation about getting old.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/noga5.png"><img alt="" class="alignnone size-medium wp-image-17723" height="186" src="https://gilkalai.files.wordpress.com/2019/07/noga5.png?w=300&amp;h=186" width="300"/>   </a><a href="https://gilkalai.files.wordpress.com/2019/07/noga6.png"><img alt="" class="alignnone size-medium wp-image-17725" height="154" src="https://gilkalai.files.wordpress.com/2019/07/noga6.png?w=300&amp;h=154" width="300"/></a></p>
<p><span style="color: #ff0000;">Some advice to the young</span></p>
<p/></div>
    </content>
    <updated>2019-07-31T21:09:15Z</updated>
    <published>2019-07-31T21:09:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="People"/>
    <category term="Noga Alon"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-03T02:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/100</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/100" rel="alternate" type="text/html"/>
    <title>TR19-100 |  Nonnegative rank measures and monotone algebraic branching programs | 

	Hervé Fournier, 

	Guillaume Malod, 

	Maud Szusterman, 

	Sébastien Tavenas</title>
    <summary>Inspired by Nisan's characterization of noncommutative complexity (Nisan 1991), we study different notions of nonnegative rank, associated complexity measures and their link with monotone computations. In particular we answer negatively an open question of Nisan asking whether nonnegative rank characterizes monotone noncommutative complexity for algebraic branching programs. We also prove a rather tight lower bound for the computation of elementary symmetric polynomials by algebraic branching programs in the monotone setting or, equivalently, in the homogeneous syntactically multilinear setting.</summary>
    <updated>2019-07-31T16:19:30Z</updated>
    <published>2019-07-31T16:19:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-03T02:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5424</id>
    <link href="https://adamsheffer.wordpress.com/2019/07/31/updates/" rel="alternate" type="text/html"/>
    <title>Updates</title>
    <summary>I did not post anything for almost five months – life has been very busy lately! I hope to get back to posting regularly relatively soon. In the meantime, I wanted to at least have a brief updates post. I just made a revision of my book about incidences and polynomial methods. Joshua Zahl and […]</summary>
    <updated>2019-07-31T02:25:50Z</updated>
    <published>2019-07-31T02:25:50Z</published>
    <category term="Incidences"/>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-08-03T02:21:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4278</id>
    <link href="https://www.scottaaronson.com/blog/?p=4278" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4278#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4278" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Links, proofs, talks, jokes</title>
    <summary xml:lang="en-US">For those who haven’t yet seen it, Erica Klarreich has a wonderful article in Quanta on Hao Huang’s proof of the Sensitivity Conjecture. This is how good popular writing about math can be. Klarreich quotes my line from this blog, “I find it hard to imagine that even God knows how to prove the Sensitivity […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>For those who haven’t yet seen it, Erica Klarreich has a <a href="https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/">wonderful article in </a><em><a href="https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/">Quanta</a></em> on Hao Huang’s proof of the Sensitivity Conjecture.  <em>This</em> is how good popular writing about math can be.</p>



<p>Klarreich quotes my line from this blog, “I find it hard to imagine that even God knows how to prove the Sensitivity Conjecture in any simpler way than this.”  However, even if God doesn’t know a simpler proof, that of course doesn’t rule out the possibility that <strong>Don Knuth</strong> does!  And indeed, a couple days ago Knuth posted <a href="https://www.cs.stanford.edu/~knuth/papers/huang.pdf">his own variant of Huang’s proof</a> on his homepage—in Knuth’s words, fleshing out the <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">argument</a> that Shalev Ben-David previously posted on this blog—and then left a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1815290">comment</a> about it here, the first comment by Knuth that I know about on this blog or any other blog.  I’m honored—although as for whether the variants that avoid the Cauchy Interlacing Theorem are actually “simpler,” I guess I’ll leave that between Huang, Ben-David, Knuth, and God.</p>



<p>In <em>Communications of the ACM</em>, Samuel Greengard has a <a href="https://cacm.acm.org/magazines/2019/8/238339-the-algorithm-that-changed-quantum-machine-learning/fulltext?mobile=false">good, detailed article</a> on Ewin Tang and her dequantization of the quantum recommendation systems algorithm.  One warning (with thanks to commenter Ted): the sentence “The only known provable separation theorem between quantum and classical is sqrt(<em>n</em>) vs. <em>n</em>” is mistaken, though it gestures in the direction of a truth.  In the <em>black-box</em> setting, we can rigorously prove all sorts of separations: sqrt(<em>n</em>) vs. <em>n</em> (for Grover search), exponential (for period-finding), and more.  In the non-black-box setting, we can’t prove any such separations at all.</p>



<p>Last week I returned to the US from the <a href="https://fqxi.org/conference/home/2019">FQXi meeting</a> in the Tuscan countryside.  This year’s theme was “Mind Matters: Intelligence and Agency in the Physical World.”  I gave a talk entitled “The Search for Physical Correlates of Consciousness: Lessons from the Failure of Integrated Information Theory” (<a href="https://www.scottaaronson.com/talks/iitfail.ppt">PowerPoint slides here</a>), which reprised my <a href="https://www.scottaaronson.com/blog/?p=1799">blog</a> <a href="https://www.scottaaronson.com/blog/?p=1823">posts</a> critical of IIT from five years ago.  There were thought-provoking talks by many others who might be known to readers of this blog, including Sean Carroll, David Chalmers, Max Tegmark, Seth Lloyd, Carlo Rovelli, Karl Friston … you can see the full schedule <a href="https://fqxi.org/conference/schedule/2019">here</a>.  Apparently video of the talks is not available yet but will be soon.</p>



<p>Let me close this post by sharing two important new insights about quantum mechanics that emerged from my conversations at the FQXi meeting:</p>



<p>(1) In Hilbert space, no one can hear you scream. Unless, that is, you scream the exact same way everywhere, or unless you split into separate copies, one for each different way of screaming.</p>



<p>(2) It’s true that, as a matter of logic, the <a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation">Schrödinger equation</a> does not imply the <a href="https://en.wikipedia.org/wiki/Born_rule">Born Rule</a>.  Having said that, if the Schrödinger equation were leading a rally, and the crowd started a chant of “BORN RULE! BORN RULE! BORN RULE!”—the Schrödinger equation would just smile and wait 13 seconds for the chant to die down before continuing.</p></div>
    </content>
    <updated>2019-07-30T14:15:03Z</updated>
    <published>2019-07-30T14:15:03Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-31T11:08:23Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/29/zipless-polycube</id>
    <link href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html" rel="alternate" type="text/html"/>
    <title>A zipless polycube</title>
    <summary>My latest arXiv preprint is “Some polycubes have no edge-unzipping” (arXiv:1907.08433, with Erik and Marty Demaine and Joe O’Rourke). It’s about polyhedral unfolding, the problem of cutting a polyhedron along some of its edges into a surface that unfolds into a flat polygon in the plane (a “net”). Although it dates back to the work of Albrecht Dürer, we still don’t know a lot about this problem, in general. We don’t know whether every convex polyhedron has an unfolding, and we don’t know whether every polycube has a folding (allowing cuts in the middle of flat faces as long as they are on boundary edges of the cubes making up the polycube).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My latest arXiv preprint is “Some polycubes have no edge-unzipping” (<a href="https://arxiv.org/abs/1907.08433">arXiv:1907.08433</a>, with Erik and Marty Demaine and Joe O’Rourke). It’s about <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)">polyhedral unfolding</a>, the problem of cutting a polyhedron along some of its edges into a surface that unfolds into a flat polygon in the plane (a “net”). Although it dates back to the work of Albrecht Dürer, we still don’t know a lot about this problem, in general. We don’t know whether every convex polyhedron has an unfolding, and we don’t know whether every polycube has a folding (allowing cuts in the middle of flat faces as long as they are on boundary edges of the cubes making up the polycube).</p>

<p>The preprint is about a variation of unfolding in which the cut has to form a path through the graph of vertices and edges. If the polyhedron has the topology of a sphere and there are no flat vertices (with a full  total angle of surrounding faces) then all vertices must be touched by a cut, and it’s the same thing to ask for an unfolding that forms a Hamiltonian path. These zipper-unfoldings have previously been studied, notably in joint work by two parent-child groups, <a href="https://11011110.github.io/blog/2010/08/12/more-from-cccg.html">Marty and his son Erik, and Anna Lubiw and her two sons Arlo and Jonah from CCCG 2010</a>. The new preprint shows that they don’t always exist for (topologically spherical) polycubes. In particular, the following shape has no flat vertices, but its graph is bipartite and unbalanced enough that it also has no Hamiltonian path.</p>

<p style="text-align: center;"><img alt="A zipless polycube" src="https://11011110.github.io/blog/assets/2019/zipless.png"/></p>

<p>It does have an unfolding, though (figure made by Erik using <a href="https://github.com/amandaghassaei/OrigamiSimulator">OrigamiSimulator</a>):</p>

<p style="text-align: center;"><img alt="Unfolding a zipless polycube" src="https://11011110.github.io/blog/assets/2019/zipless.gif"/></p>

<p>The paper also has a smaller example that’s a little tricker to prove zipless. It’s a small enough advance that we probably won’t bother trying to turn it into a conference or journal paper. (If it were just me, I’d probably have just made a blog post about it. And here we are!)</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102528987575312068">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-29T23:11:00Z</updated>
    <published>2019-07-29T23:11:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-01T06:42:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/099</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/099" rel="alternate" type="text/html"/>
    <title>TR19-099 |  Nearly Optimal Pseudorandomness From Hardness | 

	Dean Doron, 

	David Zuckerman, 

	Dana Moshkovitz, 

	Justin Oh</title>
    <summary>Existing proofs that deduce $\mathbf{BPP}=\mathbf{P}$ from circuit lower bounds convert randomized algorithms into deterministic algorithms with a large polynomial slowdown. We convert randomized algorithms into deterministic ones with little slowdown. Specifically, assuming exponential lower bounds against nondeterministic circuits, we convert any randomized algorithm over inputs of length $n$ running in time $t \ge n$ to a deterministic one running in time $t^{2+\alpha}$ for an arbitrarily small constant $\alpha &gt; 0$. Such a slowdown is nearly optimal, as, under complexity-theoretic assumptions, there are problems with an inherent quadratic derandomization slowdown. We also convert any randomized algorithm that errs rarely into a deterministic algorithm having a similar running time (with pre-processing).

Our results follow from a new, nearly optimal, explicit pseudorandom generator fooling circuits of size $s$ with seed length $(1+\alpha)\log s$, under the assumption that there exists a function $f \in \mathbf{E}$ that requires nondeterministic circuits of size at least $2^{(1-\alpha')n}$, where $\alpha = O(\alpha')$. The construction uses, among other ideas, a new connection between pseudoentropy generators and locally list recoverable codes.</summary>
    <updated>2019-07-29T19:55:04Z</updated>
    <published>2019-07-29T19:55:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-03T02:20:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5104220537083628124</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5104220537083628124/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html" rel="alternate" type="text/html"/>
    <title>Turing to be on the Bank of England 50 pound note, giving me an excuse to talk about Turing</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">BILL: Darling, guess who is soon going to be on the Bank of England 50 pound note?<br/>
<br/>
DARLING: Alan Turing. <br/>
<br/>
BILL: How did you deduce that? (She is right, see  <a href="https://www.bbc.com/news/business-48962557">here</a>.)<br/>
<br/>
DARLING: Since you asked it, it couldn't be a member of the Royal Family (you don't care about that) or some British Politician (you don't care about that either). It had to be a mathematician or computer scientist.<br/>
<br/>
BILL: It could have been Hardy. I wonder if Ramanujan could qualify---do they need to be British? At <a href="https://www.bankofengland.co.uk/banknotes/banknote-characters">this website</a> it says<br/>
<br/>
<br/>
<br/>
<i>Of course, banknotes need to be universally accepted. We therefore look for UK characters who have made an important contribution to our society and culture through their innovation, leadership or values. We do not include fictional characters, or people who are still living (except the monarch on the front of the note). Finally, we need to have a suitable portrait of the person which will be easy to recognise.</i><br/>
<br/>
(They spell <i>recognise</i> with an s instead of a z, so spellcheck flagged it, but I won't change it.) <br/>
<br/>
Note that people on the banknotes have to be <i>UK characters</i>. I honestly don't know if that means they must be citizens.<br/>
<br/>
OKAY, so here are a few thoughts on Turing.<br/>
<br/>
1) When I visited Bletchley Park there was a booklet that bragged about the fact that Bletchley Park was much better at cracking codes than Germany because  they allowed people to work there based only on ability (unlike Germany) - women worked there, Turing who was Gay worked there. I think this is simplistic. Did any Jews work there (anti-semitism was widespread in England, and the world, at the time)? I doubt any blacks worked there since if they did that would be well known by now (if I am wrong let me know). Women DID work there but was their work respected and used? (I honestly don't know). Did Germany also use women at their codebreaking centers? Was Turing known to be gay (if not then Bletchley gets no points for tolerating him). Was JUST having Turing the reason they could crack codes. Plus I am sure there were other factors aside from merit-only.<br/>
<br/>
2) Turing was given a Pardon for his ``crimes'' in August 2014. When I see things like this I wonder who was against it and why and if they were an obstacle.<br/>
<br/>
a) Human Rights Advocate Peter Tatchell noted that its wrong to just single out Turing. Other people prosecuted under that law who did not help beat the German's in WW II should also be pardoned. The government later DID such a pardon in 2017.<br/>
<br/>
b) Judge Minister Lord McNally objected to the pardon:<br/>
<br/>
<i>A posthumous pardon was not considered appropriate as Alan Turing was properly convicted of what at the time was a criminal offence. He would have known that his offence was against the law and that he would be prosecuted. It is tragic that Alan Turing was convicted of an offence that now seems both cruel and absurd—particularly poignant given his outstanding contribution to the war effort. However, the law at the time required a prosecution and, as such, long-standing policy has been to accept that such convictions took place and, rather than trying to alter the historical context and to put right what cannot be put right, ensure instead that we never again return to those times.<br/>
</i><br/>
<br/>
While I disagree with him, I do note that, based on what he wrote and his general record, I think he is not saying this from being anti-gay.  There is  a hard general question here: how does a society right past wrongs? I think pardoning and apologizing is certainly fine, but frankly it seems to weak. What else could a society due? Financial renumeration to living relatives? I don't think giving Inagh Payne (Turing's niece, who I think is still alive) would really help here.<br/>
<br/>
c) <i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage<br/>
</i><br/>
<br/>
I couldn't find Chope's reasons. On the one hand, they may be similar to McNally's. On the other hand he is against same sex marriage so its possible (though I do not know this) that he anti-gay and that is why he is against the pardon. If someone can find what his explanation for blocking the Turing bill is, or other evidence that he is anti-gay, please leave it in the comments.<br/>
<br/>
3) Did the delay matter? I was surprised to find out---Yes. Here is the full passage from Wikipedia:<br/>
<br/>
<br/>
<i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage. The bill was due to return to the House of Commons on 28 February 2014,[175] but before the bill could be debated in the House of Commons,[176] the government elected to proceed under the royal prerogative of mercy. On 24 December 2013, Queen Elizabeth II signed a pardon for Turing's conviction for "gross indecency", with immediate effect.[17] Announcing the pardon, Lord Chancellor Chris Grayling said Turing deserved to be "remembered and recognised for his fantastic contribution to the war effort" and not for his later criminal conviction.[16][18] The Queen officially pronounced Turing pardoned in August 2014.[177] The Queen's action is only the fourth royal pardon granted since the conclusion of the Second World War.[178] Pardons are normally granted only when the person is technically innocent, and a request has been made by the family or other interested party; neither condition was met in regard to Turing's conviction.[179]</i><br/>
<br/>
This amazed me! I thought the Queen had NO power (too bad--- I wish she could just say NO BREXIT). Or that she formally has power but if she ever used it, it might be blocked somehow and  taken away. So I am surprised she has a power she can use at all.<br/>
<br/>
4) I wonder if the Pardon had to happen before they put him on the Banknote. I have been told that this is a very American Question--- England has no Constitution and operates more on Custom and Tradition than on written rules. <br/>
<br/>
5) I had always assumed that Turing committed suicide. Without going into detail, the Wikipedia site on Turing does give intelligent counterarguments to this. See <a href="https://en.wikipedia.org/wiki/Alan_Turing#Death">here</a><br/></div>
    </content>
    <updated>2019-07-29T00:46:00Z</updated>
    <published>2019-07-29T00:46:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-02T13:54:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/28/any-order-puzzle</id>
    <link href="https://11011110.github.io/blog/2019/07/28/any-order-puzzle.html" rel="alternate" type="text/html"/>
    <title>Any-order puzzle deduction</title>
    <summary>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, the ordering of the rules could make a difference in how far you get in the solution. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable modal logic. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In the ensuing discussion, @axiom suggested that the extra information should be the order of deductions. That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">the ordering of the rules could make a difference in how far you get in the solution</a>. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable <a href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html">modal logic</a>. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In <a href="https://mathstodon.xyz/@11011110/102234384857906663">the ensuing discussion</a>, @axiom suggested that the extra information should be the order of deductions.
That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</p>

<p>To clarify the intuition that deduction order should not matter, I want to formalize the state of a partially-solved puzzle as a collection of bits, initially all true. In map coloring, each bit could represent the possibility that a given cell is a particular color, and we want to eventually have one true bit per cell and the rest false. A deduction is a change to a single bit. Each deduction is triggered by a rule, which typically searches for certain patterns in the state. For instance, in map coloring, the pattern that one cell has only one remaining color whose bit is true can trigger the deduction that the same color’s bit in a neighboring cell must be false. Any given deduction could be triggered by more than one rule, or by more than one instance of the same rule. Then these rules and deductions should obey some natural properties:</p>

<ul>
  <li>
    <p>The deductions can only go in one direction. If we deduce that a bit is false, we won’t later change it back to true.</p>
  </li>
  <li>
    <p>The deductions are always valid for the intended puzzle. That is, when a puzzle has a unique solution, we won’t ever deduce anything inconsistent with that solution. (However, when that assumption is violated, anything can happen.)</p>
  </li>
  <li>
    <p>It should be possible to efficiently identify all deductions that can be triggered from the current state. Ideally this should take polynomial time.</p>
  </li>
  <li>
    <p>If a deduction is triggered by one of the rules, it remains triggered until that deduction step is performed.</p>
  </li>
</ul>

<p>I’m not assuming that the deduction system is complete, i.e., that it will  reach the intended puzzle solution for all puzzles. For most natural puzzle types and most efficiently-searchable sets of deduction rules, it won’t be complete, and most likely (because of NP-completeness or related complexity issues) cannot be both complete and efficiently searchable. But nevertheless, a system of rules obeying these properties always reaches a unique state, independent of deduction order. It is the last of these properties that enforces this order-invariance. By induction on the values in the triggering patterns, each deduction that could be made by some order of deduction steps will eventually be made by a greedy algorithm that chooses deductions in an arbitrary order until it gets stuck.</p>

<p>The “remains triggered until performed” criterion should sound familiar. It is the defining property of an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>, a collection of orderings of items (here, orderings of deductions that could be made by the greedy algorithm) with the property that once an item becomes available to be added to an ordering, it remains available until it actually is added. The antimatroid name is a bit technical and off-putting, but these structures come up all the time in many different applications. I’ve written here about
<a href="https://11011110.github.io/blog/2006/06/18/reverse-search-for.html">listing all small antimatroids</a>, <a href="https://11011110.github.io/blog/2006/07/20/upright-quad-drawing.html">visualizing their structure</a>, <a href="https://11011110.github.io/blog/2006/08/30/antimatroids-as-algebras.html">algebraic axiomatization</a>, <a href="https://11011110.github.io/blog/2007/02/18/pruning-antimatroids-is.html">hardness of finding weighted feasible sets</a>, the <a href="https://11011110.github.io/blog/2007/02/20/two-partial-cubes.html">swap structure on orderings</a>, <a href="https://11011110.github.io/blog/2011/11/16/which-infinite-graphs.html">infinite antimatroids</a>, <a href="https://11011110.github.io/blog/2013/02/25/antimatroids-and-balanced.html">informative comparisons</a>, <a href="https://11011110.github.io/blog/2015/03/05/nearest-neighbor-in.html">nearest neighbors</a>, and the applications of antimatroids to <a href="https://11011110.github.io/blog/2007/02/17/shelling-and-pseudotriangulation.html">pseudotriangulation</a>, <a href="https://11011110.github.io/blog/2007/12/29/formal-knot-theory.html">knot theory</a>, <a href="https://11011110.github.io/blog/2008/03/30/how-to-implement.html">computerized education</a>, <a href="https://11011110.github.io/blog/2008/12/02/parts-assembly-and.html">parts assembly</a>, <a href="https://11011110.github.io/blog/2009/01/30/antimatroids-from-sorting.html">sorting networks</a>, <a href="https://11011110.github.io/blog/2013/10/26/rhyme-scheme-antimatroid.html">rhyme schemes</a>, <a href="https://11011110.github.io/blog/2016/04/17/local-and-inductive.html">hereditary graph properties</a>, <a href="https://11011110.github.io/blog/2017/01/17/course-prerequisites-are.html">course prerequisites</a>, and <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html">hierarchical clustering</a>. So why not add puzzle deduction to the list?</p>

<p>A nice side-effect of using deduction rules with these properties is that, if the rules are ordered by difficulty, then a greedy algorithm that always chooses the easiest rule at each step will automatically find a deduction sequence minimizing the difficulty of the hardest rule that it uses. This can be helpful in <a href="http://arxiv.org/abs/cs.DS/0507053">using deduction algorithms to automatically estimate the difficulty of a puzzle for a human solver</a>.</p>

<p>A natural way to achieve the “remains triggered until performed” property for a deduction rule is to use a pattern in the form of a monotonic Boolean combination of state bits (a function that can be expressed using only Boolean and and or operations, without negation) and to trigger a deduction when that combination becomes false. In this way, we achieve a stronger property, that once triggered the deduction remains triggered forever (even after it has already been performed). But as we’ll see below, other kinds of rules can also have the same property.</p>

<p>Now back to map coloring.</p>

<p>We saw in <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">my earlier post</a> that it doesn’t work well to use rules like “if one cell has already-colored neighbors of two colors, and only one uncolored neighbor, then that neighbor cannot be either of the same two colors”. These rules are valid (under the assumption that the puzzle solution is unique) but lose information about why the deduction on the neighboring vertex was made, preventing later deductions from being made.</p>

<p>Instead, the insight I ended up using involves <a href="https://en.wikipedia.org/wiki/Kempe_chain">Kempe chains</a>. A Kempe chain, in a colored map, is a maximal connected subset of the cells of two of the colors. If the coloring is to be unique, every Kempe chain must be anchored by one of the original givens of the puzzle, for otherwise we could swap the two colors in the chain without affecting the rest of the graph. So, I’ve started using rules of the form “if this Kempe chain in the partially colored map is not yet anchored, and can reach an anchor only by extending through this other cell, then that cell cannot be a third color”. Here, the Kempe chains that I examine to trigger this rule are maximal connected subsets of the cells whose colors are limited to some set of two colors, allowing cells that are already known to have only one of those two colors. Until we add the extension cell to the chain, the same rule will continue to be triggered, so this passes the any-order requirements above.</p>

<p>This deduction method also fits well into the visualization tools available for manual puzzle-solving in <a href="https://www.chiark.greenend.org.uk/~sgtatham/puzzles/">Simon Tatham’s puzzle collection</a>, where I found the map puzzle. This collection’s implementation of the map puzzle shows the givens and solved cells as solid colors, and allows unsolved cells to be marked by dots of any combination of the four colors. So I’ve been using these dots to indicate the remaining colors available for each cell, in cases when the deductions get complicated enough that I can’t just remember them without marking them. A cell that has dots of only one color rather than a solid color is effectively solved (we know what color it is going to end up being) but might still belong to some unanchored Kempe chains. Once all three Kempe chains through a cell of known color have been anchored, I color that cell as solid. In this way, the parts of the solution that might include unanchored Kempe chains typically remain small and distinctively colored, making the chains easy to spot.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain.png"/></p>

<p>The image above shows an example, from one of the hardest built-in difficulty levels of the puzzle (“20x15, 30 regions, Unreasonable”). An orange-brown Kempe chain can be seen in the bottom left, in the two cells colored by orange and brown dots. (Yes, I know these two colors are hard to tell apart; I can’t change them.) Its only escape cell has yellow and brown neighbors, and cannot be green (leaving the orange-brown chain unanchored), so it must be orange. This set of deductions allows us in turn to infer the colors of the other two cells in the chain, and to make them solid (their three Kempe chains all become anchored). The orange escape cell becomes dotted rather than solid, because it is part of a different Kempe chain (colored orange-green) that remains unanchored.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain-2.png"/></p>

<p>This extended deduction rule seems to be working well for the puzzles I’ve tried it on. And by obeying the requirement that deductions remain triggered until performed, it gives me confidence that I’m not hiding any usable information by doing my deductions in the wrong order. There is no wrong order: any order in which I make my deductions will eventually lead me to the same state.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102521934491138847">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-28T17:19:00Z</updated>
    <published>2019-07-28T17:19:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-01T06:42:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/098" rel="alternate" type="text/html"/>
    <title>TR19-098 |  Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit | 

	Clement Canonne, 

	Jayadev Acharya, 

	Himanshu Tyagi, 

	Ziteng Sun, 

	Yanjun Han</title>
    <summary>We study goodness-of-fit of discrete distributions in the distributed setting, where samples are divided between multiple users who can only release a limited amount of information about their samples due to various information constraints. Recently, a subset of the authors showed that having access to a common random seed (i.e., shared randomness) leads to a significant reduction in the sample complexity of this problem. In this work, we provide a complete understanding of the interplay between the amount of shared randomness available, the stringency of information constraints, and the sample complexity of the testing problem by characterizing a tight trade-off between these three parameters. We provide a general distributed goodness-of-fit protocol that as a function of the amount of shared randomness interpolates smoothly between the private- and public-coin sample complexities. We complement our upper bound with a general framework to prove lower bounds on the sample complexity of this testing problems under limited shared randomness. Finally, we instantiate our bounds for the two archetypal information constraints of communication and local privacy, and show that our sample complexity bounds are optimal as a function of all the parameters of the problem, including the amount of shared randomness.

A key component of our upper bounds is a new primitive of domain compression, a tool that allows us to map distributions to a much smaller domain size while preserving their pairwise distances, using a limited amount of randomness.</summary>
    <updated>2019-07-28T10:17:48Z</updated>
    <published>2019-07-28T10:17:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-03T02:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4251</id>
    <link href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/" rel="alternate" type="text/html"/>
    <title>Three stories about U.C. administration</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A few months ago, I was delighted to see the University of California holding on to its demands in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed … <a href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I was delighted to see the University of California <a href="https://www.theatlantic.com/science/archive/2019/03/uc-elsevier-publisher/583909/">holding on to its demands</a> in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed journals, U.C. scholars could publish in them with open access (that is, so that anybody in the world would have free access to the articles written by U.C. scholars).</p>
<p>This seemed like a reasonable model to balance profitability for publishers and open access, but there was no way to agree on it with Elsevier. Meanwhile, U.C. has not renewed its Elsevier subscriptions and Elsevier has cut off access to U.C. libraries.</p>
<p>I was very impressed to see the University of California central administration do something right, so I wondered if this was the kind of portent that is a harbinger of the apocalypse, or just a fluke. Subsequent events suggest the latter.</p>
<p>The University of California has spent a lot of time and money to build a centralized system for job applications and for job applicant review. I was first made aware of this when I chaired the recruiting committee for the Simons Director position. At first we were told that we could solicit applications through the (vastly superior) EECS-built system for job applications and reviews. After the application deadline passed, we were told that, in fact, we could <i>not</i> use the EECS system, and so the already overworked EECS faculty HR person had to manually copy all the data in the central campus system. </p>
<p>The American Mathematical Society has created a wonderfully functional system, called <a href="https://www.mathjobs.org/jobs">Mathjobs</a> where applicants for academic mathematics jobs (ranging from postdocs to professorship) can upload their application material once, and their recommenders can upload their letters once, and then all the universities that the candidate applies to have access to this material. Furthermore, if needed, both applicants and recommenders can tailor-make their material for a particular university or universities, if they want to.</p>
<p>Everybody was living happily, but not ever after, because the U.C. central campus administration decided that <i>everybody</i> in the University of California had to use the centralized system for <i>all</i> jobs. Both the AMS and U.C. mathematicians tried to find a reasonable accommodation, such as allowing the U.C. system to access the letters posted on mathjobs. The campus administration reasoned response was roughly “sucks to be you.” There is more of the story in an <a href="https://www.ams.org/journals/notices/201907/rnoti-p1085.pdf">AMS notices article</a> by the chair of math at U.C. Davis.</p>
<p>Finally, this year <a href="https://www.sfchronicle.com/nation/article/UC-Berkeley-booted-from-U-S-News-World-Report-14189464.php">U.C. Berkeley</a> will not be listed in the US News and World Report rankings because it has submitted wrong data in the past.</p></div>
    </content>
    <updated>2019-07-27T22:06:35Z</updated>
    <published>2019-07-27T22:06:35Z</published>
    <category term="Berkeley"/>
    <category term="things that are terrible"/>
    <category term="University of California"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-08-03T02:20:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7683541918979097623</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7683541918979097623/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html" rel="alternate" type="text/html"/>
    <title>The Advisor/Advisee Relationship</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I've always felt a strong advisor/advisee relationship is the single most important factor in a successful PhD career. At its best, the advisor works closely with the student to successful research agenda and help mentor them through their graduate career and beyond. The advisor/advisee relationship can feel like a parent/child relationship that lasts an entire career. Nothing gives me more pleasure as an academic than to see the success of my current and former students.<br/>
<br/>
Take your time when picking an advisor. Don't choose an advisor based solely on research area or because they are "famous". Pick the advisor that will best guide you to a successful academic career.<br/>
<br/>
At its worst, a bad advisor/advisee relationship will destroy your graduate career, making you feel miserable, perhaps dropping out of graduate school or worse, particularly if a student doesn't feel like they are being treated fairly.<br/>
<br/>
Two incidents prompted this post. On TCS-Stack Exchange, a student has <a href="https://cstheory.stackexchange.com/questions/42704/single-author-papers-against-my-advisors-will/42711">authorship issues</a> with their advisor. Unfortunately these kinds of incidents happen more often than one suspects. If you can't work it out with the advisor, go talk to someone about it, another faculty, the graduate or department chair, a grad student ombudsperson if your institution has one. We care about our students, and will work hard to resolve problems.<br/>
<br/>
In a much more <a href="https://medium.com/@huixiangvoice/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3">tragic event</a>, a student felt it easier to take his own life than feeling that he had to cover up potential academic misconduct. Again, if you ever find yourself in such a situation please reach out. Giving up is never the answer.</div>
    </content>
    <updated>2019-07-25T20:39:00Z</updated>
    <published>2019-07-25T20:39:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-02T13:54:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16124</id>
    <link href="https://rjlipton.wordpress.com/2019/07/25/discrepancy-games-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Discrepancy Games and Sensitivity</title>
    <summary>Can we connect the talks that closed this month’s Random Structures and Algorithms conference? Cropped from NYU homepage Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms conference at ETH Zurich. Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can we connect the talks that closed this month’s Random Structures and Algorithms conference?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg"><img alt="" class="alignright wp-image-16126" height="200" src="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg?w=137&amp;h=200" width="137"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from NYU <a href="https://cs.nyu.edu/spencer/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms <a href="https://math.ethz.ch/fim/conferences/19th-int-conf-random-structures-algorithms/schedule.html">conference</a> at ETH Zurich.</p>
<p>
Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this month of the Boolean sensitivity conjecture.</p>
<p>
Spencer’s <a href="https://ethz.ch/content/dam/ethz/special-interest/math/mathematical-research/fim-dam/Conferences/2019/19th Int Conf on Random Structures and Algorithms/Abstracts/Spencer_Joel.pdf">talk</a> was titled “Four Discrepancies” and based on a joint <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> with Nikhil Bansal. The main new result in the talk was a case where a bound of <img alt="{O(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n\log n})}"/> arising from reasoning about normal distribution can, surprisingly, be improved to a sharp <img alt="{O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n})}"/>. </p>
<p>
We will talk about this first, but then progress to the talk that preceded Spencer’s. It was by Hao Huang, who was extended an invitation right after his announced <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture earlier this month. Our ulterior purpose is to ask whether any concrete connections can be found besides both talks addressing problems on the <img alt="{\{-1,+1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C%2B1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,+1\}^n}"/> hypercube.<span id="more-16124"/></p>
<p>
</p><p/><h2> Discrepancy Games </h2><p/>
<p/><p>
First suppose you get a stream of single bits <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_t}"/>, each <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> or <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/>. For each bit, you can say “Keep it” or “Flip it.” In the latter case, your bit <img alt="{w_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_t}"/> is <img alt="{-v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-v_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-v_t}"/>. Your goal is to keep the sum <img alt="{\sum_{k=1}^t w_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bk%3D1%7D%5Et+w_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{k=1}^t w_k}"/> within a bounded range. OK, this is easy: you can make the sum always be <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is odd and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is even by flipping when needed.</p>
<p>
Now suppose the bits come in pairs <img alt="{(v_{t,1},v_{t,2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28v_%7Bt%2C1%7D%2Cv_%7Bt%2C2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(v_{t,1},v_{t,2})}"/> and your goal is to keep the sum in each coordinate bounded. Again there is a simple strategy: There are four kinds of vectors. For each kind, every time you see it for the second time, flip it. That keeps the contribution of each kind within <img alt="{-1 \ldots +1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1+%5Cldots+%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1 \ldots +1}"/> in each coordinate. Thus simple reasoning says each coordinate stays within <img alt="{-4 \ldots +4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-4+%5Cldots+%2B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-4 \ldots +4}"/>. </p>
<p>
The trouble with extending this idea to vectors of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is that the number of kinds is <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> and our simple-minded bounds, while constant in terms of the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors given, are exponential in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. Well, we can certainly do better. Going back to the <img alt="{n = 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 2}"/> case, we can maintain a policy of never letting both coordinates become <img alt="{+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+2}"/> or both become <img alt="{-2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2}"/>. This keeps both sums within <img alt="{-2 \ldots +2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2+%5Cldots+%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2 \ldots +2}"/> regardless of the sequence of the vectors. But for larger vector lengths <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, how large can the <em>discrepancy</em> among the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> coordinate sums—relative to zero or to each other—become?</p>
<p>
A final help is if we know the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors in any sequence we might be given is bounded. In fact, Spencer’s paper with Bhansal first considers the case <img alt="{T = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = n}"/>. There are two main questions about randomness:</p>
<ol>
<li>
Does it matter whether the sequence of vectors given is random or worst-case? <p/>
</li><li>
Can you do better than choosing “keep” or “flip” randomly?
</li></ol>
<p>
Long back, Spencer <a href="https://cs.nyu.edu/spencer/sixsigma.pdf">proved</a> that if you can see the whole sequence of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vectors in advance, then you can always keep the sums within <img alt="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-5.32+%5Csqrt%7Bn%7D+%5Cldots+%2B5.32%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}"/>, whatever the sequence. If not—if you must decide “keep” or “flip” for each vector before seeing the next—then Spencer had also <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=HTxo3kP7_5gC&amp;oi=fnd&amp;pg=PP2&amp;dq=Ten+Lectures+on+the+Probabilistic+Method+Spencer&amp;ots=hGDS5tiCgB&amp;sig=qP53Ty3AQgVJF2J4wzcmT948mmY#v=onepage&amp;q=Ten Lectures on the Probabilistic Method Spencer&amp;f=false">proved</a>:</p>
<blockquote><p><b>Theorem 1</b> <em> If an adversary can choose the next vector based on your current sums, then the best bound <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> such that you can keep all your sums within absolute value <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> grows as <img alt="{\Theta(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta(\sqrt{n\log n})}"/>. Moreover, up to the constant in the “<img alt="{\Theta,}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%2C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta,}"/>” with high probability you cannot do any better than choosing the sign for each vector randomly. </em>
</p></blockquote>
<p/><p>
See also his famous <a href="https://www.wiley.com/en-us/The+Probabilistic+Method/+4th+Edition-p-9781119061953">book</a>, <em>The Probabilistic Method</em>, with Noga Alon. The new theorem is:</p>
<blockquote><p><b>Theorem 2</b> <em> If the adversary presents vectors uniformly at random, then you <b>can</b> achieve <img alt="{B = O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%3D+O%28%5Csqrt%7Bn%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B = O(\sqrt{n})}"/> with high probability—and not by choosing the signs randomly. </em>
</p></blockquote>
<p/><p>
The algorithm defines a kind of <em>potential function</em> and has you play “keep” or “flip” according to which has the lesser growth in potential. The analysis is quite complicated. As usual we refer to the <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> for details. Instead we ask: are there insights to mine here for further advances on the Boolean sensitivity problem?</p>
<p>
</p><p/><h2> Boolean Sensitivity </h2><p/>
<p/><p>
We didn’t talk about Boolean sensitivity in our previous <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a> on it. Our purpose now is to convey how many concepts are related, hence how they might connect to discrepancy on the hypercube. </p>
<p>
To get the idea of sensitivity, first consider the parity function <img alt="{f_{\oplus}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}}"/>. If you change one bit of any argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you change the value of <img alt="{f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x)}"/>. Define <img alt="{x^i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^i}"/> to mean <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> with bit <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> flipped. Then for any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, <img alt="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%5Ei%29+%5Cneq+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}"/>. This means parity is extremely sensitive.</p>
<p>
The OR function <img alt="{f_{\vee}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}}"/> is intuitively less sensitive, but it too has an argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> such that <img alt="{f_{\vee}(x^i) \neq f_{\vee}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%28x%5Ei%29+%5Cneq+f_%7B%5Cvee%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}(x^i) \neq f_{\vee}(x)}"/> for all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, namely <img alt="{x = 0^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+0%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x = 0^n}"/>. For any Boolean function <img alt="{f: \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f: \{0,1\}^n \rightarrow \{0,1\}}"/> define its <em>sensitivity</em> (at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) by </p>
<p align="center"><img alt="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s%28f%29+%3D+s_n%28f%29+%3D+%5Cmax_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%7C%7C%5C%7Bi%3A+f%28x%5Ei%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. "/></p>
<p>The OR-of-AND function <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> is less sensitive. Say it is an OR of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> blocks, each of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> variables, and the blocks use disjoint variables so <img alt="{n = km}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+km%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = km}"/>. If <img alt="{f_2(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 1}"/>, then some block is all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, so flipping any other bit makes no difference, and the most sensitive we can get is <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. If <img alt="{f_2(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 0}"/> then the most sensitive case is when all blocks have exactly one 0. So <img alt="{s(f_2) = \max\{k,m\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f_2%29+%3D+%5Cmax%5C%7Bk%2Cm%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f_2) = \max\{k,m\}}"/>. When <img alt="{k = m = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+m+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = m = \sqrt{n}}"/>, <img alt="{s_n(f) = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n%28f%29+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s_n(f) = \sqrt{n}}"/>.</p>
<p>
If we make each block of <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> return <em>true</em> if exactly one bit is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, then we again get sensitivity <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> on the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment. Now, however, consider the related function <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> (with <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> even, <img alt="{k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 2\ell}"/>) that is still an OR over blocks, but each block is true when some consecutive pair <img alt="{x_{2\ell - 1},x_{2\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B2%5Cell+-+1%7D%2Cx_%7B2%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{2\ell - 1},x_{2\ell}}"/> are both <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> with all other pairs being both <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. Then we can’t do the same trick with the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment changing just one bit. So when <img alt="{n = 4\ell^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%5Cell%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4\ell^2}"/> and <img alt="{m = k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+k+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = k = 2\ell}"/> we again get sensitivity (no more than) <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </p>
<p>
We can, however, consider <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> to be more sensitive if we can flip more than one bit at a time. Partition <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into <em>blocks</em> <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> of two consecutive bit-places each, and given any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>, define <img alt="{x^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^B}"/> to be the result of flipping the bits in <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>. We get <img alt="{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n/2}"/> blocks, and the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment becomes a <em>true</em> case of <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> if any block is flipped. Generally define the <em>block sensitivity</em> by considering any partitions <img alt="{\mathcal{B} = \{B_j\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BB%7D+%3D+%5C%7BB_j%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{B} = \{B_j\}}"/> of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into disjoint subsets and writing </p>
<p align="center"><img alt="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%3D+%5Cmax_%7Bx%2C%5Cmathcal%7BB%7D%7D+%7C%7C%5C%7Bj%3A+f%28x%5E%7BB_j%7D%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. "/></p>
<p>Note that not every member of the partition has to flip the function—we can discard the ones that don’t flip and count only the disjoint subsets that do flip the value. So back to our example, we have </p>
<p align="center"><img alt="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%27_2%29+%3D+%5Cfrac%7Bn%7D%7B2%7D+%3D+%5Cfrac%7B1%7D%7B2%7Ds%28f%27_2%29%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. "/></p>
<p>Andris Ambainis and Xiaoming Sun <a href="https://arxiv.org/abs/1108.3494">improved</a> the constant from <img alt="{\frac{1}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2}}"/> asymptotically to <img alt="{\frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{2}{3}}"/>, but their relation is still quadratic.</p>
<p>
</p><p/><h2> Some Boolean Complexity Connections </h2><p/>
<p/><p>
This <a href="https://link.springer.com/article/10.1007/BF01200762">example</a> of quadratic discrepancy is still the best known lower bound on <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/> in terms of <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>. But no one had proved anything better than an exponential upper bound until Huang’s result, from which it follows that:</p>
<blockquote><p><b>Theorem 3</b> <em><a name="Huang"/> For all Boolean functions <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/>, <img alt="{bs(f) \leq 2s(f)^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29+%5Cleq+2s%28f%29%5E4%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{bs(f) \leq 2s(f)^4}"/>. </em>
</p></blockquote>
<p/><p>
This bound is concrete, not just asymptotic. It still leaves a gap between quadratic and quartic. It is, however, the combination of two quadratic upper bounds. One was shown by Nisan and Szegedy in their <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a>: </p>
<p align="center"><img alt="\displaystyle  bs(f) \leq 2\deg(f)^2, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%5Cleq+2%5Cdeg%28f%29%5E2%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) \leq 2\deg(f)^2, "/></p>
<p>where <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> means the degree of the unique multi-linear real polynomial that agrees with <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> on the cube <img alt="{\{-1,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,1\}^n}"/> with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> for <em>true</em>. The other is the conjecture </p>
<p align="center"><img alt="\displaystyle  \deg(f) \leq s(f)^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \deg(f) \leq s(f)^2 "/></p>
<p>in a 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a> by Craig Gotsman and Nati Linial. Huang proved this by exploiting a connection to graphs that was also shown by Gotsman and Linial. Consider any red-or-white coloring of the <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> nodes of the hypercube, let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> be the graph induced by the red nodes, and define <img alt="{g(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 1}"/> if node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is red, <img alt="{g(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 0}"/> otherwise. Now if the maximum degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a node in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is small then every red node has many white neighbors, so the Boolean function <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is very sensitive. However, going to each neighbor in the hypercube flips the parity. Hence the function </p>
<p align="center"><img alt="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%27%28x%29+%3D+g%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) "/></p>
<p>is <b>not</b> very sensitive. Moreover, it has the same sensitivity as the function <img alt="{h'(x) = h(x) \oplus f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%27%28x%29+%3D+h%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h'(x) = h(x) \oplus f_{\oplus}(x)}"/> where <img alt="{h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x)}"/> is true on the white nodes. This nice duality between <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> and the graph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> induced by the white nodes enables us to fix “<img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>” to mean whichever of the two has more nodes in the following theorem statement: </p>
<blockquote><p><b>Theorem 4</b> <em> Provided <img alt="{m &gt; 2^{n-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%5E%7Bn-1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m &gt; 2^{n-1}}"/>, every graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> induced by <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-cube has <img alt="{d(G) \geq \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq \sqrt{n}}"/> if and only if every Boolean function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has <img alt="{\deg(f) \leq s(f)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\deg(f) \leq s(f)^2}"/>. </em>
</p></blockquote>
<p/><p>
The proof uses some Fourier analysis with <img alt="{f = g'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3D+g%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f = g'}"/> as above. It, too, takes only one page of a really short paper. </p>
<p>
The main open question now is whether the 4th-power upper bound in Huang’s theorem <a href="https://rjlipton.wordpress.com/feed/#Huang">3</a> can be improved to quadratic. It is possible that a deeper application of Fourier analysis may show that cases of quadratic separation from <em>block-sensitivity</em> to <em>degree</em> and <em>degree</em> to <em>sensitivity</em> cannot “amplify” any more than quadratic. This is where there might be some commonality with discrepancy. </p>
<p>
There is a much wider suite of Boolean complexity measures besides <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>, <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/>, and <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> discussed here. For example, consider how many bits of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you need to fix in order to preserve the value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. That is, define <img alt="{C(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f)}"/> to be the maximum over <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of the minimum size of a set <img alt="{I \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I \subseteq [n]}"/> such that whenever <img alt="{x'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x'}"/> agrees with <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> on <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/>, <img alt="{f(x') = f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%27%29+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x') = f(x)}"/>. Clearly <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/> needs to include at least one bit from each <img alt="{B_j.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_j.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B_j.}"/> This proves <img alt="{C(f) \geq bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29+%5Cgeq+bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f) \geq bs(f)}"/>. There are many other relations that might be improved. We end by considering ways of broadening Huang’s techniques.</p>
<p>
</p><p/><h2> Weak Adjacency Matrices </h2><p/>
<p/><p>
We—that is Ken and I—have been thinking about how to build on Huang’s proof. We take a somewhat more-general approach compared to the paper and Ken’s <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a>.</p>
<blockquote><p><b>Definition 5</b> <em> Let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> be a graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> vertices. The <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> by <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a <b>weak adjacency</b> matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> provided </em></p><em>
<ol>
<li>
Every entry <img alt="{A_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}}"/> is bounded by <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/> in absolute value; <p/>
</li><li>
For all <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y}"/> if <img alt="{x \rightarrow y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x \rightarrow y}"/> is not an edge in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>, then <img alt="{A_{x,y}=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%3D0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}=0}"/>.
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
As usual the maximum degree of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is denoted by <img alt="{\deg(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(G)}"/>. The following is almost the same proof as the classic result on adjacency matrices. </p>
<blockquote><p><b>Lemma 6 (H-Lemma)</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then if <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> is an eigenvalue of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  | \lambda | \le \deg(G). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C+%5Clambda+%7C+%5Cle+%5Cdeg%28G%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  | \lambda | \le \deg(G). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  By the definition of eigenvalue, there is some non-zero vector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> so that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/>. Let <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> be an index so that <img alt="{|v_{k}|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|}"/> maximum. Then 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%3D%7C%28A+v%29_%7Bk%7D%7C%3D+%5Cleft%7C%5Csum_%7By%3D1%7D%5E%7Bn%7D+A_%7Bk%2Cy%7Dv_%7By%7D+%5Cright%7C+%5Cleq+%5Csum_%7By%3D1%7D%5E%7Bn%7D+%7CA_%7Bk%2Cy%7D%7C+%5Ccdot+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. "/></p>
<p>But then the last sum is upper bounded by 	</p>
<p align="center"><img alt="\displaystyle  D|v_{k}|, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%7Cv_%7Bk%7D%7C%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  D|v_{k}|, "/></p>
<p>where <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is the number of <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> so that <img alt="{A_{k,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bk%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{k,y}}"/> is not zero. This uses property (1) of the definition of a weak adjacency matrix. Property (2) implies that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is at most the degree of vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> is <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Thus 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%5Cleq+D+%7Cv_%7Bk%7D%7C+%5Cleq+%5Cdeg%28G%29+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. "/></p>
<p>Dividing by <img alt="{|v_{k}|&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|&gt;0}"/> yields the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
Let <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> be the graph that results after we delete the vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Let <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> be the matrix that results after we delete the column and row <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. </p>
<blockquote><p><b>Lemma 7</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then for any vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A-k}"/> is a weak adjacency matrix of <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G-k}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The bound on the entries of <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> is immediate. Whenever <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> has no edge from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> to <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>, then <img alt="{(A-k)_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A-k%29_%7Bx%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A-k)_{x,y}}"/> must be zero. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Lemma 8</b> <em> Suppose that <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> a <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-graph has a real symmetric weak adjacency matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> with <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> of the top eigenvalues greater than <img alt="{B \ge 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Cge+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B \ge 0}"/>. Then every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> with at least <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n-m}"/> vertices has degree at least <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/>. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Definition 9</b> <em> The <b>hypercube</b> <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> is the graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> bit vectors so that two vertices are adjacent if they differ in one bit position. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Theorem 10</b> <em> The hypercube <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> has a real symmetric weak adjacency matrix with all its eigenvalues <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{A_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%090+%26+1+%5C%5C+%09%091+%26+0+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. "/></p>
<p>and <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%09A_%7Bn-1%7D+%26+I+%5C%5C+%09%09I+%26+-A_%7Bn-1%7D+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. "/></p>
<p>
Induction shows that <img alt="{A_{n}^{2} = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%5E%7B2%7D+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}^{2} = nI}"/>. It follows that 	</p>
<p align="center"><img alt="\displaystyle  A_{n}x = \lambda x, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bn%7Dx+%3D+%5Clambda+x%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_{n}x = \lambda x, "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda Ax. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda+Ax.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda Ax. "/></p>
<p>Thus 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda^{2}x. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda%5E%7B2%7Dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda^{2}x. "/></p>
<p>So the eigenvalues are <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/> and by trace same number of each.</p>
<p>
The upper-left and lower-right blocks of <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> correspond to the two <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n-1}"/> dimensional subcubes of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>, and the two identity blocks correspond to the perfect matching connecting these two subcubes. So <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> is a weak adjacency matrix for <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Corollary 11</b> <em> Every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> with at least <img alt="{2^{n-1}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn-1%7D%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{2^{n-1}+1}"/> vertices has degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can the last two talks at the conference be further connected?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-25T20:35:29Z</updated>
    <published>2019-07-25T20:35:29Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="algoritrhms"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="discrepancy"/>
    <category term="Hao Huang"/>
    <category term="hypercube"/>
    <category term="Joel Spencer"/>
    <category term="Nikhil Bansal"/>
    <category term="randomized algorithms"/>
    <category term="randomness"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-03T02:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17669</id>
    <link href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/" rel="alternate" type="text/html"/>
    <title>TYI 39 : Can a coalition of children guarantees all being in the same class?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that … <a href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg"><img alt="" class="alignnone size-medium wp-image-17676" height="213" src="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg?w=300&amp;h=213" width="300"/></a></p>
<p>There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that each child will have at least one of these three friends in his class.</p>
<p>One of the children heard from five of his schoolmates that they found that they can make their selections in a way that will ensure that all five will be assigned to the same class!</p>
<h3><span style="color: #993366;">Test your intuition: Is there a strategy for five of the children that will ensure that all five will be assigned to the same class?</span></h3>
<p>Can a larger group of children coordinate their choices to ensure that they will all necessarily be assigned to the same class?</p>
<a name="pd_a_10371327"/><div class="CSS_Poll PDS_Poll" id="PDI_container10371327" style="display: inline-block;"/><div id="PD_superContainer"/><noscript>&lt;a href="https://polldaddy.com/p/10371327" target="_blank"&gt;Take Our Poll&lt;/a&gt;</noscript>
<p><span id="more-17669"/></p>
<p><strong>Bonus question:</strong> In case that every child lists only two friends and one of them is guaranteed to be in the same class. Is there a strategy of five children that will ensure they are in the same class?</p>
<p><strong>Answer to Bonus question</strong>: Yes. For three children you let every one choose the other two. For the remaining children you let each one choose two among the three.</p></div>
    </content>
    <updated>2019-07-25T12:59:05Z</updated>
    <published>2019-07-25T12:59:05Z</published>
    <category term="Combinatorics"/>
    <category term="Economics"/>
    <category term="Mathematics to the rescue"/>
    <category term="Test your intuition"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-03T02:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/097</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/097" rel="alternate" type="text/html"/>
    <title>TR19-097 |  Reversible Pebble Games and the Relation Between Tree-Like and General Resolution Space | 

	Florian Wörz, 

	Jacobo Toran</title>
    <summary>We show a new connection between the space measure in tree-like resolution and the reversible pebble game in graphs. Using this connection we provide several formula classes for which there is a logarithmic factor separation between the space complexity measure in tree-like and general resolution. We show that these separations are almost optimal by proving upper bounds for tree-like resolution space in terms of general resolution clause and variable space. In particular we show that for any formula F, its tree-like resolution is upper bounded by space(?)log time(?) where ? is any general resolution refutation of F. This holds considering as space(?) the clause space of the refutation as well as considering its variable space. For the concrete case of Tseitin formulas we are able to improve this bound to the optimal bound space(?)log(n), where n is the number of vertices of the corresponding graph.</summary>
    <updated>2019-07-24T12:09:27Z</updated>
    <published>2019-07-24T12:09:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-03T02:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/096</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/096" rel="alternate" type="text/html"/>
    <title>TR19-096 |  On the $\text{AC}^0[\oplus]$ complexity of Andreev&amp;#39;s Problem | 

	Aditya Potukuchi</title>
    <summary>Andreev's Problem asks the following: Given an integer $d$ and a subset of $S \subseteq \mathbb{F}_q \times \mathbb{F}_q$, is there a polynomial $y = p(x)$ of degree at most $d$ such that  for every $a \in \mathbb{F}_q$, $(a,p(a)) \in S$? We show an $\text{AC}^0[\oplus]$ lower bound for this problem. 

This problem appears to be similar to the list recovery problem for degree $d$-Reed-Solomon codes over $\mathbb{F}_q$ which asks the following: Given subsets $A_1,\ldots,A_q$ of $\mathbb{F}_q$, output all (if any) Reed-Solomon codewords contained in $A_1\times \cdots \times A_q$. For our purpose, we study this problem when $A_1, \ldots, A_q$ are random subsets of a given size, which may be of independent interest.</summary>
    <updated>2019-07-23T17:29:25Z</updated>
    <published>2019-07-23T17:29:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-03T02:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17642</id>
    <link href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="alternate" type="text/html"/>
    <title>Matan Harel, Frank Mousset, and Wojciech Samotij and the “the infamous upper tail” problem</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek! Artist: Heidi Buck. “Catch a Dragon by the Tail 2” ( source ) Upper tails via high moments and entropic … <a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png"><img alt="" class="alignnone size-full wp-image-17644" height="496" src="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png?w=640&amp;h=496" width="640"/></a></p>
<p>Artist: Heidi Buck.<strong><span style="color: #ff0000;"> “Catch a Dragon by the Tail 2”</span></strong> ( <a href="https://www.hbdragon.com/main/content/catch-dragon-tail-2">source</a> )</p>
<p class="title mathjax"><a href="https://arxiv.org/abs/1904.08212">Upper tails via high moments and entropic stability</a> by Matan Harel, Frank Mousset, and Wojciech Samotij</p>
<p><strong>Abstract:</strong></p>
<p>Suppose that <em>X</em> is a bounded-degree polynomial with nonnegative coefficients on the <em>p</em>-biased discrete hypercube. Our main result gives sharp estimates on the logarithmic upper tail probability of X whenever an associated extremal problem satisfies a certain entropic stability property. We apply this result to solve two long-standing open problems in probabilistic combinatorics: the upper tail problem for the number of arithmetic progressions of a fixed length in the <em>p</em>-random subset of the integers and the upper tail problem for the number of cliques of a fixed size in the random graph <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/>. We also make significant progress on the upper tail problem for the number of copies of a fixed regular graph <em>H</em> in <img alt="G_{n,p}." class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}."/> To accommodate readers who are interested in learning the basic method, we include a short, self-contained solution to the upper tail problem for the number of triangles in <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/> for all <em>p=p(n)</em> satisfying <img alt="\frac {\log n}{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B%5Clog+n%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac {\log n}{n}"/> <img alt="\ll" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cll&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ll"/> <img alt="p \ll 1" class="latex" src="https://s0.wp.com/latex.php?latex=p+%5Cll+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p \ll 1"/>.</p>
<p>The introduction does a very nice job of presenting the rich history of the problem.  Here is a 2002 paper by Svante Janson and Andrzej Ruciński on <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/rsa.10031?casa_token=7FoHUVq0w5IAAAAA:AqmK_4tpjDzXErWnGh4qnE2kn4NTupyoW27eSXW7Uwr5l0JgpBP5SG7PaVnJ6Lvr4JhCaSIH2HPv-QTsUg">the infamous upper tail</a>.  (And a lot has happened since then with regard to this problem and on non linear large deviation theory). Following, there is a lovely section with a short solution for the case of triangles.</p>
<p>Forthcoming reference [48] talks about lower tails! Stay tuned!</p></div>
    </content>
    <updated>2019-07-23T06:51:02Z</updated>
    <published>2019-07-23T06:51:02Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Frank Mousset"/>
    <category term="Matan Harel"/>
    <category term="Wojciech Samotij"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-03T02:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7828284719883166611</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7828284719883166611/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html" rel="alternate" type="text/html"/>
    <title>Answer to both Infinite Hats Problems from the last post</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
(This is a joint post with David Marcus. You'll see why later.)<br/>
<br/>
In a prior  I posed two infinite hat problems. Today I post the solutions. Actually this is a copy of my last post with the solutions added, so it is self contained.<br/>
<br/>
A Hat Problem that you have probably seen:<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions (the answers are in a document I point to) and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (If you have read my prior post on hat puzzles, <a href="https://blog.computationalcomplexity.org/2017/07/two-hat-problems-you-may-or-may-not.html">here</a> then you can do this one.) <br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong.<br/>
<br/>
<br/>
Answers to Q1 and Q2 are <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/infinitehats.pdf">here</a>.<br/>
<br/>
How did I get into this problem? I was looking at hat problems a while back. Then  I began discussing Q1 and Q2 by email  (Does the term <i>discussing</i> have as a default that it is by email?) with David Marcus who had just read the chapter of <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a Point</a> on hat puzzles. After a few emails back and fourth, he began looking on the web for answers. He found one. There is a website of hat puzzles! It was MY website papers on  Hat Puzzles! It is  <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/hats.html">here</a>. And on it was a relevant paper <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/infinite-hats-and-ac.pdf">here</a>. We did not find any other source of the problem or its solution. <br/>
<br/>
Q3: How well known is problem Q2 and the solution?  I've seen Q1 around but the only source on Q2 that I know of is that paper, and now this blog post. So, please leave a comment telling me if you have seen Q2 and/or the solution someplace else, and if so where.<br/>
<br/>
The responses to my last post indicated that YES the problem was out there, but the proof that you could not get all-but-18 was not well known. <br/>
<br/>
I THINK that all of the proofs that you can't do all-but-18 in the comment of the last post were essentially the same as the solution I pointed to in this blog. I would be interested if there is an alternative proof. <br/></div>
    </content>
    <updated>2019-07-22T03:00:00Z</updated>
    <published>2019-07-22T03:00:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-02T13:54:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/095" rel="alternate" type="text/html"/>
    <title>TR19-095 |  Unambiguous Catalytic Computation | 

	Chetan Gupta, 

	Rahul Jain, 

	Vimal Raj Sharma, 

	Raghunath Tewari</title>
    <summary>The catalytic Turing machine is a model of computation defined by Buhrman, Cleve,
Kouck, Loff, and Speelman (STOC 2014). Compared to the classical space-bounded Turing
machine, this model has an extra space which is filled with arbitrary content in addition
to the clean space. In such a model we study if this additional filled space can be used to
increase the power of computation or not, with the condition that the initial content of this
extra filled space must be restored at the end of the computation.
In this paper, we define the notion of unambiguous catalytic Turing machine and prove
that under a standard derandomization assumption, the class of problems solved by an
unambiguous catalytic Turing machine is same as the class of problems solved by a general
nondeterministic catalytic Turing machine in the logspace setting.</summary>
    <updated>2019-07-21T11:21:02Z</updated>
    <published>2019-07-21T11:21:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-03T02:20:38Z</updated>
    </source>
  </entry>
</feed>
