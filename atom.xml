<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-07-08T07:22:09Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03633</id>
    <link href="http://arxiv.org/abs/2007.03633" rel="alternate" type="text/html"/>
    <title>Streaming Complexity of SVMs</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Andoni:Alexandr.html">Alexandr Andoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Burns:Collin.html">Collin Burns</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yi.html">Yi Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahabadi:Sepideh.html">Sepideh Mahabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03633">PDF</a><br/><b>Abstract: </b>We study the space complexity of solving the bias-regularized SVM problem in
the streaming model. This is a classic supervised learning problem that has
drawn lots of attention, including for developing fast algorithms for solving
the problem approximately. One of the most widely used algorithms for
approximately optimizing the SVM objective is Stochastic Gradient Descent
(SGD), which requires only $O(\frac{1}{\lambda\epsilon})$ random samples, and
which immediately yields a streaming algorithm that uses
$O(\frac{d}{\lambda\epsilon})$ space. For related problems, better streaming
algorithms are only known for smooth functions, unlike the SVM objective that
we focus on in this work. We initiate an investigation of the space complexity
for both finding an approximate optimum of this objective, and for the related
``point estimation'' problem of sketching the data set to evaluate the function
value $F_\lambda$ on any query $(\theta, b)$. We show that, for both problems,
for dimensions $d=1,2$, one can obtain streaming algorithms with space
polynomially smaller than $\frac{1}{\lambda\epsilon}$, which is the complexity
of SGD for strongly convex functions like the bias-regularized SVM, and which
is known to be tight in general, even for $d=1$. We also prove polynomial lower
bounds for both point estimation and optimization. In particular, for point
estimation we obtain a tight bound of $\Theta(1/\sqrt{\epsilon})$ for $d=1$ and
a nearly tight lower bound of $\widetilde{\Omega}(d/{\epsilon}^2)$ for $d =
\Omega( \log(1/\epsilon))$. Finally, for optimization, we prove a
$\Omega(1/\sqrt{\epsilon})$ lower bound for $d = \Omega( \log(1/\epsilon))$,
and show similar bounds when $d$ is constant.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03631</id>
    <link href="http://arxiv.org/abs/2007.03631" rel="alternate" type="text/html"/>
    <title>Lower Bounds for XOR of Forrelations</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Girish:Uma.html">Uma Girish</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Ran.html">Ran Raz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhan:Wei.html">Wei Zhan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03631">PDF</a><br/><b>Abstract: </b>The Forrelation problem, introduced by Aaronson [A10] and Aaronson and
Ambainis [AA15], is a well studied problem in the context of separating quantum
and classical models. Variants of this problem were used to give exponential
separations between quantum and classical query complexity [A10, AA15]; quantum
query complexity and bounded-depth circuits [RT19]; and quantum and classical
communication complexity [GRT19]. In all these separations, the lower bound for
the classical model only holds when the advantage of the protocol (over a
random guess) is more than $\approx 1/\sqrt{N}$, that is, the success
probability is larger than $\approx 1/2 + 1/\sqrt{N}$. To achieve separations
when the classical protocol has smaller advantage, we study in this work the
XOR of $k$ independent copies of the Forrelation function (where $k\ll N$). We
prove a very general result that shows that any family of Boolean functions
that is closed under restrictions, whose Fourier mass at level $2k$ is bounded
by $\alpha^k$, cannot compute the XOR of $k$ independent copies of the
Forrelation function with advantage better than
$O\left(\frac{\alpha^k}{{N^{k/2}}}\right)$. This is a strengthening of a result
of [CHLT19], that gave a similar result for $k=1$, using the technique of
[RT19]. As an application of our result, we give the first example of a partial
Boolean function that can be computed by a simultaneous-message quantum
protocol of cost $\mbox{polylog}(N)$ (when players share $\mbox{polylog}(N)$
EPR pairs), however, any classical interactive randomized protocol of cost at
most $\tilde{o}(N^{1/4})$, has quasipolynomially small advantage over a random
guess. We also give the first example of a partial Boolean function that has a
quantum query algorithm of cost $\mbox{polylog}(N)$, and such that, any
constant-depth circuit of quasipolynomial size has quasipolynomially small
advantage over a random guess.
</p></div>
    </summary>
    <updated>2020-07-08T01:20:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03556</id>
    <link href="http://arxiv.org/abs/2007.03556" rel="alternate" type="text/html"/>
    <title>Natural family-free genomic distance</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubert:Diego_P=.html">Diego P. Rubert</a>, Fábio V. Martinez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braga:Mar=iacute=lia_D=_V=.html">Marília D. V. Braga</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03556">PDF</a><br/><b>Abstract: </b>A classical problem in comparative genomics is to compute the rearrangement
distance, that is the minimum number of large-scale rearrangements required to
transform a given genome into another given genome.
</p>
<p>While the most traditional approaches in this area are family-based, i.e.,
require the classification of DNA fragments into families, more recently an
alternative family-free approach was proposed, and consists of studying the
rearrangement distances without prior family assignment. On the one hand the
computation of genomic distances in the family-free setting helps to match
occurrences of duplicated genes and find homologies, but on the other hand this
computation is NP-hard. In this paper, by letting structural rearrangements be
represented by the generic double cut and join (DCJ) operation and also
allowing insertions and deletions of DNA segments, we propose a new and more
general family-free genomic distance, providing an efficient ILP formulation to
solve it.
</p>
<p>Our experiments show that the ILP produces accurate results and can handle
not only bacterial genomes, but also fungi and insects, or subsets of
chromosomes of mammals and plants.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03492</id>
    <link href="http://arxiv.org/abs/2007.03492" rel="alternate" type="text/html"/>
    <title>Computing a maximum clique in geometric superclasses of disk graphs</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grelier:Nicolas.html">Nicolas Grelier</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03492">PDF</a><br/><b>Abstract: </b>In the 90's Clark, Colbourn and Johnson wrote a seminal paper, where they
proved that maximum clique can be solved in polynomial time in unit disk
graphs. Since then, the complexity of maximum clique in intersection graphs of
(unit) d-dimensional balls has been investigated. For ball graphs, the problem
is NP-hard, as shown by Bonamy et al. (FOCS '18). They also gave an efficient
polynomial time approximation scheme (EPTAS) for disk graphs, however the
complexity of maximum clique in this setting remains unknown. In this paper, we
show the existence of a polynomial time algorithm for solving maximum clique in
a geometric superclass of unit disk graphs. Moreover, we give partial results
toward obtaining an EPTAS for intersection graphs of convex pseudo-disks.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03483</id>
    <link href="http://arxiv.org/abs/2007.03483" rel="alternate" type="text/html"/>
    <title>Skeletonization via Local Separators</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Andreas Bærentzen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rotenberg:Eva.html">Eva Rotenberg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03483">PDF</a><br/><b>Abstract: </b>We propose a new algorithm for curve skeleton computation which differs from
previous algorithms by being based on the notion of local separators. The main
benefits of this approach are that it is able to capture relatively fine
details and that it works robustly on a range of shape representations.
Specifically, our method works on shape representations that can be construed
as a spatially embedded graphs. Such representations include meshes, volumetric
shapes, and graphs computed from point clouds. We describe a simple pipeline
where geometric data is initially converted to a graph, optionally simplified,
local separators are computed and selected, and finally a skeleton is
constructed. We test our pipeline on polygonal meshes, volumetric shapes, and
point clouds. Finally, we compare our results to other methods for
skeletonization according to performance and quality.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03402</id>
    <link href="http://arxiv.org/abs/2007.03402" rel="alternate" type="text/html"/>
    <title>Quantum Lower and Upper Bounds for 2D-Grid and Dyck Language</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ambainis:Andris.html">Andris Ambainis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balodis:Kaspars.html">Kaspars Balodis</a>, Jānis Iraids, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khadiev:Kamil.html">Kamil Khadiev</a>, Vladislavs Kļevickis, Krišjānis Prūsis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Yixin.html">Yixin Shen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smotrovs:Juris.html">Juris Smotrovs</a>, Jevgēnijs Vihrovs <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03402">PDF</a><br/><b>Abstract: </b>We study the quantum query complexity of two problems.
</p>
<p>First, we consider the problem of determining if a sequence of parentheses is
a properly balanced one (a Dyck word), with a depth of at most $k$. We call
this the $Dyck_{k,n}$ problem. We prove a lower bound of $\Omega(c^k
\sqrt{n})$, showing that the complexity of this problem increases exponentially
in $k$. Here $n$ is the length of the word. When $k$ is a constant, this is
interesting as a representative example of star-free languages for which a
surprising $\tilde{O}(\sqrt{n})$ query quantum algorithm was recently
constructed by Aaronson et al. Their proof does not give rise to a general
algorithm. When $k$ is not a constant, $Dyck_{k,n}$ is not context-free. We
give an algorithm with $O\left(\sqrt{n}(\log{n})^{0.5k}\right)$ quantum queries
for $Dyck_{k,n}$ for all $k$. This is better than the trival upper bound $n$
for $k=o\left(\frac{\log(n)}{\log\log n}\right)$.
</p>
<p>Second, we consider connectivity problems on grid graphs in 2 dimensions, if
some of the edges of the grid may be missing. By embedding the "balanced
parentheses" problem into the grid, we show a lower bound of
$\Omega(n^{1.5-\epsilon})$ for the directed 2D grid and
$\Omega(n^{2-\epsilon})$ for the undirected 2D grid. The directed problem is
interesting as a black-box model for a class of classical dynamic programming
strategies including the one that is usually used for the well-known edit
distance problem. We also show a generalization of this result to more than 2
dimensions.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03057</id>
    <link href="http://arxiv.org/abs/2007.03057" rel="alternate" type="text/html"/>
    <title>Approximation algorithms for car-sharing problems</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luo:Kelin.html">Kelin Luo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spieksma:Frits_C=_R=.html">Frits C. R. Spieksma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03057">PDF</a><br/><b>Abstract: </b>We consider several variants of a car-sharing problem. Given are a number of
requests each consisting of a pick-up location and a drop-off location, a
number of cars, and nonnegative, symmetric travel times that satisfy the
triangle inequality. Each request needs to be served by a car, which means that
a car must first visit the pick-up location of the request, and then visit the
drop-off location of the request. Each car can serve two requests. One problem
is to serve all requests with the minimum total travel time (called
$\CS_{sum}$), and the other problem is to serve all requests with the minimum
total latency (called $\CS_{lat}$). We also study the special case where the
pick-up and drop-off location of a request coincide. We propose two basic
algorithms, called the match and assign algorithm and the transportation
algorithm. We show that the best of the resulting two solutions is a $
2$-approximation for $\CS_{sum}$ (and a $7/5$-approximation for its special
case), and a $5/3 $-approximation for $\CS_{lat}$ (and a $3/2$-approximation
for its special case); these ratios are better than the ratios of the
individual algorithms. Finally, we indicate how our algorithms can be applied
to more general settings where each car can serve more than two requests, or
where cars have distinct speeds.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03040</id>
    <link href="http://arxiv.org/abs/2007.03040" rel="alternate" type="text/html"/>
    <title>Near-Linear Time Edit Distance for Indel Channels</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganesh:Arun.html">Arun Ganesh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sy:Aaron.html">Aaron Sy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03040">PDF</a><br/><b>Abstract: </b>We consider the following model for sampling pairs of strings: $s_1$ is a
uniformly random bitstring of length $n$, and $s_2$ is the bitstring arrived at
by applying substitutions, insertions, and deletions to each bit of $s_1$ with
some probability. We show that the edit distance between $s_1$ and $s_2$ can be
computed in $O(n \ln n)$ time with high probability, as long as each bit of
$s_1$ has a mutation applied to it with probability at most a small constant.
The algorithm is simple and only uses the textbook dynamic programming
algorithm as a primitive, first computing an approximate alignment between the
two strings, and then running the dynamic programming algorithm restricted to
entries close to the approximate alignment. The analysis of our algorithm
provides theoretical justification for alignment heuristics used in practice
such as BLAST, FASTA, and MAFFT, which also start by computing approximate
alignments quickly and then find the best alignment near the approximate
alignment. Our main technical contribution is a partitioning of alignments such
that the number of the subsets in the partition is not too large and every
alignment in one subset is worse than an alignment considered by our algorithm
with high probability. Similar techniques may be of interest in the
average-case analysis of other problems commonly solved via dynamic
programming.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.03039</id>
    <link href="http://arxiv.org/abs/2007.03039" rel="alternate" type="text/html"/>
    <title>Streaming Verification for Graph Problems: Optimal Tradeoffs and Nonlinear Sketches</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarti:Amit.html">Amit Chakrabarti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Prantar.html">Prantar Ghosh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thaler:Justin.html">Justin Thaler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.03039">PDF</a><br/><b>Abstract: </b>We study graph computations in an enhanced data streaming setting, where a
space-bounded client reading the edge stream of a massive graph may delegate
some of its work to a cloud service. We seek algorithms that allow the client
to verify a purported proof sent by the cloud service that the work done in the
cloud is correct. A line of work starting with Chakrabarti et al. (ICALP 2009)
has provided such algorithms, which we call schemes, for several statistical
and graph-theoretic problems, many of which exhibit a tradeoff between the
length of the proof and the space used by the streaming verifier.
</p>
<p>This work designs new schemes for a number of basic graph
problems---including triangle counting, maximum matching, topological sorting,
and single-source shortest paths---where past work had either failed to obtain
smooth tradeoffs between these two key complexity measures or only obtained
suboptimal tradeoffs. Our key innovation is having the verifier compute certain
nonlinear sketches of the input stream, leading to either new or improved
tradeoffs. In many cases, our schemes in fact provide optimal tradeoffs up to
logarithmic factors.
</p>
<p>Specifically, for most graph problems that we study, it is known that the
product of the verifier's space cost $v$ and the proof length $h$ must be at
least $\Omega(n^2)$ for $n$-vertex graphs. However, matching upper bounds are
only known for a handful of settings of $h$ and $v$ on the curve $h \cdot
v=\tilde{\Theta}(n^2)$. For example, for counting triangles and maximum
matching, schemes with costs lying on this curve are only known for
$(h=\tilde{O}(n^2), v=\tilde{O}(1))$, $(h=\tilde{O}(n), v=\tilde{O}(n))$, and
the trivial $(h=\tilde{O}(1), v=\tilde{O}(n^2))$. A major message of this work
is that by exploiting nonlinear sketches, a significant ``portion'' of costs on
the tradeoff curve $h \cdot v = n^2$ can be achieved.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02392</id>
    <link href="http://arxiv.org/abs/2007.02392" rel="alternate" type="text/html"/>
    <title>Efficient Parameter Estimation of Truncated Boolean Product Distributions</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fotakis:Dimitris.html">Dimitris Fotakis</a>, Alkis Kalavasis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tzamos:Christos.html">Christos Tzamos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02392">PDF</a><br/><b>Abstract: </b>We study the problem of estimating the parameters of a Boolean product
distribution in $d$ dimensions, when the samples are truncated by a set $S
\subset \{0, 1\}^d$ accessible through a membership oracle. This is the first
time that the computational and statistical complexity of learning from
truncated samples is considered in a discrete setting.
</p>
<p>We introduce a natural notion of fatness of the truncation set $S$, under
which truncated samples reveal enough information about the true distribution.
We show that if the truncation set is sufficiently fat, samples from the true
distribution can be generated from truncated samples. A stunning consequence is
that virtually any statistical task (e.g., learning in total variation
distance, parameter estimation, uniformity or identity testing) that can be
performed efficiently for Boolean product distributions, can also be performed
from truncated samples, with a small increase in sample complexity. We
generalize our approach to ranking distributions over $d$ alternatives, where
we show how fatness implies efficient parameter estimation of Mallows models
from truncated samples.
</p>
<p>Exploring the limits of learning discrete models from truncated samples, we
identify three natural conditions that are necessary for efficient
identifiability: (i) the truncation set $S$ should be rich enough; (ii) $S$
should be accessible through membership queries; and (iii) the truncation by
$S$ should leave enough randomness in all directions. By carefully adapting the
Stochastic Gradient Descent approach of (Daskalakis et al., FOCS 2018), we show
that these conditions are also sufficient for efficient learning of truncated
Boolean product distributions.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02374</id>
    <link href="http://arxiv.org/abs/2007.02374" rel="alternate" type="text/html"/>
    <title>Detail Preserved Point Cloud Completion via Separated Feature Aggregation</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wenxiao.html">Wenxiao Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yan:Qingan.html">Qingan Yan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Chunxia.html">Chunxia Xiao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02374">PDF</a><br/><b>Abstract: </b>Point cloud shape completion is a challenging problem in 3D vision and
robotics. Existing learning-based frameworks leverage encoder-decoder
architectures to recover the complete shape from a highly encoded global
feature vector. Though the global feature can approximately represent the
overall shape of 3D objects, it would lead to the loss of shape details during
the completion process. In this work, instead of using a global feature to
recover the whole complete surface, we explore the functionality of multi-level
features and aggregate different features to represent the known part and the
missing part separately. We propose two different feature aggregation
strategies, named global \&amp; local feature aggregation(GLFA) and residual
feature aggregation(RFA), to express the two kinds of features and reconstruct
coordinates from their combination. In addition, we also design a refinement
component to prevent the generated point cloud from non-uniform distribution
and outliers. Extensive experiments have been conducted on the ShapeNet
dataset. Qualitative and quantitative evaluations demonstrate that our proposed
network outperforms current state-of-the art methods especially on detail
preservation.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02306</id>
    <link href="http://arxiv.org/abs/2007.02306" rel="alternate" type="text/html"/>
    <title>Radial Intersection Count Image: a Clutter Resistant 3D Shape Descriptor</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blokland:Bart_Iver_van.html">Bart Iver van Blokland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Theoharis:Theoharis.html">Theoharis Theoharis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02306">PDF</a><br/><b>Abstract: </b>A novel shape descriptor for cluttered scenes is presented, the Radial
Intersection Count Image (RICI), and is shown to significantly outperform the
classic Spin Image (SI) and 3D Shape Context (3DSC) in both uncluttered and,
more significantly, cluttered scenes. It is also faster to compute and compare.
The clutter resistance of the RICI is mainly due to the design of a novel
distance function, capable of disregarding clutter to a great extent. As
opposed to the SI and 3DSC, which both count point samples, the RICI uses
intersection counts with the mesh surface, and is therefore noise-free. For
efficient RICI construction, novel algorithms of general interest were
developed. These include an efficient circle-triangle intersection algorithm
and an algorithm for projecting a point into SI-like ($\alpha$, $\beta$)
coordinates. The 'clutterbox experiment' is also introduced as a better way of
evaluating descriptors' response to clutter. The SI, 3DSC, and RICI are
evaluated in this framework and the advantage of the RICI is clearly
demonstrated.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02278</id>
    <link href="http://arxiv.org/abs/2007.02278" rel="alternate" type="text/html"/>
    <title>TilinGNN: Learning to Tile with Self-Supervised Graph Neural Network</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Hao.html">Hao Xu</a>, Ka Hei Hui, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fu:Chi=Wing.html">Chi-Wing Fu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hao.html">Hao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02278">PDF</a><br/><b>Abstract: </b>We introduce the first neural optimization framework to solve a classical
instance of the tiling problem. Namely, we seek a non-periodic tiling of an
arbitrary 2D shape using one or more types of tiles: the tiles maximally fill
the shape's interior without overlaps or holes. To start, we reformulate tiling
as a graph problem by modeling candidate tile locations in the target shape as
graph nodes and connectivity between tile locations as edges. Further, we build
a graph convolutional neural network, coined TilinGNN, to progressively
propagate and aggregate features over graph edges and predict tile placements.
TilinGNN is trained by maximizing the tiling coverage on target shapes, while
avoiding overlaps and holes between the tiles. Importantly, our network is
self-supervised, as we articulate these criteria as loss terms defined on the
network outputs, without the need of ground-truth tiling solutions. After
training, the runtime of TilinGNN is roughly linear to the number of candidate
tile locations, significantly outperforming traditional combinatorial search.
We conducted various experiments on a variety of shapes to showcase the speed
and versatility of TilinGNN. We also present comparisons to alternative methods
and manual solutions, robustness analysis, and ablation studies to demonstrate
the quality of our approach.
</p></div>
    </summary>
    <updated>2020-07-08T01:03:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02245</id>
    <link href="http://arxiv.org/abs/2007.02245" rel="alternate" type="text/html"/>
    <title>Computational LEGO Technic Design</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Hao.html">Hao Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hui:Ka=Hei.html">Ka-Hei Hui</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fu:Chi=Wing.html">Chi-Wing Fu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hao.html">Hao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02245">PDF</a><br/><b>Abstract: </b>We introduce a method to automatically compute LEGO Technic models from user
input sketches, optionally with motion annotations. The generated models
resemble the input sketches with coherently-connected bricks and simple
layouts, while respecting the intended symmetry and mechanical properties
expressed in the inputs. This complex computational assembly problem involves
an immense search space, and a much richer brick set and connection mechanisms
than regular LEGO. To address it, we first comprehensively model the brick
properties and connection mechanisms, then formulate the construction
requirements into an objective function, accounting for faithfulness to input
sketch, model simplicity, and structural integrity. Next, we model the problem
as a sketch cover, where we iteratively refine a random initial layout to cover
the input sketch, while guided by the objective. At last, we provide a working
system to analyze the balance, stress, and assemblability of the generated
model. To evaluate our method, we compared it with four baselines and
professional designs by a LEGO expert, demonstrating the superiority of our
automatic designs. Also, we recruited several users to try our system, employed
it to create models of varying forms and complexities, and physically built
most of them.
</p></div>
    </summary>
    <updated>2020-07-08T00:21:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01859</id>
    <link href="http://arxiv.org/abs/2007.01859" rel="alternate" type="text/html"/>
    <title>Improved flat-back 3D gadgets in origami extrusions completely downward compatible with the conventional pyramid-supported 3D gadgets</title>
    <feedworld_mtime>1594166400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doi:Mamoru.html">Mamoru Doi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01859">PDF</a><br/><b>Abstract: </b>An origami extrusion is a folding of a 3D object in the middle of a flat
piece of paper, using 3D gadgets which create faces with solid angles. In this
paper we focus on 3D gadgets which create a top face parallel to the ambient
paper and two side faces sharing a ridge, with two outgoing simple pleats,
where a simple pleat is a pair of a mountain fold and a valley fold. There are
two such types of 3D gadgets. One is the conventional type of 3D gadgets with a
triangular pyramid supporting the two side faces from inside. The other is the
newer type of 3D gadgets presented in our previous paper, which improve the
conventional ones in several respects: They have flat back sides above the
ambient paper and no gap between the side faces; they are less interfering with
adjacent gadgets so that we can make the extrusion higher at one time; they are
downward compatible with conventional ones if constructible; they have a
modified flat-back gadget used for repetition which does not interfere with
adjacent gadgets; the angles of their outgoing pleats can be changed under
certain conditions. However, there are cases where we can apply the
conventional gadgets while we cannot our previous ones. The purpose of this
paper is to improve our previous 3D gadgets to be completely downward
compatible with the conventional ones, in the sense that any conventional
gadget can be replaced by our improved one with the same outgoing pleats, but
the converse is not always possible. To be more precise, we prove that for any
given conventional 3D gadget there are an infinite number of improved 3D
gadgets which are compatible with it, and the conventional 3D gadget can be
replaced with any of these 3D gadgets without affecting any other conventional
3D gadget. Also, we see that our improved 3D gadget keep all of the above
advantages over the conventional ones.
</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/07/postdoc-at-uc-san-diego-apply-by-august-7-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/07/postdoc-at-uc-san-diego-apply-by-august-7-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at UC San Diego (apply by August 7, 2020)</title>
    <summary>The UCSD CS department created a new postdoc program, modeled after the CI fellows program. To apply, you need to identify a UCSD theory faculty as a mentor, contact them and see if they are interested. If so, both you and the mentor need to apply. The deadline for both applications is Aug 7, so […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UCSD CS department created a new postdoc program, modeled after the CI fellows program. To apply, you need to identify a UCSD theory faculty as a mentor, contact them and see if they are interested. If so, both you and the mentor need to apply. The deadline for both applications is Aug 7, so time is of the essence.</p>
<p>Website: <a href="https://forms.gle/7mMKS6xmCjWoMT817">https://forms.gle/7mMKS6xmCjWoMT817</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2020-07-07T21:36:50Z</updated>
    <published>2020-07-07T21:36:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-08T07:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/101</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/101" rel="alternate" type="text/html"/>
    <title>TR20-101 |  Lower Bounds for XOR of Forrelations | 

	Uma Girish, 

	Ran Raz, 

	Wei Zhan</title>
    <summary>The Forrelation problem, first introduced by Aaronson [AA10] and Aaronson and Ambainis [AA15], is  a well studied computational problem in the context of separating quantum and classical computational models. Variants of this problem were used to give tight separations between quantum and classical query complexity [AA15]; the first separation between poly-logarithmic quantum query complexity and bounded-depth circuits of super-polynomial size, a result that also implied an oracle separation of the classes BQP and PH [RT19]; and improved separations between quantum and classical communication complexity [GRT19]. In all these separations, the lower bound for the classical model only holds when the advantage of the protocol (over a random guess) is more than $\approx 1/\sqrt{N}$, that is, the success probability is larger than $\approx 1/2 + 1/\sqrt{N}$. This is unavoidable as $\approx 1/\sqrt{N}$ is the correlation between two coordinates of an input that is sampled from the Forrelation distribution, and hence there are simple classical protocols that achieve advantage $\approx 1/\sqrt{N}$, in all these models.

To achieve separations when the classical protocol has smaller advantage, we study in this work the XOR of $k$ independent copies of (a variant of) the Forrelation function (where $k\ll N$). We prove a very general result that shows that any family of Boolean functions that is closed under restrictions, whose Fourier mass at level $2k$ is bounded by $\alpha^k$ (that is, the sum of the absolute values of all Fourier coefficients at level $2k$ is bounded by $\alpha^k$), cannot compute the XOR of $k$ independent copies of the Forrelation function with advantage better than $O\left(\frac{\alpha^k}{{N^{k/2}}}\right)$. This is a strengthening of a result of [CHLT19], that gave a similar statement for $k=1$, using the technique of [RT19]. We give several applications of our result. In particular, we obtain the following separations:

Quantum versus Classical Communication Complexity: We give the first example of a partial Boolean function that can be computed by a simultaneous-message quantum protocol with communication complexity $\mbox{polylog}(N)$ (where Alice and Bob also share $\mbox{polylog}(N)$ EPR pairs), and such that, any classical randomized protocol of communication complexity at most $\tilde{o}(N^{1/4})$, with any number of rounds,  has quasipolynomially small advantage over a random guess. Previously, only separations where the classical protocol has polynomially small advantage were known between these models [G16, GRT19].

Quantum Query Complexity versus Bounded Depth Circuits: We give the first example of a partial Boolean function that has a quantum query algorithm with query complexity $\mbox{polylog}(N)$, and such that, any constant-depth circuit of quasipolynomial size has quasipolynomially small advantage over a random guess. Previously, only separations where the constant-depth circuit has polynomially small advantage were known [RT19].</summary>
    <updated>2020-07-07T16:03:43Z</updated>
    <published>2020-07-07T16:03:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-08T07:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4892</id>
    <link href="https://www.scottaaronson.com/blog/?p=4892" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4892#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4892" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My Enlightenment fanaticism</title>
    <summary xml:lang="en-US">If there were ever a time for liberals and progressives to put aside their internal squabbles, you’d think it was now. The President of the United States is a racist gangster, who might not leave if he loses the coming election—all the more reason to ensure he loses in a landslide. Due in part to […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>If there were ever a time for liberals and progressives to put aside their internal squabbles, you’d think it was now.  The President of the United States is a racist gangster, who might not leave if he loses the coming election—all the more reason to ensure he loses in a landslide.  Due in part to that gangster’s breathtaking incompetence, 130,000 Americans are now dead, and the economy tanked, from a pandemic that the rest of the world has under much better control.  The gangster’s latest “response” to the pandemic has been to disrupt the lives of thousands of foreign scientists—including several of my students—by threatening to cancel their visas.  (American universities will, of course, do whatever they legally can to work around this act of pure spite.)</p>



<p>So how is the left responding to this historic moment?</p>



<p>This weekend, 536 people did so by … <a href="https://docs.google.com/document/d/17ZqWl5grm_F5Kn_0OarY9Q2jlOnk200PvhM5e3isPvY/preview?pru=AAABc0ugms8*_1VPq2TCPXlcaha9KVY3_Q">trying to cancel Steven Pinker</a>, stripping him of “distinguished fellow” and “media expert” status (whatever those are) in the Linguistics Society of America for ideological reasons.</p>



<p>Yes, Steven Pinker: the celebrated linguist and cognitive scientist, author of <em>The Language Instinct</em> and <em>How the Mind Works</em> (which had a massive impact on me as a teenager) and many other books, and academic torch-bearer for the Enlightenment in our time.  For years, I’d dreaded the day they’d <em>finally</em> come for Steve, even while friends assured me my fears must be inflated since, after all, they hadn’t come for him yet.</p>



<p>I concede that the cancelers’ logic is impeccable.  If they can get Pinker, everyone will quickly realize that there’s no longer any limit to who they can get—including me, including any writer or scientist who crosses them.  If you’ve ever taken, or aspire to take, any public stand riskier than “waffles are tasty,” then don’t delude yourself that you’ll be magically spared—<em>certainly</em> not by your own progressive credentials.</p>



<p>I don’t know if the “charges” against Pinker merit a considered response  (Pinker <a href="https://twitter.com/sapinker/status/1279934082210816003">writes</a> that some people wondered if they were satire).  For those who care, though, <a href="https://whyevolutionistrue.com/2020/07/05/the-purity-posse-pursues-pinker/">here’s</a> a detailed and excellent takedown by the biologist and blogger Jerry Coyne, and <a href="https://medium.com/@bhpartee/my-response-to-the-pinker-petition-open-letter-to-the-linguistics-community-80e2e4d9dbe2">here’s another</a> by Barbara Partee.</p>



<p>So, it seems Pinker once used the term “urban crime,” which can be a racist dogwhistle—except that in this case, it literally meant “urban crime.”  Pinker once referred to <a href="https://en.wikipedia.org/wiki/1984_New_York_City_Subway_shooting">Bernie Goetz</a>, whose 1984 shooting of four robbers in the NYC subway polarized the US at the time, as a “mild-mannered engineer,” in a sentence whose purpose was to <em>contrast</em> that description with the ferocity of Goetz’s act.  Pinker “appropriated” the work of a Black scholar, Harvard Dean Lawrence Bobo, which apparently meant <a href="https://twitter.com/sapinker/status/1268180637418164224?fbclid=IwAR1drpt4R2khSEEyiKiQMXEYloxy_6YzDTIvUEhb_FEkxL-KAPe9XvPYurg">approvingly citing him</a> in a tweet.  Etc.  Ironically, it occurred to me that the would-be Red Guards could’ve built a much stronger case against Pinker had they seriously engaged with his decades of writing—writing that really <em>does</em> take direct aim at their whole worldview, they aren’t wrong about that—rather than superficially collecting a few tweets.</p>



<p>What Coyne calls the “Purity Posse” sleazily gaslights its readers as follows:</p>



<blockquote class="wp-block-quote"><p>We want to note here that we have no desire to judge Dr. Pinker’s actions in moral terms, or claim to know what his aims are. Nor do we seek to “cancel” Dr. Pinker, or to bar him from participating in the linguistics and LSA communities (though many of our signatories may well believe that doing so would be the right course of action).</p></blockquote>



<p>In other words: many of us “may well believe” that Pinker’s scientific career should be ended entirely.  But magnanimously, <em>for now</em>, we’ll settle for a display of our power that leaves the condemned heretic still kicking.  So don’t accuse us of wanting to “cancel” anyone!</p>



<p>In that same generous spirit:</p>



<blockquote class="wp-block-quote"><p>Though no doubt related, we set aside questions of Dr. Pinker’s tendency to move in the proximity of what The Guardian called a revival of “scientific racism”, his public support for David Brooks (who has been argued to be a proponent of “gender essentialism”), his expert testimonial in favor of Jeffrey Epstein (which Dr. Pinker now regrets), or his dubious past stances on rape and feminism.</p></blockquote>



<p>See, even while we make these charges, we disclaim all moral responsibility for making them.  (For the record, Alan Dershowitz asked Pinker for a linguist’s opinion of a statute, so Pinker provided it; Pinker didn’t know at the time that the request had anything to do with Epstein.)</p>



<p>Again and again, spineless institutions have responded to these sorts of ultimatums by capitulating to them.  So I confess that the news about Pinker depressed me all weekend.  The more time passed, though, the more it looked like the Purity Posse might have <em>actually</em> overplayed its hand this time.  Steven Pinker is not weak prey.</p>



<p>Let’s start with what’s missing from the petition: Noam Chomsky <a href="https://twitter.com/ZaidJilani/status/1279505236181356544">pointedly refused to sign</a>.  How that must’ve stung his comrades!  For that matter, virtually all of the world’s well-known linguists refused to sign.  <a href="https://en.wikipedia.org/wiki/Ray_Jackendoff">Ray Jackendoff</a> and <a href="https://en.wikipedia.org/wiki/Michel_DeGraff">Michel DeGraff</a> were originally on the petition, but their names turned out to have been forged (were others?).</p>



<p>But despite the flimsiness of the petition, suppose the Linguistics Society of America caved.  OK, I mused, how many people have even <em>heard</em> of the Linguistics Society of America, compared to the number who’ve heard of Pinker or read his books?  If the LSA expelled Pinker, wouldn’t they be forever known to the world <em>only</em> as the organization that had done that?</p>



<p>I’m tired of the believers in the Enlightenment being constantly on the defensive.  “No, I’m not a racist or a misogynist … on the contrary, I’ve spent decades advocating for … yes, I did say that, but you completely misunderstood my meaning, which in context was … <em>please, I’m begging you</em>, can’t we sit and discuss this like human beings?”</p>



<p>It’s time for more of us to stand up and say: yes, I am a center-left extremist.  Yes, I’m an Enlightenment fanatic, a radical for liberal moderation and reason.  If liberalism is the vanilla of worldviews, then I aspire to be the most intense vanilla anyone has ever tasted.  I’m not a closeted fascist.  I’m not a watered-down leftist.  I’m something else.  I consider myself ferociously anti-racist and anti-sexist and anti-homophobic and pro-downtrodden, but I don’t cede to any ideological faction the right to dictate what those terms mean.  The world is too complicated, too full of ironies and surprises, for me to outsource my conscience in that way.</p>



<p>Enlightenment liberalism at least has the virtue that it’s not some utopian dream: on the contrary, it’s already led to most of the peace and prosperity that this sorry world has ever known, wherever and whenever it’s been allowed to operate.  And while “the death of the Enlightenment” gets proclaimed every other day, liberal ideals have by now endured for centuries.  They’ve outlasted kings and dictators, the Holocaust and the gulag.  They certainly have it within them to outlast some online sneerers.</p>



<p>Yes, sometimes martyrdom (or at least career martyrdom) is the only honorable course, and yes, the childhood bullies <em>did</em> gift me with a sizeable persecution complex—I’ll grant the sneerers that.  But on reflection, no, I don’t want to be a martyr for Enlightenment values.  I want Enlightenment values to <em>win</em>, and not by vanquishing their opponents but by persuading them.  As Pinker <a href="https://twitter.com/sapinker/status/1279936590236790784">writes</a>:</p>



<blockquote class="wp-block-quote"><p>A final comment: I feel sorry for the signatories. Moralistic dudgeon is a shallow and corrosive indulgence, &amp; policing the norms of your peer group a stunting of the intellect. Learning new ideas &amp; rethinking conventional wisdom are deeper pleasures … and ultimately better for the world. Our natural state is ignorance, fallibility, &amp; self-deception. Progress comes only from broaching &amp; evaluating ideas, including those that feel unfamiliar and uncomfortable.</p></blockquote>



<p>Spend a lot of time on Twitter and Reddit and news sites, and it <em>feels like</em> the believers in the above sentiment are wildly outnumbered by the self-certain ideologues of all sides.  But just like the vanilla in a cake can be hard to taste, so there are more Enlightenment liberals than it seems, even in academia—especially if we include all those who never explicitly identified that way, because they were too busy building or fixing or discovering or teaching, and because they mistakenly imagined that if they just left the Purity Posse alone then the Posse would do likewise.  If that’s you, then please ask yourself now: <em>what is my personal break-point for speaking up?</em></p></div>
    </content>
    <updated>2020-07-07T14:21:30Z</updated>
    <published>2020-07-07T14:21:30Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-07T18:40:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1352</id>
    <link href="https://ptreview.sublinear.info/?p=1352" rel="alternate" type="text/html"/>
    <title>News for June 2020</title>
    <summary>Sublinear algorithms in times of social distancing…always something exciting. This month we have a slew of results on sublinear algorithms for classic graph problems and a paper on permutation testing. Palette Sparsification Beyond (∆ + 1) Vertex Coloring by Noga Alon and Sepehr Assadi (arXiv). A basic fact from graph theory is that any graph […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sublinear algorithms in times of social distancing…always something exciting. This month we have a slew of results on sublinear algorithms for classic graph problems and a paper on permutation testing. </p>



<p/>



<p><strong>Palette Sparsification Beyond (∆ + 1) Vertex Coloring</strong> by Noga Alon and Sepehr Assadi (<a href="https://arxiv.org/pdf/2006.10456.pdf">arXiv</a>). A basic fact from graph theory is that any graph has a \((\Delta+1)\)-coloring, where \(\Delta\) is the maximum degree. Followers of property testing are likely familiar with a fantastic result of <a href="https://www.cs.rutgers.edu/~sa1497/pages/sublinear_vertex-coloring_2019.html">Assadi-Chen-Khanna</a> (ACK) on sublinear algorithms, that gives a sublinear algorithm for \((\Delta+1)\)-coloring. (The running time is \(\widetilde{O}(n^{3/2})\), where \(n\) is the number of vertices.) The key tool is a palette sparsification theorem: suppose each vertex is given a “palette” of \((\Delta+1)\) colors. Each vertex randomly sparsifies its palette by sampling \(O(\log n)\) colors, and is constrained to only use these colors. Remarkably, whp the graph can still be properly colored. This tool is at the heart of sublinear time/space algorithms for coloring. This paper gives numerous extensions to this theorem, where one can tradeoff a larger initially palette for a smaller final sample. Another extension is for triangle-free graphs, where the initial palette is of size \(O(\Delta/\ln \Delta)\) and the sample is of size \(O(\Delta^\gamma + \sqrt{\ln n})\) (for parameter \(\gamma &lt; 1\). This leads to an \(O(n^{3/2 + \gamma})\) time algorithm for \(O(\Delta/\ln \Delta)\) coloring of triangle-free graphs.</p>



<p/>



<p><strong>When Algorithms for Maximal Independent Set and Maximal Matching Run in Sublinear-Time</strong> by Sepehr Assadi and Shay Solomon (<a href="https://arxiv.org/pdf/2006.07628.pdf">arXiv</a>). Taking off from sublinear coloring algorithms, one can ask if there are sublinear time algorithms for Maximal Independent Set (MIS) and Maximal Matching (MM). Alas, ACK prove that this is impossible. This paper investigates when one can get a sublinear time algorithm for these problems. For graph \(G\), let \(\beta(G)\) be the “neighborhood independence number”, the size of the largest independent set contained in a vertex neighborhood. This papers shows that both problems can be solved in \(\widetilde{O}(n \beta(G))\) time. Examples of natural classes of graphs where \(\beta(G)\) is constant: line graphs and unit-disk graphs. An interesting aspect is that MIS algorithm is actually deterministic! It’s the simple marking algorithm that rules out neighborhoods of chosen vertices; the analysis shows that not much time is wasted in remarking the same vertex. </p>



<p><strong>Sublinear Algorithms and Lower Bounds for Metric TSP Cost Estimation</strong> by Yu Chen, Sampath Kannan, and Sanjeev Khanna (<a href="https://arxiv.org/pdf/2006.05490.pdf">arXiv</a>). This paper studies sublinear algorithms for the metric TSP problem. The input is an \(n \times n\) distance matrix. One can 2-approximate the TSP by computing the MST, and a result of <a href="http://wrap.warwick.ac.uk/2416/">Czumaj-Sohler</a> gives a \((1+\varepsilon)\)-approximation algorithm for the latter, running in \(O(n\varepsilon^{-O(1)})\) time. The main question is: can one beat the 2-factor approximation in sublinear time? This paper considers the graphic TSP setting, where the distance matrix corresponds to the shortest path metric of an unweighted graph. One result is a \((2-\varepsilon_0)\)-approximation algorithm (for an explicit constant \(\varepsilon_0\)) that runs in \(\widetilde{O}(n)\) time. For the important \((1,2)\) TSP setting (all distances are either 1 or 2), the paper gives a \(O(n^{1.5})\) time 1.63-approximation algorithm. Interestingly, there is a lower bound showing that \((1+\varepsilon)\)-approximations, for arbitrarily small \(\varepsilon\), cannot be achieved in \(o(n^2)\) time. One of the key tools is sublinear algorithms for estimating the maximum matching size, itself a well-studied problem in the community.</p>



<p><strong>Improved algorithm for permutation testing </strong>by Xiaojin Zhang (<a href="https://arxiv.org/pdf/2006.08473.pdf">arXiv</a>). <a href="http://cs.haifa.ac.il/~ilan/online-papers/permutations.pdf">Newman-Rabinovich-Rajendraprasad-Sohler</a> (NRRS) introduced the problem of testing forbidden patterns in permutations, as a (vast) generalization of monotonicity testing. Consider an input function \(f:[n] \to \mathbb{R}\). Let \(\pi\) be a permutation in \(S_k\). The input \(f\) “contains” \(\pi\) if there exists a sequence of \(k\) indices in \([n]\) such that \(f\) restricted to this sequence induces permutation \(\pi\). (So, we can also define \(\pi\)-freeness.) In this language, the property of (non-increasing) monotonicity is precisely \((1,2)\)-freeness. NRRS prove that \((1,2,\ldots, k)\)-freeness can be tested using \((\varepsilon^{-1} \log n)^{O(k^2)}\) non-adaptive queries, but \((1,3,2)\)-freeness requires \(\Omega(\sqrt{n})\) non-adaptive queries. With adaptivity, the latter problem can be tested in polylogarithmic queries. Let us focus on testing \((1,2,\ldots, k)\)-freeness, treating \(k\) as constant. Note that \((1,2,\ldots, k)\)-freeness means that, for any set of \(k\) indices in \([n]\), the corresponding restriction of \(f\) is not increasing. <a href="https://conferences.computer.org/focs/2019/pdfs/FOCS2019-7pBwCpNH4Mz2L4MJWVl6Xp/5f6qMDluQwlh4Pag7dwdTz/5pe8FOCIi5mX0NFChBc78g.pdf">BenEliezer-Canonne-Letzter-Waingarten</a> showed an optimal \((\log n)^{\lceil \log k\rceil}\) non-adaptive algorithm. They also give a (complex) adaptive algorithm making only \(O(\log n)\) queries. This paper gives a simpler \(O(\log n)\) algorithm, with better dependence on \(\varepsilon\). Moreover, this paper also gives a \(O(\varepsilon^{-1}\log^3 n)\) adaptive algorithm for testing \((1,3,2)\)-freeness, beating the previous bound of \(O(\varepsilon^{-4}\log^{20}n)\).</p></div>
    </content>
    <updated>2020-07-07T06:26:32Z</updated>
    <published>2020-07-07T06:26:32Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-07-08T01:41:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02660</id>
    <link href="http://arxiv.org/abs/2007.02660" rel="alternate" type="text/html"/>
    <title>Solving Packing Problems with Few Small Items Using Rainbow Matchings</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannach:Max.html">Max Bannach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berndt:Sebastian.html">Sebastian Berndt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maack:Marten.html">Marten Maack</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lassota:Alexandra.html">Alexandra Lassota</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rau:Malin.html">Malin Rau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skambath:Malte.html">Malte Skambath</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02660">PDF</a><br/><b>Abstract: </b>An important area of combinatorial optimization is the study of packing and
covering problems, such as Bin Packing, Multiple Knapsack, and Bin Covering.
Those problems have been studied extensively from the viewpoint of
approximation algorithms, but their parameterized complexity has only been
investigated barely. For problem instances containing no "small" items,
classical matching algorithms yield optimal solutions in polynomial time. In
this paper we approach them by their distance from triviality, measuring the
problem complexity by the number $k$ of small items.
</p>
<p>Our main results are fixed-parameter algorithms for vector versions of Bin
Packing, Multiple Knapsack, and Bin Covering parameterized by $k$. The
algorithms are randomized with one-sided error and run in time $4^{k} \cdot k!
\cdot n^{O(1)}$. To achieve this, we introduce a colored matching problem to
which we reduce all these packing problems. The colored matching problem is
natural in itself and we expect it to be useful for other applications. We also
present a deterministic fixed-parameter for Bin Packing with run time
$(k!)^{2}\cdot k \cdot 2^{k}\cdot n\cdot \log(n)$.
</p></div>
    </summary>
    <updated>2020-07-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02533</id>
    <link href="http://arxiv.org/abs/2007.02533" rel="alternate" type="text/html"/>
    <title>Computational Complexity Characterization of Protecting Elections from Bribery</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Lin.html">Lin Chen</a>, Ahmed Sunny, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Lei.html">Lei Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Shouhuai.html">Shouhuai Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Zhimin.html">Zhimin Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Yang.html">Yang Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Weidong.html">Weidong Shi</a>, Nolan Shah Texas Tech University, University of Texas Rio Grande Valley, University of Texas San Antonio, Auburn University at Montgomery, University of Houston, Amazon Web Services) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02533">PDF</a><br/><b>Abstract: </b>The bribery problem in election has received considerable attention in the
literature, upon which various algorithmic and complexity results have been
obtained. It is thus natural to ask whether we can protect an election from
potential bribery. We assume that the protector can protect a voter with some
cost (e.g., by isolating the voter from potential bribers). A protected voter
cannot be bribed. Under this setting, we consider the following bi-level
decision problem: Is it possible for the protector to protect a proper subset
of voters such that no briber with a fixed budget on bribery can alter the
election result? The goal of this paper is to give a full picture on the
complexity of protection problems. We give an extensive study on the protection
problem and provide algorithmic and complexity results. Comparing our results
with that on the bribery problems, we observe that the protection problem is in
general significantly harder. Indeed, it becomes $\sum_{p}^2$-complete even for
very restricted special cases, while most bribery problems lie in NP. However,
it is not necessarily the case that the protection problem is always harder.
Some of the protection problems can still be solved in polynomial time, while
some of them remain as hard as the bribery problem under the same setting.
</p></div>
    </summary>
    <updated>2020-07-07T23:21:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02509</id>
    <link href="http://arxiv.org/abs/2007.02509" rel="alternate" type="text/html"/>
    <title>On the weight and density bounds of polynomial threshold functions</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Erhan Oztop, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Asada:Minoru.html">Minoru Asada</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02509">PDF</a><br/><b>Abstract: </b>In this report, we show that all n-variable Boolean function can be
represented as polynomial threshold functions (PTF) with at most $0.75 \times
2^n$ non-zero integer coefficients and give an upper bound on the absolute
value of these coefficients. To our knowledge this provides the best known
bound on both the PTF density (number of monomials) and weight (sum of the
coefficient magnitudes) of general Boolean functions. The special case of Bent
functions is also analyzed and shown that any n-variable Bent function can be
represented with integer coefficients less than $2^n$ while also obeying the
aforementioned density bound. Finally, sparse Boolean functions, which are
almost constant except for $m &lt;&lt; 2^n$ number of variable assignments, are shown
to have small weight PTFs with density at most $m+2^{n-1}$.
</p></div>
    </summary>
    <updated>2020-07-07T23:41:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02431</id>
    <link href="http://arxiv.org/abs/2007.02431" rel="alternate" type="text/html"/>
    <title>A stochastic calculus approach to the oracle separation of BQP and PH</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xinyu.html">Xinyu Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02431">PDF</a><br/><b>Abstract: </b>After presentations of Raz and Tal's oracle separation of BQP and PH result,
several people (e.g. Ryan O'Donnell, James Lee, Avishay Tal) suggested that the
proof may be simplified by stochastic calculus. In this short note, we describe
such a simplification.
</p></div>
    </summary>
    <updated>2020-07-07T23:49:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02377</id>
    <link href="http://arxiv.org/abs/2007.02377" rel="alternate" type="text/html"/>
    <title>New Hardness Results for Planar Graph Problems in P and an Algorithm for Sparsest Cut</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abboud:Amir.html">Amir Abboud</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen=Addad:Vincent.html">Vincent Cohen-Addad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klein:Philip_N=.html">Philip N. Klein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02377">PDF</a><br/><b>Abstract: </b>The Sparsest Cut is a fundamental optimization problem that has been
extensively studied. For planar inputs the problem is in $P$ and can be solved
in $\tilde{O}(n^3)$ time if all vertex weights are $1$. Despite a significant
amount of effort, the best algorithms date back to the early 90's and can only
achieve $O(\log n)$-approximation in $\tilde{O}(n)$ time or a constant factor
approximation in $\tilde{O}(n^2)$ time [Rao, STOC92]. Our main result is an
$\Omega(n^{2-\epsilon})$ lower bound for Sparsest Cut even in planar graphs
with unit vertex weights, under the $(min,+)$-Convolution conjecture, showing
that approximations are inevitable in the near-linear time regime. To
complement the lower bound, we provide a constant factor approximation in
near-linear time, improving upon the 25-year old result of Rao in both time and
accuracy.
</p>
<p>Our lower bound accomplishes a repeatedly raised challenge by being the first
fine-grained lower bound for a natural planar graph problem in P. Moreover, we
prove near-quadratic lower bounds under SETH for variants of the closest pair
problem in planar graphs, and use them to show that the popular Average-Linkage
procedure for Hierarchical Clustering cannot be simulated in truly subquadratic
time.
</p>
<p>We prove an $\Omega(n/\log{n})$ lower bound on the number of communication
rounds required to compute the weighted diameter of a network in the CONGEST
model, even when the underlying graph is planar and all nodes are $D=4$ hops
away from each other. This is the first poly($n$) + $\omega(D)$ lower bound in
the planar-distributed setting, and it complements the recent poly$(D,
\log{n})$ upper bounds of Li and Parter [STOC 2019] for (exact) unweighted
diameter and for ($1+\epsilon$) approximate weighted diameter.
</p></div>
    </summary>
    <updated>2020-07-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02370</id>
    <link href="http://arxiv.org/abs/2007.02370" rel="alternate" type="text/html"/>
    <title>Complexity of the Multilevel Critical Node Problem</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Adel Nabli, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carvalho:Margarida.html">Margarida Carvalho</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hosteins:Pierre.html">Pierre Hosteins</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02370">PDF</a><br/><b>Abstract: </b>In this work, we analyze a sequential game played in a graph called the
Multilevel Critical Node problem (MCN). A defender and an attacker are the
players of this game. The defender starts by preventively interdicting vertices
(vaccination) from being attacked. Then, the attacker infects a subset of
non-vaccinated vertices and, finally, the defender reacts with a protection
strategy. We provide the first computational complexity results associated with
MCN and its subgames. Moreover, by considering unitary, weighted, undirected
and directed graphs, we clarify how the theoretical tractability or
intractability of those problems vary. Our findings contribute with new
NP-complete, $\Sigma_2^p$-complete and $\Sigma_3^p$-complete problems.
</p></div>
    </summary>
    <updated>2020-07-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.02330</id>
    <link href="http://arxiv.org/abs/2007.02330" rel="alternate" type="text/html"/>
    <title>Universal codes in the shared-randomness model for channels with general distortion capabilities</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bauwens:Bruno.html">Bruno Bauwens</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zimand:Marius.html">Marius Zimand</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.02330">PDF</a><br/><b>Abstract: </b>Consider a channel that is capable of corrupting the data that is transmitted
through it. In its standard form, the channel coding problem asks for an
encoding function mapping messages to codewords that makes communication over
the given channel resilient to a given noise level. This means that when a
codeword is sent over the channel, the receiver is able to recover it from a
noisy version, provided the added noise is below some bound. We study a
stronger type of code, called a universal code. A universal code is an encoding
that is resilient to a given noise level for every channel and that, moreover,
works without knowing the channel.
</p>
<p>In contrast to encoding, the decoding function knows the type of channel. We
allow the encoding and the decoding functions to share randomness, which is
unavailable to the channel. For a universal code, there are two parameters of
interest: the rate, which is the ratio between the message length and the
codeword length, and the number of shared random bits. There are two scenarios
for the type of attack that a channel can perform. In the oblivious scenario,
the channel adds noise based on the message and the encoding function but does
not know the codeword. In the Hamming scenario, the channel knows the codeword
and is fully adversarial. We show the existence in both scenarios of universal
codes with rate converging to the optimal value as n grows, where n is the
codeword length. The number of shared random bits is O(log n) in the oblivious
scenario, and O(n) in the Hamming scenario, which, for typical values of the
noise level, we show to be optimal, modulo the constant hidden in the O()
notation. In both scenarios, the universal encoding is done in time polynomial
in n, but the channel-dependent decoding procedures are not efficient.
</p></div>
    </summary>
    <updated>2020-07-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01980</id>
    <link href="http://arxiv.org/abs/2007.01980" rel="alternate" type="text/html"/>
    <title>Linear Bandits with Limited Adaptivity and Learning Distributional Optimal Design</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ruan:Yufei.html">Yufei Ruan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Jiaqi.html">Jiaqi Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Yuan.html">Yuan Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01980">PDF</a><br/><b>Abstract: </b>Motivated by practical needs such as large-scale learning, we study the
impact of adaptivity constraints to linear contextual bandits, a central
problem in online active learning. We consider two popular limited adaptivity
models in literature: batch learning and rare policy switches. We show that,
when the context vectors are adversarially chosen in $d$-dimensional linear
contextual bandits, the learner needs $\Omega(d \log T/ \log (d \log T))$
policy switches to achieve the minimax-optimal expected regret, almost matching
the $O(d \log T)$ upper bound by Abbasi-Yadkori et al. [2011]; for stochastic
context vectors, even in the more restricted batch learning model, only $O(\log
\log T)$ batches are needed to achieve the optimal regret. Together with the
known results in literature, our results present a complete picture about the
adaptivity constraints in linear contextual bandits. Along the way, we propose
\emph{distributional optimal design}, a natural extension of the optimal
experiment design, and provide a sample-efficient learning algorithm for the
problem, which may be of independent interest.
</p></div>
    </summary>
    <updated>2020-07-07T23:58:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.01897</id>
    <link href="http://arxiv.org/abs/2007.01897" rel="alternate" type="text/html"/>
    <title>b-articulation points and b-bridges in strongly biconnected directed graphs</title>
    <feedworld_mtime>1594080000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaberi:Raed.html">Raed Jaberi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.01897">PDF</a><br/><b>Abstract: </b>A directed graph $G=(V,E)$ is called strongly biconnected if $G$ is strongly
connected and the underlying graph of $G$ is biconnected. This class of
directed graphs was first introduced by Wu and Grumbach. Let $G=(V,E)$ be a
strongly biconnected directed graph. An edge $e\in E$ is a b-bridge if the
subgraph $G\setminus \left\lbrace e\right\rbrace =(V,E\setminus \left\lbrace
e\right\rbrace) $ is not strongly biconnected. A vertex $w\in V$ is a
b-articulation point if $G\setminus \left\lbrace w\right\rbrace$ is not
strongly biconnected, where $G\setminus \left\lbrace w\right\rbrace$ is the
subgraph obtained from $G$ by removing $w$. In this paper we study
b-articulation points and b-bridges.
</p></div>
    </summary>
    <updated>2020-07-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/100</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/100" rel="alternate" type="text/html"/>
    <title>TR20-100 |  Streaming Verification for Graph Problems: Optimal Tradeoffs and Nonlinear Sketches | 

	Amit Chakrabarti, 

	Prantar Ghosh, 

	Justin Thaler</title>
    <summary>We study graph computations in an enhanced data streaming setting, where a space-bounded client reading the edge stream of a massive graph may delegate some of its work to a cloud service. We seek algorithms that allow the client to verify a purported proof sent by the cloud service that the work done in the cloud is correct.
  A line of work starting with Chakrabarti et al. (ICALP 2009) has provided such algorithms, which we call schemes, for several statistical and graph-theoretic problems, many of which exhibit a tradeoff between the length of the proof and the space used by the streaming verifier.
  
  This work designs new schemes for a number of basic graph problems---including triangle counting, maximum matching, topological sorting, and single-source shortest paths---where past work had either failed to obtain smooth tradeoffs between these two key complexity measures or only obtained suboptimal tradeoffs. Our key innovation is having the verifier compute certain nonlinear sketches of the input stream, leading to either new or improved tradeoffs. In many cases, our schemes in fact provide optimal tradeoffs up to logarithmic factors. 

  Specifically, for most graph problems that we study, it is known that the product of the verifier's space cost $v$ and the proof length $h$ must be at least $\Omega(n^2)$ for $n$-vertex graphs. However, matching upper bounds are only known for a handful of settings of $h$ and $v$ on the curve $h \cdot v=\tilde{\Theta}(n^2)$. For example, for counting triangles and maximum matching, schemes with costs lying on this curve are only known for $(h=\tilde{O}(n^2), v=\tilde{O}(1))$, $(h=\tilde{O}(n), v=\tilde{O}(n))$, and the trivial $(h=\tilde{O}(1), v=\tilde{O}(n^2))$. A major message of this work is that by exploiting nonlinear sketches, a significant ``portion'' of costs on the tradeoff curve $h \cdot v = n^2$ can be achieved.</summary>
    <updated>2020-07-06T17:16:45Z</updated>
    <published>2020-07-06T17:16:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-08T07:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/099</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/099" rel="alternate" type="text/html"/>
    <title>TR20-099 |  KRW Composition Theorems via Lifting | 

	Susanna de Rezende, 

	Or Meir, 

	Jakob Nordström, 

	Toniann Pitassi, 

	Robert Robere</title>
    <summary>One of the major open problems in complexity theory is proving super-logarithmic lower bounds on the depth of circuits (i.e., $\mathbf{P}\not\subseteq\mathbf{NC}^1$). Karchmer, Raz, and Wigderson (Computational Complexity 5(3/4), 1995) suggested to approach this problem by proving that depth complexity behaves “as expected” with respect to the composition of functions $f \diamond g$. They showed that the validity of this conjecture would imply that $\mathbf{P}\not\subseteq\mathbf{NC}^1$.

Several works have made progress toward resolving this conjecture by proving special cases. In particular, these works proved the KRW conjecture for every outer function $f$, but only for few inner functions $g$. Thus, it is an important challenge to prove the KRW conjecture for a wider range of inner functions.

In this work, we extend significantly the range of inner functions that can be handled. First, we consider the $\textit{monotone}$ version of the KRW conjecture. We prove it for every monotone inner function $g$ whose depth complexity can be lower bounded via a query-to-communication lifting theorem. This allows us to handle several new and well-studied functions such as the $s\textbf{-}t$-connectivity, clique, and generation functions.

In order to carry this progress back to the $\textit{non-monotone}$ setting, we introduce a new notion of $\textit{semi-monotone}$ composition, which combines the non-monotone complexity of the outer function $f$ with the monotone complexity of the inner function $g$. In this setting, we prove the KRW conjecture for a similar selection of inner functions $g$, but only for a specific choice of the outer function $f$.</summary>
    <updated>2020-07-06T11:22:16Z</updated>
    <published>2020-07-06T11:22:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-08T07:20:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/07/06/GAN-min-max/</id>
    <link href="http://offconvex.github.io/2020/07/06/GAN-min-max/" rel="alternate" type="text/html"/>
    <title>Training GANs - From Theory to Practice</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>GANs, originally discovered in the context of unsupervised learning, have had far reaching implications to science, engineering, and society. However, training GANs remains challenging (in part) due to the lack of convergent algorithms for nonconvex-nonconcave min-max optimization. In this post, we present a <a href="https://arxiv.org/abs/2006.12376">new first-order algorithm</a> for min-max optimization which is particularly suited to GANs. This algorithm is guaranteed to converge to an equilibrium, is competitive in terms of time and memory with gradient descent-ascent and, most importantly, GANs trained using it seem to be stable.</p>

<h2 id="gans-and-min-max-optimization">GANs and min-max optimization</h2>

<p>Starting with the work of <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets">Goodfellow et al.</a>, Generative Adversarial Nets (GANs) have become a critical component in various ML systems; for prior posts on GANs, see <a href="https://www.offconvex.org/2018/03/12/bigan/">here</a> for a post on  GAN architecture, and <a href="https://www.offconvex.org/2017/03/15/GANs/">here</a> and <a href="https://www.offconvex.org/2017/07/06/GANs3/">here</a> for posts which discuss  some of the many difficulties arising when training GANs.</p>

<p>Mathematically, a GAN consists of a generator neural network $\mathcal{G}$ and a discriminator neural network $\mathcal{D}$ that are competing against each other in a way that, together, they learn the unknown distribution from which a given dataset arises.  The generator takes a random “noise” vector as input and maps this vector to a sample; for instance, an image. The discriminator takes samples – “fake” ones produced by the generator and “real” ones from the given dataset – as inputs.  The discriminator then tries to classify these samples as “real” or “fake”. As a designer, we would like the generated samples to be indistinguishable from those of the dataset. Thus, our goal is to choose weights $x$ for the generator network that allow it to generate samples which are difficult for <em>any</em> discriminator to tell apart from real samples. This leads to a min-max optimization problem where we look for weights $x$ which <em>minimize</em> the rate (measured by a loss function $f$) at which any discriminator correctly classifies the real and fake samples. And, we seek weights $y$ for the discriminator network which <em>maximize</em> this rate.</p>

<blockquote>
  <p><strong>Min-max formulation of GANs</strong> <br/> <br/></p>

  

  

  <p>where $\zeta$ is a random sample from the dataset, and $\xi \sim N(0,I_d)$ is a noise vector which the generator maps to a “fake” sample.  $f_{\zeta, \xi}$ measures how accurately the discriminator $\mathcal{D}(y;\cdot)$ distinguishes $\zeta$ from $\mathcal{G}(x;\xi)$ produced by the generator using the input noise $\xi$.</p>
</blockquote>

<p>In this formulation, there are several choices that we have to make as a GAN designer, and an important one is that of a loss function. One concrete choice is from the paper of Goodfellow et al.: the cross-entropy loss function:</p>



<p>See <a href="https://machinelearningmastery.com/generative-adversarial-network-loss-functions/">here</a> for a summary and comparison of different loss functions.</p>

<p>Once we fix the loss function (and the architecture of the generator and discriminator), we can compute unbiased estimates of the value of $f$ and its gradients $\nabla_x f$ and $\nabla_y f$ using batches consisting of random Gaussian noise vectors $\xi_1,\ldots, \xi_n \sim N(0,I_d)$ and random samples from the dataset $\zeta_1, \ldots, \zeta_n$.  For example, the stochastic batch gradient</p>



<p>gives us an unbiased estimate for $\nabla_x f(x,y)$.</p>

<blockquote>
  <p>But how do we solve the min-max optimization problem above using such a first-order access to $f$?</p>
</blockquote>

<h2 id="gradient-descent-ascent-and-variants">Gradient descent-ascent and variants</h2>

<p>Perhaps the simplest algorithm we can try for min-max optimization is gradient descent-ascent (GDA). As the generator wants to minimize with respect to $x$ and the discriminator wants to maximize with respect to $y$, the idea is to do descent steps for $x$ and ascent steps for $y$. How exactly to do this is not clear, and one strategy is to let the generator and discriminator alternate:</p>





<p>Other variants include, for instance, <a href="https://arxiv.org/abs/1311.1869">optimistic mirror descent</a> (OMD) (see also <a href="https://arxiv.org/abs/1807.02629">here</a> and  <a href="https://arxiv.org/abs/1711.00141">here</a> for applications of OMD to GANs, and <a href="https://arxiv.org/abs/1901.08511">here</a> for an analysis of OMD and related methods)</p>





<p>The advantage of such algorithms is that they are quite practical. The problem, as we discuss next, is that they are not always guaranteed to converge. Most of these guarantees only hold for special classes of loss functions $f$ that satisfy properties such as concavity (see <a href="https://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization.pdf">here</a> and <a href="https://arxiv.org/abs/1906.00331">here</a>) or <a href="https://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods.pdf">monotonicity</a>, or under the assumptions that these algorithms are provided with special starting points (see <a href="https://arxiv.org/abs/1706.08500">here</a>, <a href="https://arxiv.org/abs/1910.07512">here</a>).</p>

<h2 id="convergence-problems-with-current-algorithms">Convergence problems with current algorithms</h2>

<p>Unfortunately there are simple functions for which some min-max optimization algorithms may never converge to <em>any</em> point.  For instance GDA may not converge on $f(x,y) = xy$  (see Figure 1, and our <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a> for a more detailed discussion).</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_2.gif"/>
<br/>
<b>Figure 1.</b> GDA on $f(x,y) = xy, \, \, \, \, x,y \in [-5,5]$ (the red line is the set of global min-max points). GDA is non-convergent from almost every initial point. 
</div>
<p><br/></p>

<p>As for examples relevant to ML, when using GDA to train a GAN on a dataset consisting of points sampled from a mixture of four Gaussians in $\mathbb{R}^2$, we observe that GDA tends to cause the generator to cycle between different modes corresponding to the four Gaussians. We also used GDA to train a GAN on the subset of the MNIST digits which have “0” or “1” as their label, which we refer to as the 0-1 MNIST dataset.  We observed a cycling behavior for this dataset as well: After learning how to generate images of $0$’s, the GAN trained by GDA then forgets how to generate $0$’s for a long time and only generates $1$’s.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_Gaussian.gif" style="width: 400px;"/>
<img alt="" src="http://www.offconvex.org/assets/GDA_MNIST.gif" style="width: 400px;"/>
<br/>
<b>Figure 2.</b> Mode oscillation when GDA is used to train GANs on the four Guassian mixture dataset (left) and the 0-1 MNIST dataset (right).
</div>

<p><br/></p>

<p>In algorithms such as GDA where the discriminator only makes local updates, cycling can happen for the following reason: Once the discriminator learns to identify one of the modes (say mode “A”), the generator can update $x$ in a way that greatly decreases f, by (at least temporarily) ìfoolingî the discriminator. The generator does this by learning to generate samples from a different mode (say mode “B”) which the discriminator has not yet learned to identify, and stops generating samples from mode A. However, after many iterations, the discriminator ìcatches upî to the generator and learns how to identify mode B. Since the generator is no longer generating samples from mode A, the discriminator may then ìforgetî how to identify samples from this mode. And this can cause the generator to switch back to generating only mode A.</p>

<h2 id="our-first-order-algorithm">Our first-order algorithm</h2>

<p>To solve the min-max optimization problem, at any point $(x,y)$, we should ideally allow the discriminator to find the global maximum, $\max_z f(x,z)$. However, this may be hard for nonconcave $f$. But we could still let the discriminator run a convergent algorithm (such as gradient ascent) until it reaches a <strong>first-order stationary point</strong>, allowing it to compute an approximation $h$ for the global max function.  (Note that even though $\max_z f(x,z)$ is only a function of $x$, since $h$ is a “local’’ approximation it could also depend on the initial point $y$ where we start gradient ascent.) And we also empower the generator to simulate the discriminator’s update by running gradient ascent (see <a href="https://arxiv.org/abs/2006.12376">our paper</a> for discriminators with access to a more general class of first-order algorithms).</p>

<blockquote>
  <p><strong>Idea 1: Use a local approximation to global max</strong>
<br/><br/>
Starting at the point $(x,y)$, update $y$ by computing multiple gradient ascent steps for $y$ until a point $w$ is reached where  is close to zero and define $h(x,y) := f(x,w)$.</p>
</blockquote>

<p>We would like the generator to minimize $h(\cdot,y)$. To minimize $h$, we would ideally like to update $x$ in the direction $-\nabla_x h$.  However, $h$ may be discontinuous in $x$ (see our <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a> for why this can happen). Moreover, even at points where $h$ is differentiable, computing the gradient of $h$ can take a long time and requires a large amount of memory.</p>

<p>Thus, realistically, we only have access to the value of $h$. A naive approach to minimizing $h$ would be to propose a random update to $x$, for instance an update sampled from a standard Gaussian, and then only accept this update if it causes the value of $h$ to decrease. Unfortunately, this does not lead to fast algorithms as even at points where $h$ is differentiable, in high dimensions, a random Gaussian step will be almost orthogonal to the steepest descent direction $-\nabla_x h(x,y)$, making the progress slow.</p>

<p>Another idea is to have the generator propose at each iteration an update in the direction of the gradient $-\nabla_x f(x,y)$, and to then have the discriminator update $y$ using gradient ascent. To see why this may be a reasonable thing to do, notice that once the generator proposes an update $v$ to $x$, the discriminator will only make updates which increase the value of f or, $h(x+v,y) \geq f(x+v,y)$. And, since $y$ is a first-order stationary point for $f(x, \cdot)$ (because $y$ was computed using gradient ascent in the <em>previous</em> iteration), we also have that $h(x,y)=f(x,y)$. Hence,</p>



<p><em>This means that decreasing $h$ requires us to decrease $f$ (the converse is not true). So it indeed makes sense to move in the direction $-\nabla_x f(x,y)$!</em></p>

<p>While making updates using $-\nabla_x f(x,y)$ may allow the generator to decrease $h$ more quickly than updating in a random direction, it is not always the case that updating in the direction of $-\nabla_x f$ will lead to a decrease in $h$ (and doing so may even lead to an increase in $h$!). Instead, our algorithm has the generator perform a random search by proposing an update in the direction of a batch gradient with mean $-\nabla_x f$, and accepts this move only if the value of $h$ (the local approximation) decreases. The accept-reject step prevents our algorithm from cycling between modes, and using the batch gradient for the random search allows our algorithm to be competitive with prior first-order methods in terms of running time.</p>

<blockquote>
  <p><strong>Idea 2: Use zeroth-order optimization with batch gradients</strong>
<br/><br/>
Sample a batch gradient $v$ with mean $-\nabla_x f(x,y)$.
<br/>
If $h(x+ v, y) &lt; h(x,y) $ accept the step $x+v$; otherwise reject it.</p>
</blockquote>

<p>A final issue, that applies even in the special case of minimization, is that converging to a <em>local</em> minimum point does not mean that point is desirable from an application standpoint. The same is true for the more general setting of min-max optimization. To help our algorithm escape undesirable local min-max equilibria, we use a randomized accept-reject rule inspired by <a href="https://towardsdatascience.com/optimization-techniques-simulated-annealing-d6a4785a1de7">simulated annealing</a>. Simulated annealing algorithms seek to minimize a function via a randomized search, while gradually decreasing the acceptance probability of this search; in some cases this allows one to reach the global minimum of a nonconvex function (see for instance <a href="https://arxiv.org/abs/1711.02621">this paper</a>). These three ideas lead us to our algorithm.</p>

<blockquote>
  <p><strong>Our algorithm</strong>
<br/><br/>
<em>Input</em>: Initial point $(x,y)$, $f: \mathbb{R}^d \times \mathbb{R}^d\rightarrow \mathbb{R}$
<br/>
<em>Output:</em> A local min-max equilibrium $(x,y)$</p>

  <p><br/> <br/></p>

  <p>For $i = 1,2, \ldots$ <br/>
<br/>
<strong>Step 1:</strong> Generate a batch gradient $v$ with mean $-\nabla_x f(x,y)$ and propose the generator update $x+v$.
<br/><br/>
<strong>Step 2:</strong> Compute $h(x+v, y) = f(x+v, w)$, by simulating a discriminator update $w$ via gradient ascent on $f(x+v, \cdot)$ starting at $y$.
<br/><br/>
<strong>Step 3:</strong>  If $h(x+v, y)$ is less than $h(x,y) = f(x,y)$, accept both updates: $(x,y) = (x+v, w)$. Else, accept both updates with some small probability.</p>
</blockquote>

<p>In our paper, we show that our algorithm is guaranteed to converge to a type of local min-max equilibrium in $\mathrm{poly}(\frac{1}{\varepsilon},d, b, L)$ time whenever $f$ is bounded by some $b&gt;0$ and has $L$-Lipschitz gradients. Our algorithm does not require any special starting points, or any additional assumptions on $f$ such as convexity or monotonicity. (See Definition 3.2 and Theorem 3.3 in our paper.)</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_2.gif" style="width: 400px;"/>
<img alt="" src="http://www.offconvex.org/assets/OurAlgorithm_surface_run1.gif" style="width: 400px;"/>
<br/>
<b>Figure 3.</b> GDA (left) and a version of our algorithm (right) on $f(x,y) = xy, \, \, \, \, x,y \in [-5,5]$. While GDA is non-convergent from almost every initial point, our algorithm converges to the set of global min-max points (the red line). To ensure it converges to a (local) equilibrium, our algorithm's generator proposes multiple updates, simulates the discriminator's response, and rejects updates which do not lead to a net decrease in $f$. It only stops if it can't find such an update after many attempts. (To stay inside $[-5,5]\times [-5,5]$ this version of our algorithm uses <i>projected</i> gradients.)
</div>

<p><br/></p>

<h2 id="so-how-does-our-algorithm-perform-in-practice">So, how does our algorithm perform in practice?</h2>

<p>When training a GAN on the mixture of four Gaussians dataset, we found that our algorithm avoids the cycling behavior observed in GDA. We ran each algorithm multiple times, and evaluated the results visually. By the 1500’th iteration GDA learned only one mode in 100% of the runs, and tended to cycle between two or more modes. In contrast, our algorithm was able to learn all four modes 68% of the runs, and three modes 26% of the runs.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/Both_algorithms_Gaussian.gif"/>
<br/>
<b>Figure 4.</b> GAN trained using GDA and our algorithm on a four Gaussian mixture dataset. While GDA cycles between the Gaussian modes (red dots), our algorithm learns all four modes.
</div>
<p><br/></p>

<p>When training on the 0-1 MNIST dataset, we found that GDA tends to briefly generate shapes that look like a combination of $0$’s and $1$’s, then switches to generating only $1$’s, and then re-learns how to generate $0$’s. In contrast, our algorithm seems to learn how to generate both $0$’s and $1$’s early on and does not stop generating either digit. We repeated this simulation multiple times for both algorithms, and visually inspected the images at the 1000’th iteration. GANs trained using our algorithm generated both digits by the 1000’th iteration in 86% of the runs, while those trained using GDA only did so in 23% of the runs.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/MNIST_bothAlgorithms.gif"/>
<br/>
<b>Figure 5.</b> We trained a GAN with GDA and our algorithm on the
0-1 MNIST dataset.  During the first 1000 iterations, GDA (left)
forgets how to generate $0$'s, while our algorithm (right) learns how to
generate both $0$'s and $1$'s early on and does not stop generating either digit.
</div>

<p><br/></p>

<p>While here we have focused on comparing our algorithm to GDA, in our paper we also include a comparison to <a href="https://arxiv.org/abs/1611.02163">Unrolled GANs</a>, which exhibits cycling between modes. We also present results for CIFAR-10 (see Figures 3 and 7 in our paper), where we compute FID scores to track the progress of our algorithm. See our paper for more details; the code is available on <a href="https://github.com/mangoubi/Min-max-optimization-algorithm-for-training-GANs">GitHub</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post we have shown how to develop a practical and convergent first-order algorithm for training GANs. Our algorithm synthesizes an approximation to the global max function based on first-order algorithms, random search using batch gradients, and simulated annealing. Our simulations show that a version of this algorithm can lead to more stable training of GANs. And yet the amount of memory and time required by each iteration of our algorithm is competitive with GDA. This post, together with the <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a>, show that different local approximations to the global max function $\max_z f(x,z)$ can lead to different types of convergent algorithms for min-max optimization. We believe that this idea should be useful in other applications of min-max optimization.</p></div>
    </summary>
    <updated>2020-07-06T09:00:00Z</updated>
    <published>2020-07-06T09:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-07-08T01:41:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-05-the-first-blockchain-or-how-to-time-stamp-a-digital-document/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-05-the-first-blockchain-or-how-to-time-stamp-a-digital-document/" rel="alternate" type="text/html"/>
    <title>The First Blockchain or How to Time-Stamp a Digital Document</title>
    <summary>This post is about the work of Stuart Haber and W. Scott Stornetta from 1991 on How to Time-Stamp a Digital Document and their followup paper Improving the Efficiency and Reliability of Digital Time-Stamping. In many ways, this work introduced the idea of a chain of hashes to create a...</summary>
    <updated>2020-07-06T02:58:00Z</updated>
    <published>2020-07-06T02:58:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-08T02:55:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3270621784797289581</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3270621784797289581/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/a-table-for-matrix-mortality-what-i.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3270621784797289581" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3270621784797289581" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/a-table-for-matrix-mortality-what-i.html" rel="alternate" type="text/html"/>
    <title>A table for Matrix Mortality- what I wanted for Hilbert's 10th problem</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In <a href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html">this post</a> I speculated on why I could not find anywhere a table of which cases of Hilbert's 10th problem were solvable, unsolvable, and unknown. (I then made such a table. It was very clunky,  which may answer the question.)<br/>
<br/>
I told my formal lang theory class about Hilbert's 10th problem as a natural example of an undecidable question- that is, an example that had nothing to do with Turing Machines. On the final I asked<br/>
<br/>
<i>Give an example of an undecidable problem that has nothing to do with Turing Machines.</i><br/>
<br/>
Because of the pandemic this was a 2-day take home final which was open-book, open-notes, open-web. So they could have looked at my slides.<br/>
<br/>
And indeed, most of them did give Hilbert's 10 problem (more formally, the set of all polynomials in many vars over Z which have a Diophantine solution).<br/>
<br/>
But some did not. Some said there could never be such a problem (this is an incorrect answer), Some were incoherent. One just wrote ``Kruskal Trees''  (not sure if he was referring to MSTs or WQOs or to something that Clyde Kruskal did in class one day).<br/>
<br/>
One student said that the problem of, given a CFG G, is the complement of L(G) also CFG.<br/>
This is indeed undecidable and does not have to do with TMs. I doubt the student could have proven that. I doubt I could have proven that. I do not doubt that my advisor Harry Lewis could have proven that, and indeed I emailed him asking for a proof and he emailed me a sketch, which I wrote out in more detail <a href="https://www.cs.umd.edu/users/gasarch/COURSES/452/S20/notes/undcfg.pdf">here</a>.<br/>
<br/>
The most interesting answer was given by some students who apparently looked at the web (rather than at my slides) for lists of problems and found the following called Matrix Mortality:<br/>
<br/>
{ (M_1,...,M_L) : such that some product of these matrices (you are allowed to use a matrix many times) is the 0 matrix}<br/>
<br/>
Why was this the most interesting? The TA did not know this problem was undecidable until he saw it on the exams and looked it up. I did not know it was undecidable until my TA told me.<br/>
<br/>
I then raised the question: How many matrices to you need and how big do their dimensions have to be?<br/>
<br/>
Unlike H10, there IS a table of this. In <a href="https://arxiv.org/abs/1404.0644">this paper</a> they have such a table. I state some results:<br/>
<br/>
Undecidable:<br/>
6 matrices, 3x3<br/>
4 matrices, 5x5<br/>
3 matrices 9x9<br/>
2 matrices 15x15<br/>
<br/>
Decidable<br/>
2 matrices 2x2<br/>
<br/>
So there are some gaps to fill, but there is not the vast gulf that exists between dec and undec for Hilberts 10th problem. I also note that the paper was about UNDEC but mentioned the DEC results, where as the papers on H10 about UNDEC seem to never mention the DEC.<br/>
<br/>
I am glad to know another natural Undec problem and I will likely tell my students about it next spring. And much like H10, I won't be proving it.<br/>
<br/>
An open problem in education: how come some of my students got it wrong? gave an answer that was not in my notes or slides? One student told me it was easier to google<br/>
<br/>
<i>Natural Undecidable Questions</i><br/>
<br/>
then look through my slides. Another one said:<br/>
<br/>
<i>In class you said `this is a natural undecidable problem'.</i><br/>
<i><br/></i>
<i>On the exam you said `a problem that does not mention Turing Machines'</i><br/>
<i><br/></i>
<i>I did not know they were the same. </i><br/>
<br/>
That student submitted the Matrix problem stated above. It IS a fair point that `natural' is an<br/>
undefined term.  But the problem on the final used the well defined concept `does not mention Turing Machines'<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-07-06T02:19:00Z</updated>
    <published>2020-07-06T02:19:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-07T06:18:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor</id>
    <link href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html" rel="alternate" type="text/html"/>
    <title>The shape of the Wankel rotor</title>
    <summary>I’ve written a number of posts about curvilinear triangles that are not the Reuleaux triangle, including MIT’s Kresge Auditorium, triforce string art, valve covers, a patio table, and the logo of Whale Cove, Nunavut. I’ve long intended to write about another obvious topic in this theme, the curved-triangle rotor of the Wankel engine, but was finally pushed into doing so by seeing that two recent popular mathematics books, How Round Is Your Circle? (2008) and Icons of Mathematics (2011) repeat the falsehood that Wankel rotors are Reuleaux triangles. They are not.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve written a number of posts about curvilinear triangles that are not the <a href="https://en.wikipedia.org/wiki/Reuleaux_triangle">Reuleaux triangle</a>, including <a href="https://11011110.github.io/blog/2016/04/30/shape-of-kresge.html">MIT’s Kresge Auditorium</a>, <a href="https://web.archive.org/web/20190217225035/https://plus.google.com/100003628603413742554/posts/DpF5krEaU9u">triforce string art</a>, <a href="https://11011110.github.io/blog/2018/04/17/mythical-reuleaux-manhole.html">valve covers</a>, <a href="https://11011110.github.io/blog/2018/06/24/la-maddalena-non-reuleaux.html">a patio table</a>, and <a href="https://11011110.github.io/blog/2020/06/30/linkage.html">the logo of Whale Cove, Nunavut</a>. I’ve long intended to write about another obvious topic in this theme, the curved-triangle rotor of the <a href="https://en.wikipedia.org/wiki/Wankel_engine">Wankel engine</a>, but was finally pushed into doing so by seeing that two recent popular mathematics books, <em><a href="https://en.wikipedia.org/wiki/How_Round_Is_Your_Circle">How Round Is Your Circle?</a></em> (2008) and <em><a href="https://en.wikipedia.org/wiki/Icons_of_Mathematics">Icons of Mathematics</a></em> (2011) repeat the falsehood that Wankel rotors are Reuleaux triangles. They are not.</p>

<p>Wikipedia has <a href="https://commons.wikimedia.org/wiki/File:Wankel_Cycle_anim_en.gif">a good visualization of how Wankel engines work</a>, which I’ve copied below. They go through the same four steps as a conventional <a href="https://en.wikipedia.org/wiki/Four-stroke_engine">four-stroke combustion engine</a>, in which a piston pulls away from the combustion chamber, sucking in a mixture of fuel and air, pushes back towards the chamber, compressing the mixture, ignites the mixture, pushing the piston back out and applying force to the drive shaft, and then pushes back towards the chamber, pushing the exhaust out. The difference is that in a Wankel engine, these four steps happen at four different locations within the combustion chamber, as the gases within it are pushed around by a curved triangular piston, the rotor of the engine.</p>

<p style="text-align: center;"><img alt="Animation of a Wankel engine by Y tambe from https://commons.wikimedia.org/wiki/File:Wankel_Cycle_anim_en.gif" src="https://11011110.github.io/blog/assets/2020/animated-wankel.gif"/></p>

<p>The driveshaft in the engine is the fixed smaller gear in the center of the animation; in the actual engine, this gearwheel would itself be spinning, but this is not shown. The triangular rotor connects to the driveshaft by an eccentric planetary gear, and spins around the driveshaft like a hula hoop around a spinning dancer. The gears have teeth and radii in the ratio 3:2, causing the driveshaft to spin three times faster than the rotor. As it does so, the three corners of the rotor (the “apex seals”) stay in contact with the outer wall of the engine, called its stator, so that the gases in the engine do not leak between different phases.</p>

<p>The shape of the stator is not determined by the curve of the rotor itself, but only by the trajectory of the moving apex seals. This trajectory is a curve called an <a href="https://en.wikipedia.org/wiki/Epitrochoid">epitrochoid</a>. If you’ve ever played with a spirograph, you know what an epitroichoid is: it’s what you get by fixing one circular disk, letting another circular disk rotate around it, placing a point somewhere within the rotating disk, and tracing the curve that it follows. Here’s <a href="https://commons.wikimedia.org/wiki/File:EpitrochoidIn3.gif">another Wikipedia animation</a>:</p>

<p style="text-align: center;"><img alt="Animation of an epitrochoid by Sam Derbyshire from https://commons.wikimedia.org/wiki/File:EpitrochoidIn3.gif" src="https://11011110.github.io/blog/assets/2020/animated-epitrochoid.gif"/></p>

<p>Different ratios of radii between the inner and outer disk give you different numbers of lobes in the curve, and different placements of the moving point in the outer disk (closer to or farther from the disk center) give you curves that are closer to a circle or more curvy. Placing the moving point on the outer circle itself gives you pointy rather than curvy epitrochoids, and placing it even farther out turns the inner bulges of these curves into self-crossing loops.</p>

<p>Spirograph trajectories differ from rotating apex seal trajectories in at least three ways: in the Wankel engine, the central circle (the driveshaft) rotates rather than being held stationary, the outer circle (the planetary gear) surrounds the central circle rather than being outside it, and the point whose motion is being traced (the apex seal) is outside the outer circle rather than inside it. Nevertheless, the shape is still a two-lobed epitrochoid; see the “double generation theorem” of the Bernoullis, as described by Nash,<sup id="fnref:nash"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:nash">1</a></sup> for why the same curve can be generated in multiple ways. Modulo the scale of the whole system, there is one free parameter controlling the precise shape of this epitrochoid: the ratio of the distances from the center of the rotor to the apex seals and to the planetary gear. If the apex seals are too close in, the planetary gear will bash into into the stator; if they are too far out, the stator will be close to circular and there will be little change in pressure from one part of the combustion cycle to another, losing engine efficiency. The choice made in actual engines is not the one that places the apex seals as close as possible, but seems to involve more careful optimization that considers the shape and size of the regions formed by the rotor and stator at different stages of the combustion cycle.</p>

<p>Once the stator shape has been determined, one can then proceed to answer the question we started with: what is the shape of the rotor? The main design constraint is that it should touch or at least stay close to the inner bulge of the stator (on its “side seals”), to prevent exhaust gas from flowing back around to the intake. The shape that achieves this can be understood by a thought experiment in which we imagine the rotor as somehow being fixed in space while the vehicle containing it rotates around it, rather than vice versa. As the vehicle rotates, its stator passes through parts of the space that cannot be occupied by the rotor. The parts of space that remain untouched by the rotating stator are available to be used by the rotor, and should be used by it if we want a rotor that stays in contact with the stator on its side seals. Mathematically, this is described as an “envelope” of the positions of the rotating stator with respect to the fixed rotor. This envelope is a curved triangle, but not a Reuleaux triangle. Its curves are flatter than a Reuleaux triangle’s arcs, but also they are not circular arcs. As an envelope of algebraic curves, they are presumably algebraic themselves, but of higher order; trigonometric formulas are given by Shung and Pennock.<sup id="fnref:sp"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:sp">2</a></sup></p>

<p>In practice, the rotor shape varies from its ideal envelope-of-epitrochoid form, in a couple of different ways. First, as Drogosz explains,<sup id="fnref:drogosz"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:drogosz">3</a></sup> for ease of manufacturing it is often approximated by circular arcs rather than exactly following the envelope shape. As long as the approximation stays within the envelope, the rotor will avoid colliding with the stator, and the side seal contact is not so important near the corners of the triangle, so that’s where the approximation is most noticeable. Second, real Wankel rotors often have scoops taken out from the middles of their sides, to form mini-combustion chambers that guide and shape the combustion gases within the engine.</p>

<p>For more details of all this, see:</p>

<div class="footnotes">
  <ol>
    <li id="fn:nash">
      <p>Nash, David H. (1977), “Rotary engine geometry”, <em>Mathematics Magazine</em> 2: 87–89, <a href="https://doi.org/doi:10.1080/0025570X.1977.11976621">doi:10.1080/0025570X.1977.11976621</a>, <a href="https://www.jstor.org/stable/2689731">JSTOR:2689731</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:nash">↩</a></p>
    </li>
    <li id="fn:sp">
      <p>Shung, J. B. &amp; Pennock, G. R. (1994), “Geometry for trochoidal-type machines with conjugate envelopes”, <em>Mechanism and Machine Theory</em> 29 (1): 25–42, <a href="https://doi.org/10.1016/0094-114X(94)90017-5">doi:10.1016/0094-114X(94)90017-5</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:sp">↩</a></p>
    </li>
    <li id="fn:drogosz">
      <p>Drogosz, P. (2010), “Geometry of the Wankel rotary engine”, <em>Journal of KONES</em> 17 (3): 69–74, <a href="http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-article-BUJ5-0031-0018">http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-article-BUJ5-0031-0018</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:drogosz">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/104464015428969365">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-07-05T14:59:00Z</updated>
    <published>2020-07-05T14:59:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-06T00:35:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/098" rel="alternate" type="text/html"/>
    <title>TR20-098 |  Impossibility of Derandomizing the Isolation Lemma for all Families | 

	Rohit Gurjar, 

	Thomas Thierauf, 

	Manindra Agrawal</title>
    <summary>The Isolation Lemma states that when random weights are assigned to the elements of a finite set $E$, then in any given family of subsets of $E$, exactly one set has the minimum weight, with high probability. In this note, we present two proofs for the fact that it is impossible to efficiently derandomize the Isolation Lemma for arbitrary families.

The first proof is from Chari, Rohatgi and Srinivasan and uses the potential method. An alternate proof is due to the first author of this note. It uses the polynomial method. However, it is not written anywhere. The main purpose of this note is to present that proof. Additionally we show that the above lower bounds are almost tight with respect to various parameters.</summary>
    <updated>2020-07-05T06:22:25Z</updated>
    <published>2020-07-05T06:22:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-08T07:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17257</id>
    <link href="https://rjlipton.wordpress.com/2020/07/04/intellectual-fireworks/" rel="alternate" type="text/html"/>
    <title>Intellectual Fireworks?</title>
    <summary>Some different ideas for marking the Fourth “Founding Frenemies” source John Adams and Thomas Jefferson did not use Zoom. Their correspondence, from 1777 up to their deaths hours apart on July 4, 1826, fills a 600-page book. Today, Independence Day in the US, we consider the kind of intellectual fireworks represented by the correspondence. Jefferson […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some different ideas for marking the Fourth</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/07/list-coincidence-adams-jefferson-2.jpg"><img alt="" class="alignright wp-image-17259" height="90" src="https://rjlipton.files.wordpress.com/2020/07/list-coincidence-adams-jefferson-2.jpg?w=180&amp;h=90" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">“Founding Frenemies” <a href="https://www.history.com/news/jefferson-adams-founding-frenemies">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Adams and Thomas Jefferson did not use Zoom. Their correspondence, from 1777 up to their deaths hours apart on July 4, 1826, fills a 600-page <a href="https://www.amazon.com/Adams-Jefferson-Letters-Complete-Correspondence-Jefferson/dp/0807842303">book</a>. </p>
<p>
Today, Independence Day in the US, we consider the kind of intellectual fireworks represented by the correspondence.</p>
<p>
Jefferson and Adams were intellectual opposites as well as political rivals. Adams favored a strong central government to bridle human passions, whereas Jefferson’s support for the French Revolution continued beyond its devolution into the Reign of Terror. They debated many other points of politics, philosophy, and culture. </p>
<p>
Abigail Adams, the wife of John, joined in some of the exchanges. Because she often stayed in Massachusetts while he was in Philadelphia or New York or elsewhere, the husband and wife exchanged many letters—over 1,100 in all. His letter to her on July 3, 1776, instituted the use of fireworks to celebrate anniversaries of the Declaration of Independence.</p>
<p>
Today there is not much in the way of fireworks displays. Most have been canceled because we cannot allow crowds to view them. In the Buffalo area, some townships are having small displays with limited access, and some displays are being set on high points for possible area viewing. So we felt we should write about fireworks of a different kind, a kind that is not restricted by the pandemic and might thrive through it. But first we’ll make a point about the history of fireworks.</p>
<p>
</p><p/><h2> Fireworks: Ancient, Early, and Modern </h2><p/>
<p/><p>
Fireworks go back at least 1,100 years to China, where chemists discovered the fun of stuffing volatile compounds into tubes of bamboo or paper and setting them off. Some have pyrotechnics going back another 1,000 years, to about 200 BCE, insofar as bamboo was known to pop with a loud sound when dried and heated. Gunpowder traveled best of the compounds and made its way into Europe at least by the 1200s. The first recorded wide-scale fireworks display in England was in 1486 for the wedding of King Henry VII to Elizabeth of York, which ended the Wars of the Roses. Shakespeare mentions fireworks in <em>Love’s Labours Lost</em>. The Mughals in India from the 1500s to the 1800s made fireworks a diversion for noble women on the Diwali holiday:</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/07/diwali_570_850.jpg"><img alt="" class="aligncenter size-medium wp-image-17260" height="254" src="https://rjlipton.files.wordpress.com/2020/07/diwali_570_850.jpg?w=300&amp;h=254" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cleveland Museum of Art <a href="https://www.clevelandart.org/art/1971.82">source</a></font>
</td>
</tr>
</tbody></table>
<p>
Our point is that 1776 isn’t even halfway back to the beginning of using fireworks for celebrations, even just in the West. Can we even call it “Early”? Lavish displays to mark major events were common by the mid-1700s. A royal display in 1749 was accompanied by orchestral music commissioned from George Frideric Handel and went ahead despite rain. Over 12,000 people also paid to attend the main rehearsal six days earlier, many braving an hours-long traffic jam on approaches to the London Bridge. That feels quite modern to us. Adams’s <a href="https://founders.archives.gov/documents/Adams/04-02-02-0016">letter</a> mentioned other social features we know today:</p>
<blockquote><p><b> </b> <em> It ought to be solemnized with Pomp and Parade, with Shews, Games, Sports, Guns, Bells, Bonfires and Illuminations from one End of this Continent to the other from this Time forward forever more. </em>
</p></blockquote>
<p/><p>
The pandemic has curtailed others of these. The major North American team sports have not resumed either. Some parades have been run in “reverse” mode: the floats and performers stay put while spectators drive by slowly in cars.</p>
<p>
Adams’s letter has another, earlier, passage that chills today. The letter begins by saying that the Declaration was supposed to have been made in December, 1775, and enumerates plans the colonies had made contingent on this. He then says that what caused the plans to be aborted was an outbreak of disease:</p>
<blockquote><p><b> </b> <em> All these Causes however in Conjunction would not have disappointed Us, if it had not been for a Misfortune, which could not be foreseen, and perhaps could not have been prevented, I mean the Prevalence of the small Pox among our Troops. . . . This fatal Pestilence compleated our Destruction.—It is a Frown of Providence upon Us, which We ought to lay to heart. </em>
</p></blockquote>
<p/><p>
The ellipsis is in the letter—as Ken’s children have pointed out, trailing off thought with dots in letters or e-mails or Facebook posts or texts is a distinctive habit of us older folk. Thus a specific outbreak of a contagious disease changed our history then as now.</p>
<p>
</p><p/><h2> Ideas: Ancient, Early, and Modern </h2><p/>
<p/><p>
We have <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news/">remarked</a> on how the pandemic has affected opportunities to exchange ideas and how to compensate. One impacted series that both of us intended to visit this spring has been the series of workshops at the Simons Institute in Berkeley. </p>
<p>
Still, the Simons Foundation has continued its other ways to stimulate ideas. Here we offer our congratulations to Venkatesan Guruswami, Omer Reingold, and David Woodruff, who have just been <a href="https://www.simonsfoundation.org/grant/simons-investigators/?tab=awardees&amp;filter_years=2020">appointed</a> as Simons investigators for 2020. </p>
<p>
In briefly talking about their work, we want to make a point about how the pandemic enables <em>taking the long view</em> of ideas—in a way that appointments such as these promote. It is easy to get wrapped up in immediate aspects of a current hot problem and not be aware that it has a history. The history may not involve exactly the same ideas as the problem, but related ideas whose importance was appreciated much earlier. “Early” may not mean the Middle Ages or the 1700s as with fireworks, but it can mean times before any of us were born.</p>
<p>
Venkatesan and Omer and David each have done some stellar research, broadly in various parts of theory. They each have many results, but we thought we would highlight just one result each. We picked a result that we think is representative, is deep, is beautiful, and is one that we personally admire the most.</p>
<p>
</p><p/><h3> “Ancient” Times </h3><p/>
<p/><p>
Venkatesan did important work on a problem that was created before complexity theory existed. Our favorite is his ground-breaking work on list decoding.</p>
<p>
What is the best way to encode data to protect it against various kinds of errors? This is still open. But Venkatesan changed the landscape. </p>
<p>
The questions about error correcting codes go back to the 1940’s. Usually the first results are <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">credited</a> to Richard Hamming in 1947. Soon the notion of list decoding was introduced. The cool idea is that doing not require an answer, but allow a list of possible answers. The hope is that with other information about the message we might be able to select <i>the</i> answer.</p>
<p>
Venkatesan and Ken’s colleague Atri Rudra found explicit <a href="https://en.wikipedia.org/wiki/List_decoding">codes</a> that achieve list-decoding capacity, that is, they have optimal redundancy. </p>
<p>
What we like so much is the model is so natural and so powerful. There are many applications of list decoding to complexity theory. See Madhu Sudan’s <a href="http://people.csail.mit.edu/madhu/papers/noneed/ifip-journ.ps">survey</a> for some additional comments. </p>
<p>
</p><p/><h3> Early Times </h3><p/>
<p/><p>
Omer did his most important work on problems that were first studied in the early days of complexity theory. Our favorite is his beautiful work on small-memory deterministic graph <a href="https://en.wikipedia.org/wiki/SL_(complexity)">walks</a>. </p>
<p>
Is <img alt="{\mathsf{L &lt; NL}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BL+%3C+NL%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{L &lt; NL}}"/>? This is still <a href="https://en.wikipedia.org/wiki/NL_(complexity)">open</a>. But Omer made a huge contribution to our understanding of fundamental complexity classes. Romas Aleliunas, Dick Karp, Laszlo Lovasz, and Charlie Rackoff proved earlier that random small space could navigate undirected graphs provided they could flip coins. In a sense Omer removed the coins to get his result that undirected graph connectivity is in <img alt="{\mathsf{L}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BL%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{L}}"/>. The previous result was easy—I can say that because I (Dick) was a co-author on it—but Omer’s theorem is deep.</p>
<p>
Omer’s <a href="https://omereingold.files.wordpress.com/2014/10/sl.pdf">proof</a> drew heavily on expander graphs and the zig-zag product from his earlier work with Salil Vadhan and Avi Wigderson for creating them. </p>
<p>
</p><p/><h3> Modern Times </h3><p/>
<p/><p>
David did his most important work on problems that were only created relatively recently. Our favorite is his work on approximately <a href="http://www.cs.cmu.edu/afs/cs/user/dwoodruf/www/knw10b.pdf">counting</a> distinct elements. This work is joint with Daniel Kane and Jelani Nelson and appeared at PODS 2010. It was the first streaming algorithm with an optimal combination of space usage and update time. Here is the relevant table from their paper (KNW):</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/07/algtable.jpg"><img alt="" class="aligncenter wp-image-17261" height="163" src="https://rjlipton.files.wordpress.com/2020/07/algtable.jpg?w=500&amp;h=163" width="500"/></a></p>
<p>
Streaming algorithms are relatively new and parts of data science are newer. But working with data is old, as old as codes. This finally leads us to pose an outlandish question:</p>
<blockquote><p><b> </b> <em> Can all of this work be usefully interpreted from the standpoint of coding theory? </em>
</p></blockquote>
<p/><p>
This is outlandish, because the word “code” does not even appear in either Reingold’s paper or KNW. But part of holding coding theory to be a paradigm, as both Ken and I experienced in graduate school, is that its perspective should expand. Is this capable of creating intellectual fireworks? We’ll see.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Have a safe and happy fourth of July.</p>
<p>
[some small fixes]</p></font></font></div>
    </content>
    <updated>2020-07-05T00:41:25Z</updated>
    <published>2020-07-05T00:41:25Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="coding theory"/>
    <category term="David Woodruff"/>
    <category term="fireworks"/>
    <category term="Fourth of July"/>
    <category term="John Adams"/>
    <category term="Omer Reingold"/>
    <category term="pandemic"/>
    <category term="Simons Foundation"/>
    <category term="Thomas Jefferson"/>
    <category term="Venkatesan Guruswami"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-08T07:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/03/postdoc-in-quantum-computing-at-nagoya-and-mie-universities-apply-by-july-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/03/postdoc-in-quantum-computing-at-nagoya-and-mie-universities-apply-by-july-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in quantum computing at Nagoya and Mie Universities (apply by July 15, 2020)</title>
    <summary>Nagoya and Mie Universities (Japan) are looking for several postdoctoral researchers to work on quantum computing, especially on the following subjects: 1) quantum algorithms, 2) quantum complexity theory, 3) theoretical aspects of quantum programming languages, 4) development of software verification tools for quantum programs, 5) quantum information theory. Website: http://francoislegall.com/jobs.html Email: legall@math.nagoya-u.ac.jp</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Nagoya and Mie Universities (Japan) are looking for several postdoctoral researchers to work on quantum computing, especially on the following subjects:</p>
<p>1) quantum algorithms,<br/>
2) quantum complexity theory,<br/>
3) theoretical aspects of quantum programming languages,<br/>
4) development of software verification tools for quantum programs,<br/>
5) quantum information theory.</p>
<p>Website: <a href="http://francoislegall.com/jobs.html">http://francoislegall.com/jobs.html</a><br/>
Email: legall@math.nagoya-u.ac.jp</p></div>
    </content>
    <updated>2020-07-03T11:18:55Z</updated>
    <published>2020-07-03T11:18:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-08T07:20:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4888</id>
    <link href="https://www.scottaaronson.com/blog/?p=4888" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4888#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4888" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott’s Zoom tip: Email the link!</title>
    <summary xml:lang="en-US">Like many academics, I’ve now been regularly “attending” conferences and giving talks via Zoom for four months. Naturally, I’ve learned a lot about how to use this platform—one that, despite numerous quirks and flaws, actually works well enough that it could probably replace at least 2/3 of in-person talks and meetings after the covid crisis […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Like many academics, I’ve now been regularly “attending” conferences and giving talks via Zoom for four months.  Naturally, I’ve learned a lot about how to use this platform—one that, despite numerous quirks and flaws, <em>actually works</em> well enough that it could probably replace at least 2/3 of in-person talks and meetings after the covid crisis is over.  But one particular lesson is so important that I thought I’d make a public service announcement of it.  So without further ado:</p>



<p><strong>Email the link.</strong></p>



<p>You know, the thing like</p>



<p>https://us02web.zoom.us/jblahblah</p>



<p>that you actually click to get to the actual conversation.  <em>Definitely</em> email the link to the speaker (!).  But also email it to whomever said they plan to attend.  Resend the link between a day and an hour in advance, so that it doesn’t get buried, but turns up right away when people search their inboxes.  If possible, put the link in <em>every single email</em> about the meeting or lecture.  Even if you already sent the link for previous iterations of the meeting and it hasn’t changed, send it again.  Don’t assume people will find the link on the web.  Don’t make them click through five other links or open an attached PDF for it.  Don’t send ten emails that explain every possible detail of the meeting except how to get to it.  Just <strong>email the link.</strong>  That’s all.  Thanks!</p></div>
    </content>
    <updated>2020-07-03T06:43:42Z</updated>
    <published>2020-07-03T06:43:42Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-07T18:40:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7759</id>
    <link href="https://windowsontheory.org/2020/07/02/crowdsourcing-masters-program/" rel="alternate" type="text/html"/>
    <title>Crowdsourcing Masters program</title>
    <summary>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone. As I wrote before, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone.</p>



<p>As <a href="https://windowsontheory.org/2018/02/20/research-masters/">I wrote before</a>, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can be a great option. This is particularly the case if the program is funded (i.e., students get a stipend and don’t need to pay tuition). Such programs are not common in the U.S., but there are some excellent choices around the world.</p>



<p>Since (as far as I know) there is no single source listing such programs, I thought a crowdsourced Google spreadsheet might be useful and so created one here: <a href="http://tiny.cc/tcsmasters" rel="nofollow">http://tiny.cc/tcsmasters</a></p>



<p>If you know of more places, please fill out this form: <a href="https://forms.gle/qfnbEZYYYDtFCDpx9" rel="nofollow">https://forms.gle/qfnbEZYYYDtFCDpx9</a> </p></div>
    </content>
    <updated>2020-07-02T19:26:22Z</updated>
    <published>2020-07-02T19:26:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-08T07:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at University of Oxford (apply by September 11, 2020)</title>
    <summary>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science. Website: https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars Email: pdrf.admin@all-souls.ox.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science.</p>
<p>Website: <a href="https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars">https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars</a><br/>
Email: pdrf.admin@all-souls.ox.ac.uk</p></div>
    </content>
    <updated>2020-06-30T16:27:02Z</updated>
    <published>2020-06-30T16:27:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-08T07:20:53Z</updated>
    </source>
  </entry>
</feed>
